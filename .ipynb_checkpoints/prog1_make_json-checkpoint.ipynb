{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{\"words\": [\"CHICAGO\", \"AT\", \"ATLANTA\"], \"ner\": [\"B-ORG\", \"O\", \"B-LOC\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1704f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a61a1431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('data/original/train.json','r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7119be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse = []\n",
    "for d in data:\n",
    "    new_d = {}\n",
    "    new_d[\"words\"] = d[]\"tokens\"]\n",
    "    new_d[\"ner\"] = d[\"coarse_tags\"]\n",
    "    coarse.append(new_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse = [key_change(d,\"tokens\",\"words\", for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8baa74ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tokens': ['Paul', 'International', 'airport', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0],\n",
       "  'id': '0'},\n",
       " {'tokens': ['It',\n",
       "   'starred',\n",
       "   'Hicks',\n",
       "   \"'s\",\n",
       "   'wife',\n",
       "   ',',\n",
       "   'Ellaline',\n",
       "   'Terriss',\n",
       "   'and',\n",
       "   'Edmund',\n",
       "   'Payne',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 7, 0, 0, 0, 7, 7, 0, 7, 7, 0],\n",
       "  'fine_tags': [0, 0, 51, 0, 0, 0, 50, 50, 0, 50, 50, 0],\n",
       "  'id': '1'},\n",
       " {'tokens': ['``',\n",
       "   'Time',\n",
       "   '``',\n",
       "   'magazine',\n",
       "   'said',\n",
       "   'the',\n",
       "   'film',\n",
       "   'was',\n",
       "   '``',\n",
       "   'a',\n",
       "   'multimillion',\n",
       "   'dollar',\n",
       "   'improvisation',\n",
       "   'that',\n",
       "   'does',\n",
       "   'everything',\n",
       "   'but',\n",
       "   'what',\n",
       "   'the',\n",
       "   'title',\n",
       "   'promises',\n",
       "   \"''\",\n",
       "   'and',\n",
       "   'suggested',\n",
       "   'that',\n",
       "   '``',\n",
       "   'writer',\n",
       "   'George',\n",
       "   'Axelrod',\n",
       "   '(',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Seven',\n",
       "   'Year',\n",
       "   'Itch',\n",
       "   '``',\n",
       "   ')',\n",
       "   'and',\n",
       "   'director',\n",
       "   'Richard',\n",
       "   'Quine',\n",
       "   'should',\n",
       "   'have',\n",
       "   'taken',\n",
       "   'a',\n",
       "   'hint',\n",
       "   'from',\n",
       "   'Holden',\n",
       "   '[',\n",
       "   \"'s\",\n",
       "   'character',\n",
       "   'Richard',\n",
       "   'Benson',\n",
       "   ']',\n",
       "   ',',\n",
       "   'who',\n",
       "   'writes',\n",
       "   'his',\n",
       "   'movie',\n",
       "   ',',\n",
       "   'takes',\n",
       "   'a',\n",
       "   'long',\n",
       "   'sober',\n",
       "   'look',\n",
       "   'at',\n",
       "   'what',\n",
       "   'he',\n",
       "   'has',\n",
       "   'wrought',\n",
       "   ',',\n",
       "   'and',\n",
       "   'burns',\n",
       "   'it',\n",
       "   '.',\n",
       "   \"''\"],\n",
       "  'coarse_tags': [0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   53,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '2'},\n",
       " {'tokens': ['Pakistani',\n",
       "   'scientists',\n",
       "   'and',\n",
       "   'engineers',\n",
       "   \"'\",\n",
       "   'working',\n",
       "   'at',\n",
       "   'IAEA',\n",
       "   'became',\n",
       "   'aware',\n",
       "   'of',\n",
       "   'advancing',\n",
       "   'Indian',\n",
       "   'nuclear',\n",
       "   'program',\n",
       "   'towards',\n",
       "   'making',\n",
       "   'the',\n",
       "   'bombs',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '3'},\n",
       " {'tokens': ['In',\n",
       "   'February',\n",
       "   '2008',\n",
       "   ',',\n",
       "   'Church',\n",
       "   \"'s\",\n",
       "   'Chicken',\n",
       "   'entered',\n",
       "   'the',\n",
       "   'UK',\n",
       "   'market',\n",
       "   'under',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Texas',\n",
       "   'Chicken',\n",
       "   '``',\n",
       "   'name',\n",
       "   ',',\n",
       "   'claiming',\n",
       "   'to',\n",
       "   'have',\n",
       "   'signed',\n",
       "   'up',\n",
       "   '50',\n",
       "   'former',\n",
       "   'Dixy',\n",
       "   'Chicken',\n",
       "   'franchisees',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '4'},\n",
       " {'tokens': ['This',\n",
       "   'rivalry',\n",
       "   'intensified',\n",
       "   'in',\n",
       "   '1919',\n",
       "   'when',\n",
       "   'Arsenal',\n",
       "   'were',\n",
       "   'unexpectedly',\n",
       "   'promoted',\n",
       "   'to',\n",
       "   'the',\n",
       "   'First',\n",
       "   'Division',\n",
       "   ',',\n",
       "   'taking',\n",
       "   'a',\n",
       "   'place',\n",
       "   'that',\n",
       "   'Tottenham',\n",
       "   'believed',\n",
       "   'should',\n",
       "   'be',\n",
       "   'theirs',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   36,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '5'},\n",
       " {'tokens': ['Seizures',\n",
       "   'often',\n",
       "   'begin',\n",
       "   'as',\n",
       "   'apnea',\n",
       "   ',',\n",
       "   'cyanosis',\n",
       "   ',',\n",
       "   'and',\n",
       "   'hypertonia',\n",
       "   'and',\n",
       "   'last',\n",
       "   'less',\n",
       "   'than',\n",
       "   '1',\n",
       "   'minute',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '6'},\n",
       " {'tokens': ['The',\n",
       "   'platform',\n",
       "   'is',\n",
       "   'based',\n",
       "   'on',\n",
       "   'the',\n",
       "   '2003',\n",
       "   'Rolls-Royce',\n",
       "   'Phantom',\n",
       "   'and',\n",
       "   'has',\n",
       "   'styling',\n",
       "   'heavily',\n",
       "   'derived',\n",
       "   'from',\n",
       "   'the',\n",
       "   'Rolls-Royce',\n",
       "   '100EX',\n",
       "   ',',\n",
       "   'a',\n",
       "   'concept',\n",
       "   'car',\n",
       "   'unveiled',\n",
       "   'to',\n",
       "   'celebrate',\n",
       "   'the',\n",
       "   'company',\n",
       "   \"'s\",\n",
       "   'centennial',\n",
       "   'in',\n",
       "   '2004',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '7'},\n",
       " {'tokens': ['Only',\n",
       "   'one',\n",
       "   'of',\n",
       "   'four',\n",
       "   'entered',\n",
       "   'Corvettes',\n",
       "   '-',\n",
       "   'GT1',\n",
       "   'C6R',\n",
       "   'of',\n",
       "   'Luc',\n",
       "   'Alphand',\n",
       "   'Aventures',\n",
       "   '-',\n",
       "   'eventually',\n",
       "   'finished',\n",
       "   'the',\n",
       "   'race',\n",
       "   ',',\n",
       "   'taking',\n",
       "   'second',\n",
       "   'place',\n",
       "   'in',\n",
       "   'class',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '8'},\n",
       " {'tokens': ['He',\n",
       "   'has',\n",
       "   'also',\n",
       "   'written',\n",
       "   'several',\n",
       "   'plays',\n",
       "   'and',\n",
       "   'various',\n",
       "   'articles',\n",
       "   'on',\n",
       "   'the',\n",
       "   'Iranian',\n",
       "   'Constitutional',\n",
       "   'Revolution',\n",
       "   'of',\n",
       "   '1905-1911',\n",
       "   ',',\n",
       "   'the',\n",
       "   'French',\n",
       "   'Revolution',\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Russian',\n",
       "   'Revolution',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   19,\n",
       "   19,\n",
       "   19,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   19,\n",
       "   19,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   19,\n",
       "   19,\n",
       "   0],\n",
       "  'id': '9'},\n",
       " {'tokens': ['After',\n",
       "   'many',\n",
       "   'appeals',\n",
       "   ',',\n",
       "   'the',\n",
       "   'case',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Supreme',\n",
       "   'Court',\n",
       "   ',',\n",
       "   'which',\n",
       "   'in',\n",
       "   '1992',\n",
       "   'ruled',\n",
       "   'in',\n",
       "   '``',\n",
       "   'Two',\n",
       "   'Pesos',\n",
       "   ',',\n",
       "   'Inc',\n",
       "   '.',\n",
       "   'v',\n",
       "   '.',\n",
       "   'Taco',\n",
       "   'Cabana',\n",
       "   ',',\n",
       "   'Inc',\n",
       "   '.',\n",
       "   '``',\n",
       "   'in',\n",
       "   'favor',\n",
       "   'of',\n",
       "   'Taco',\n",
       "   'Cabana',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0],\n",
       "  'id': '10'},\n",
       " {'tokens': ['The',\n",
       "   'army',\n",
       "   'and',\n",
       "   'guards',\n",
       "   'present',\n",
       "   'in',\n",
       "   'the',\n",
       "   'south',\n",
       "   'were',\n",
       "   'also',\n",
       "   'Assyrians',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '11'},\n",
       " {'tokens': ['Imelda',\n",
       "   'de',\n",
       "   \"'\",\n",
       "   'Lambertazzi',\n",
       "   'is',\n",
       "   'a',\n",
       "   '``',\n",
       "   'melodramma',\n",
       "   'tragico',\n",
       "   \"''\",\n",
       "   'or',\n",
       "   'tragic',\n",
       "   'opera',\n",
       "   'in',\n",
       "   'two',\n",
       "   'acts',\n",
       "   'by',\n",
       "   'Gaetano',\n",
       "   'Donizett',\n",
       "   'i',\n",
       "   'from',\n",
       "   'a',\n",
       "   'libretto',\n",
       "   'by',\n",
       "   'Andrea',\n",
       "   'Leone',\n",
       "   'Tottola',\n",
       "   ',',\n",
       "   'based',\n",
       "   'on',\n",
       "   'the',\n",
       "   'tragedy',\n",
       "   '``',\n",
       "   'Imelda',\n",
       "   \"''\",\n",
       "   'by',\n",
       "   'Gabriele',\n",
       "   'Sperduti',\n",
       "   '.'],\n",
       "  'coarse_tags': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0],\n",
       "  'fine_tags': [6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0],\n",
       "  'id': '12'},\n",
       " {'tokens': ['Amphiphysin',\n",
       "   'is',\n",
       "   'a',\n",
       "   'brain-enriched',\n",
       "   'protein',\n",
       "   'with',\n",
       "   'an',\n",
       "   'N-terminal',\n",
       "   'lipid',\n",
       "   'interaction',\n",
       "   ',',\n",
       "   'dimerisation',\n",
       "   'and',\n",
       "   'membrane',\n",
       "   'bending',\n",
       "   'BAR',\n",
       "   'domain',\n",
       "   ',',\n",
       "   'a',\n",
       "   'middle',\n",
       "   'clathrin',\n",
       "   'and',\n",
       "   'adaptor',\n",
       "   'binding',\n",
       "   'domain',\n",
       "   'and',\n",
       "   'a',\n",
       "   'C-terminal',\n",
       "   'SH3',\n",
       "   'domain',\n",
       "   '.'],\n",
       "  'coarse_tags': [6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0],\n",
       "  'fine_tags': [40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   40,\n",
       "   40,\n",
       "   0],\n",
       "  'id': '13'},\n",
       " {'tokens': ['Decorations',\n",
       "   'and',\n",
       "   'awards',\n",
       "   'can',\n",
       "   'be',\n",
       "   'conferred',\n",
       "   'on',\n",
       "   'Croatian',\n",
       "   'or',\n",
       "   'foreign',\n",
       "   'nationals',\n",
       "   ',',\n",
       "   'legal',\n",
       "   'entities',\n",
       "   'as',\n",
       "   'well',\n",
       "   'as',\n",
       "   'units',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Armed',\n",
       "   'Forces',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Republic',\n",
       "   'of',\n",
       "   'Croatia',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Ministry',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Interior',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '14'},\n",
       " {'tokens': ['The',\n",
       "   'pandemic',\n",
       "   'affected',\n",
       "   'the',\n",
       "   'Mediterranean',\n",
       "   'Basin',\n",
       "   'most',\n",
       "   'severely',\n",
       "   'and',\n",
       "   'most',\n",
       "   'frequently',\n",
       "   ',',\n",
       "   'but',\n",
       "   'also',\n",
       "   'infected',\n",
       "   'the',\n",
       "   'Near',\n",
       "   'East',\n",
       "   'and',\n",
       "   'Northern',\n",
       "   'Europe',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '15'},\n",
       " {'tokens': ['The',\n",
       "   'rivalry',\n",
       "   'began',\n",
       "   'to',\n",
       "   'heat',\n",
       "   'up',\n",
       "   'in',\n",
       "   'the',\n",
       "   'early',\n",
       "   '2000s',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '16'},\n",
       " {'tokens': ['In',\n",
       "   '1783',\n",
       "   'Campbell',\n",
       "   'married',\n",
       "   'Olympia',\n",
       "   'Elizabeth',\n",
       "   '(',\n",
       "   'died',\n",
       "   '1794',\n",
       "   ')',\n",
       "   ',',\n",
       "   'eldest',\n",
       "   'daughter',\n",
       "   'of',\n",
       "   'William',\n",
       "   'Morshead',\n",
       "   'of',\n",
       "   'Cartuther',\n",
       "   ',',\n",
       "   'Cornwall',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   25,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '17'},\n",
       " {'tokens': ['Neville',\n",
       "   'performed',\n",
       "   'a',\n",
       "   'Spinning',\n",
       "   'Back',\n",
       "   'Kick',\n",
       "   'on',\n",
       "   'Tozawa',\n",
       "   'to',\n",
       "   'retain',\n",
       "   'the',\n",
       "   'title',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [52, 0, 0, 0, 0, 0, 0, 52, 0, 0, 0, 0, 0],\n",
       "  'id': '18'},\n",
       " {'tokens': ['From',\n",
       "   'her',\n",
       "   'locations',\n",
       "   'Mrs.',\n",
       "   'Strong',\n",
       "   'created',\n",
       "   'papers',\n",
       "   'for',\n",
       "   'the',\n",
       "   'Duke',\n",
       "   'of',\n",
       "   'Windsor',\n",
       "   'and',\n",
       "   'Wallis',\n",
       "   ',',\n",
       "   'The',\n",
       "   'Duchess',\n",
       "   'of',\n",
       "   'Windsor',\n",
       "   ',',\n",
       "   'Barbara',\n",
       "   'Hutton',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Rockefeller',\n",
       "   ',',\n",
       "   'Astor',\n",
       "   ',',\n",
       "   'Vanderbilt',\n",
       "   ',',\n",
       "   'and',\n",
       "   'DuPont',\n",
       "   'families',\n",
       "   ',',\n",
       "   'as',\n",
       "   'well',\n",
       "   'as',\n",
       "   'Bette',\n",
       "   'Davis',\n",
       "   ',',\n",
       "   'Diana',\n",
       "   'Vreeland',\n",
       "   ',',\n",
       "   'Jacqueline',\n",
       "   'Bouvier',\n",
       "   'Kennedy',\n",
       "   ',',\n",
       "   'Barbara',\n",
       "   'Paley',\n",
       "   ',',\n",
       "   'and',\n",
       "   'other',\n",
       "   'icons',\n",
       "   'of',\n",
       "   'style',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '19'},\n",
       " {'tokens': ['As',\n",
       "   'a',\n",
       "   'result',\n",
       "   'of',\n",
       "   'outdoing',\n",
       "   'the',\n",
       "   'competition',\n",
       "   ',',\n",
       "   'Binion',\n",
       "   'received',\n",
       "   'death',\n",
       "   'threats',\n",
       "   ',',\n",
       "   'although',\n",
       "   'eventually',\n",
       "   'casinos',\n",
       "   'raised',\n",
       "   'their',\n",
       "   'limits',\n",
       "   'to',\n",
       "   'keep',\n",
       "   'up',\n",
       "   'with',\n",
       "   'him',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '20'},\n",
       " {'tokens': ['Its',\n",
       "   'title',\n",
       "   'is',\n",
       "   'also',\n",
       "   'seen',\n",
       "   'as',\n",
       "   'The',\n",
       "   'Gale',\n",
       "   'Storm',\n",
       "   'Show',\n",
       "   ':',\n",
       "   'Oh',\n",
       "   ',',\n",
       "   'Susanna',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "  'id': '21'},\n",
       " {'tokens': ['Known',\n",
       "   'locally',\n",
       "   'as',\n",
       "   '``',\n",
       "   'Fairbottom',\n",
       "   'Bobs',\n",
       "   '``',\n",
       "   'it',\n",
       "   'is',\n",
       "   'now',\n",
       "   'preserved',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Henry',\n",
       "   'Ford',\n",
       "   'Museum',\n",
       "   'in',\n",
       "   'Dearborn',\n",
       "   ',',\n",
       "   'Michigan',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '22'},\n",
       " {'tokens': ['The',\n",
       "   'latter',\n",
       "   'group',\n",
       "   'included',\n",
       "   'ZU-23-2M',\n",
       "   'Wróbel',\n",
       "   'universal',\n",
       "   'naval',\n",
       "   'gun',\n",
       "   'and',\n",
       "   'its',\n",
       "   'successor',\n",
       "   ',',\n",
       "   'the',\n",
       "   'artillery-rocket',\n",
       "   'set',\n",
       "   'ZU-23-2MR',\n",
       "   'Wróbel',\n",
       "   'II',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 8, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   66,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   66,\n",
       "   66,\n",
       "   0],\n",
       "  'id': '23'},\n",
       " {'tokens': ['Sheremetyevo',\n",
       "   'International',\n",
       "   'Airport',\n",
       "   'has',\n",
       "   'four',\n",
       "   'operating',\n",
       "   'passenger',\n",
       "   'terminals',\n",
       "   'and',\n",
       "   'one',\n",
       "   'special',\n",
       "   'terminal',\n",
       "   'reserved',\n",
       "   'for',\n",
       "   'the',\n",
       "   'use',\n",
       "   'of',\n",
       "   'private',\n",
       "   'and',\n",
       "   'business',\n",
       "   'aviation',\n",
       "   '.'],\n",
       "  'coarse_tags': [2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '24'},\n",
       " {'tokens': ['The',\n",
       "   'Victoria',\n",
       "   'line',\n",
       "   ',',\n",
       "   'Northern',\n",
       "   'City',\n",
       "   'Line',\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'London',\n",
       "   'Overground',\n",
       "   'North',\n",
       "   'London',\n",
       "   'Line',\n",
       "   'converge',\n",
       "   'at',\n",
       "   'this',\n",
       "   'location',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 4, 4, 0, 4, 4, 4, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '25'},\n",
       " {'tokens': ['Using',\n",
       "   '``',\n",
       "   'bite-and-hold',\n",
       "   \"''\",\n",
       "   'tactics',\n",
       "   ',',\n",
       "   'with',\n",
       "   'objectives',\n",
       "   'limited',\n",
       "   'to',\n",
       "   'what',\n",
       "   'could',\n",
       "   'be',\n",
       "   'held',\n",
       "   'against',\n",
       "   'German',\n",
       "   'counter-attacks',\n",
       "   ',',\n",
       "   'the',\n",
       "   'British',\n",
       "   'devastated',\n",
       "   'the',\n",
       "   'German',\n",
       "   'defence',\n",
       "   ',',\n",
       "   'which',\n",
       "   'prompted',\n",
       "   'a',\n",
       "   'crisis',\n",
       "   'among',\n",
       "   'the',\n",
       "   'German',\n",
       "   'commanders',\n",
       "   'and',\n",
       "   'caused',\n",
       "   'a',\n",
       "   'severe',\n",
       "   'loss',\n",
       "   'of',\n",
       "   'morale',\n",
       "   'in',\n",
       "   'the',\n",
       "   '4th',\n",
       "   'Army',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0],\n",
       "  'id': '26'},\n",
       " {'tokens': ['During',\n",
       "   'medical',\n",
       "   'school',\n",
       "   ',',\n",
       "   'Reitman',\n",
       "   'often',\n",
       "   'worked',\n",
       "   'as',\n",
       "   'the',\n",
       "   'house',\n",
       "   'doctor',\n",
       "   'at',\n",
       "   'sporting',\n",
       "   'events',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Boston',\n",
       "   'Garden',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 13, 0],\n",
       "  'id': '27'},\n",
       " {'tokens': ['Normally',\n",
       "   ',',\n",
       "   'when',\n",
       "   'the',\n",
       "   'new',\n",
       "   'window',\n",
       "   'appears',\n",
       "   ',',\n",
       "   'it',\n",
       "   'displays',\n",
       "   'the',\n",
       "   'same',\n",
       "   'buffer',\n",
       "   'as',\n",
       "   'the',\n",
       "   'previous',\n",
       "   'one',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '28'},\n",
       " {'tokens': ['Formerly',\n",
       "   'known',\n",
       "   'as',\n",
       "   'the',\n",
       "   'Communiplex',\n",
       "   ',',\n",
       "   'it',\n",
       "   'is',\n",
       "   'home',\n",
       "   'to',\n",
       "   'the',\n",
       "   'WHL',\n",
       "   \"'s\",\n",
       "   'Prince',\n",
       "   'Albert',\n",
       "   'Raiders',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Prince',\n",
       "   'Albert',\n",
       "   'Mintos',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0],\n",
       "  'id': '29'},\n",
       " {'tokens': ['The',\n",
       "   'chapel',\n",
       "   'of',\n",
       "   'Stalmine',\n",
       "   'was',\n",
       "   'first',\n",
       "   'mentioned',\n",
       "   'about',\n",
       "   '1200',\n",
       "   'and',\n",
       "   'a',\n",
       "   'cemetery',\n",
       "   'was',\n",
       "   'consecrated',\n",
       "   'in',\n",
       "   '1230',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '30'},\n",
       " {'tokens': ['The',\n",
       "   'score',\n",
       "   'to',\n",
       "   '``',\n",
       "   'Spring',\n",
       "   'Breakdown',\n",
       "   \"''\",\n",
       "   'was',\n",
       "   'composed',\n",
       "   'by',\n",
       "   'Deborah',\n",
       "   'Lurie',\n",
       "   'who',\n",
       "   'recorded',\n",
       "   'her',\n",
       "   'score',\n",
       "   'with',\n",
       "   'the',\n",
       "   'Hollywood',\n",
       "   'Studio',\n",
       "   'Symphony',\n",
       "   'conducted',\n",
       "   'by',\n",
       "   'Blake',\n",
       "   'Neely',\n",
       "   'and',\n",
       "   'recorded',\n",
       "   'by',\n",
       "   'Greg',\n",
       "   'Dennen',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Eastwood',\n",
       "   'Scoring',\n",
       "   'Stage',\n",
       "   'at',\n",
       "   'Warner',\n",
       "   'Brothers',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0],\n",
       "  'id': '31'},\n",
       " {'tokens': ['Dozens',\n",
       "   'of',\n",
       "   'brands',\n",
       "   'appeared',\n",
       "   'on',\n",
       "   'drugstore',\n",
       "   'shelves',\n",
       "   ',',\n",
       "   'in',\n",
       "   'numerous',\n",
       "   'formulations',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '32'},\n",
       " {'tokens': ['The',\n",
       "   'Swedish',\n",
       "   'national',\n",
       "   'men',\n",
       "   \"'s\",\n",
       "   'ice',\n",
       "   'hockey',\n",
       "   'team',\n",
       "   ',',\n",
       "   'affectionately',\n",
       "   'known',\n",
       "   'as',\n",
       "   '``',\n",
       "   'Tre',\n",
       "   'Kronor',\n",
       "   '``',\n",
       "   '(',\n",
       "   'English',\n",
       "   ':',\n",
       "   'Three',\n",
       "   'Crowns',\n",
       "   ';',\n",
       "   'the',\n",
       "   'national',\n",
       "   'symbol',\n",
       "   'of',\n",
       "   'Sweden',\n",
       "   ')',\n",
       "   ',',\n",
       "   'is',\n",
       "   'regarded',\n",
       "   'as',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'best',\n",
       "   'in',\n",
       "   'the',\n",
       "   'world',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '33'},\n",
       " {'tokens': ['Significant',\n",
       "   'technical',\n",
       "   'and',\n",
       "   'materials',\n",
       "   'problems',\n",
       "   'were',\n",
       "   'encountered',\n",
       "   'with',\n",
       "   'FBRs',\n",
       "   ',',\n",
       "   'and',\n",
       "   'geological',\n",
       "   'exploration',\n",
       "   'showed',\n",
       "   'that',\n",
       "   'scarcity',\n",
       "   'of',\n",
       "   'uranium',\n",
       "   'was',\n",
       "   'not',\n",
       "   'going',\n",
       "   'to',\n",
       "   'be',\n",
       "   'a',\n",
       "   'concern',\n",
       "   'for',\n",
       "   'some',\n",
       "   'time',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   41,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '34'},\n",
       " {'tokens': ['In',\n",
       "   '1992',\n",
       "   ',',\n",
       "   'another',\n",
       "   'film',\n",
       "   'adaptation',\n",
       "   'of',\n",
       "   'the',\n",
       "   'novel',\n",
       "   'was',\n",
       "   'made',\n",
       "   ',',\n",
       "   '``',\n",
       "   \"L'Atlantide\",\n",
       "   '``',\n",
       "   ',',\n",
       "   'directed',\n",
       "   'by',\n",
       "   'Bob',\n",
       "   'Swaim',\n",
       "   'and',\n",
       "   'starring',\n",
       "   'Tchéky',\n",
       "   'Karyo',\n",
       "   ',',\n",
       "   'Jean',\n",
       "   'Rochefort',\n",
       "   ',',\n",
       "   'Anna',\n",
       "   'Galiena',\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'famous',\n",
       "   'Spanish',\n",
       "   'actor',\n",
       "   ',',\n",
       "   'Fernando',\n",
       "   'Rey',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   53,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0],\n",
       "  'id': '35'},\n",
       " {'tokens': ['Audi',\n",
       "   'in',\n",
       "   'fourth',\n",
       "   'and',\n",
       "   'Jaguar',\n",
       "   'in',\n",
       "   'fifth',\n",
       "   'were',\n",
       "   'separated',\n",
       "   'by',\n",
       "   'one',\n",
       "   'point',\n",
       "   '.'],\n",
       "  'coarse_tags': [5, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [37, 0, 0, 0, 52, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '36'},\n",
       " {'tokens': ['He',\n",
       "   'is',\n",
       "   'also',\n",
       "   'a',\n",
       "   'member',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Board',\n",
       "   'of',\n",
       "   'Overseers',\n",
       "   'of',\n",
       "   'Memorial',\n",
       "   'Sloan-Kettering',\n",
       "   'Cancer',\n",
       "   'Center',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 8, 8, 0],\n",
       "  'id': '37'},\n",
       " {'tokens': ['Section',\n",
       "   '907',\n",
       "   'of',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'Freedom',\n",
       "   'Support',\n",
       "   'Act',\n",
       "   'bans',\n",
       "   'any',\n",
       "   'kind',\n",
       "   'of',\n",
       "   'direct',\n",
       "   'United',\n",
       "   'States',\n",
       "   'aid',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Azerbaijani',\n",
       "   'government',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '38'},\n",
       " {'tokens': ['Chiltern',\n",
       "   'Air',\n",
       "   'Support',\n",
       "   \"'s\",\n",
       "   'Luton',\n",
       "   'helicopter',\n",
       "   '(',\n",
       "   'EC135T2',\n",
       "   'CPDS',\n",
       "   ')',\n",
       "   'moved',\n",
       "   'from',\n",
       "   'London',\n",
       "   'Luton',\n",
       "   'Airport',\n",
       "   'to',\n",
       "   'RAF',\n",
       "   'Henlow',\n",
       "   ',',\n",
       "   'near',\n",
       "   'Hitchin',\n",
       "   'and',\n",
       "   'Shillington',\n",
       "   '.'],\n",
       "  'coarse_tags': [5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [28,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '39'},\n",
       " {'tokens': ['This',\n",
       "   'song',\n",
       "   'was',\n",
       "   'recorded',\n",
       "   'in',\n",
       "   'Puerto',\n",
       "   'Rico',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Alpha',\n",
       "   'Recording',\n",
       "   'Studios',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 4, 4, 0, 0, 2, 2, 2, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 21, 21, 0, 0, 11, 11, 11, 0],\n",
       "  'id': '40'},\n",
       " {'tokens': ['The',\n",
       "   'Shawshank',\n",
       "   'Redemption',\n",
       "   'is',\n",
       "   'a',\n",
       "   '1994',\n",
       "   'American',\n",
       "   'drama',\n",
       "   'film',\n",
       "   'written',\n",
       "   'and',\n",
       "   'directed',\n",
       "   'by',\n",
       "   'Frank',\n",
       "   'Darabont',\n",
       "   ',',\n",
       "   'based',\n",
       "   'on',\n",
       "   'the',\n",
       "   '1982',\n",
       "   'Stephen',\n",
       "   'King',\n",
       "   'novella',\n",
       "   '``',\n",
       "   'Rita',\n",
       "   'Hayworth',\n",
       "   'and',\n",
       "   'Shawshank',\n",
       "   'Redemption',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   53,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '41'},\n",
       " {'tokens': ['For',\n",
       "   'freighter',\n",
       "   'destinations',\n",
       "   'see',\n",
       "   'Air',\n",
       "   'China',\n",
       "   'Cargo',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '42'},\n",
       " {'tokens': ['Planned',\n",
       "   'to',\n",
       "   'connect',\n",
       "   'Downtown',\n",
       "   'Newark',\n",
       "   'and',\n",
       "   'Elizabeth',\n",
       "   'via',\n",
       "   'Newark',\n",
       "   'Liberty',\n",
       "   'International',\n",
       "   'Airport',\n",
       "   ',',\n",
       "   'NJT',\n",
       "   'is',\n",
       "   'no',\n",
       "   'longer',\n",
       "   'pursuing',\n",
       "   'the',\n",
       "   'Newark-Elizabeth',\n",
       "   'Rail',\n",
       "   'Link',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0],\n",
       "  'id': '43'},\n",
       " {'tokens': ['On',\n",
       "   '25',\n",
       "   'April',\n",
       "   ',',\n",
       "   'Krukenberg',\n",
       "   'was',\n",
       "   'appointed',\n",
       "   'by',\n",
       "   'General',\n",
       "   'Helmuth',\n",
       "   'Weidling',\n",
       "   'as',\n",
       "   'the',\n",
       "   'commander',\n",
       "   'of',\n",
       "   '(',\n",
       "   'Berlin',\n",
       "   ')',\n",
       "   'Defence',\n",
       "   'Sector',\n",
       "   'C',\n",
       "   ',',\n",
       "   'which',\n",
       "   'included',\n",
       "   'the',\n",
       "   'SS',\n",
       "   'Division',\n",
       "   'Nordland',\n",
       "   ',',\n",
       "   'whose',\n",
       "   'previous',\n",
       "   'commander',\n",
       "   'Joachim',\n",
       "   'Ziegler',\n",
       "   'was',\n",
       "   'relieved',\n",
       "   'of',\n",
       "   'his',\n",
       "   'command',\n",
       "   'the',\n",
       "   'same',\n",
       "   'day',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   57,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   57,\n",
       "   57,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   57,\n",
       "   57,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '44'},\n",
       " {'tokens': ['To',\n",
       "   'enforce',\n",
       "   'the',\n",
       "   'injunction',\n",
       "   ',',\n",
       "   'Quixtar',\n",
       "   'filed',\n",
       "   'an',\n",
       "   'action',\n",
       "   'against',\n",
       "   '30',\n",
       "   'anonymous',\n",
       "   'bloggers',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '45'},\n",
       " {'tokens': ['The',\n",
       "   'Eighth',\n",
       "   'Army',\n",
       "   'began',\n",
       "   'to',\n",
       "   'attack',\n",
       "   'Italian',\n",
       "   'units',\n",
       "   ',',\n",
       "   'located',\n",
       "   'using',\n",
       "   'information',\n",
       "   'from',\n",
       "   'Ultra',\n",
       "   ',',\n",
       "   'at',\n",
       "   'Ruweisat',\n",
       "   'Ridge',\n",
       "   'and',\n",
       "   'from',\n",
       "   'again',\n",
       "   'at',\n",
       "   'Tel',\n",
       "   'El',\n",
       "   'Eisa',\n",
       "   'on',\n",
       "   '22',\n",
       "   'July',\n",
       "   'and',\n",
       "   'Miteirya',\n",
       "   'Ridge',\n",
       "   'after',\n",
       "   'which',\n",
       "   'another',\n",
       "   'lull',\n",
       "   'fell',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   24,\n",
       "   24,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   24,\n",
       "   24,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '46'},\n",
       " {'tokens': ['Hoey',\n",
       "   'was',\n",
       "   'born',\n",
       "   'in',\n",
       "   'Mallusk',\n",
       "   ',',\n",
       "   'County',\n",
       "   'Antrim',\n",
       "   ',',\n",
       "   'and',\n",
       "   'studied',\n",
       "   'at',\n",
       "   'Belfast',\n",
       "   'Royal',\n",
       "   'Academy',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Ulster',\n",
       "   'College',\n",
       "   'of',\n",
       "   'Physical',\n",
       "   'Education',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0],\n",
       "  'id': '47'},\n",
       " {'tokens': ['In',\n",
       "   '1963',\n",
       "   'Leicester',\n",
       "   'City',\n",
       "   'Council',\n",
       "   '(',\n",
       "   'LCC',\n",
       "   ')',\n",
       "   ',',\n",
       "   'identifying',\n",
       "   'a',\n",
       "   'gap',\n",
       "   'in',\n",
       "   'cultural',\n",
       "   'provision',\n",
       "   'for',\n",
       "   'live',\n",
       "   'performances',\n",
       "   ',',\n",
       "   'built',\n",
       "   'a',\n",
       "   '262-seat',\n",
       "   'theatre',\n",
       "   'in',\n",
       "   'Leicester',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '48'},\n",
       " {'tokens': ['He',\n",
       "   'plays',\n",
       "   'Chief',\n",
       "   'Irvin',\n",
       "   'Irving',\n",
       "   'on',\n",
       "   'Amazon',\n",
       "   'Prime',\n",
       "   \"'s\",\n",
       "   '``',\n",
       "   'Bosch',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 7, 7, 0, 7, 7, 0, 0, 1, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 54, 54, 0, 54, 54, 0, 0, 2, 0, 0],\n",
       "  'id': '49'},\n",
       " {'tokens': ['10th',\n",
       "   'century',\n",
       "   ')',\n",
       "   'was',\n",
       "   'a',\n",
       "   'Chinese',\n",
       "   'landscape',\n",
       "   'painter',\n",
       "   'of',\n",
       "   'the',\n",
       "   'late',\n",
       "   'Five',\n",
       "   'Dynasties',\n",
       "   'and',\n",
       "   'Ten',\n",
       "   'Kingdoms',\n",
       "   'and',\n",
       "   'early',\n",
       "   'Northern',\n",
       "   'Song',\n",
       "   'periods',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '50'},\n",
       " {'tokens': ['In',\n",
       "   '2010',\n",
       "   ',',\n",
       "   'Al',\n",
       "   'Jazeera',\n",
       "   \"'s\",\n",
       "   'Teymoor',\n",
       "   'Nabili',\n",
       "   'suggested',\n",
       "   'that',\n",
       "   'the',\n",
       "   'article',\n",
       "   '``',\n",
       "   'Cyrus',\n",
       "   'Cylinder',\n",
       "   \"''\",\n",
       "   'had',\n",
       "   'been',\n",
       "   'edited',\n",
       "   'for',\n",
       "   'political',\n",
       "   'purposes',\n",
       "   'by',\n",
       "   '``',\n",
       "   'an',\n",
       "   'apparent',\n",
       "   'tussle',\n",
       "   'of',\n",
       "   'opinions',\n",
       "   'in',\n",
       "   'the',\n",
       "   'shadowy',\n",
       "   'world',\n",
       "   'of',\n",
       "   'hard',\n",
       "   'drives',\n",
       "   'and',\n",
       "   \"'independent\",\n",
       "   \"'\",\n",
       "   'editors',\n",
       "   'that',\n",
       "   'comprise',\n",
       "   'the',\n",
       "   'Wikipedia',\n",
       "   'industry',\n",
       "   '.',\n",
       "   \"''\"],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   31,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '51'},\n",
       " {'tokens': ['The',\n",
       "   'Church',\n",
       "   'of',\n",
       "   'England',\n",
       "   'parish',\n",
       "   'church',\n",
       "   'of',\n",
       "   'St',\n",
       "   'John',\n",
       "   'The',\n",
       "   'Evangelist',\n",
       "   'in',\n",
       "   'Friern',\n",
       "   'Barnet',\n",
       "   'Road',\n",
       "   'is',\n",
       "   'Grade',\n",
       "   'II',\n",
       "   '*',\n",
       "   'listed',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '52'},\n",
       " {'tokens': ['The',\n",
       "   'new',\n",
       "   'Samsat',\n",
       "   'district',\n",
       "   'is',\n",
       "   'a',\n",
       "   'peninsula',\n",
       "   'surrounded',\n",
       "   'on',\n",
       "   'the',\n",
       "   'three',\n",
       "   'sides',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Atatürk',\n",
       "   'Dam',\n",
       "   'Lake',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 0],\n",
       "  'fine_tags': [0, 23, 23, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 22, 22, 0],\n",
       "  'id': '53'},\n",
       " {'tokens': ['The',\n",
       "   'drill',\n",
       "   'hall',\n",
       "   'is',\n",
       "   'long',\n",
       "   'and',\n",
       "   'has',\n",
       "   'two',\n",
       "   'tall',\n",
       "   'mansard',\n",
       "   'towers',\n",
       "   '.'],\n",
       "  'coarse_tags': [2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [11, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '54'},\n",
       " {'tokens': ['As',\n",
       "   'a',\n",
       "   'protest',\n",
       "   ',',\n",
       "   'the',\n",
       "   'incumbent',\n",
       "   'Helikopter',\n",
       "   'Service',\n",
       "   'applied',\n",
       "   'for',\n",
       "   'the',\n",
       "   'airline',\n",
       "   'routes',\n",
       "   'that',\n",
       "   'Braathens',\n",
       "   'SAFE',\n",
       "   'operated',\n",
       "   'from',\n",
       "   'Stavanger',\n",
       "   ',',\n",
       "   'but',\n",
       "   'this',\n",
       "   'application',\n",
       "   'was',\n",
       "   'rejected',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '55'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'a',\n",
       "   'European',\n",
       "   'professional',\n",
       "   'basketball',\n",
       "   'player',\n",
       "   'in',\n",
       "   'Germany',\n",
       "   'from',\n",
       "   '1998-1999',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 21, 0, 0, 0, 0, 21, 0, 0, 0],\n",
       "  'id': '56'},\n",
       " {'tokens': ['The',\n",
       "   'bascule',\n",
       "   'bridge',\n",
       "   'carries',\n",
       "   'NJ',\n",
       "   'Transit',\n",
       "   'Rail',\n",
       "   'Operations',\n",
       "   'North',\n",
       "   'Jersey',\n",
       "   'Coast',\n",
       "   'Line',\n",
       "   'between',\n",
       "   'the',\n",
       "   'Bradley',\n",
       "   'Beach',\n",
       "   'and',\n",
       "   'Belmar',\n",
       "   'stations',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 0, 0, 2, 2, 0, 2, 2, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0],\n",
       "  'id': '57'},\n",
       " {'tokens': ['Their',\n",
       "   'first',\n",
       "   ',',\n",
       "   '1972',\n",
       "   'album',\n",
       "   'was',\n",
       "   'released',\n",
       "   'under',\n",
       "   'the',\n",
       "   'name',\n",
       "   '``',\n",
       "   'Atkinson',\n",
       "   ',',\n",
       "   'Danko',\n",
       "   'and',\n",
       "   'Ford',\n",
       "   '(',\n",
       "   'with',\n",
       "   'Brockie',\n",
       "   'and',\n",
       "   'Hilton',\n",
       "   ')',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '58'},\n",
       " {'tokens': ['The',\n",
       "   'Bayerische',\n",
       "   'Staatsbibliothek',\n",
       "   'furthermore',\n",
       "   'is',\n",
       "   'Europe',\n",
       "   \"'s\",\n",
       "   'second-largest',\n",
       "   'journals',\n",
       "   'library',\n",
       "   '(',\n",
       "   'after',\n",
       "   'the',\n",
       "   'British',\n",
       "   'Library',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 2, 2, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0],\n",
       "  'fine_tags': [0, 10, 10, 0, 0, 21, 0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 0],\n",
       "  'id': '59'},\n",
       " {'tokens': ['The',\n",
       "   'Outerbridge',\n",
       "   'Crossing',\n",
       "   ',',\n",
       "   'which',\n",
       "   'opened',\n",
       "   'to',\n",
       "   'traffic',\n",
       "   'on',\n",
       "   'June',\n",
       "   '29',\n",
       "   ',',\n",
       "   '1928',\n",
       "   ',',\n",
       "   'is',\n",
       "   'a',\n",
       "   'cantilever',\n",
       "   'bridge',\n",
       "   'over',\n",
       "   'the',\n",
       "   'Arthur',\n",
       "   'Kill',\n",
       "   'that',\n",
       "   'connects',\n",
       "   'Perth',\n",
       "   'Amboy',\n",
       "   'with',\n",
       "   'Staten',\n",
       "   'Island',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   23,\n",
       "   23,\n",
       "   0],\n",
       "  'id': '60'},\n",
       " {'tokens': ['Raisna',\n",
       "   'Chauhan',\n",
       "   'is',\n",
       "   'a',\n",
       "   'village',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Meerut',\n",
       "   'district',\n",
       "   'of',\n",
       "   'Uttar',\n",
       "   'Pradesh',\n",
       "   'state',\n",
       "   ',',\n",
       "   'India',\n",
       "   ',',\n",
       "   'and',\n",
       "   'forms',\n",
       "   'a',\n",
       "   'part',\n",
       "   'of',\n",
       "   'the',\n",
       "   'National',\n",
       "   'Capital',\n",
       "   'Region',\n",
       "   '(',\n",
       "   'NCR',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '61'},\n",
       " {'tokens': ['The',\n",
       "   'law',\n",
       "   'proposed',\n",
       "   'to',\n",
       "   'establish',\n",
       "   'a',\n",
       "   'corporativist',\n",
       "   'state',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '62'},\n",
       " {'tokens': ['In',\n",
       "   '1654',\n",
       "   'the',\n",
       "   'Congregazione',\n",
       "   'dei',\n",
       "   'Nobili',\n",
       "   'put',\n",
       "   'Picchiatti',\n",
       "   'in',\n",
       "   'charge',\n",
       "   'of',\n",
       "   'designing',\n",
       "   'and',\n",
       "   'building',\n",
       "   'the',\n",
       "   'Palazzo',\n",
       "   'Monte',\n",
       "   'dei',\n",
       "   'Poveri',\n",
       "   'Vergognosi',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0],\n",
       "  'id': '63'},\n",
       " {'tokens': ['While',\n",
       "   'considerably',\n",
       "   'reduced',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Papal',\n",
       "   'States',\n",
       "   'nevertheless',\n",
       "   'still',\n",
       "   'covered',\n",
       "   'the',\n",
       "   'Latium',\n",
       "   'and',\n",
       "   'large',\n",
       "   'areas',\n",
       "   'northwest',\n",
       "   'of',\n",
       "   'Rome',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 21, 21, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '64'},\n",
       " {'tokens': ['All',\n",
       "   'seven',\n",
       "   'packages',\n",
       "   'were',\n",
       "   'won',\n",
       "   'by',\n",
       "   'the',\n",
       "   'incumbent',\n",
       "   'operator',\n",
       "   'Widerøe',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '65'},\n",
       " {'tokens': ['This',\n",
       "   'was',\n",
       "   'part',\n",
       "   'of',\n",
       "   'a',\n",
       "   'wider',\n",
       "   'Bicentennial',\n",
       "   'Boycott',\n",
       "   'movement',\n",
       "   'which',\n",
       "   'started',\n",
       "   'in',\n",
       "   'the',\n",
       "   'leadup',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Bicentennial',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 19, 19, 19, 0, 0, 0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '66'},\n",
       " {'tokens': ['The',\n",
       "   'Laccadives',\n",
       "   'are',\n",
       "   'different',\n",
       "   'in',\n",
       "   'structure',\n",
       "   'from',\n",
       "   'the',\n",
       "   'Maldives',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 4, 0, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 23, 0, 0, 0, 0, 0, 0, 23, 0],\n",
       "  'id': '67'},\n",
       " {'tokens': ['The',\n",
       "   'Broch',\n",
       "   'of',\n",
       "   'West',\n",
       "   'Burrafirth',\n",
       "   'is',\n",
       "   'an',\n",
       "   'Iron',\n",
       "   'Age',\n",
       "   'broch',\n",
       "   'located',\n",
       "   'on',\n",
       "   'the',\n",
       "   'west',\n",
       "   'side',\n",
       "   'of',\n",
       "   'Mainland',\n",
       "   ',',\n",
       "   'Shetland',\n",
       "   '(',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   23,\n",
       "   23,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   23,\n",
       "   0,\n",
       "   23,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '68'},\n",
       " {'tokens': ['As',\n",
       "   'a',\n",
       "   'senior',\n",
       "   ',',\n",
       "   'he',\n",
       "   'hit',\n",
       "   '.277',\n",
       "   ',',\n",
       "   'tied',\n",
       "   'for',\n",
       "   'the',\n",
       "   'team',\n",
       "   'lead',\n",
       "   'with',\n",
       "   'six',\n",
       "   'home',\n",
       "   'runs',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '69'},\n",
       " {'tokens': ['Prior',\n",
       "   'to',\n",
       "   'issuing',\n",
       "   'AR-15',\n",
       "   \"'s\",\n",
       "   ',',\n",
       "   'The',\n",
       "   'Patrol',\n",
       "   'began',\n",
       "   'participating',\n",
       "   'in',\n",
       "   'a',\n",
       "   'program',\n",
       "   'with',\n",
       "   'the',\n",
       "   'US',\n",
       "   'Government',\n",
       "   'and',\n",
       "   'purchased',\n",
       "   'surplus',\n",
       "   'M-14',\n",
       "   'rifles',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   66,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '70'},\n",
       " {'tokens': ['The',\n",
       "   'game',\n",
       "   \"'s\",\n",
       "   'source',\n",
       "   'code',\n",
       "   'was',\n",
       "   'shared',\n",
       "   'with',\n",
       "   'other',\n",
       "   'institutions',\n",
       "   'with',\n",
       "   'a',\n",
       "   'PDP-1',\n",
       "   'across',\n",
       "   'the',\n",
       "   'country',\n",
       "   'as',\n",
       "   'the',\n",
       "   'MIT',\n",
       "   'students',\n",
       "   'themselves',\n",
       "   'moved',\n",
       "   'about',\n",
       "   ',',\n",
       "   'allowing',\n",
       "   'the',\n",
       "   'game',\n",
       "   'to',\n",
       "   'gain',\n",
       "   'popularity',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '71'},\n",
       " {'tokens': ['12',\n",
       "   'Corazones',\n",
       "   '(',\n",
       "   ',',\n",
       "   '``',\n",
       "   '12',\n",
       "   'Hearts',\n",
       "   \"''\",\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'Spanish',\n",
       "   '-language',\n",
       "   'dating',\n",
       "   'game',\n",
       "   'show',\n",
       "   'produced',\n",
       "   'in',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'for',\n",
       "   'the',\n",
       "   'television',\n",
       "   'network',\n",
       "   'Telemundo',\n",
       "   'since',\n",
       "   'January',\n",
       "   '2005',\n",
       "   ',',\n",
       "   'based',\n",
       "   'on',\n",
       "   'its',\n",
       "   'namesake',\n",
       "   'Argentine',\n",
       "   'TV',\n",
       "   'show',\n",
       "   'format',\n",
       "   'The',\n",
       "   'show',\n",
       "   'is',\n",
       "   'filmed',\n",
       "   'in',\n",
       "   'Los',\n",
       "   'Angeles',\n",
       "   'and',\n",
       "   'revolves',\n",
       "   'around',\n",
       "   'the',\n",
       "   'twelve',\n",
       "   'Zodiac',\n",
       "   'signs',\n",
       "   'that',\n",
       "   'identify',\n",
       "   'each',\n",
       "   'contestant',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '72'},\n",
       " {'tokens': ['The',\n",
       "   'coachbuilder',\n",
       "   'and',\n",
       "   'seller',\n",
       "   'was',\n",
       "   'Hooper',\n",
       "   '&',\n",
       "   'amp',\n",
       "   ';',\n",
       "   'Co',\n",
       "   '.',\n",
       "   'in',\n",
       "   'London',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 28, 28, 28, 28, 28, 28, 0, 21, 0],\n",
       "  'id': '73'},\n",
       " {'tokens': ['She',\n",
       "   'was',\n",
       "   'a',\n",
       "   'younger',\n",
       "   'sister',\n",
       "   'of',\n",
       "   'Emeric',\n",
       "   ',',\n",
       "   'King',\n",
       "   'of',\n",
       "   'Hungary',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 55, 0, 0, 0, 21, 0],\n",
       "  'id': '74'},\n",
       " {'tokens': ['Though',\n",
       "   'only',\n",
       "   'in',\n",
       "   'length',\n",
       "   ',',\n",
       "   'The',\n",
       "   'Salamander',\n",
       "   'Glacier',\n",
       "   'is',\n",
       "   'about',\n",
       "   'wide',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 24, 24, 0, 0, 0, 0],\n",
       "  'id': '75'},\n",
       " {'tokens': ['The',\n",
       "   'video',\n",
       "   ',',\n",
       "   'shot',\n",
       "   'in',\n",
       "   'Los',\n",
       "   'Angeles',\n",
       "   'on',\n",
       "   'location',\n",
       "   'at',\n",
       "   'The',\n",
       "   'Echo',\n",
       "   ',',\n",
       "   'The',\n",
       "   'Standard',\n",
       "   'Hotel',\n",
       "   'and',\n",
       "   'the',\n",
       "   'streets',\n",
       "   'of',\n",
       "   'Downtown',\n",
       "   'LA',\n",
       "   ',',\n",
       "   'was',\n",
       "   'premiered',\n",
       "   'by',\n",
       "   'UK',\n",
       "   'music',\n",
       "   'tastemaker',\n",
       "   'Clash',\n",
       "   '(',\n",
       "   'magazine',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '76'},\n",
       " {'tokens': ['State',\n",
       "   'Route',\n",
       "   '151',\n",
       "   '(',\n",
       "   'SR',\n",
       "   '151',\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'state',\n",
       "   'highway',\n",
       "   'in',\n",
       "   'the',\n",
       "   'U.S',\n",
       "   '.',\n",
       "   'state',\n",
       "   'of',\n",
       "   'California',\n",
       "   '.'],\n",
       "  'coarse_tags': [4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 0],\n",
       "  'fine_tags': [27, 27, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 21, 0, 0, 21, 0],\n",
       "  'id': '77'},\n",
       " {'tokens': ['Before',\n",
       "   'the',\n",
       "   'vote',\n",
       "   ',',\n",
       "   'there',\n",
       "   'were',\n",
       "   'calls',\n",
       "   'for',\n",
       "   'the',\n",
       "   'bills',\n",
       "   'to',\n",
       "   'be',\n",
       "   'separated',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Diet',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 0],\n",
       "  'id': '78'},\n",
       " {'tokens': ['Based',\n",
       "   'initially',\n",
       "   'at',\n",
       "   'Cley',\n",
       "   'next',\n",
       "   'the',\n",
       "   'Sea',\n",
       "   ',',\n",
       "   'it',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'Sheringham',\n",
       "   'in',\n",
       "   'mid-1918',\n",
       "   'and',\n",
       "   'remained',\n",
       "   'on',\n",
       "   'the',\n",
       "   'Norfolk',\n",
       "   'coast',\n",
       "   'until',\n",
       "   'disbandment',\n",
       "   'on',\n",
       "   '24',\n",
       "   'March',\n",
       "   '1919',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '79'},\n",
       " {'tokens': ['On',\n",
       "   'May',\n",
       "   '4',\n",
       "   ',',\n",
       "   '2013',\n",
       "   ',',\n",
       "   'the',\n",
       "   'light',\n",
       "   'was',\n",
       "   'reactivated',\n",
       "   'and',\n",
       "   'has',\n",
       "   'been',\n",
       "   'operated',\n",
       "   'seasonally',\n",
       "   'ever',\n",
       "   'since',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '80'},\n",
       " {'tokens': ['``',\n",
       "   'It',\n",
       "   'gives',\n",
       "   'a',\n",
       "   'good',\n",
       "   'impression',\n",
       "   'in',\n",
       "   'terms',\n",
       "   'of',\n",
       "   'technology',\n",
       "   ',',\n",
       "   'solidarity',\n",
       "   'and',\n",
       "   'efficiency',\n",
       "   '.',\n",
       "   \"''\"],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '81'},\n",
       " {'tokens': ['The',\n",
       "   'King-Emperor',\n",
       "   ',',\n",
       "   'George',\n",
       "   'V',\n",
       "   ',',\n",
       "   'released',\n",
       "   'him',\n",
       "   'in',\n",
       "   '1920',\n",
       "   'as',\n",
       "   'the',\n",
       "   'result',\n",
       "   'of',\n",
       "   'a',\n",
       "   'general',\n",
       "   'amnesty',\n",
       "   'order',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 54, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '82'},\n",
       " {'tokens': ['It',\n",
       "   'is',\n",
       "   'now',\n",
       "   'home',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Fort',\n",
       "   'George',\n",
       "   'Island',\n",
       "   'Visitor',\n",
       "   'Center',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 11, 11, 11, 11, 11, 0],\n",
       "  'id': '83'},\n",
       " {'tokens': ['Along',\n",
       "   'with',\n",
       "   'the',\n",
       "   'state',\n",
       "   'and',\n",
       "   'local',\n",
       "   'law',\n",
       "   'enforcement',\n",
       "   'agencies',\n",
       "   ',',\n",
       "   'the',\n",
       "   'federal',\n",
       "   'government',\n",
       "   'also',\n",
       "   'maintains',\n",
       "   'several',\n",
       "   'departments',\n",
       "   'that',\n",
       "   'service',\n",
       "   'citizens',\n",
       "   'of',\n",
       "   'the',\n",
       "   'county',\n",
       "   'such',\n",
       "   'as',\n",
       "   'the',\n",
       "   'US',\n",
       "   'Park',\n",
       "   'Police',\n",
       "   ',',\n",
       "   'US',\n",
       "   'Postal',\n",
       "   'Police',\n",
       "   ',',\n",
       "   'Andrews',\n",
       "   'Air',\n",
       "   'Force',\n",
       "   'Base',\n",
       "   'Security',\n",
       "   'Police',\n",
       "   ',',\n",
       "   'and',\n",
       "   'other',\n",
       "   'federal',\n",
       "   'police',\n",
       "   'located',\n",
       "   'on',\n",
       "   'various',\n",
       "   'federal',\n",
       "   'property',\n",
       "   'within',\n",
       "   'the',\n",
       "   'county',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '84'},\n",
       " {'tokens': ['Despite',\n",
       "   'the',\n",
       "   'title',\n",
       "   '``',\n",
       "   'hammerless',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   'the',\n",
       "   'Model',\n",
       "   '1903',\n",
       "   'does',\n",
       "   'have',\n",
       "   'a',\n",
       "   'hammer',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '85'},\n",
       " {'tokens': ['Since',\n",
       "   '1989',\n",
       "   'until',\n",
       "   'his',\n",
       "   'death',\n",
       "   ',',\n",
       "   'he',\n",
       "   'was',\n",
       "   'a',\n",
       "   'member',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Masaryk',\n",
       "   'Democratic',\n",
       "   'Movement',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 18, 18, 0],\n",
       "  'id': '86'},\n",
       " {'tokens': ['This',\n",
       "   'building',\n",
       "   ',',\n",
       "   'also',\n",
       "   'restored',\n",
       "   'by',\n",
       "   'John',\n",
       "   'McAslan',\n",
       "   '+',\n",
       "   'Partners',\n",
       "   ',',\n",
       "   'houses',\n",
       "   'a',\n",
       "   'restaurant',\n",
       "   ',',\n",
       "   'art',\n",
       "   'galleries',\n",
       "   ',',\n",
       "   'meeting',\n",
       "   'rooms',\n",
       "   ',',\n",
       "   'shop',\n",
       "   ',',\n",
       "   'visitor',\n",
       "   'reception',\n",
       "   'and',\n",
       "   'administration',\n",
       "   'offices',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '87'},\n",
       " {'tokens': ['L.C', '.'],\n",
       "  'coarse_tags': [0, 0],\n",
       "  'fine_tags': [0, 0],\n",
       "  'id': '88'},\n",
       " {'tokens': ['Although',\n",
       "   'the',\n",
       "   'field',\n",
       "   'was',\n",
       "   'designed',\n",
       "   'originally',\n",
       "   'to',\n",
       "   'serve',\n",
       "   'only',\n",
       "   'municipal',\n",
       "   'civil',\n",
       "   'airport',\n",
       "   'needs',\n",
       "   ',',\n",
       "   'it',\n",
       "   'had',\n",
       "   'an',\n",
       "   'Air',\n",
       "   'Force',\n",
       "   'connection',\n",
       "   'almost',\n",
       "   'from',\n",
       "   'the',\n",
       "   'beginning',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '89'},\n",
       " {'tokens': ['Bruno',\n",
       "   'Zanoni',\n",
       "   '(',\n",
       "   'born',\n",
       "   '29',\n",
       "   'July',\n",
       "   '1952',\n",
       "   ')',\n",
       "   'is',\n",
       "   'an',\n",
       "   'Italian',\n",
       "   'racing',\n",
       "   'cyclist',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0],\n",
       "  'fine_tags': [52, 52, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0],\n",
       "  'id': '90'},\n",
       " {'tokens': ['Griffis',\n",
       "   'defeated',\n",
       "   'Ernie',\n",
       "   'Johnson',\n",
       "   'to',\n",
       "   'challenge',\n",
       "   'Mallen',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 7, 7, 0, 0, 7, 0],\n",
       "  'fine_tags': [52, 0, 52, 52, 0, 0, 52, 0],\n",
       "  'id': '91'},\n",
       " {'tokens': ['Men',\n",
       "   'in',\n",
       "   'Her',\n",
       "   'Diary',\n",
       "   'is',\n",
       "   'a',\n",
       "   '1945',\n",
       "   'American',\n",
       "   'comedy',\n",
       "   'film',\n",
       "   '.'],\n",
       "  'coarse_tags': [1, 1, 1, 1, 0, 0, 0, 4, 0, 0, 0],\n",
       "  'fine_tags': [2, 2, 2, 2, 0, 0, 0, 21, 0, 0, 0],\n",
       "  'id': '92'},\n",
       " {'tokens': ['``',\n",
       "   'Fliegerkorps',\n",
       "   \"''\",\n",
       "   'under',\n",
       "   'Generaloberst',\n",
       "   'Bruno',\n",
       "   'Loerzer',\n",
       "   'at',\n",
       "   'Frankfurt',\n",
       "   ',',\n",
       "   'and',\n",
       "   'V.',\n",
       "   '``',\n",
       "   'Fliegerkorps',\n",
       "   \"''\",\n",
       "   'under',\n",
       "   'command',\n",
       "   'of',\n",
       "   'General',\n",
       "   'Robert',\n",
       "   'Ritter',\n",
       "   'von',\n",
       "   'Greim',\n",
       "   'at',\n",
       "   'Gersthofen',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   57,\n",
       "   57,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   57,\n",
       "   57,\n",
       "   57,\n",
       "   57,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '93'},\n",
       " {'tokens': ['He',\n",
       "   'left',\n",
       "   'for',\n",
       "   'Italy',\n",
       "   'in',\n",
       "   'April',\n",
       "   '1857',\n",
       "   'and',\n",
       "   'also',\n",
       "   'visited',\n",
       "   'Greece',\n",
       "   'before',\n",
       "   'returning',\n",
       "   'to',\n",
       "   'France',\n",
       "   'in',\n",
       "   '1861',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 21, 0, 0, 0],\n",
       "  'id': '94'},\n",
       " {'tokens': ['The',\n",
       "   'non-stop',\n",
       "   'service',\n",
       "   'is',\n",
       "   'offered',\n",
       "   'between',\n",
       "   'Zhuhai',\n",
       "   'and',\n",
       "   'Guangzhou',\n",
       "   'South',\n",
       "   'only',\n",
       "   ',',\n",
       "   'and',\n",
       "   'travel',\n",
       "   'between',\n",
       "   'Zhuhai',\n",
       "   '(',\n",
       "   'Gongbei',\n",
       "   ')',\n",
       "   'and',\n",
       "   'Zhuhai',\n",
       "   'Airport',\n",
       "   'will',\n",
       "   'be',\n",
       "   'cut',\n",
       "   'down',\n",
       "   'to',\n",
       "   '25',\n",
       "   'minutes',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '95'},\n",
       " {'tokens': ['Although',\n",
       "   'the',\n",
       "   'game',\n",
       "   'features',\n",
       "   'his',\n",
       "   'name',\n",
       "   ',',\n",
       "   'Tom',\n",
       "   'Clancy',\n",
       "   'had',\n",
       "   'little',\n",
       "   'to',\n",
       "   'no',\n",
       "   'involvement',\n",
       "   'in',\n",
       "   'the',\n",
       "   'development',\n",
       "   'of',\n",
       "   'any',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Splinter',\n",
       "   'Cell',\n",
       "   'games',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '96'},\n",
       " {'tokens': ['The',\n",
       "   'C.',\n",
       "   'E.',\n",
       "   'Toberman',\n",
       "   'Estate',\n",
       "   ',',\n",
       "   'also',\n",
       "   'known',\n",
       "   'as',\n",
       "   'Villa',\n",
       "   'Las',\n",
       "   'Colinas',\n",
       "   ',',\n",
       "   'is',\n",
       "   'a',\n",
       "   'gated',\n",
       "   'Mission',\n",
       "   'Revival',\n",
       "   'mansion',\n",
       "   'and',\n",
       "   'estate',\n",
       "   'on',\n",
       "   'Camino',\n",
       "   'Palmero',\n",
       "   'in',\n",
       "   'Hollywood',\n",
       "   ',',\n",
       "   'Los',\n",
       "   'Angeles',\n",
       "   ',',\n",
       "   'California',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '97'},\n",
       " {'tokens': ['Mount',\n",
       "   'Diablo',\n",
       "   'has',\n",
       "   'inspired',\n",
       "   'many',\n",
       "   'artists',\n",
       "   'and',\n",
       "   'writers',\n",
       "   '.'],\n",
       "  'coarse_tags': [4, 4, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [24, 24, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '98'},\n",
       " {'tokens': ['Nevertheless',\n",
       "   ',',\n",
       "   'an',\n",
       "   'extensive',\n",
       "   '``',\n",
       "   'guardianship',\n",
       "   \"''\",\n",
       "   'was',\n",
       "   'given',\n",
       "   'to',\n",
       "   'clerics',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '99'},\n",
       " {'tokens': ['The',\n",
       "   'Thirty',\n",
       "   'Years',\n",
       "   \"'\",\n",
       "   'Peace',\n",
       "   'was',\n",
       "   'a',\n",
       "   'treaty',\n",
       "   'signed',\n",
       "   'between',\n",
       "   'the',\n",
       "   'ancient',\n",
       "   'Greek',\n",
       "   'city-states',\n",
       "   'of',\n",
       "   'Athens',\n",
       "   'and',\n",
       "   'Sparta',\n",
       "   'in',\n",
       "   '446/445',\n",
       "   'BCE',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '100'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'honoured',\n",
       "   'with',\n",
       "   'the',\n",
       "   'Order',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Republic',\n",
       "   'of',\n",
       "   'Guinea',\n",
       "   'and',\n",
       "   'Nigeria',\n",
       "   ',',\n",
       "   'second',\n",
       "   'highest',\n",
       "   'national',\n",
       "   'honours',\n",
       "   'of',\n",
       "   'Grand',\n",
       "   'Commander',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Order',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Niger',\n",
       "   '(',\n",
       "   'GCON',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   39,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '101'},\n",
       " {'tokens': ['The',\n",
       "   'p53',\n",
       "   'protein',\n",
       "   'functions',\n",
       "   'as',\n",
       "   'a',\n",
       "   'transcription',\n",
       "   'factor',\n",
       "   'with',\n",
       "   'a',\n",
       "   'crucial',\n",
       "   'role',\n",
       "   'in',\n",
       "   'orchestrating',\n",
       "   'the',\n",
       "   'cellular',\n",
       "   'stress',\n",
       "   'response',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 40, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '102'},\n",
       " {'tokens': ['London',\n",
       "   'Bridge',\n",
       "   'station',\n",
       "   'was',\n",
       "   'opened',\n",
       "   'on',\n",
       "   '14',\n",
       "   'December',\n",
       "   '1836',\n",
       "   ',',\n",
       "   'making',\n",
       "   'it',\n",
       "   'the',\n",
       "   'oldest',\n",
       "   'London',\n",
       "   'railway',\n",
       "   'terminus',\n",
       "   'that',\n",
       "   'is',\n",
       "   'still',\n",
       "   'running',\n",
       "   '.'],\n",
       "  'coarse_tags': [2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '103'},\n",
       " {'tokens': ['Michael',\n",
       "   'Witheford',\n",
       "   'of',\n",
       "   '``',\n",
       "   'TimeOut',\n",
       "   'Melbourne',\n",
       "   '``',\n",
       "   'describes',\n",
       "   'the',\n",
       "   'album',\n",
       "   'as',\n",
       "   'being',\n",
       "   '``',\n",
       "   'almost',\n",
       "   'a',\n",
       "   'concept',\n",
       "   'record',\n",
       "   ';',\n",
       "   'the',\n",
       "   'soundscape',\n",
       "   'of',\n",
       "   'a',\n",
       "   'drive',\n",
       "   'over',\n",
       "   'the',\n",
       "   'West',\n",
       "   'Gate',\n",
       "   'Bridge',\n",
       "   'towards',\n",
       "   'the',\n",
       "   'refineries',\n",
       "   'and',\n",
       "   'container',\n",
       "   'docks',\n",
       "   'and',\n",
       "   'far',\n",
       "   'beyond',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '104'},\n",
       " {'tokens': ['Crews',\n",
       "   'liked',\n",
       "   'the',\n",
       "   'aircraft',\n",
       "   ',',\n",
       "   'and',\n",
       "   'generally',\n",
       "   'rated',\n",
       "   'them',\n",
       "   'better',\n",
       "   'than',\n",
       "   'the',\n",
       "   'Spey-equipped',\n",
       "   'FGR.2s',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 58, 58, 0],\n",
       "  'id': '105'},\n",
       " {'tokens': ['South',\n",
       "   'of',\n",
       "   '120th',\n",
       "   'Street',\n",
       "   ',',\n",
       "   'the',\n",
       "   'eastern',\n",
       "   'side',\n",
       "   'of',\n",
       "   'Claremont',\n",
       "   'Avenue',\n",
       "   'features',\n",
       "   'the',\n",
       "   'heavily',\n",
       "   'fortified',\n",
       "   'backside',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Barnard',\n",
       "   'College',\n",
       "   'campus',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '106'},\n",
       " {'tokens': ['Bintan',\n",
       "   'Resorts',\n",
       "   'is',\n",
       "   'separated',\n",
       "   'from',\n",
       "   'the',\n",
       "   'rest',\n",
       "   'of',\n",
       "   'Bintan',\n",
       "   'by',\n",
       "   'a',\n",
       "   'barbed',\n",
       "   'wire',\n",
       "   'fence',\n",
       "   ',',\n",
       "   'and',\n",
       "   'land',\n",
       "   'access',\n",
       "   'to',\n",
       "   'the',\n",
       "   'rest',\n",
       "   'of',\n",
       "   'the',\n",
       "   'land',\n",
       "   'is',\n",
       "   'via',\n",
       "   'a',\n",
       "   'single',\n",
       "   'security',\n",
       "   'checkpoint',\n",
       "   '(',\n",
       "   'Post',\n",
       "   '1',\n",
       "   'checkpoint',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '107'},\n",
       " {'tokens': ['Furthermore',\n",
       "   ',',\n",
       "   'because',\n",
       "   'the',\n",
       "   'playoff',\n",
       "   'format',\n",
       "   'was',\n",
       "   'also',\n",
       "   'changed',\n",
       "   'to',\n",
       "   'ensure',\n",
       "   'exclusive',\n",
       "   'intradivisional',\n",
       "   'play',\n",
       "   'for',\n",
       "   'the',\n",
       "   'first',\n",
       "   'two',\n",
       "   'rounds',\n",
       "   'of',\n",
       "   'the',\n",
       "   '2021',\n",
       "   'Stanley',\n",
       "   'Cup',\n",
       "   'playoffs',\n",
       "   ',',\n",
       "   'any',\n",
       "   'postseason',\n",
       "   'rematch',\n",
       "   'between',\n",
       "   'Dallas',\n",
       "   'and',\n",
       "   'Tampa',\n",
       "   'Bay',\n",
       "   'will',\n",
       "   'take',\n",
       "   'place',\n",
       "   'no',\n",
       "   'later',\n",
       "   'than',\n",
       "   'the',\n",
       "   'second',\n",
       "   'round',\n",
       "   ',',\n",
       "   'making',\n",
       "   'this',\n",
       "   'series',\n",
       "   'the',\n",
       "   'first',\n",
       "   'Stanley',\n",
       "   'Cup',\n",
       "   'Finals',\n",
       "   'since',\n",
       "   '1967',\n",
       "   'Stanley',\n",
       "   'Cup',\n",
       "   'Finals',\n",
       "   '(',\n",
       "   'which',\n",
       "   'preceded',\n",
       "   'the',\n",
       "   '1967',\n",
       "   'NHL',\n",
       "   'expansion',\n",
       "   ')',\n",
       "   'for',\n",
       "   'which',\n",
       "   'a',\n",
       "   'rematch',\n",
       "   'in',\n",
       "   'the',\n",
       "   'following',\n",
       "   'year',\n",
       "   \"'s\",\n",
       "   'Finals',\n",
       "   'will',\n",
       "   'be',\n",
       "   'impossible',\n",
       "   'due',\n",
       "   'to',\n",
       "   'League',\n",
       "   'realignment',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '108'},\n",
       " {'tokens': ['She',\n",
       "   'died',\n",
       "   'after',\n",
       "   'giving',\n",
       "   'birth',\n",
       "   'to',\n",
       "   'a',\n",
       "   'boy',\n",
       "   'and',\n",
       "   'told',\n",
       "   'the',\n",
       "   'Brahman',\n",
       "   'about',\n",
       "   'the',\n",
       "   'real',\n",
       "   'identity',\n",
       "   'of',\n",
       "   'the',\n",
       "   'boy',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 54, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '109'},\n",
       " {'tokens': ['The',\n",
       "   'whole',\n",
       "   'area',\n",
       "   'where',\n",
       "   'the',\n",
       "   'Sports',\n",
       "   'Center',\n",
       "   'is',\n",
       "   'located',\n",
       "   'is',\n",
       "   'the',\n",
       "   'town',\n",
       "   \"'s\",\n",
       "   'most',\n",
       "   'important',\n",
       "   'entertainment',\n",
       "   'area',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 13, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '110'},\n",
       " {'tokens': ['Rivière',\n",
       "   'represented',\n",
       "   'the',\n",
       "   'first',\n",
       "   'constituency',\n",
       "   'of',\n",
       "   'Alpes-Maritimes',\n",
       "   'in',\n",
       "   'the',\n",
       "   'French',\n",
       "   'National',\n",
       "   'Assembly',\n",
       "   'from',\n",
       "   '2002',\n",
       "   'to',\n",
       "   '2007',\n",
       "   'as',\n",
       "   'a',\n",
       "   'member',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Union',\n",
       "   'for',\n",
       "   'a',\n",
       "   'Popular',\n",
       "   'Movement',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   0],\n",
       "  'id': '111'},\n",
       " {'tokens': ['Faculty',\n",
       "   'of',\n",
       "   'Food',\n",
       "   'Technology',\n",
       "   '(',\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'faculty',\n",
       "   'of',\n",
       "   'Latvia',\n",
       "   'University',\n",
       "   'of',\n",
       "   'Life',\n",
       "   'Sciences',\n",
       "   'and',\n",
       "   'Technologies',\n",
       "   'founded',\n",
       "   'in',\n",
       "   '1948',\n",
       "   '.'],\n",
       "  'coarse_tags': [2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '112'},\n",
       " {'tokens': ['However',\n",
       "   'both',\n",
       "   'Apdf',\n",
       "   'and',\n",
       "   'AmiPDF',\n",
       "   'are',\n",
       "   'native',\n",
       "   'and',\n",
       "   'need',\n",
       "   'no',\n",
       "   'X11',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 8, 0, 8, 0, 0, 0, 0, 0, 8, 0],\n",
       "  'fine_tags': [0, 0, 64, 0, 64, 0, 0, 0, 0, 0, 62, 0],\n",
       "  'id': '113'},\n",
       " {'tokens': ['He',\n",
       "   'continued',\n",
       "   'to',\n",
       "   'contribute',\n",
       "   'to',\n",
       "   'liberal',\n",
       "   'politics',\n",
       "   'and',\n",
       "   'published',\n",
       "   'poetry',\n",
       "   'and',\n",
       "   'hymns',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '114'},\n",
       " {'tokens': ['The',\n",
       "   'Club',\n",
       "   'later',\n",
       "   'changed',\n",
       "   'its',\n",
       "   'name',\n",
       "   'from',\n",
       "   'College',\n",
       "   'Barge',\n",
       "   'Club',\n",
       "   'to',\n",
       "   'College',\n",
       "   'Boat',\n",
       "   'Club',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 32, 32, 32, 0, 32, 32, 32, 0],\n",
       "  'id': '115'},\n",
       " {'tokens': ['In',\n",
       "   '2012',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Prosecco',\n",
       "   'research',\n",
       "   'team',\n",
       "   'at',\n",
       "   'I',\n",
       "   'NRIA',\n",
       "   'Paris-Rocquencourt',\n",
       "   'developed',\n",
       "   'an',\n",
       "   'efficient',\n",
       "   'method',\n",
       "   'of',\n",
       "   'extracting',\n",
       "   'the',\n",
       "   'secret',\n",
       "   'key',\n",
       "   'from',\n",
       "   'several',\n",
       "   'PKCS',\n",
       "   '#',\n",
       "   '11',\n",
       "   'cryptographic',\n",
       "   'devices',\n",
       "   ',',\n",
       "   'including',\n",
       "   'the',\n",
       "   'SecurID',\n",
       "   '800',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   0],\n",
       "  'id': '116'},\n",
       " {'tokens': ['William',\n",
       "   \"'s\",\n",
       "   'successful',\n",
       "   'invasion',\n",
       "   'of',\n",
       "   'England',\n",
       "   'with',\n",
       "   'a',\n",
       "   'Dutch',\n",
       "   'fleet',\n",
       "   'and',\n",
       "   'army',\n",
       "   'led',\n",
       "   'to',\n",
       "   'his',\n",
       "   'accession',\n",
       "   'to',\n",
       "   'the',\n",
       "   'English',\n",
       "   'throne',\n",
       "   'as',\n",
       "   'William',\n",
       "   'III',\n",
       "   'of',\n",
       "   'England',\n",
       "   'jointly',\n",
       "   'with',\n",
       "   'his',\n",
       "   'wife',\n",
       "   'Mary',\n",
       "   'II',\n",
       "   'of',\n",
       "   'England',\n",
       "   ',',\n",
       "   'James',\n",
       "   \"'\",\n",
       "   'daughter',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '117'},\n",
       " {'tokens': ['Construction',\n",
       "   'of',\n",
       "   'Tarbela',\n",
       "   'Dam',\n",
       "   'was',\n",
       "   'carried',\n",
       "   'out',\n",
       "   'in',\n",
       "   'three',\n",
       "   'stages',\n",
       "   'to',\n",
       "   'meet',\n",
       "   'the',\n",
       "   'diversion',\n",
       "   'requirements',\n",
       "   'of',\n",
       "   'the',\n",
       "   'river',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '118'},\n",
       " {'tokens': ['Lead',\n",
       "   'guitar',\n",
       "   'was',\n",
       "   'not',\n",
       "   'played',\n",
       "   'by',\n",
       "   'Ace',\n",
       "   'Frehley',\n",
       "   'as',\n",
       "   'he',\n",
       "   'was',\n",
       "   'not',\n",
       "   'musically',\n",
       "   'involved',\n",
       "   'with',\n",
       "   'the',\n",
       "   'album',\n",
       "   'and',\n",
       "   'it',\n",
       "   'was',\n",
       "   'not',\n",
       "   'played',\n",
       "   'by',\n",
       "   'Vinnie',\n",
       "   'Vincent',\n",
       "   'either',\n",
       "   ';',\n",
       "   'it',\n",
       "   'was',\n",
       "   'played',\n",
       "   'by',\n",
       "   'Steve',\n",
       "   'Farris',\n",
       "   ',',\n",
       "   'who',\n",
       "   'would',\n",
       "   'go',\n",
       "   'on',\n",
       "   'to',\n",
       "   'be',\n",
       "   'the',\n",
       "   'lead',\n",
       "   'guitarist',\n",
       "   'of',\n",
       "   'the',\n",
       "   '1980s',\n",
       "   'pop',\n",
       "   'rock',\n",
       "   'group',\n",
       "   'Mr.',\n",
       "   'Mister',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   0],\n",
       "  'id': '119'},\n",
       " {'tokens': ['He', 'died', 'in', 'a', 'plane', 'crash', 'in', '2002', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '120'},\n",
       " {'tokens': ['The',\n",
       "   'house',\n",
       "   'he',\n",
       "   'lived',\n",
       "   'in',\n",
       "   'on',\n",
       "   'Coldwell',\n",
       "   'Street',\n",
       "   'is',\n",
       "   'called',\n",
       "   'Treves',\n",
       "   'House',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 2, 2, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 27, 27, 0, 0, 11, 11, 0],\n",
       "  'id': '121'},\n",
       " {'tokens': ['The',\n",
       "   'development',\n",
       "   'was',\n",
       "   'devised',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Greek',\n",
       "   'planner',\n",
       "   'Constantinos',\n",
       "   'Apostolou',\n",
       "   'Doxiadis',\n",
       "   ',',\n",
       "   'who',\n",
       "   'also',\n",
       "   'designed',\n",
       "   'Islamabad',\n",
       "   'and',\n",
       "   'Riyadh',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 4, 0, 7, 7, 7, 0, 0, 0, 0, 2, 0, 2, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 21, 0, 54, 54, 54, 0, 0, 0, 0, 11, 0, 11, 0],\n",
       "  'id': '122'},\n",
       " {'tokens': ['The',\n",
       "   'quarterfinals',\n",
       "   'of',\n",
       "   'the',\n",
       "   'tournament',\n",
       "   'will',\n",
       "   'be',\n",
       "   'held',\n",
       "   'at',\n",
       "   'campus',\n",
       "   'sites',\n",
       "   ',',\n",
       "   'while',\n",
       "   'the',\n",
       "   'semifinals',\n",
       "   'and',\n",
       "   'final',\n",
       "   'took',\n",
       "   'place',\n",
       "   'at',\n",
       "   'Glenn',\n",
       "   'Warner',\n",
       "   'Soccer',\n",
       "   'Facility',\n",
       "   'in',\n",
       "   'Annapolis',\n",
       "   ',',\n",
       "   'Maryland',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   13,\n",
       "   13,\n",
       "   13,\n",
       "   13,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '123'},\n",
       " {'tokens': ['275',\n",
       "   'creating',\n",
       "   'a',\n",
       "   'special',\n",
       "   'oversight',\n",
       "   'committee',\n",
       "   'for',\n",
       "   'the',\n",
       "   'special',\n",
       "   'protection',\n",
       "   'of',\n",
       "   'children',\n",
       "   'from',\n",
       "   'all',\n",
       "   'forms',\n",
       "   'of',\n",
       "   'neglect',\n",
       "   ',',\n",
       "   'abuse',\n",
       "   ',',\n",
       "   'cruelty',\n",
       "   ',',\n",
       "   'exploitation',\n",
       "   ',',\n",
       "   'discrimination',\n",
       "   'and',\n",
       "   'other',\n",
       "   'conditions',\n",
       "   'prejudicial',\n",
       "   'to',\n",
       "   'their',\n",
       "   'development',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '124'},\n",
       " {'tokens': ['He',\n",
       "   'watched',\n",
       "   'the',\n",
       "   '1958',\n",
       "   'World',\n",
       "   'Cup',\n",
       "   'as',\n",
       "   'a',\n",
       "   'journalist',\n",
       "   'and',\n",
       "   'saw',\n",
       "   'the',\n",
       "   'Brazilian',\n",
       "   'national',\n",
       "   'football',\n",
       "   'team',\n",
       "   \"'s\",\n",
       "   'football',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 20, 20, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '125'},\n",
       " {'tokens': ['Bottlenose',\n",
       "   'dolphins',\n",
       "   'live',\n",
       "   'in',\n",
       "   'captivity',\n",
       "   'across',\n",
       "   'the',\n",
       "   'world',\n",
       "   ',',\n",
       "   'though',\n",
       "   'exact',\n",
       "   'numbers',\n",
       "   'are',\n",
       "   'hard',\n",
       "   'to',\n",
       "   'determine',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '126'},\n",
       " {'tokens': ['Both', 'fights', 'took', 'place', 'at', 'featherweight', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '127'},\n",
       " {'tokens': ['Born',\n",
       "   'in',\n",
       "   '1943',\n",
       "   ',',\n",
       "   'Stedman',\n",
       "   'attended',\n",
       "   'the',\n",
       "   'University',\n",
       "   'of',\n",
       "   'Canterbury',\n",
       "   ',',\n",
       "   'graduating',\n",
       "   'with',\n",
       "   'a',\n",
       "   'BSc',\n",
       "   '(',\n",
       "   'Hons',\n",
       "   ')',\n",
       "   'in',\n",
       "   'physics',\n",
       "   'in',\n",
       "   '1965',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   56,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   44,\n",
       "   44,\n",
       "   44,\n",
       "   44,\n",
       "   44,\n",
       "   44,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '128'},\n",
       " {'tokens': ['On',\n",
       "   'commencement',\n",
       "   'day',\n",
       "   ',',\n",
       "   'June',\n",
       "   '22',\n",
       "   ',',\n",
       "   'less',\n",
       "   'than',\n",
       "   '4',\n",
       "   'weeks',\n",
       "   'after',\n",
       "   'the',\n",
       "   'Court',\n",
       "   'began',\n",
       "   'interviewing',\n",
       "   'students',\n",
       "   ',',\n",
       "   'the',\n",
       "   'senior',\n",
       "   'class',\n",
       "   'exercises',\n",
       "   'in',\n",
       "   'Sanders',\n",
       "   'Theatre',\n",
       "   'were',\n",
       "   'followed',\n",
       "   'by',\n",
       "   'another',\n",
       "   'ceremony',\n",
       "   'at',\n",
       "   'the',\n",
       "   'stadium',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   14,\n",
       "   14,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '129'},\n",
       " {'tokens': ['Cantelo',\n",
       "   \"'s\",\n",
       "   'two',\n",
       "   'sons',\n",
       "   'happened',\n",
       "   'across',\n",
       "   'a',\n",
       "   'photograph',\n",
       "   'of',\n",
       "   'Maxim',\n",
       "   ',',\n",
       "   'whose',\n",
       "   'similarity',\n",
       "   'to',\n",
       "   'their',\n",
       "   'father',\n",
       "   'led',\n",
       "   'them',\n",
       "   'to',\n",
       "   'believe',\n",
       "   'that',\n",
       "   'he',\n",
       "   'was',\n",
       "   'still',\n",
       "   'alive',\n",
       "   'and',\n",
       "   'had',\n",
       "   'assumed',\n",
       "   'a',\n",
       "   'new',\n",
       "   'identity',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '130'},\n",
       " {'tokens': ['BIDS',\n",
       "   'functionality',\n",
       "   'can',\n",
       "   'be',\n",
       "   'augmented',\n",
       "   'with',\n",
       "   'BIDS',\n",
       "   'Helper',\n",
       "   ',',\n",
       "   'a',\n",
       "   'Visual',\n",
       "   'Studio',\n",
       "   'add-in',\n",
       "   'with',\n",
       "   'features',\n",
       "   'that',\n",
       "   'extended',\n",
       "   'and',\n",
       "   'enhance',\n",
       "   'business',\n",
       "   'intelligence',\n",
       "   'development',\n",
       "   'functionality',\n",
       "   'in',\n",
       "   'SQL',\n",
       "   'Server',\n",
       "   '2005',\n",
       "   ',',\n",
       "   '200',\n",
       "   '8',\n",
       "   ',',\n",
       "   'and',\n",
       "   '2008',\n",
       "   'R2',\n",
       "   'BI',\n",
       "   'Development',\n",
       "   'Studio',\n",
       "   '(',\n",
       "   'BIDS',\n",
       "   ')',\n",
       "   'and',\n",
       "   'SQL',\n",
       "   'Server',\n",
       "   '2012',\n",
       "   'SQL',\n",
       "   'Server',\n",
       "   'Data',\n",
       "   'Tools',\n",
       "   '(',\n",
       "   'SSDT',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [64,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   0,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   0,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   0,\n",
       "   64,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '131'},\n",
       " {'tokens': ['The',\n",
       "   'season',\n",
       "   'aired',\n",
       "   'on',\n",
       "   'Nickelodeon',\n",
       "   ',',\n",
       "   'which',\n",
       "   'is',\n",
       "   'owned',\n",
       "   'by',\n",
       "   'Viacom',\n",
       "   ',',\n",
       "   'and',\n",
       "   'was',\n",
       "   'produced',\n",
       "   'by',\n",
       "   'United',\n",
       "   'Plankton',\n",
       "   'Pictures',\n",
       "   'and',\n",
       "   'Nickelodeon',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   31,\n",
       "   0],\n",
       "  'id': '132'},\n",
       " {'tokens': ['The',\n",
       "   'Pistons',\n",
       "   'had',\n",
       "   'just',\n",
       "   'dispatched',\n",
       "   'the',\n",
       "   'Celtics',\n",
       "   'in',\n",
       "   'six',\n",
       "   'games',\n",
       "   ',',\n",
       "   'while',\n",
       "   'the',\n",
       "   'Lakers',\n",
       "   'were',\n",
       "   'coming',\n",
       "   'off',\n",
       "   'back-to-back',\n",
       "   'seven-game',\n",
       "   'wins',\n",
       "   'over',\n",
       "   'the',\n",
       "   'Utah',\n",
       "   'Jazz',\n",
       "   'and',\n",
       "   'Dallas',\n",
       "   'Mavericks',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0],\n",
       "  'id': '133'},\n",
       " {'tokens': ['However',\n",
       "   ',',\n",
       "   'the',\n",
       "   'land',\n",
       "   'was',\n",
       "   'owned',\n",
       "   'by',\n",
       "   'Israel',\n",
       "   'Railways',\n",
       "   'and',\n",
       "   'not',\n",
       "   'approved',\n",
       "   'for',\n",
       "   'building',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 28, 28, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '134'},\n",
       " {'tokens': ['The',\n",
       "   'village',\n",
       "   'was',\n",
       "   'badly',\n",
       "   'affected',\n",
       "   'by',\n",
       "   'the',\n",
       "   'French',\n",
       "   'Dysentery',\n",
       "   'Epidemic',\n",
       "   'of',\n",
       "   '1779',\n",
       "   'such',\n",
       "   'that',\n",
       "   '250',\n",
       "   'died',\n",
       "   'and',\n",
       "   'the',\n",
       "   'graveyard',\n",
       "   'had',\n",
       "   'to',\n",
       "   'be',\n",
       "   'extended',\n",
       "   'this',\n",
       "   'may',\n",
       "   'be',\n",
       "   'the',\n",
       "   'origin',\n",
       "   'of',\n",
       "   'the',\n",
       "   'five',\n",
       "   'crosses',\n",
       "   '(',\n",
       "   'Les',\n",
       "   'Cinq',\n",
       "   'Croix',\n",
       "   ')'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   43,\n",
       "   43,\n",
       "   43,\n",
       "   43,\n",
       "   43,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '135'},\n",
       " {'tokens': ['Ex-',\n",
       "   'Lizzy',\n",
       "   'guitarist',\n",
       "   'Brian',\n",
       "   'Robertson',\n",
       "   'was',\n",
       "   'asked',\n",
       "   'if',\n",
       "   'he',\n",
       "   'wanted',\n",
       "   'to',\n",
       "   'participate',\n",
       "   'but',\n",
       "   'had',\n",
       "   'previous',\n",
       "   'commitments',\n",
       "   'to',\n",
       "   'his',\n",
       "   'own',\n",
       "   'solo',\n",
       "   'career',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   35,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '136'},\n",
       " {'tokens': ['He',\n",
       "   'has',\n",
       "   'since',\n",
       "   'written',\n",
       "   'and',\n",
       "   'directed',\n",
       "   'nineteen',\n",
       "   'features',\n",
       "   ',',\n",
       "   'including',\n",
       "   '``',\n",
       "   'Mad',\n",
       "   'Jack',\n",
       "   '``',\n",
       "   '(',\n",
       "   '2000',\n",
       "   ')',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Goth',\n",
       "   '``',\n",
       "   '(',\n",
       "   '2003',\n",
       "   ')',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Demon',\n",
       "   \"'s\",\n",
       "   'Kiss',\n",
       "   '``',\n",
       "   'and',\n",
       "   '``',\n",
       "   'Within',\n",
       "   'the',\n",
       "   'Woods',\n",
       "   '``',\n",
       "   ',',\n",
       "   'along',\n",
       "   'with',\n",
       "   'creating',\n",
       "   'two',\n",
       "   'independent',\n",
       "   'horror',\n",
       "   'franchises',\n",
       "   ',',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Camp',\n",
       "   'Blood',\n",
       "   '``',\n",
       "   'and',\n",
       "   '``',\n",
       "   'Death',\n",
       "   'Factory',\n",
       "   '``',\n",
       "   'series',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '137'},\n",
       " {'tokens': ['K2',\n",
       "   'is',\n",
       "   'further',\n",
       "   'north',\n",
       "   'than',\n",
       "   'the',\n",
       "   'Himalayan',\n",
       "   'mountains',\n",
       "   'so',\n",
       "   'the',\n",
       "   'climate',\n",
       "   'is',\n",
       "   'colder',\n",
       "   ';',\n",
       "   'the',\n",
       "   'Karakoram',\n",
       "   'range',\n",
       "   'is',\n",
       "   'wider',\n",
       "   'than',\n",
       "   'the',\n",
       "   'Himalayan',\n",
       "   'so',\n",
       "   'more',\n",
       "   'ice',\n",
       "   'and',\n",
       "   'snow',\n",
       "   'is',\n",
       "   'trapped',\n",
       "   'there',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [24,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   24,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   24,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   24,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '138'},\n",
       " {'tokens': ['In',\n",
       "   '2012',\n",
       "   ',',\n",
       "   'Rajasthan',\n",
       "   'government',\n",
       "   'in',\n",
       "   'India',\n",
       "   'declared',\n",
       "   '``',\n",
       "   'Jawai',\n",
       "   'Bandh',\n",
       "   'forests',\n",
       "   '``',\n",
       "   'as',\n",
       "   'a',\n",
       "   'conservation',\n",
       "   'reserve',\n",
       "   'forest',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 5, 5, 0, 4, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 30, 30, 0, 21, 0, 0, 25, 25, 25, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '139'},\n",
       " {'tokens': ['After',\n",
       "   'the',\n",
       "   'disaster',\n",
       "   'of',\n",
       "   'Helike',\n",
       "   ',',\n",
       "   'which',\n",
       "   'was',\n",
       "   'destroyed',\n",
       "   'by',\n",
       "   'an',\n",
       "   'earthquake',\n",
       "   'and',\n",
       "   'buried',\n",
       "   'by',\n",
       "   'a',\n",
       "   'tsunami',\n",
       "   'in',\n",
       "   '373',\n",
       "   'BC',\n",
       "   ',',\n",
       "   'Aigion',\n",
       "   'took',\n",
       "   'the',\n",
       "   'territory',\n",
       "   'of',\n",
       "   'the',\n",
       "   'neighbouring',\n",
       "   'city',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '140'},\n",
       " {'tokens': ['Robert',\n",
       "   'Barnes',\n",
       "   'was',\n",
       "   'a',\n",
       "   'philanthropist',\n",
       "   'during',\n",
       "   'his',\n",
       "   'lifetime',\n",
       "   ',',\n",
       "   'but',\n",
       "   'his',\n",
       "   'greatest',\n",
       "   'contribution',\n",
       "   'came',\n",
       "   'after',\n",
       "   'this',\n",
       "   'death',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [54, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '141'},\n",
       " {'tokens': ['After',\n",
       "   'losing',\n",
       "   'another',\n",
       "   'two',\n",
       "   'seats',\n",
       "   'in',\n",
       "   'the',\n",
       "   'March',\n",
       "   '1898',\n",
       "   'elections',\n",
       "   ',',\n",
       "   'the',\n",
       "   'party',\n",
       "   'merged',\n",
       "   'with',\n",
       "   'Shimpotō',\n",
       "   'in',\n",
       "   'June',\n",
       "   '1898',\n",
       "   'to',\n",
       "   'form',\n",
       "   'the',\n",
       "   'Kenseitō',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   0],\n",
       "  'id': '142'},\n",
       " {'tokens': ['The',\n",
       "   'event',\n",
       "   'took',\n",
       "   'place',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Racquet',\n",
       "   'Park',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Amelia',\n",
       "   'Island',\n",
       "   'Plantation',\n",
       "   ',',\n",
       "   'in',\n",
       "   'Amelia',\n",
       "   'Island',\n",
       "   ',',\n",
       "   'Florida',\n",
       "   ',',\n",
       "   'U.S',\n",
       "   '.',\n",
       "   'from',\n",
       "   'April',\n",
       "   '2',\n",
       "   'through',\n",
       "   'April',\n",
       "   '8',\n",
       "   ',',\n",
       "   '2007',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '143'},\n",
       " {'tokens': ['After',\n",
       "   'they',\n",
       "   'see',\n",
       "   'the',\n",
       "   'picture',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Castle',\n",
       "   'and',\n",
       "   'try',\n",
       "   'their',\n",
       "   'hand',\n",
       "   'at',\n",
       "   'the',\n",
       "   'games',\n",
       "   'they',\n",
       "   'might',\n",
       "   'come',\n",
       "   'here',\n",
       "   'and',\n",
       "   'try',\n",
       "   'the',\n",
       "   'real',\n",
       "   'thing',\n",
       "   '.',\n",
       "   \"''\"],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '144'},\n",
       " {'tokens': ['Ismaridae',\n",
       "   'is',\n",
       "   'a',\n",
       "   'family',\n",
       "   'of',\n",
       "   'insects',\n",
       "   'belonging',\n",
       "   'to',\n",
       "   'the',\n",
       "   'order',\n",
       "   'Hymenoptera',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0],\n",
       "  'fine_tags': [40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 40, 0],\n",
       "  'id': '145'},\n",
       " {'tokens': ['1', ',', '22', 'June', '1895', 'to', '1896', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '146'},\n",
       " {'tokens': ['In',\n",
       "   'the',\n",
       "   'summer',\n",
       "   'of',\n",
       "   '2010',\n",
       "   ',',\n",
       "   'authorities',\n",
       "   'launched',\n",
       "   'a',\n",
       "   'two-month-long',\n",
       "   'crackdown',\n",
       "   'campaign',\n",
       "   'against',\n",
       "   'opposition',\n",
       "   'activists',\n",
       "   'arresting',\n",
       "   'more',\n",
       "   'than',\n",
       "   '250',\n",
       "   'individuals',\n",
       "   'including',\n",
       "   '23',\n",
       "   'leading',\n",
       "   'activists',\n",
       "   ',',\n",
       "   'most',\n",
       "   'of',\n",
       "   'them',\n",
       "   'members',\n",
       "   'of',\n",
       "   'Haq',\n",
       "   'Movement',\n",
       "   'and',\n",
       "   'Al',\n",
       "   'Wafa',\n",
       "   \"'\",\n",
       "   'Islamic',\n",
       "   'party',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   0,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '147'},\n",
       " {'tokens': ['She',\n",
       "   'also',\n",
       "   'did',\n",
       "   'a',\n",
       "   'presentation',\n",
       "   'for',\n",
       "   'sponsor',\n",
       "   'Pepsi-Cola',\n",
       "   'and',\n",
       "   'bantered',\n",
       "   'a',\n",
       "   'bit',\n",
       "   'with',\n",
       "   'humorist',\n",
       "   'Sam',\n",
       "   'Levenson',\n",
       "   'who',\n",
       "   'stated',\n",
       "   'how',\n",
       "   'glad',\n",
       "   'he',\n",
       "   'was',\n",
       "   'to',\n",
       "   'be',\n",
       "   'alive',\n",
       "   'in',\n",
       "   'these',\n",
       "   'times',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '148'},\n",
       " {'tokens': ['The',\n",
       "   'Travancore',\n",
       "   'Rupee',\n",
       "   'was',\n",
       "   'the',\n",
       "   'highest',\n",
       "   'denomination',\n",
       "   'of',\n",
       "   'currency',\n",
       "   'issued',\n",
       "   'for',\n",
       "   'general',\n",
       "   'circulation',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 42, 42, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '149'},\n",
       " {'tokens': ['According',\n",
       "   'to',\n",
       "   'Bajpayee',\n",
       "   ',',\n",
       "   'the',\n",
       "   'role',\n",
       "   'of',\n",
       "   'Sardar',\n",
       "   'Khan',\n",
       "   'is',\n",
       "   'the',\n",
       "   'most',\n",
       "   'negative',\n",
       "   'role',\n",
       "   'he',\n",
       "   'has',\n",
       "   'done',\n",
       "   'till',\n",
       "   'date',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 50, 0, 0, 0, 0, 54, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '150'},\n",
       " {'tokens': ['The',\n",
       "   '1941–42',\n",
       "   'cricket',\n",
       "   'season',\n",
       "   'was',\n",
       "   'cancelled',\n",
       "   'and',\n",
       "   'many',\n",
       "   'cricket',\n",
       "   'and',\n",
       "   'football',\n",
       "   'grounds',\n",
       "   'were',\n",
       "   'converted',\n",
       "   'into',\n",
       "   'army',\n",
       "   'bases',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '151'},\n",
       " {'tokens': ['Reynolds',\n",
       "   'Reynolds',\n",
       "   'was',\n",
       "   'Costner',\n",
       "   'Costner',\n",
       "   \"'s\",\n",
       "   'uncredited',\n",
       "   'second',\n",
       "   'unit',\n",
       "   'director',\n",
       "   'and',\n",
       "   'set',\n",
       "   'advisor',\n",
       "   'for',\n",
       "   'the',\n",
       "   'western',\n",
       "   'epic',\n",
       "   'and',\n",
       "   'Costner',\n",
       "   'Costner',\n",
       "   'directorial',\n",
       "   'debut',\n",
       "   '``',\n",
       "   'Dances',\n",
       "   'with',\n",
       "   'Wolves',\n",
       "   '``',\n",
       "   '(',\n",
       "   '1990',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [50,\n",
       "   53,\n",
       "   0,\n",
       "   50,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   50,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '152'},\n",
       " {'tokens': ['Until',\n",
       "   '1928',\n",
       "   'there',\n",
       "   'were',\n",
       "   'no',\n",
       "   'official',\n",
       "   'RFB',\n",
       "   'groups',\n",
       "   'in',\n",
       "   'Bavaria',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 5, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 32, 0, 0, 21, 0],\n",
       "  'id': '153'},\n",
       " {'tokens': ['The',\n",
       "   'Kiev',\n",
       "   'pocket',\n",
       "   'was',\n",
       "   'sealed',\n",
       "   'when',\n",
       "   'panzers',\n",
       "   'of',\n",
       "   'the',\n",
       "   '3',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '154'},\n",
       " {'tokens': ['To',\n",
       "   'this',\n",
       "   'end',\n",
       "   'Turner',\n",
       "   'convinced',\n",
       "   'the',\n",
       "   'Spartacist',\n",
       "   'League',\n",
       "   'to',\n",
       "   'create',\n",
       "   'a',\n",
       "   'pan-union',\n",
       "   'Militant',\n",
       "   'Labor',\n",
       "   'Civil',\n",
       "   'Rights',\n",
       "   'Committee',\n",
       "   'in',\n",
       "   'September',\n",
       "   '1967',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '155'},\n",
       " {'tokens': ['The',\n",
       "   'ZSU-57-2',\n",
       "   'first',\n",
       "   'saw',\n",
       "   'major',\n",
       "   'use',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Vietnam',\n",
       "   'War',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Vietnam',\n",
       "   'People',\n",
       "   \"'s\",\n",
       "   'Army',\n",
       "   '(',\n",
       "   'VPA',\n",
       "   ')',\n",
       "   ',',\n",
       "   'in',\n",
       "   'the',\n",
       "   'beginning',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Easter',\n",
       "   'Offensive',\n",
       "   'in',\n",
       "   '1972',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   66,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '156'},\n",
       " {'tokens': ['There', 'are', 'two', '400', 'kV', 'lines', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '157'},\n",
       " {'tokens': ['The',\n",
       "   'draw',\n",
       "   'took',\n",
       "   'place',\n",
       "   'on',\n",
       "   '29',\n",
       "   'May',\n",
       "   '2019',\n",
       "   'at',\n",
       "   'Radisson',\n",
       "   'Blu',\n",
       "   'Sea',\n",
       "   'Plaza',\n",
       "   'Hotel',\n",
       "   'in',\n",
       "   'Dakar',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 0, 21, 0],\n",
       "  'id': '158'},\n",
       " {'tokens': ['In',\n",
       "   'Cochin',\n",
       "   ',',\n",
       "   'India',\n",
       "   ',',\n",
       "   'at',\n",
       "   'the',\n",
       "   'shore',\n",
       "   'establishment',\n",
       "   'HMS',\n",
       "   '``',\n",
       "   'Chinkara',\n",
       "   \"''\",\n",
       "   '(',\n",
       "   'home',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Landing',\n",
       "   'Craft',\n",
       "   'Storage',\n",
       "   ',',\n",
       "   'Section',\n",
       "   '21',\n",
       "   ')',\n",
       "   ',',\n",
       "   'many',\n",
       "   'such',\n",
       "   'craft',\n",
       "   'were',\n",
       "   'towed',\n",
       "   'out',\n",
       "   'to',\n",
       "   'the',\n",
       "   '10',\n",
       "   'fathom',\n",
       "   'mark',\n",
       "   'and',\n",
       "   'sunk',\n",
       "   'by',\n",
       "   'various',\n",
       "   'means',\n",
       "   'from',\n",
       "   'axe',\n",
       "   'to',\n",
       "   '40mm',\n",
       "   'Bofors',\n",
       "   'gun',\n",
       "   'fire',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   63,\n",
       "   63,\n",
       "   63,\n",
       "   63,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   66,\n",
       "   66,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '159'},\n",
       " {'tokens': ['Jonathan',\n",
       "   'Ormond',\n",
       "   'Torrens',\n",
       "   'is',\n",
       "   'a',\n",
       "   'Canadian',\n",
       "   'actor',\n",
       "   'and',\n",
       "   'television',\n",
       "   'personality',\n",
       "   'best',\n",
       "   'known',\n",
       "   'for',\n",
       "   'his',\n",
       "   'co-hosting',\n",
       "   'of',\n",
       "   '``',\n",
       "   'Street',\n",
       "   'Cents',\n",
       "   '``',\n",
       "   ',',\n",
       "   'his',\n",
       "   'talk',\n",
       "   'show',\n",
       "   '``',\n",
       "   'Jonovision',\n",
       "   '``',\n",
       "   ',',\n",
       "   'and',\n",
       "   'his',\n",
       "   'role',\n",
       "   'as',\n",
       "   '``',\n",
       "   'J-Roc',\n",
       "   '``',\n",
       "   'in',\n",
       "   'the',\n",
       "   'popular',\n",
       "   'Canadian',\n",
       "   'mockumentary',\n",
       "   '``',\n",
       "   'Trailer',\n",
       "   'Park',\n",
       "   'Boys',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [50,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '160'},\n",
       " {'tokens': ['Local',\n",
       "   'people',\n",
       "   'raised',\n",
       "   'money',\n",
       "   'to',\n",
       "   'construct',\n",
       "   'it',\n",
       "   'in',\n",
       "   '1905',\n",
       "   'and',\n",
       "   'reconstructed',\n",
       "   'it',\n",
       "   'many',\n",
       "   'times',\n",
       "   'afterwards',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '161'},\n",
       " {'tokens': ['Accordingly',\n",
       "   ',',\n",
       "   'R101',\n",
       "   'changed',\n",
       "   'course',\n",
       "   ':',\n",
       "   'the',\n",
       "   'new',\n",
       "   'course',\n",
       "   'would',\n",
       "   'take',\n",
       "   'it',\n",
       "   'directly',\n",
       "   'over',\n",
       "   'the',\n",
       "   'Beauvais',\n",
       "   'Ridge',\n",
       "   ',',\n",
       "   'an',\n",
       "   'area',\n",
       "   'notorious',\n",
       "   'for',\n",
       "   'turbulent',\n",
       "   'wind',\n",
       "   'conditions',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '162'},\n",
       " {'tokens': ['As',\n",
       "   'of',\n",
       "   '692—after',\n",
       "   'Wu',\n",
       "   'Zetian',\n",
       "   'had',\n",
       "   'seized',\n",
       "   'the',\n",
       "   'throne',\n",
       "   'from',\n",
       "   'her',\n",
       "   'son',\n",
       "   'Emperor',\n",
       "   'Ruizong',\n",
       "   'in',\n",
       "   '690',\n",
       "   'and',\n",
       "   'taken',\n",
       "   'the',\n",
       "   'throne',\n",
       "   'herself',\n",
       "   ',',\n",
       "   'establishing',\n",
       "   'Zhou',\n",
       "   'and',\n",
       "   'interrupting',\n",
       "   'Tang—',\n",
       "   'Li',\n",
       "   'Zhaode',\n",
       "   'was',\n",
       "   'still',\n",
       "   'serving',\n",
       "   'as',\n",
       "   'the',\n",
       "   'deputy',\n",
       "   'minister',\n",
       "   'of',\n",
       "   'defense',\n",
       "   'when',\n",
       "   'he',\n",
       "   'secretly',\n",
       "   'suggested',\n",
       "   'to',\n",
       "   'Wu',\n",
       "   'Zetian',\n",
       "   'that',\n",
       "   'her',\n",
       "   'nephew',\n",
       "   'Wu',\n",
       "   'Chengsi',\n",
       "   'the',\n",
       "   'Prince',\n",
       "   'of',\n",
       "   'Wei',\n",
       "   'was',\n",
       "   'becoming',\n",
       "   'too',\n",
       "   'powerful',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '163'},\n",
       " {'tokens': ['It',\n",
       "   'is',\n",
       "   'considered',\n",
       "   'to',\n",
       "   'be',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'holiest',\n",
       "   'Islamic',\n",
       "   'sites',\n",
       "   'in',\n",
       "   'Egypt',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 21, 0],\n",
       "  'id': '164'},\n",
       " {'tokens': ['With',\n",
       "   'a',\n",
       "   'total',\n",
       "   'tournament',\n",
       "   'attendance',\n",
       "   'of',\n",
       "   '18,901',\n",
       "   ',',\n",
       "   'this',\n",
       "   'remains',\n",
       "   'this',\n",
       "   'best',\n",
       "   'attended',\n",
       "   'men',\n",
       "   \"'s\",\n",
       "   'volleyball',\n",
       "   'championship',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '165'},\n",
       " {'tokens': ['The',\n",
       "   'new',\n",
       "   'building',\n",
       "   'contained',\n",
       "   'the',\n",
       "   'Trumbull',\n",
       "   'dining',\n",
       "   'hall',\n",
       "   ',',\n",
       "   'common',\n",
       "   'room',\n",
       "   ',',\n",
       "   'and',\n",
       "   'library',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '166'},\n",
       " {'tokens': ['His',\n",
       "   'firm',\n",
       "   'focuses',\n",
       "   'on',\n",
       "   'the',\n",
       "   'conversion',\n",
       "   'of',\n",
       "   'non-residential',\n",
       "   'buildings',\n",
       "   'to',\n",
       "   'residential',\n",
       "   'uses',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '167'},\n",
       " {'tokens': ['The',\n",
       "   'surgery',\n",
       "   'was',\n",
       "   'effective',\n",
       "   ',',\n",
       "   'and',\n",
       "   'he',\n",
       "   'lost',\n",
       "   'more',\n",
       "   'than',\n",
       "   'within',\n",
       "   'a',\n",
       "   'year',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '168'},\n",
       " {'tokens': ['``',\n",
       "   'Chanson',\n",
       "   \"d'Armor\",\n",
       "   '``',\n",
       "   'is',\n",
       "   'known',\n",
       "   'as',\n",
       "   'the',\n",
       "   'first',\n",
       "   'Breton-speaking',\n",
       "   'film',\n",
       "   'in',\n",
       "   'history',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 1, 1, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 2, 2, 0, 0, 0, 0, 0, 0, 46, 0, 0, 0, 0],\n",
       "  'id': '169'},\n",
       " {'tokens': ['3',\n",
       "   'Idiots',\n",
       "   'is',\n",
       "   'a',\n",
       "   'Pakistani',\n",
       "   'television',\n",
       "   'series',\n",
       "   'that',\n",
       "   'airs',\n",
       "   'on',\n",
       "   'Aaj',\n",
       "   'TV',\n",
       "   'on',\n",
       "   'Saturdays',\n",
       "   'at',\n",
       "   '8',\n",
       "   'pm',\n",
       "   '.'],\n",
       "  'coarse_tags': [1, 1, 0, 0, 4, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [1, 1, 0, 0, 21, 0, 0, 0, 0, 0, 31, 31, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '170'},\n",
       " {'tokens': ['In',\n",
       "   'December',\n",
       "   '1976',\n",
       "   ',',\n",
       "   'Wendy',\n",
       "   \"'s\",\n",
       "   'opened',\n",
       "   'its',\n",
       "   '500th',\n",
       "   'restaurant',\n",
       "   ',',\n",
       "   'located',\n",
       "   'in',\n",
       "   'Toronto',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 28, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '171'},\n",
       " {'tokens': ['Between',\n",
       "   '1865',\n",
       "   'and',\n",
       "   '1867',\n",
       "   'she',\n",
       "   'became',\n",
       "   'a',\n",
       "   'pupil',\n",
       "   'of',\n",
       "   'Theodor',\n",
       "   'Kullak',\n",
       "   'and',\n",
       "   'studied',\n",
       "   'composition',\n",
       "   'under',\n",
       "   'Richard',\n",
       "   'Wuerst',\n",
       "   'at',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Akademie',\n",
       "   'der',\n",
       "   'Tonkunst',\n",
       "   '``',\n",
       "   'in',\n",
       "   'Berlin',\n",
       "   ',',\n",
       "   'where',\n",
       "   'she',\n",
       "   'lived',\n",
       "   'together',\n",
       "   'with',\n",
       "   'her',\n",
       "   'sister',\n",
       "   'Harriet',\n",
       "   'Backer',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0],\n",
       "  'id': '172'},\n",
       " {'tokens': ['Co-developer',\n",
       "   'Glenn',\n",
       "   'Howerton',\n",
       "   'described',\n",
       "   'the',\n",
       "   'show',\n",
       "   'as',\n",
       "   '``',\n",
       "   'essentially',\n",
       "   'an',\n",
       "   'expanded',\n",
       "   'version',\n",
       "   'of',\n",
       "   'the',\n",
       "   'actual',\n",
       "   'episode',\n",
       "   'of',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Nightman',\n",
       "   'Cometh',\n",
       "   ',',\n",
       "   '``',\n",
       "   'which',\n",
       "   'was',\n",
       "   'the',\n",
       "   'final',\n",
       "   'episode',\n",
       "   'for',\n",
       "   'season',\n",
       "   'four',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '173'},\n",
       " {'tokens': ['One',\n",
       "   'of',\n",
       "   'the',\n",
       "   'first',\n",
       "   'implementations',\n",
       "   'made',\n",
       "   'available',\n",
       "   'by',\n",
       "   'LPA',\n",
       "   'was',\n",
       "   'micro-PROLOG',\n",
       "   'which',\n",
       "   'ran',\n",
       "   'on',\n",
       "   'popular',\n",
       "   '8-bit',\n",
       "   'home',\n",
       "   'computers',\n",
       "   'such',\n",
       "   'as',\n",
       "   'the',\n",
       "   'Sinclair',\n",
       "   'Spectrum',\n",
       "   'and',\n",
       "   'Apple',\n",
       "   'II',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   0],\n",
       "  'id': '174'},\n",
       " {'tokens': ['She',\n",
       "   'also',\n",
       "   'bred',\n",
       "   'sea',\n",
       "   'monsters',\n",
       "   'and',\n",
       "   'her',\n",
       "   'great',\n",
       "   'waves',\n",
       "   'crashed',\n",
       "   'against',\n",
       "   'the',\n",
       "   'rocks',\n",
       "   ',',\n",
       "   'putting',\n",
       "   'sailors',\n",
       "   'at',\n",
       "   'risk',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '175'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'made',\n",
       "   'Knight',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Legion',\n",
       "   'of',\n",
       "   'Honour',\n",
       "   'in',\n",
       "   '1831',\n",
       "   'and',\n",
       "   'Officer',\n",
       "   'in',\n",
       "   '1835',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '176'},\n",
       " {'tokens': ['``',\n",
       "   'Champion',\n",
       "   'Lover',\n",
       "   '``',\n",
       "   'revealed',\n",
       "   'an',\n",
       "   'uncharacteristically',\n",
       "   'hard-edged',\n",
       "   'sound',\n",
       "   ',',\n",
       "   'with',\n",
       "   'the',\n",
       "   '12',\n",
       "   \"''\",\n",
       "   '``',\n",
       "   'Sex',\n",
       "   '``',\n",
       "   'mix',\n",
       "   'of',\n",
       "   'the',\n",
       "   'track',\n",
       "   'representing',\n",
       "   'a',\n",
       "   'move',\n",
       "   'towards',\n",
       "   'dancehall',\n",
       "   ',',\n",
       "   'and',\n",
       "   'sentiments',\n",
       "   'that',\n",
       "   'were',\n",
       "   'less',\n",
       "   'innocent',\n",
       "   'in',\n",
       "   'content',\n",
       "   'than',\n",
       "   'other',\n",
       "   'Glasgow',\n",
       "   'recordings',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '177'},\n",
       " {'tokens': ['In',\n",
       "   '1914',\n",
       "   ',',\n",
       "   'following',\n",
       "   'the',\n",
       "   'New',\n",
       "   'Zealand',\n",
       "   'occupation',\n",
       "   'of',\n",
       "   'German',\n",
       "   'Samoa',\n",
       "   ',',\n",
       "   'the',\n",
       "   'pound',\n",
       "   'sterling',\n",
       "   'replaced',\n",
       "   'the',\n",
       "   'German',\n",
       "   'mark',\n",
       "   'as',\n",
       "   'the',\n",
       "   'currency',\n",
       "   'of',\n",
       "   'the',\n",
       "   'territory',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '178'},\n",
       " {'tokens': ['Sam',\n",
       "   'was',\n",
       "   'the',\n",
       "   'starting',\n",
       "   'quarterback',\n",
       "   'for',\n",
       "   'the',\n",
       "   '2008',\n",
       "   'National',\n",
       "   'Champions',\n",
       "   ',',\n",
       "   'Coventry',\n",
       "   'Jets',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 5, 5, 0],\n",
       "  'fine_tags': [52, 0, 0, 0, 0, 0, 0, 0, 20, 20, 0, 37, 37, 0],\n",
       "  'id': '179'},\n",
       " {'tokens': ['The',\n",
       "   'character',\n",
       "   'will',\n",
       "   'be',\n",
       "   'portrayed',\n",
       "   'by',\n",
       "   'Sharon',\n",
       "   'Duncan-Brewster',\n",
       "   'in',\n",
       "   'the',\n",
       "   '2021',\n",
       "   'Denis',\n",
       "   'Villeneuve',\n",
       "   'film',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Dune',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 7, 7, 0, 0, 0, 1, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 50, 50, 0, 0, 0, 53, 53, 0, 0, 0, 2, 0, 0],\n",
       "  'id': '180'},\n",
       " {'tokens': ['He',\n",
       "   'is',\n",
       "   'afraid',\n",
       "   'of',\n",
       "   'monkeys',\n",
       "   ',',\n",
       "   'insects',\n",
       "   ',',\n",
       "   'and',\n",
       "   'many',\n",
       "   'other',\n",
       "   'things',\n",
       "   ',',\n",
       "   'though',\n",
       "   'his',\n",
       "   'fears',\n",
       "   'fluctuate',\n",
       "   'as',\n",
       "   'the',\n",
       "   'series',\n",
       "   'progresses',\n",
       "   'as',\n",
       "   'Ron',\n",
       "   'matures',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '181'},\n",
       " {'tokens': ['Simultaneously',\n",
       "   'launched',\n",
       "   'in',\n",
       "   'Switzerland',\n",
       "   ',',\n",
       "   'the',\n",
       "   'television',\n",
       "   'production',\n",
       "   'sweets',\n",
       "   ',',\n",
       "   'in',\n",
       "   'which',\n",
       "   'he',\n",
       "   'tries',\n",
       "   'to',\n",
       "   'save',\n",
       "   'as',\n",
       "   'a',\n",
       "   'charming',\n",
       "   'Blender',\n",
       "   'his',\n",
       "   'company',\n",
       "   'with',\n",
       "   'all',\n",
       "   'the',\n",
       "   'tricks',\n",
       "   'from',\n",
       "   'ruin',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '182'},\n",
       " {'tokens': ['Both',\n",
       "   'patchouli',\n",
       "   'oil',\n",
       "   'and',\n",
       "   'incense',\n",
       "   'underwent',\n",
       "   'a',\n",
       "   'surge',\n",
       "   'in',\n",
       "   'popularity',\n",
       "   'in',\n",
       "   'the',\n",
       "   '1960s',\n",
       "   'and',\n",
       "   '1970s',\n",
       "   'in',\n",
       "   'the',\n",
       "   'US',\n",
       "   'and',\n",
       "   'Europe',\n",
       "   ',',\n",
       "   'mainly',\n",
       "   'as',\n",
       "   'a',\n",
       "   'result',\n",
       "   'of',\n",
       "   'the',\n",
       "   'hippie',\n",
       "   'movement',\n",
       "   'of',\n",
       "   'those',\n",
       "   'decades',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '183'},\n",
       " {'tokens': ['She',\n",
       "   'made',\n",
       "   'her',\n",
       "   'debut',\n",
       "   'at',\n",
       "   'The',\n",
       "   'Proms',\n",
       "   'in',\n",
       "   '2000',\n",
       "   ',',\n",
       "   'singing',\n",
       "   'Mozart',\n",
       "   \"'s\",\n",
       "   'Mass',\n",
       "   'in',\n",
       "   'C',\n",
       "   'minor',\n",
       "   'and',\n",
       "   'Alban',\n",
       "   'Berg',\n",
       "   \"'s\",\n",
       "   '``',\n",
       "   'Altenberg',\n",
       "   'Lieder',\n",
       "   '``',\n",
       "   'with',\n",
       "   'the',\n",
       "   'Bochumer',\n",
       "   'Symphoniker',\n",
       "   ',',\n",
       "   'conducted',\n",
       "   'by',\n",
       "   'Simon',\n",
       "   'Rattle',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0],\n",
       "  'id': '184'},\n",
       " {'tokens': ['On',\n",
       "   '15',\n",
       "   'January',\n",
       "   '2016',\n",
       "   ',',\n",
       "   'Guto',\n",
       "   'transferred',\n",
       "   'to',\n",
       "   'China',\n",
       "   'League',\n",
       "   'One',\n",
       "   'side',\n",
       "   'Wuhan',\n",
       "   'Zall',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 0, 0, 5, 5, 5, 0, 5, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 52, 0, 0, 36, 36, 36, 0, 37, 37, 0],\n",
       "  'id': '185'},\n",
       " {'tokens': ['In',\n",
       "   'order',\n",
       "   'to',\n",
       "   'preserve',\n",
       "   'Rafflesiaceae',\n",
       "   ',',\n",
       "   'Wurdack',\n",
       "   'and',\n",
       "   'Davis',\n",
       "   'split',\n",
       "   'Euphorbiaceae',\n",
       "   'sensu',\n",
       "   'stricto',\n",
       "   'into',\n",
       "   'Euphorbiaceae',\n",
       "   'sensu',\n",
       "   'strictissimo',\n",
       "   'and',\n",
       "   'Peraceae',\n",
       "   ',',\n",
       "   'a',\n",
       "   'new',\n",
       "   'family',\n",
       "   'comprising',\n",
       "   '``',\n",
       "   'Pera',\n",
       "   \"''\",\n",
       "   'and',\n",
       "   'four',\n",
       "   'other',\n",
       "   'genera',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   56,\n",
       "   0,\n",
       "   56,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '186'},\n",
       " {'tokens': ['Cattle', 'trains', 'at', 'Luton', 'swimming', 'club', '.'],\n",
       "  'coarse_tags': [7, 0, 0, 4, 0, 0, 0],\n",
       "  'fine_tags': [52, 0, 0, 21, 0, 0, 0],\n",
       "  'id': '187'},\n",
       " {'tokens': ['Alexandros',\n",
       "   'is',\n",
       "   'best',\n",
       "   'known',\n",
       "   'today',\n",
       "   'for',\n",
       "   'the',\n",
       "   'Venus',\n",
       "   'de',\n",
       "   'Milo',\n",
       "   '(',\n",
       "   'Aphrodite',\n",
       "   'of',\n",
       "   'Milos',\n",
       "   ')',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Louvre',\n",
       "   'Museum',\n",
       "   'in',\n",
       "   'Paris',\n",
       "   ',',\n",
       "   'France',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '188'},\n",
       " {'tokens': ['Its',\n",
       "   'purpose',\n",
       "   'was',\n",
       "   'to',\n",
       "   'provide',\n",
       "   'a',\n",
       "   'number',\n",
       "   'of',\n",
       "   'basic',\n",
       "   'but',\n",
       "   'effective',\n",
       "   'pillbox',\n",
       "   'designs',\n",
       "   'that',\n",
       "   'could',\n",
       "   'be',\n",
       "   'constructed',\n",
       "   'by',\n",
       "   'soldiers',\n",
       "   'and',\n",
       "   'local',\n",
       "   'labour',\n",
       "   'at',\n",
       "   'appropriate',\n",
       "   'defensive',\n",
       "   'locations',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '189'},\n",
       " {'tokens': ['Ted',\n",
       "   'Robert',\n",
       "   'Gurr',\n",
       "   'has',\n",
       "   'also',\n",
       "   'modeled',\n",
       "   'political',\n",
       "   'violence',\n",
       "   ',',\n",
       "   'such',\n",
       "   'as',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Palestinian',\n",
       "   'territories',\n",
       "   'and',\n",
       "   'in',\n",
       "   'Rwanda',\n",
       "   '/',\n",
       "   'Congo',\n",
       "   '(',\n",
       "   'two',\n",
       "   'of',\n",
       "   'the',\n",
       "   'world',\n",
       "   \"'s\",\n",
       "   'regions',\n",
       "   'of',\n",
       "   'most',\n",
       "   'rapidly',\n",
       "   'growing',\n",
       "   'population',\n",
       "   ')',\n",
       "   'using',\n",
       "   'similar',\n",
       "   'variables',\n",
       "   'in',\n",
       "   'several',\n",
       "   'comparative',\n",
       "   'cases',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [56,\n",
       "   56,\n",
       "   56,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '190'},\n",
       " {'tokens': ['The', 'race', 'was', 'won', 'by', 'Fausto', 'Coppi', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 52, 52, 0],\n",
       "  'id': '191'},\n",
       " {'tokens': ['Also',\n",
       "   ',',\n",
       "   'voters',\n",
       "   'of',\n",
       "   'the',\n",
       "   'U.S',\n",
       "   '.',\n",
       "   'territories',\n",
       "   ',',\n",
       "   'commonwealths',\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'District',\n",
       "   'of',\n",
       "   'Columbia',\n",
       "   'chose',\n",
       "   'their',\n",
       "   'non-voting',\n",
       "   'delegates',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '192'},\n",
       " {'tokens': ['The',\n",
       "   'title',\n",
       "   'song',\n",
       "   'was',\n",
       "   'composed',\n",
       "   'specifically',\n",
       "   'for',\n",
       "   'the',\n",
       "   'advertisement',\n",
       "   'by',\n",
       "   'Jonze',\n",
       "   \"'s\",\n",
       "   'brother',\n",
       "   ',',\n",
       "   'Sam',\n",
       "   '``',\n",
       "   'Squeak',\n",
       "   'E.',\n",
       "   'Clean',\n",
       "   \"''\",\n",
       "   'Spiegel',\n",
       "   ',',\n",
       "   'and',\n",
       "   'its',\n",
       "   'lyrics',\n",
       "   'were',\n",
       "   'sung',\n",
       "   'by',\n",
       "   'Jonze',\n",
       "   \"'s\",\n",
       "   'then-girlfriend',\n",
       "   ',',\n",
       "   'Karen',\n",
       "   'O',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Grammy',\n",
       "   '-nominated',\n",
       "   'rock',\n",
       "   'band',\n",
       "   'Yeah',\n",
       "   'Yeah',\n",
       "   'Yeahs',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   0],\n",
       "  'id': '193'},\n",
       " {'tokens': ['In',\n",
       "   '1916',\n",
       "   ',',\n",
       "   'Falla',\n",
       "   'arranged',\n",
       "   'a',\n",
       "   'rendition',\n",
       "   'of',\n",
       "   'the',\n",
       "   'work',\n",
       "   'for',\n",
       "   'sextet',\n",
       "   'and',\n",
       "   'small',\n",
       "   'orchestra',\n",
       "   'and',\n",
       "   'the',\n",
       "   'following',\n",
       "   'year',\n",
       "   'he',\n",
       "   'made',\n",
       "   'a',\n",
       "   'concert',\n",
       "   'version',\n",
       "   ',',\n",
       "   'also',\n",
       "   'for',\n",
       "   'small',\n",
       "   'orchestra',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '194'},\n",
       " {'tokens': ['Note',\n",
       "   ':',\n",
       "   'Round',\n",
       "   '3/Race',\n",
       "   '9',\n",
       "   'was',\n",
       "   'the',\n",
       "   'Olympic',\n",
       "   'event',\n",
       "   ',',\n",
       "   'which',\n",
       "   'counts',\n",
       "   'also',\n",
       "   'for',\n",
       "   'the',\n",
       "   'World',\n",
       "   'Cup',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 3, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0],\n",
       "  'fine_tags': [0, 0, 20, 20, 20, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 20, 20, 0],\n",
       "  'id': '195'},\n",
       " {'tokens': ['A',\n",
       "   'Latin',\n",
       "   'name',\n",
       "   'for',\n",
       "   'Algol',\n",
       "   'from',\n",
       "   'the',\n",
       "   '16th',\n",
       "   'century',\n",
       "   'was',\n",
       "   '``',\n",
       "   'Caput',\n",
       "   'Larvae',\n",
       "   \"''\",\n",
       "   'or',\n",
       "   '``',\n",
       "   'the',\n",
       "   'Spectre',\n",
       "   \"'s\",\n",
       "   'Head',\n",
       "   \"''\",\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   38,\n",
       "   38,\n",
       "   38,\n",
       "   0,\n",
       "   38,\n",
       "   38,\n",
       "   38,\n",
       "   38,\n",
       "   38,\n",
       "   38,\n",
       "   0],\n",
       "  'id': '196'},\n",
       " {'tokens': ['In',\n",
       "   'third',\n",
       "   'place',\n",
       "   'was',\n",
       "   'former',\n",
       "   'Congressman',\n",
       "   'Gillis',\n",
       "   'Long',\n",
       "   'of',\n",
       "   'Alexandria',\n",
       "   ',',\n",
       "   'with',\n",
       "   '164,276',\n",
       "   '(',\n",
       "   '14',\n",
       "   'percent',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 7, 7, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 55, 55, 0, 21, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '197'},\n",
       " {'tokens': ['After',\n",
       "   'the',\n",
       "   'Romanian',\n",
       "   'Revolution',\n",
       "   'of',\n",
       "   '1989',\n",
       "   'he',\n",
       "   'joined',\n",
       "   'the',\n",
       "   'National',\n",
       "   'Liberal',\n",
       "   'Party',\n",
       "   ',',\n",
       "   'being',\n",
       "   'appointed',\n",
       "   'director',\n",
       "   'of',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Viitorul',\n",
       "   '``',\n",
       "   'newspaper',\n",
       "   ',',\n",
       "   'the',\n",
       "   'official',\n",
       "   'daily',\n",
       "   'of',\n",
       "   'the',\n",
       "   'party',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '198'},\n",
       " {'tokens': ['The',\n",
       "   'station',\n",
       "   'will',\n",
       "   'also',\n",
       "   'be',\n",
       "   'linked',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Crossrail',\n",
       "   'network',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '199'},\n",
       " {'tokens': ['Underlying',\n",
       "   'are',\n",
       "   '100',\n",
       "   'points',\n",
       "   'on',\n",
       "   '4',\n",
       "   'January',\n",
       "   '1971',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '200'},\n",
       " {'tokens': ['He',\n",
       "   'had',\n",
       "   'no',\n",
       "   'male',\n",
       "   'children',\n",
       "   'or',\n",
       "   'heirs',\n",
       "   'of',\n",
       "   'his',\n",
       "   'own',\n",
       "   ',',\n",
       "   'and',\n",
       "   'in',\n",
       "   'his',\n",
       "   'will',\n",
       "   'he',\n",
       "   'left',\n",
       "   'the',\n",
       "   'kingdom',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Roman',\n",
       "   'Republic',\n",
       "   ',',\n",
       "   'believing',\n",
       "   'that',\n",
       "   'if',\n",
       "   'he',\n",
       "   'did',\n",
       "   'not',\n",
       "   'then',\n",
       "   'Rome',\n",
       "   'would',\n",
       "   'take',\n",
       "   'the',\n",
       "   'kingdom',\n",
       "   'anyway',\n",
       "   'and',\n",
       "   'this',\n",
       "   'way',\n",
       "   'would',\n",
       "   'avoid',\n",
       "   'bloodshed',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '201'},\n",
       " {'tokens': ['42',\n",
       "   'Camelopardalis',\n",
       "   'is',\n",
       "   'a',\n",
       "   'single',\n",
       "   'star',\n",
       "   'in',\n",
       "   'the',\n",
       "   'constellation',\n",
       "   'Camelopardalis',\n",
       "   ',',\n",
       "   'located',\n",
       "   'roughly',\n",
       "   '770',\n",
       "   'light',\n",
       "   'years',\n",
       "   'away',\n",
       "   'from',\n",
       "   'the',\n",
       "   'Sun',\n",
       "   '.'],\n",
       "  'coarse_tags': [6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0],\n",
       "  'fine_tags': [38,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0],\n",
       "  'id': '202'},\n",
       " {'tokens': ['Then',\n",
       "   'the',\n",
       "   'crab',\n",
       "   'pieces',\n",
       "   'are',\n",
       "   'mixed',\n",
       "   'with',\n",
       "   'stir-fried',\n",
       "   'spice',\n",
       "   'paste',\n",
       "   'together',\n",
       "   'with',\n",
       "   'crab',\n",
       "   'broth',\n",
       "   ',',\n",
       "   'scallion',\n",
       "   ',',\n",
       "   'tomato',\n",
       "   'ketchup',\n",
       "   ',',\n",
       "   'chili',\n",
       "   'sauce',\n",
       "   ',',\n",
       "   'oyster',\n",
       "   'sauce',\n",
       "   ',',\n",
       "   'salt',\n",
       "   'and',\n",
       "   'pepper',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '203'},\n",
       " {'tokens': ['Dejected',\n",
       "   'and',\n",
       "   'depressed',\n",
       "   ',',\n",
       "   'Mahima',\n",
       "   'attempts',\n",
       "   'to',\n",
       "   'take',\n",
       "   'her',\n",
       "   'own',\n",
       "   'life',\n",
       "   'many',\n",
       "   'times',\n",
       "   'only',\n",
       "   'to',\n",
       "   'be',\n",
       "   'rescued',\n",
       "   'by',\n",
       "   'Preesha',\n",
       "   'and',\n",
       "   'Rudra',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   0],\n",
       "  'id': '204'},\n",
       " {'tokens': ['The',\n",
       "   'Mil',\n",
       "   'Mi-58',\n",
       "   'was',\n",
       "   'a',\n",
       "   'projected',\n",
       "   'twin-turbine',\n",
       "   'passenger',\n",
       "   'helicopter',\n",
       "   'based',\n",
       "   'on',\n",
       "   'the',\n",
       "   'Mil',\n",
       "   'Mi-28',\n",
       "   'first',\n",
       "   'announced',\n",
       "   'at',\n",
       "   'the',\n",
       "   '1995',\n",
       "   'Paris',\n",
       "   'Air',\n",
       "   'Show',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   0],\n",
       "  'id': '205'},\n",
       " {'tokens': ['Alumnus',\n",
       "   'Thomas',\n",
       "   'Wolfe',\n",
       "   'says',\n",
       "   'he',\n",
       "   'learned',\n",
       "   'more',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Farnsworth',\n",
       "   'Room',\n",
       "   'than',\n",
       "   'anywhere',\n",
       "   'else',\n",
       "   'at',\n",
       "   'Harvard',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 7, 7, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 5, 0],\n",
       "  'fine_tags': [0, 54, 54, 0, 0, 0, 0, 0, 0, 11, 11, 0, 0, 0, 0, 29, 0],\n",
       "  'id': '206'},\n",
       " {'tokens': ['In',\n",
       "   '2017',\n",
       "   ',',\n",
       "   'Hannity',\n",
       "   'continued',\n",
       "   'to',\n",
       "   'advocate',\n",
       "   'for',\n",
       "   'waterboarding',\n",
       "   ',',\n",
       "   'raising',\n",
       "   'the',\n",
       "   'example',\n",
       "   'of',\n",
       "   'using',\n",
       "   'it',\n",
       "   'against',\n",
       "   'a',\n",
       "   'kidnapper',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '207'},\n",
       " {'tokens': ['Sorbonne',\n",
       "   'University',\n",
       "   'has',\n",
       "   'many',\n",
       "   'notable',\n",
       "   'teachers',\n",
       "   ',',\n",
       "   'some',\n",
       "   'of',\n",
       "   'whom',\n",
       "   'have',\n",
       "   'themselves',\n",
       "   'graduated',\n",
       "   'from',\n",
       "   'the',\n",
       "   'members',\n",
       "   'of',\n",
       "   'the',\n",
       "   'group',\n",
       "   ':'],\n",
       "  'coarse_tags': [5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [29, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '208'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'appointed',\n",
       "   'by',\n",
       "   'the',\n",
       "   'infant',\n",
       "   'king',\n",
       "   'Louis',\n",
       "   'XIV',\n",
       "   'of',\n",
       "   'France',\n",
       "   'during',\n",
       "   'the',\n",
       "   'regency',\n",
       "   'of',\n",
       "   'Anne',\n",
       "   'of',\n",
       "   'Austria',\n",
       "   'at',\n",
       "   'a',\n",
       "   'time',\n",
       "   'when',\n",
       "   'the',\n",
       "   'colonies',\n",
       "   'were',\n",
       "   'owned',\n",
       "   'by',\n",
       "   'the',\n",
       "   'French',\n",
       "   'West',\n",
       "   'India',\n",
       "   'Company',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   0],\n",
       "  'id': '209'},\n",
       " {'tokens': ['When',\n",
       "   'all',\n",
       "   'parties',\n",
       "   'arrive',\n",
       "   'on',\n",
       "   'Tandun',\n",
       "   'III',\n",
       "   ',',\n",
       "   'they',\n",
       "   'find',\n",
       "   'that',\n",
       "   'the',\n",
       "   'planet',\n",
       "   'has',\n",
       "   'devastated',\n",
       "   'due',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Yuuzhan',\n",
       "   'Vong',\n",
       "   'invasion',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '210'},\n",
       " {'tokens': ['Wilcots',\n",
       "   'is',\n",
       "   'now',\n",
       "   'an',\n",
       "   'analyst',\n",
       "   'for',\n",
       "   'Sky',\n",
       "   'Sports',\n",
       "   'in',\n",
       "   'the',\n",
       "   'UK',\n",
       "   'and',\n",
       "   'a',\n",
       "   'guest',\n",
       "   'analyst',\n",
       "   'for',\n",
       "   'Pro',\n",
       "   'Football',\n",
       "   'Focus',\n",
       "   'TV',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   31,\n",
       "   31,\n",
       "   31,\n",
       "   0],\n",
       "  'id': '211'},\n",
       " {'tokens': ['John',\n",
       "   'Meyer',\n",
       "   'started',\n",
       "   'his',\n",
       "   'career',\n",
       "   'in',\n",
       "   '1967',\n",
       "   'working',\n",
       "   'in',\n",
       "   'a',\n",
       "   'Berkeley',\n",
       "   'hi-fi',\n",
       "   'store',\n",
       "   'doing',\n",
       "   'custom',\n",
       "   'installs',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [51, 51, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '212'},\n",
       " {'tokens': ['Before',\n",
       "   'its',\n",
       "   'first',\n",
       "   'presentation',\n",
       "   'at',\n",
       "   'the',\n",
       "   '1912',\n",
       "   'Salon',\n",
       "   'des',\n",
       "   'Indépendants',\n",
       "   'in',\n",
       "   'Paris',\n",
       "   'it',\n",
       "   'was',\n",
       "   'rejected',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Cubists',\n",
       "   'as',\n",
       "   'being',\n",
       "   'too',\n",
       "   'Futurist',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '213'},\n",
       " {'tokens': ['On',\n",
       "   '29',\n",
       "   'May',\n",
       "   '2017',\n",
       "   ',',\n",
       "   'Horan',\n",
       "   'performed',\n",
       "   'on',\n",
       "   'The',\n",
       "   'Today',\n",
       "   'Show',\n",
       "   \"'s\",\n",
       "   'Citi',\n",
       "   'Concert',\n",
       "   'Series',\n",
       "   ',',\n",
       "   'closing',\n",
       "   'the',\n",
       "   'show',\n",
       "   'with',\n",
       "   'a',\n",
       "   'live',\n",
       "   'TV',\n",
       "   'debut',\n",
       "   'of',\n",
       "   '``',\n",
       "   'On',\n",
       "   'the',\n",
       "   'Loose',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '214'},\n",
       " {'tokens': ['It',\n",
       "   'still',\n",
       "   'displays',\n",
       "   'some',\n",
       "   'characteristic',\n",
       "   'chalk',\n",
       "   'species',\n",
       "   ',',\n",
       "   'including',\n",
       "   'cowslip',\n",
       "   ',',\n",
       "   'marjoram',\n",
       "   ',',\n",
       "   'field',\n",
       "   'scabious',\n",
       "   'and',\n",
       "   'wild',\n",
       "   'basil',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '215'},\n",
       " {'tokens': ['The',\n",
       "   'faults',\n",
       "   'bounding',\n",
       "   'these',\n",
       "   'grabens',\n",
       "   'are',\n",
       "   'associated',\n",
       "   'with',\n",
       "   'most',\n",
       "   'of',\n",
       "   'the',\n",
       "   'earthquakes',\n",
       "   'that',\n",
       "   'affect',\n",
       "   'the',\n",
       "   'archipelago',\n",
       "   ',',\n",
       "   'although',\n",
       "   'some',\n",
       "   'earthquakes',\n",
       "   'with',\n",
       "   'epicentres',\n",
       "   'in',\n",
       "   'Sicily',\n",
       "   'may',\n",
       "   'have',\n",
       "   'damaging',\n",
       "   'effects',\n",
       "   ',',\n",
       "   'such',\n",
       "   'as',\n",
       "   'the',\n",
       "   '1693',\n",
       "   'Sicily',\n",
       "   'earthquake',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   16,\n",
       "   16,\n",
       "   16,\n",
       "   0],\n",
       "  'id': '216'},\n",
       " {'tokens': ['Wolfe',\n",
       "   \"'s\",\n",
       "   'men',\n",
       "   'fired',\n",
       "   'and',\n",
       "   'the',\n",
       "   'VC',\n",
       "   'stopped',\n",
       "   ',',\n",
       "   'having',\n",
       "   'struck',\n",
       "   'one',\n",
       "   'American',\n",
       "   'vehicle',\n",
       "   \"'s\",\n",
       "   'gun',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0],\n",
       "  'fine_tags': [57, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0],\n",
       "  'id': '217'},\n",
       " {'tokens': ['Former',\n",
       "   'Atlanta',\n",
       "   'Falcons',\n",
       "   'quarterback',\n",
       "   'Michael',\n",
       "   'Vick',\n",
       "   'is',\n",
       "   'on',\n",
       "   'the',\n",
       "   'cover',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 5, 5, 0, 7, 7, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 37, 37, 0, 52, 52, 0, 0, 0, 0, 0],\n",
       "  'id': '218'},\n",
       " {'tokens': ['He',\n",
       "   'served',\n",
       "   'seven',\n",
       "   'years',\n",
       "   'in',\n",
       "   'the',\n",
       "   'office',\n",
       "   'of',\n",
       "   'constable',\n",
       "   'at',\n",
       "   'Carlisle',\n",
       "   'before',\n",
       "   'being',\n",
       "   'dismissed',\n",
       "   'from',\n",
       "   'his',\n",
       "   'role',\n",
       "   'in',\n",
       "   '1844',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '219'},\n",
       " {'tokens': ['All',\n",
       "   'three',\n",
       "   'operate',\n",
       "   'between',\n",
       "   'April',\n",
       "   'and',\n",
       "   'October',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '220'},\n",
       " {'tokens': ['Beside',\n",
       "   'that',\n",
       "   ',',\n",
       "   'the',\n",
       "   'airport',\n",
       "   'group',\n",
       "   'owns',\n",
       "   '35',\n",
       "   '%',\n",
       "   'of',\n",
       "   'Hobart',\n",
       "   'Airport',\n",
       "   'and',\n",
       "   '1',\n",
       "   '%',\n",
       "   'of',\n",
       "   'Vienna',\n",
       "   'International',\n",
       "   'Airport',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 7, 7, 7, 0],\n",
       "  'id': '221'},\n",
       " {'tokens': ['A',\n",
       "   'total',\n",
       "   'of',\n",
       "   '2.2',\n",
       "   'million',\n",
       "   'cars',\n",
       "   'were',\n",
       "   'produced',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '222'},\n",
       " {'tokens': ['When',\n",
       "   'news',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Pope',\n",
       "   \"'s\",\n",
       "   'condemnation',\n",
       "   'reached',\n",
       "   'Heraclius',\n",
       "   ',',\n",
       "   'he',\n",
       "   'was',\n",
       "   'already',\n",
       "   'old',\n",
       "   'and',\n",
       "   'ill',\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'news',\n",
       "   'is',\n",
       "   'said',\n",
       "   'to',\n",
       "   'have',\n",
       "   'hastened',\n",
       "   'his',\n",
       "   'death',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '223'},\n",
       " {'tokens': ['In',\n",
       "   '1958',\n",
       "   ',',\n",
       "   'Matters',\n",
       "   '&',\n",
       "   'amp',\n",
       "   ';',\n",
       "   'Co',\n",
       "   '.',\n",
       "   'offered',\n",
       "   'residential',\n",
       "   'land',\n",
       "   'in',\n",
       "   'the',\n",
       "   'area',\n",
       "   'bounded',\n",
       "   'by',\n",
       "   'Salisbury',\n",
       "   'Highway',\n",
       "   ',',\n",
       "   'Shepherdson',\n",
       "   'Road',\n",
       "   ',',\n",
       "   'Sunderland',\n",
       "   'Avenue',\n",
       "   ',',\n",
       "   'and',\n",
       "   'Catalina',\n",
       "   'Avenue',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0],\n",
       "  'id': '224'},\n",
       " {'tokens': ['All',\n",
       "   'of',\n",
       "   'these',\n",
       "   'different',\n",
       "   'groups',\n",
       "   'took',\n",
       "   'part',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Iranian',\n",
       "   'revolution',\n",
       "   'in',\n",
       "   '1979',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 19, 0, 0, 0],\n",
       "  'id': '225'},\n",
       " {'tokens': ['(',\n",
       "   'Rome',\n",
       "   ')',\n",
       "   'served',\n",
       "   'as',\n",
       "   'a',\n",
       "   'lecturer',\n",
       "   'in',\n",
       "   'St.',\n",
       "   'John',\n",
       "   \"'s\",\n",
       "   'Regional',\n",
       "   'Seminary',\n",
       "   ',',\n",
       "   'Hyderabad',\n",
       "   'from',\n",
       "   '1964-1976',\n",
       "   'during',\n",
       "   'the',\n",
       "   'archbishopric',\n",
       "   'of',\n",
       "   'Arulappa',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '226'},\n",
       " {'tokens': ['It',\n",
       "   'hosted',\n",
       "   'races',\n",
       "   'from',\n",
       "   '1903',\n",
       "   'to',\n",
       "   '1914',\n",
       "   ',',\n",
       "   'including',\n",
       "   'a',\n",
       "   'race',\n",
       "   'in',\n",
       "   '1905',\n",
       "   'AAA',\n",
       "   'Championship',\n",
       "   'Car',\n",
       "   'season',\n",
       "   'won',\n",
       "   'by',\n",
       "   'Louis',\n",
       "   'Chevrolet',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0],\n",
       "  'id': '227'},\n",
       " {'tokens': ['On',\n",
       "   'May',\n",
       "   '19',\n",
       "   ',',\n",
       "   '2017',\n",
       "   ',',\n",
       "   'two',\n",
       "   'Chinese',\n",
       "   'Su-30',\n",
       "   'fighter',\n",
       "   'jets',\n",
       "   'intercepted',\n",
       "   'a',\n",
       "   'WC-135',\n",
       "   'over',\n",
       "   'the',\n",
       "   'East',\n",
       "   'China',\n",
       "   'Sea',\n",
       "   ',',\n",
       "   'prompting',\n",
       "   'a',\n",
       "   'formal',\n",
       "   'complaint',\n",
       "   'from',\n",
       "   'the',\n",
       "   'Pentagon',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   22,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0],\n",
       "  'id': '228'},\n",
       " {'tokens': ['Its',\n",
       "   'current',\n",
       "   'chairman',\n",
       "   ',',\n",
       "   'Han',\n",
       "   'Keen',\n",
       "   'Juan',\n",
       "   'bought',\n",
       "   'over',\n",
       "   'the',\n",
       "   'establishment',\n",
       "   'which',\n",
       "   'was',\n",
       "   'about',\n",
       "   'to',\n",
       "   'fold',\n",
       "   'up',\n",
       "   'in',\n",
       "   '1986',\n",
       "   'and',\n",
       "   'revived',\n",
       "   'the',\n",
       "   'business',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '229'},\n",
       " {'tokens': ['A',\n",
       "   'mezzo-soprano',\n",
       "   ',',\n",
       "   'Allitsen',\n",
       "   'was',\n",
       "   'also',\n",
       "   'well',\n",
       "   'known',\n",
       "   'as',\n",
       "   'a',\n",
       "   'singing',\n",
       "   'teacher',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '230'},\n",
       " {'tokens': ['While',\n",
       "   'Russian',\n",
       "   'troops',\n",
       "   'from',\n",
       "   'Moldova',\n",
       "   'proper',\n",
       "   'and',\n",
       "   'from',\n",
       "   'the',\n",
       "   'security',\n",
       "   'zone',\n",
       "   'were',\n",
       "   'evacuated',\n",
       "   'to',\n",
       "   'Russia',\n",
       "   'by',\n",
       "   'January',\n",
       "   '1993',\n",
       "   ',',\n",
       "   'Russia',\n",
       "   'continued',\n",
       "   'to',\n",
       "   'have',\n",
       "   'a',\n",
       "   'significant',\n",
       "   'military',\n",
       "   'presence',\n",
       "   'in',\n",
       "   'Transnistria',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '231'},\n",
       " {'tokens': ['Dajani',\n",
       "   'has',\n",
       "   'also',\n",
       "   'been',\n",
       "   'active',\n",
       "   'in',\n",
       "   'forming',\n",
       "   'relationships',\n",
       "   'with',\n",
       "   'Jewish',\n",
       "   'and',\n",
       "   'Christian',\n",
       "   'religious',\n",
       "   'leaders',\n",
       "   'and',\n",
       "   'peace',\n",
       "   'activists',\n",
       "   'to',\n",
       "   'spread',\n",
       "   'the',\n",
       "   'Wasatia',\n",
       "   'message',\n",
       "   'of',\n",
       "   'understanding',\n",
       "   ',',\n",
       "   'tolerance',\n",
       "   ',',\n",
       "   'coexistence',\n",
       "   'and',\n",
       "   'brotherhood',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   0,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '232'},\n",
       " {'tokens': ['It',\n",
       "   'was',\n",
       "   'from',\n",
       "   'Tan',\n",
       "   'Son',\n",
       "   'Nhut',\n",
       "   'Air',\n",
       "   'Base',\n",
       "   'that',\n",
       "   'the',\n",
       "   'last',\n",
       "   'U.S',\n",
       "   '.',\n",
       "   'Airman',\n",
       "   'left',\n",
       "   'South',\n",
       "   'Vietnam',\n",
       "   'in',\n",
       "   'March',\n",
       "   '1973',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '233'},\n",
       " {'tokens': ['The',\n",
       "   'Old',\n",
       "   'Second',\n",
       "   'National',\n",
       "   'Bank',\n",
       "   'of',\n",
       "   'Aurora',\n",
       "   'was',\n",
       "   'designed',\n",
       "   'by',\n",
       "   'George',\n",
       "   'Grant',\n",
       "   'Elmslie',\n",
       "   'in',\n",
       "   '1924',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 7, 7, 7, 0, 0, 0],\n",
       "  'fine_tags': [0, 11, 11, 11, 11, 11, 11, 0, 0, 0, 54, 54, 54, 0, 0, 0],\n",
       "  'id': '234'},\n",
       " {'tokens': ['As',\n",
       "   'the',\n",
       "   'first',\n",
       "   'such',\n",
       "   'body',\n",
       "   'to',\n",
       "   'be',\n",
       "   'discovered',\n",
       "   ',',\n",
       "   'Ceres',\n",
       "   'was',\n",
       "   'given',\n",
       "   'the',\n",
       "   'designation',\n",
       "   '1',\n",
       "   'Ceres',\n",
       "   'under',\n",
       "   'the',\n",
       "   'modern',\n",
       "   'system',\n",
       "   'of',\n",
       "   'minor-planet',\n",
       "   'designations',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '235'},\n",
       " {'tokens': ['The',\n",
       "   'river',\n",
       "   'drains',\n",
       "   'a',\n",
       "   'populated',\n",
       "   'and',\n",
       "   'economically',\n",
       "   'vital',\n",
       "   'area',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Colorado',\n",
       "   'Western',\n",
       "   'Slope',\n",
       "   'called',\n",
       "   'the',\n",
       "   'Roaring',\n",
       "   'Fork',\n",
       "   'Valley',\n",
       "   'or',\n",
       "   'Roaring',\n",
       "   'Fork',\n",
       "   'Watershed',\n",
       "   ',',\n",
       "   'which',\n",
       "   'includes',\n",
       "   'the',\n",
       "   'resort',\n",
       "   'city',\n",
       "   'of',\n",
       "   'Aspen',\n",
       "   'and',\n",
       "   'the',\n",
       "   'resorts',\n",
       "   'of',\n",
       "   'Aspen',\n",
       "   '/',\n",
       "   'Snowmass',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '236'},\n",
       " {'tokens': ['The',\n",
       "   'current',\n",
       "   'terminal',\n",
       "   'naming',\n",
       "   'system',\n",
       "   'was',\n",
       "   'introduced',\n",
       "   'in',\n",
       "   'December',\n",
       "   '2009',\n",
       "   ';',\n",
       "   'previously',\n",
       "   ',',\n",
       "   'the',\n",
       "   'terminals',\n",
       "   'were',\n",
       "   'numbered',\n",
       "   ':',\n",
       "   'Sheremetyevo-1',\n",
       "   '(',\n",
       "   'now',\n",
       "   'Terminal',\n",
       "   'B',\n",
       "   ')',\n",
       "   ',',\n",
       "   'Sheremetyevo-2',\n",
       "   '(',\n",
       "   'now',\n",
       "   'Terminal',\n",
       "   'F',\n",
       "   ')',\n",
       "   ',',\n",
       "   'and',\n",
       "   'Sheremetevo-3',\n",
       "   '(',\n",
       "   'now',\n",
       "   'Terminal',\n",
       "   'D',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '237'},\n",
       " {'tokens': ['PASA',\n",
       "   'entered',\n",
       "   'Argentina',\n",
       "   'in',\n",
       "   'the',\n",
       "   'early',\n",
       "   '1990s',\n",
       "   ',',\n",
       "   'when',\n",
       "   'the',\n",
       "   'nation',\n",
       "   'was',\n",
       "   'emerging',\n",
       "   'from',\n",
       "   'a',\n",
       "   'decade',\n",
       "   'of',\n",
       "   'economic',\n",
       "   'crisis',\n",
       "   '.'],\n",
       "  'coarse_tags': [5, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [28, 0, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '238'},\n",
       " {'tokens': ['The',\n",
       "   'TranzCoastal',\n",
       "   ',',\n",
       "   'introduced',\n",
       "   'as',\n",
       "   'the',\n",
       "   'Coastal',\n",
       "   'Pacific',\n",
       "   'in',\n",
       "   '1987',\n",
       "   'and',\n",
       "   'rebranded',\n",
       "   'as',\n",
       "   'the',\n",
       "   'TranzCoastal',\n",
       "   'in',\n",
       "   '1995',\n",
       "   ',',\n",
       "   'passes',\n",
       "   'through',\n",
       "   'Rangiora',\n",
       "   'heading',\n",
       "   'north',\n",
       "   'in',\n",
       "   'the',\n",
       "   'morning',\n",
       "   'and',\n",
       "   'south',\n",
       "   'again',\n",
       "   'in',\n",
       "   'the',\n",
       "   'afternoon',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '239'},\n",
       " {'tokens': ['Jurist',\n",
       "   'was',\n",
       "   'launched',\n",
       "   'as',\n",
       "   'part',\n",
       "   'of',\n",
       "   'Operation',\n",
       "   'Zipper',\n",
       "   ',',\n",
       "   'the',\n",
       "   'overall',\n",
       "   'British',\n",
       "   'plan',\n",
       "   'to',\n",
       "   'liberate',\n",
       "   'Malaya',\n",
       "   ',',\n",
       "   'including',\n",
       "   'Singapore',\n",
       "   '.'],\n",
       "  'coarse_tags': [3, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 4, 0],\n",
       "  'fine_tags': [15,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '240'},\n",
       " {'tokens': ['6000', ',', 'along', 'with', 'No', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0],\n",
       "  'id': '241'},\n",
       " {'tokens': ['Under',\n",
       "   'non-dividing',\n",
       "   'conditions',\n",
       "   '(',\n",
       "   'when',\n",
       "   'the',\n",
       "   'cell',\n",
       "   'is',\n",
       "   'in',\n",
       "   'the',\n",
       "   'G0',\n",
       "   'phase',\n",
       "   'of',\n",
       "   'the',\n",
       "   'cell',\n",
       "   'cycle',\n",
       "   ')',\n",
       "   ',',\n",
       "   'Retinoblastoma',\n",
       "   'protein',\n",
       "   '(',\n",
       "   'Rb',\n",
       "   ')',\n",
       "   'is',\n",
       "   'bound',\n",
       "   'with',\n",
       "   'the',\n",
       "   'E2F',\n",
       "   'transcription',\n",
       "   'factor',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   40,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '242'},\n",
       " {'tokens': ['Soviet',\n",
       "   'Premier',\n",
       "   'Nikolai',\n",
       "   'Ryzhkov',\n",
       "   'and',\n",
       "   'Anatoly',\n",
       "   'Dobrynin',\n",
       "   'attended',\n",
       "   'Lê',\n",
       "   'Duẩn',\n",
       "   \"'s\",\n",
       "   'funeral',\n",
       "   '.'],\n",
       "  'coarse_tags': [4, 0, 7, 7, 0, 7, 7, 0, 7, 7, 0, 0, 0],\n",
       "  'fine_tags': [21, 0, 55, 55, 0, 55, 55, 0, 55, 55, 0, 0, 0],\n",
       "  'id': '243'},\n",
       " {'tokens': ['The',\n",
       "   'new',\n",
       "   'show',\n",
       "   ',',\n",
       "   'which',\n",
       "   'shares',\n",
       "   'its',\n",
       "   'name',\n",
       "   'with',\n",
       "   'the',\n",
       "   'film',\n",
       "   ',',\n",
       "   'is',\n",
       "   'executive-produced',\n",
       "   'by',\n",
       "   'McG',\n",
       "   ',',\n",
       "   'with',\n",
       "   'Peter',\n",
       "   'Johnson',\n",
       "   'and',\n",
       "   'Craig',\n",
       "   'Silverstein',\n",
       "   'serving',\n",
       "   'as',\n",
       "   'executive',\n",
       "   'producers',\n",
       "   'and',\n",
       "   'writers',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   53,\n",
       "   53,\n",
       "   0,\n",
       "   53,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '244'},\n",
       " {'tokens': ['He',\n",
       "   'played',\n",
       "   'college',\n",
       "   'football',\n",
       "   'at',\n",
       "   'Michigan',\n",
       "   'State',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 5, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 37, 37, 0],\n",
       "  'id': '245'},\n",
       " {'tokens': ['Savoldelli',\n",
       "   'went',\n",
       "   'on',\n",
       "   'to',\n",
       "   'win',\n",
       "   'his',\n",
       "   'second',\n",
       "   'Giro',\n",
       "   \"d'Italia\",\n",
       "   'while',\n",
       "   'fending',\n",
       "   'off',\n",
       "   'the',\n",
       "   'attacks',\n",
       "   'of',\n",
       "   'Gilberto',\n",
       "   'Simoni',\n",
       "   'and',\n",
       "   'José',\n",
       "   'Rujano',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0],\n",
       "  'id': '246'},\n",
       " {'tokens': ['The',\n",
       "   'song',\n",
       "   '``',\n",
       "   'Por',\n",
       "   'la',\n",
       "   'boca',\n",
       "   'vive',\n",
       "   'el',\n",
       "   'pez',\n",
       "   '``',\n",
       "   'is',\n",
       "   'a',\n",
       "   'DLC',\n",
       "   'song',\n",
       "   'in',\n",
       "   'the',\n",
       "   'video',\n",
       "   'game',\n",
       "   'Guitar',\n",
       "   'Hero',\n",
       "   'World',\n",
       "   'Tour'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '247'},\n",
       " {'tokens': ['James',\n",
       "   'McConnell',\n",
       "   '``',\n",
       "   'Mac',\n",
       "   \"''\",\n",
       "   'Anderson',\n",
       "   '(',\n",
       "   'August',\n",
       "   '9',\n",
       "   ',',\n",
       "   '1907',\n",
       "   'in',\n",
       "   'New',\n",
       "   'Orleans',\n",
       "   '–',\n",
       "   'April',\n",
       "   '3',\n",
       "   ',',\n",
       "   '1998',\n",
       "   'in',\n",
       "   'Jackson',\n",
       "   'County',\n",
       "   ',',\n",
       "   'Mississippi',\n",
       "   ')',\n",
       "   'was',\n",
       "   'an',\n",
       "   'American',\n",
       "   'painter',\n",
       "   ',',\n",
       "   'muralist',\n",
       "   ',',\n",
       "   'and',\n",
       "   'pottery',\n",
       "   'designer',\n",
       "   'and',\n",
       "   'decorator',\n",
       "   ',',\n",
       "   'youngest',\n",
       "   'of',\n",
       "   'the',\n",
       "   'three',\n",
       "   'brothers',\n",
       "   '(',\n",
       "   'along',\n",
       "   'with',\n",
       "   'Walter',\n",
       "   'Inglis',\n",
       "   'Anderson',\n",
       "   'and',\n",
       "   'founder',\n",
       "   'Peter',\n",
       "   'Anderson',\n",
       "   ')',\n",
       "   'who',\n",
       "   'collaborated',\n",
       "   'at',\n",
       "   'Shearwater',\n",
       "   'Pottery',\n",
       "   ',',\n",
       "   'Ocean',\n",
       "   'Springs',\n",
       "   ',',\n",
       "   'Mississippi',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [51,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '248'},\n",
       " {'tokens': [',',\n",
       "   'chocolate',\n",
       "   'malts',\n",
       "   ',',\n",
       "   'fountain',\n",
       "   'colas',\n",
       "   ',',\n",
       "   'and',\n",
       "   'milkshakes',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '249'},\n",
       " {'tokens': ['is',\n",
       "   'a',\n",
       "   'subway',\n",
       "   'station',\n",
       "   'on',\n",
       "   'the',\n",
       "   'Tokyo',\n",
       "   'Metro',\n",
       "   'Hibiya',\n",
       "   'Line',\n",
       "   'in',\n",
       "   'Tsukiji',\n",
       "   ',',\n",
       "   'Chūō',\n",
       "   ',',\n",
       "   'Tokyo',\n",
       "   ',',\n",
       "   'Japan',\n",
       "   ',',\n",
       "   'operated',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Tokyo',\n",
       "   'subway',\n",
       "   'operator',\n",
       "   'Tokyo',\n",
       "   'Metro',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0],\n",
       "  'id': '250'},\n",
       " {'tokens': ['As',\n",
       "   'a',\n",
       "   'line',\n",
       "   'of',\n",
       "   'severe',\n",
       "   'thunderstorms',\n",
       "   'pushed',\n",
       "   'into',\n",
       "   'Mississippi',\n",
       "   ',',\n",
       "   '13',\n",
       "   'tornadoes',\n",
       "   'touched',\n",
       "   'down',\n",
       "   'across',\n",
       "   'parts',\n",
       "   'of',\n",
       "   'the',\n",
       "   'state',\n",
       "   'during',\n",
       "   'the',\n",
       "   'nighttime',\n",
       "   'hours',\n",
       "   'of',\n",
       "   'December',\n",
       "   '23',\n",
       "   'and',\n",
       "   'in',\n",
       "   'the',\n",
       "   'early',\n",
       "   'morning',\n",
       "   'hours',\n",
       "   'of',\n",
       "   'the',\n",
       "   'following',\n",
       "   'day',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '251'},\n",
       " {'tokens': ['The',\n",
       "   'station',\n",
       "   'is',\n",
       "   'within',\n",
       "   'walking',\n",
       "   'distance',\n",
       "   'to',\n",
       "   'Raffles',\n",
       "   'Marina',\n",
       "   ',',\n",
       "   'Tuas',\n",
       "   'Checkpoint',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Malaysia–Singapore',\n",
       "   'Second',\n",
       "   'Link',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 0, 0, 4, 4, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 25, 25, 0, 25, 25, 0, 0, 25, 25, 25, 0],\n",
       "  'id': '252'},\n",
       " {'tokens': ['A',\n",
       "   'few',\n",
       "   'notable',\n",
       "   'names',\n",
       "   'who',\n",
       "   'have',\n",
       "   'all',\n",
       "   'performed',\n",
       "   'at',\n",
       "   'The',\n",
       "   'Old',\n",
       "   'Rep',\n",
       "   'include',\n",
       "   ':'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50, 0, 0],\n",
       "  'id': '253'},\n",
       " {'tokens': ['Outside',\n",
       "   'politics',\n",
       "   'Voie',\n",
       "   'has',\n",
       "   'had',\n",
       "   'a',\n",
       "   'diverse',\n",
       "   'career',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 7, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 54, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '254'},\n",
       " {'tokens': ['Those',\n",
       "   'who',\n",
       "   'remain',\n",
       "   'in',\n",
       "   'Malta',\n",
       "   'try',\n",
       "   'to',\n",
       "   'pick',\n",
       "   'up',\n",
       "   'employment',\n",
       "   'opportunities',\n",
       "   'in',\n",
       "   'the',\n",
       "   'country',\n",
       "   \"'s\",\n",
       "   'very',\n",
       "   'limited',\n",
       "   'labour',\n",
       "   'market',\n",
       "   'and',\n",
       "   'they',\n",
       "   'spark',\n",
       "   'and',\n",
       "   'fuel',\n",
       "   'explicit',\n",
       "   'xenophobic',\n",
       "   'reactions',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '255'},\n",
       " {'tokens': ['The',\n",
       "   'team',\n",
       "   'at',\n",
       "   'the',\n",
       "   'centre',\n",
       "   'of',\n",
       "   'the',\n",
       "   'row',\n",
       "   'was',\n",
       "   'the',\n",
       "   'Spanish',\n",
       "   'basketball',\n",
       "   'team',\n",
       "   ',',\n",
       "   'who',\n",
       "   'won',\n",
       "   'the',\n",
       "   'gold',\n",
       "   'medal',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Basketball',\n",
       "   'ID',\n",
       "   ',',\n",
       "   'beating',\n",
       "   'Russia',\n",
       "   '87–63',\n",
       "   ',',\n",
       "   'despite',\n",
       "   'fielding',\n",
       "   'a',\n",
       "   'team',\n",
       "   'mainly',\n",
       "   'composed',\n",
       "   'of',\n",
       "   'athletes',\n",
       "   'with',\n",
       "   'no',\n",
       "   'intellectual',\n",
       "   'disability',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '256'},\n",
       " {'tokens': ['Once',\n",
       "   'again',\n",
       "   ',',\n",
       "   'every',\n",
       "   'member',\n",
       "   'of',\n",
       "   'the',\n",
       "   'blue',\n",
       "   'team',\n",
       "   'lost',\n",
       "   'weight—87',\n",
       "   'pounds',\n",
       "   ',',\n",
       "   'reclaiming',\n",
       "   'their',\n",
       "   'immunity',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '257'},\n",
       " {'tokens': ['In',\n",
       "   '2008',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Obama',\n",
       "   'presidential',\n",
       "   'campaign',\n",
       "   'spent',\n",
       "   '$',\n",
       "   '643,000',\n",
       "   'out',\n",
       "   'of',\n",
       "   'its',\n",
       "   '$',\n",
       "   '16',\n",
       "   'million',\n",
       "   'Internet',\n",
       "   'budget',\n",
       "   'to',\n",
       "   'promote',\n",
       "   'his',\n",
       "   'Facebook',\n",
       "   'account',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '258'},\n",
       " {'tokens': ['The', 'airline', 'closed', 'operations', 'in', '2005', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '259'},\n",
       " {'tokens': ['In',\n",
       "   'October',\n",
       "   '1992',\n",
       "   ',',\n",
       "   'six',\n",
       "   'zebras',\n",
       "   'were',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'land',\n",
       "   'that',\n",
       "   'had',\n",
       "   'sufficient',\n",
       "   'natural',\n",
       "   'grazing',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 48, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '260'},\n",
       " {'tokens': ['It',\n",
       "   'was',\n",
       "   'subsequently',\n",
       "   'transferred',\n",
       "   'to',\n",
       "   'Telesat',\n",
       "   'when',\n",
       "   'it',\n",
       "   'merged',\n",
       "   'with',\n",
       "   'Loral',\n",
       "   'Skynet',\n",
       "   'in',\n",
       "   '2007',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 28, 0, 0, 0, 0, 28, 28, 0, 0, 0],\n",
       "  'id': '261'},\n",
       " {'tokens': ['Her',\n",
       "   'doctoral',\n",
       "   'thesis',\n",
       "   'was',\n",
       "   'entitled',\n",
       "   '``',\n",
       "   'Writing',\n",
       "   ',',\n",
       "   'Teachers',\n",
       "   'and',\n",
       "   'Students',\n",
       "   'in',\n",
       "   'Graeco-Roman',\n",
       "   'Egypt',\n",
       "   '.',\n",
       "   \"''\"],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0],\n",
       "  'id': '262'},\n",
       " {'tokens': ['The',\n",
       "   '90,000',\n",
       "   'Pakistani',\n",
       "   'troops',\n",
       "   'under',\n",
       "   'Niazi',\n",
       "   \"'s\",\n",
       "   'command',\n",
       "   'surrendered',\n",
       "   'to',\n",
       "   'Gen',\n",
       "   'Aurora',\n",
       "   'as',\n",
       "   'prisoners',\n",
       "   'of',\n",
       "   'war',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 4, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 21, 0, 0, 54, 0, 0, 0, 0, 54, 54, 0, 0, 0, 0, 0],\n",
       "  'id': '263'},\n",
       " {'tokens': ['Calvin',\n",
       "   'Goldspink',\n",
       "   ',',\n",
       "   'Aaron',\n",
       "   'Renfree',\n",
       "   ',',\n",
       "   'Hannah',\n",
       "   'Richings',\n",
       "   'and',\n",
       "   'Jay',\n",
       "   'Asforis',\n",
       "   'do',\n",
       "   'not',\n",
       "   'have',\n",
       "   'any',\n",
       "   'solos',\n",
       "   'in',\n",
       "   'this',\n",
       "   'song',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [51,\n",
       "   51,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '264'},\n",
       " {'tokens': ['It',\n",
       "   'is',\n",
       "   'the',\n",
       "   'sequel',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Sega',\n",
       "   'Dreamcast',\n",
       "   'game',\n",
       "   '``',\n",
       "   'Airforce',\n",
       "   'Delta',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 8, 8, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 28, 28, 0, 0, 61, 61, 0, 0],\n",
       "  'id': '265'},\n",
       " {'tokens': ['In',\n",
       "   '1964',\n",
       "   ',',\n",
       "   'producer',\n",
       "   'Stanley',\n",
       "   'Todd',\n",
       "   'discussed',\n",
       "   'a',\n",
       "   'film',\n",
       "   'project',\n",
       "   'with',\n",
       "   'Lansing',\n",
       "   ',',\n",
       "   'tentatively',\n",
       "   'titled',\n",
       "   '``',\n",
       "   'Project',\n",
       "   '22',\n",
       "   '``',\n",
       "   ',',\n",
       "   'with',\n",
       "   'location',\n",
       "   'shooting',\n",
       "   'planned',\n",
       "   'in',\n",
       "   'Yugoslavia',\n",
       "   ',',\n",
       "   'and',\n",
       "   'George',\n",
       "   'Hamilton',\n",
       "   'and',\n",
       "   'Geraldine',\n",
       "   'Chaplin',\n",
       "   'named',\n",
       "   'to',\n",
       "   'the',\n",
       "   'cast',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   50,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '266'},\n",
       " {'tokens': ['In',\n",
       "   'recent',\n",
       "   'history',\n",
       "   ',',\n",
       "   'major',\n",
       "   'events',\n",
       "   'of',\n",
       "   'the',\n",
       "   '20th',\n",
       "   'century',\n",
       "   ',',\n",
       "   'such',\n",
       "   'as',\n",
       "   'the',\n",
       "   'Division',\n",
       "   'of',\n",
       "   'Korea',\n",
       "   'and',\n",
       "   'later',\n",
       "   'the',\n",
       "   '1990s',\n",
       "   'North',\n",
       "   'Korean',\n",
       "   'famine',\n",
       "   'have',\n",
       "   'played',\n",
       "   'an',\n",
       "   'important',\n",
       "   'role',\n",
       "   'in',\n",
       "   'shaping',\n",
       "   'sex',\n",
       "   'relations',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   16,\n",
       "   16,\n",
       "   16,\n",
       "   16,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '267'},\n",
       " {'tokens': ['This',\n",
       "   'obviated',\n",
       "   'adding',\n",
       "   'new',\n",
       "   'DNA',\n",
       "   'polymerase',\n",
       "   'after',\n",
       "   'each',\n",
       "   'PCR',\n",
       "   'cycle',\n",
       "   ',',\n",
       "   'thus',\n",
       "   'greatly',\n",
       "   'simplifying',\n",
       "   'DNA',\n",
       "   'mutagenesis',\n",
       "   'and',\n",
       "   'assembly',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '268'},\n",
       " {'tokens': ['Outfielder',\n",
       "   'Andre',\n",
       "   'Dawson',\n",
       "   'was',\n",
       "   'signed',\n",
       "   'as',\n",
       "   'a',\n",
       "   'free',\n",
       "   'agent',\n",
       "   'prior',\n",
       "   'to',\n",
       "   'the',\n",
       "   '1987',\n",
       "   'season',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 52, 52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '269'},\n",
       " {'tokens': ['As',\n",
       "   'an',\n",
       "   'undergraduate',\n",
       "   'student',\n",
       "   'at',\n",
       "   'UBC',\n",
       "   ',',\n",
       "   'MacDonald',\n",
       "   'spent',\n",
       "   'his',\n",
       "   'first',\n",
       "   'three',\n",
       "   'summers',\n",
       "   'on',\n",
       "   'a',\n",
       "   'survey',\n",
       "   'crew',\n",
       "   'in',\n",
       "   'Northern',\n",
       "   'British',\n",
       "   'Columbia',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '270'},\n",
       " {'tokens': ['The',\n",
       "   'city',\n",
       "   'was',\n",
       "   'first',\n",
       "   'mentioned',\n",
       "   'in',\n",
       "   'the',\n",
       "   '10th',\n",
       "   'century',\n",
       "   ',',\n",
       "   'and',\n",
       "   'is',\n",
       "   'now',\n",
       "   'an',\n",
       "   'administrative',\n",
       "   ',',\n",
       "   'industrial',\n",
       "   'and',\n",
       "   'cultural',\n",
       "   'center',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '271'},\n",
       " {'tokens': ['Their',\n",
       "   'best',\n",
       "   'results',\n",
       "   'were',\n",
       "   'in',\n",
       "   'the',\n",
       "   '1964',\n",
       "   'season',\n",
       "   ',',\n",
       "   'when',\n",
       "   'they',\n",
       "   'won',\n",
       "   'the',\n",
       "   'silver',\n",
       "   'medal',\n",
       "   'at',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'Figure',\n",
       "   'Skating',\n",
       "   'Championships',\n",
       "   'and',\n",
       "   'placed',\n",
       "   '6th',\n",
       "   'at',\n",
       "   'the',\n",
       "   'World',\n",
       "   'Championships',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0],\n",
       "  'id': '272'},\n",
       " {'tokens': ['The', 'total', 'area', 'of', 'the', 'town', 'was', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '273'},\n",
       " {'tokens': ['Rainer',\n",
       "   'back',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'Cup',\n",
       "   'full',\n",
       "   'time',\n",
       "   'in',\n",
       "   '1997',\n",
       "   'with',\n",
       "   'former',\n",
       "   'partner',\n",
       "   'Hardee',\n",
       "   \"'s\",\n",
       "   'returning',\n",
       "   'to',\n",
       "   'sponsor',\n",
       "   'the',\n",
       "   'new',\n",
       "   '#',\n",
       "   '20',\n",
       "   'and',\n",
       "   'Greg',\n",
       "   'Sacks',\n",
       "   'driving',\n",
       "   'the',\n",
       "   'car',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '274'},\n",
       " {'tokens': ['Yeungnam',\n",
       "   'University',\n",
       "   'Hospital',\n",
       "   'Station',\n",
       "   'is',\n",
       "   'a',\n",
       "   'station',\n",
       "   'of',\n",
       "   'Daegu',\n",
       "   'Subway',\n",
       "   'Line',\n",
       "   '1',\n",
       "   'in',\n",
       "   'Daemyeong-dong',\n",
       "   ',',\n",
       "   'Nam',\n",
       "   'District',\n",
       "   ',',\n",
       "   'Daegu',\n",
       "   ',',\n",
       "   'South',\n",
       "   'Korea',\n",
       "   '.'],\n",
       "  'coarse_tags': [2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '275'},\n",
       " {'tokens': ['2744',\n",
       "   'Birgitta',\n",
       "   ',',\n",
       "   'provisional',\n",
       "   'designation',\n",
       "   ',',\n",
       "   'is',\n",
       "   'a',\n",
       "   'stony',\n",
       "   'asteroid',\n",
       "   'and',\n",
       "   'a',\n",
       "   'Mars',\n",
       "   '-crosser',\n",
       "   'on',\n",
       "   'an',\n",
       "   'eccentric',\n",
       "   'orbit',\n",
       "   'from',\n",
       "   'the',\n",
       "   'innermost',\n",
       "   'regions',\n",
       "   'of',\n",
       "   'the',\n",
       "   'asteroid',\n",
       "   'belt',\n",
       "   ',',\n",
       "   'approximately',\n",
       "   'in',\n",
       "   'diameter',\n",
       "   '.'],\n",
       "  'coarse_tags': [6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [38,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '276'},\n",
       " {'tokens': ['Shivachevo',\n",
       "   'is',\n",
       "   'located',\n",
       "   '260',\n",
       "   'km',\n",
       "   'east',\n",
       "   'of',\n",
       "   'Sofia',\n",
       "   ',',\n",
       "   '35',\n",
       "   'km',\n",
       "   'west',\n",
       "   'of',\n",
       "   'the',\n",
       "   'city',\n",
       "   'of',\n",
       "   'Sliven',\n",
       "   '(',\n",
       "   'pop',\n",
       "   '.'],\n",
       "  'coarse_tags': [4, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0],\n",
       "  'fine_tags': [21, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0],\n",
       "  'id': '277'},\n",
       " {'tokens': ['Roderick',\n",
       "   'Charles',\n",
       "   'Young',\n",
       "   '(',\n",
       "   'born',\n",
       "   '1966',\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'United',\n",
       "   'States',\n",
       "   'District',\n",
       "   'Judge',\n",
       "   'of',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'District',\n",
       "   'Court',\n",
       "   'for',\n",
       "   'the',\n",
       "   'Eastern',\n",
       "   'District',\n",
       "   'of',\n",
       "   'Virginia',\n",
       "   'and',\n",
       "   'former',\n",
       "   'United',\n",
       "   'States',\n",
       "   'magistrate',\n",
       "   'judge',\n",
       "   'of',\n",
       "   'the',\n",
       "   'same',\n",
       "   'court',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '278'},\n",
       " {'tokens': ['``',\n",
       "   'The',\n",
       "   'Boys',\n",
       "   'of',\n",
       "   'Wexford',\n",
       "   '``',\n",
       "   '(',\n",
       "   'also',\n",
       "   'known',\n",
       "   'as',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Flight',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Earls',\n",
       "   '``',\n",
       "   ')',\n",
       "   'is',\n",
       "   'an',\n",
       "   'Irish',\n",
       "   'ballad',\n",
       "   'commemorating',\n",
       "   'the',\n",
       "   'Irish',\n",
       "   'Rebellion',\n",
       "   'of',\n",
       "   '1798',\n",
       "   'and',\n",
       "   ',',\n",
       "   'more',\n",
       "   'specifically',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Wexford',\n",
       "   'Rebellion',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   19,\n",
       "   19,\n",
       "   19,\n",
       "   19,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   19,\n",
       "   19,\n",
       "   0],\n",
       "  'id': '279'},\n",
       " {'tokens': ['She',\n",
       "   'has',\n",
       "   'also',\n",
       "   'played',\n",
       "   'for',\n",
       "   'Temir',\n",
       "   'Zholy',\n",
       "   ',',\n",
       "   'CSHVSM',\n",
       "   'and',\n",
       "   'BIIK',\n",
       "   'Kazygurt',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Kazakhstani',\n",
       "   'Championship',\n",
       "   'and',\n",
       "   'for',\n",
       "   'Universitet',\n",
       "   'Vitebsk',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Belarusian',\n",
       "   'Premier',\n",
       "   'League',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0],\n",
       "  'id': '280'},\n",
       " {'tokens': ['Bedford', 'F.C', '.'],\n",
       "  'coarse_tags': [0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0],\n",
       "  'id': '281'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'promoted',\n",
       "   'to',\n",
       "   'the',\n",
       "   'rank',\n",
       "   'of',\n",
       "   'brigadier',\n",
       "   'general',\n",
       "   'on',\n",
       "   'September',\n",
       "   '7',\n",
       "   ',',\n",
       "   '1862',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '282'},\n",
       " {'tokens': ['1969',\n",
       "   '-',\n",
       "   'The',\n",
       "   'Renault',\n",
       "   '12',\n",
       "   'medium-sized',\n",
       "   'saloon',\n",
       "   'and',\n",
       "   'estate',\n",
       "   'range',\n",
       "   'is',\n",
       "   'launched',\n",
       "   ',',\n",
       "   'but',\n",
       "   'it',\n",
       "   'missed',\n",
       "   'out',\n",
       "   'on',\n",
       "   'the',\n",
       "   'European',\n",
       "   'Car',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Year',\n",
       "   'award',\n",
       "   ',',\n",
       "   'which',\n",
       "   'goes',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Fiat',\n",
       "   '128',\n",
       "   'from',\n",
       "   'Italy',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '283'},\n",
       " {'tokens': ['The',\n",
       "   'North',\n",
       "   'Lyell',\n",
       "   'Mine',\n",
       "   ',',\n",
       "   'scene',\n",
       "   'of',\n",
       "   'the',\n",
       "   '1912',\n",
       "   'North',\n",
       "   'Mount',\n",
       "   'Lyell',\n",
       "   'Disaster',\n",
       "   'was',\n",
       "   'at',\n",
       "   'its',\n",
       "   'northernmost',\n",
       "   'end',\n",
       "   ',',\n",
       "   'on',\n",
       "   'the',\n",
       "   'slopes',\n",
       "   'of',\n",
       "   'Mount',\n",
       "   'Lyell',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   16,\n",
       "   16,\n",
       "   16,\n",
       "   16,\n",
       "   16,\n",
       "   16,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   24,\n",
       "   24,\n",
       "   0],\n",
       "  'id': '284'},\n",
       " {'tokens': ['She',\n",
       "   'graduated',\n",
       "   'from',\n",
       "   'high',\n",
       "   'school',\n",
       "   'in',\n",
       "   '1918',\n",
       "   ',',\n",
       "   'and',\n",
       "   'began',\n",
       "   'working',\n",
       "   'as',\n",
       "   'a',\n",
       "   'stenographer',\n",
       "   'at',\n",
       "   'a',\n",
       "   'local',\n",
       "   'law',\n",
       "   'office',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '285'},\n",
       " {'tokens': ['She',\n",
       "   'started',\n",
       "   'her',\n",
       "   'career',\n",
       "   'after',\n",
       "   'winning',\n",
       "   'the',\n",
       "   '2005',\n",
       "   'EEG',\n",
       "   'Singing',\n",
       "   'Contest',\n",
       "   '(',\n",
       "   'aka',\n",
       "   '24th',\n",
       "   'annual',\n",
       "   'New',\n",
       "   'Talent',\n",
       "   'Singing',\n",
       "   'Awards',\n",
       "   'Hong',\n",
       "   'Kong',\n",
       "   'Regional',\n",
       "   'Finals',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '286'},\n",
       " {'tokens': ['The',\n",
       "   'Clinical',\n",
       "   'Pharmacogenetics',\n",
       "   'Implementation',\n",
       "   'Consortium',\n",
       "   'recommends',\n",
       "   'avoiding',\n",
       "   'amitriptyline',\n",
       "   'in',\n",
       "   'patients',\n",
       "   'who',\n",
       "   'are',\n",
       "   'CYP2D6',\n",
       "   'ultrarapid',\n",
       "   'or',\n",
       "   'poor',\n",
       "   'metabolizers',\n",
       "   ',',\n",
       "   'due',\n",
       "   'to',\n",
       "   'the',\n",
       "   'risk',\n",
       "   'for',\n",
       "   'a',\n",
       "   'lack',\n",
       "   'of',\n",
       "   'efficacy',\n",
       "   'and',\n",
       "   'side',\n",
       "   'effects',\n",
       "   ',',\n",
       "   'respectively',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   49,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '287'},\n",
       " {'tokens': ['After',\n",
       "   'residency',\n",
       "   'in',\n",
       "   'Pediatrics',\n",
       "   'at',\n",
       "   'Hokkaido',\n",
       "   'University',\n",
       "   'Hospital',\n",
       "   ',',\n",
       "   'he',\n",
       "   'worked',\n",
       "   'as',\n",
       "   'a',\n",
       "   'pediatrician',\n",
       "   'in',\n",
       "   'Japan',\n",
       "   'for',\n",
       "   'several',\n",
       "   'years',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 6, 0, 2, 2, 2, 0, 0, 0, 0, 0, 6, 0, 4, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 49, 0, 8, 8, 8, 0, 0, 0, 0, 0, 49, 0, 21, 0, 0, 0, 0],\n",
       "  'id': '288'},\n",
       " {'tokens': ['The',\n",
       "   'Allenby',\n",
       "   'Bridge',\n",
       "   '(',\n",
       "   'English',\n",
       "   'name',\n",
       "   ';',\n",
       "   '``',\n",
       "   'Gesher',\n",
       "   'Allenby',\n",
       "   '``',\n",
       "   ')',\n",
       "   ',',\n",
       "   'known',\n",
       "   'officially',\n",
       "   'in',\n",
       "   'Jordan',\n",
       "   'as',\n",
       "   'the',\n",
       "   'King',\n",
       "   'Hussein',\n",
       "   'Bridge',\n",
       "   '(',\n",
       "   '``',\n",
       "   'Jisr',\n",
       "   'al-Malek',\n",
       "   'Hussein',\n",
       "   '``',\n",
       "   ')',\n",
       "   ',',\n",
       "   'and',\n",
       "   'also',\n",
       "   'called',\n",
       "   'Al-Karameh',\n",
       "   'Bridge',\n",
       "   'by',\n",
       "   'Palestinian',\n",
       "   'Arabs',\n",
       "   ',',\n",
       "   'is',\n",
       "   'a',\n",
       "   'bridge',\n",
       "   'that',\n",
       "   'crosses',\n",
       "   'the',\n",
       "   'Jordan',\n",
       "   'River',\n",
       "   'near',\n",
       "   'the',\n",
       "   'city',\n",
       "   'of',\n",
       "   'Jericho',\n",
       "   ',',\n",
       "   'and',\n",
       "   'connects',\n",
       "   'the',\n",
       "   'West',\n",
       "   'Bank',\n",
       "   'with',\n",
       "   'Jordan',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '289'},\n",
       " {'tokens': ['A',\n",
       "   'study',\n",
       "   'showed',\n",
       "   'that',\n",
       "   'in',\n",
       "   '1880',\n",
       "   'only',\n",
       "   '.4',\n",
       "   'percent',\n",
       "   'of',\n",
       "   'space',\n",
       "   'in',\n",
       "   'the',\n",
       "   'newspaper',\n",
       "   'was',\n",
       "   'dedicated',\n",
       "   'to',\n",
       "   'sports',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '290'},\n",
       " {'tokens': ['New',\n",
       "   'York',\n",
       "   'City',\n",
       "   'Council',\n",
       "   \"'s\",\n",
       "   '2nd',\n",
       "   'district',\n",
       "   'covers',\n",
       "   'the',\n",
       "   'East',\n",
       "   'Village',\n",
       "   ',',\n",
       "   'Alphabet',\n",
       "   'City',\n",
       "   ',',\n",
       "   'Peter',\n",
       "   'Cooper',\n",
       "   'Village',\n",
       "   ',',\n",
       "   'Rose',\n",
       "   'Hill',\n",
       "   ',',\n",
       "   'Kips',\n",
       "   'Bay',\n",
       "   ',',\n",
       "   'Gramercy',\n",
       "   'Park',\n",
       "   'and',\n",
       "   'parts',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Lower',\n",
       "   'East',\n",
       "   'Side',\n",
       "   '.'],\n",
       "  'coarse_tags': [5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   26,\n",
       "   26,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0],\n",
       "  'id': '291'},\n",
       " {'tokens': ['This',\n",
       "   'is',\n",
       "   'due',\n",
       "   'to',\n",
       "   'the',\n",
       "   'fact',\n",
       "   'that',\n",
       "   'collagen',\n",
       "   'makes',\n",
       "   'up',\n",
       "   'about',\n",
       "   '25–35',\n",
       "   '%',\n",
       "   'of',\n",
       "   'the',\n",
       "   'protein',\n",
       "   'in',\n",
       "   'our',\n",
       "   'bodies',\n",
       "   'and',\n",
       "   'contains',\n",
       "   'a',\n",
       "   'hydroxyproline',\n",
       "   'at',\n",
       "   'almost',\n",
       "   'every',\n",
       "   '3rd',\n",
       "   'residue',\n",
       "   'in',\n",
       "   'its',\n",
       "   'amino',\n",
       "   'acid',\n",
       "   'sequence',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   40,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '292'},\n",
       " {'tokens': ['Herodotus',\n",
       "   ',',\n",
       "   'in',\n",
       "   'his',\n",
       "   '``',\n",
       "   'Histories',\n",
       "   '``',\n",
       "   ',',\n",
       "   'Book',\n",
       "   'II',\n",
       "   ',',\n",
       "   'gives',\n",
       "   'a',\n",
       "   'detailed',\n",
       "   'if',\n",
       "   'selectively',\n",
       "   'coloured',\n",
       "   'and',\n",
       "   'imaginative',\n",
       "   'description',\n",
       "   'of',\n",
       "   'ancient',\n",
       "   'Egypt',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '293'},\n",
       " {'tokens': ['Marwin',\n",
       "   'Hitz',\n",
       "   '(',\n",
       "   'born',\n",
       "   '18',\n",
       "   'September',\n",
       "   '1987',\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'Swiss',\n",
       "   'footballer',\n",
       "   'who',\n",
       "   'plays',\n",
       "   'as',\n",
       "   'a',\n",
       "   'goalkeeper',\n",
       "   'for',\n",
       "   'Borussia',\n",
       "   'Dortmund',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Bundesliga',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   0],\n",
       "  'id': '294'},\n",
       " {'tokens': ['Rhos',\n",
       "   'Bwlch-y-rhandir',\n",
       "   'is',\n",
       "   'an',\n",
       "   'amazing',\n",
       "   'Site',\n",
       "   'of',\n",
       "   'Special',\n",
       "   'Scientific',\n",
       "   'Interest',\n",
       "   'situated',\n",
       "   'on',\n",
       "   'Bwlch',\n",
       "   'y',\n",
       "   'Rhandir',\n",
       "   'farm',\n",
       "   'in',\n",
       "   'Llangwyryfon',\n",
       "   ',',\n",
       "   'Ceredigion',\n",
       "   ',',\n",
       "   'west',\n",
       "   'Wales',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '295'},\n",
       " {'tokens': ['Over',\n",
       "   'the',\n",
       "   'course',\n",
       "   'of',\n",
       "   'the',\n",
       "   'battle',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Schleswig-Holstein',\n",
       "   '``',\n",
       "   'had',\n",
       "   'fired',\n",
       "   'only',\n",
       "   'twenty',\n",
       "   '17',\n",
       "   'cm',\n",
       "   'rounds',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '296'},\n",
       " {'tokens': ['Harbour',\n",
       "   'Esplanade',\n",
       "   'is',\n",
       "   'also',\n",
       "   'the',\n",
       "   'location',\n",
       "   'of',\n",
       "   'office',\n",
       "   'buildings',\n",
       "   'and',\n",
       "   'restaurants',\n",
       "   ',',\n",
       "   'whilst',\n",
       "   'the',\n",
       "   'Capital',\n",
       "   'City',\n",
       "   'Trail',\n",
       "   'runs',\n",
       "   'parallel',\n",
       "   'along',\n",
       "   'some',\n",
       "   'of',\n",
       "   'its',\n",
       "   'length',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '297'},\n",
       " {'tokens': ['At',\n",
       "   'this',\n",
       "   'time',\n",
       "   'there',\n",
       "   'were',\n",
       "   '400,000',\n",
       "   'cases',\n",
       "   'reported',\n",
       "   'each',\n",
       "   'year',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '298'},\n",
       " {'tokens': ['On',\n",
       "   '30',\n",
       "   'December',\n",
       "   '1875',\n",
       "   'this',\n",
       "   'seat',\n",
       "   'was',\n",
       "   'again',\n",
       "   'abolished',\n",
       "   ',',\n",
       "   'but',\n",
       "   'only',\n",
       "   'for',\n",
       "   'a',\n",
       "   'few',\n",
       "   'years',\n",
       "   'as',\n",
       "   'it',\n",
       "   'was',\n",
       "   'reinstated',\n",
       "   'on',\n",
       "   '8',\n",
       "   'April',\n",
       "   '1879',\n",
       "   ',',\n",
       "   'and',\n",
       "   'remained',\n",
       "   'the',\n",
       "   'single',\n",
       "   'parliamentary',\n",
       "   'representation',\n",
       "   'from',\n",
       "   'sub-Saharan',\n",
       "   'Africa',\n",
       "   'anywhere',\n",
       "   'in',\n",
       "   'a',\n",
       "   'European',\n",
       "   'legislature',\n",
       "   'until',\n",
       "   'the',\n",
       "   'fall',\n",
       "   'of',\n",
       "   'the',\n",
       "   'third',\n",
       "   'republic',\n",
       "   'in',\n",
       "   '1940',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '299'},\n",
       " {'tokens': ['Dartmouth', 'beat', 'Army', '32–10', 'in', 'the', 'final', '.'],\n",
       "  'coarse_tags': [5, 0, 5, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [37, 0, 37, 0, 0, 0, 0, 0],\n",
       "  'id': '300'},\n",
       " {'tokens': ['During',\n",
       "   'the',\n",
       "   'World',\n",
       "   'Cup',\n",
       "   ',',\n",
       "   'he',\n",
       "   'had',\n",
       "   'a',\n",
       "   'strong',\n",
       "   'performance',\n",
       "   'against',\n",
       "   'Argentina',\n",
       "   'in',\n",
       "   'the',\n",
       "   'round',\n",
       "   'of',\n",
       "   '16',\n",
       "   ',',\n",
       "   'when',\n",
       "   'he',\n",
       "   'scored',\n",
       "   '21',\n",
       "   'points',\n",
       "   'to',\n",
       "   'lead',\n",
       "   'Brazil',\n",
       "   'to',\n",
       "   'a',\n",
       "   'win',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '301'},\n",
       " {'tokens': ['This',\n",
       "   'latter',\n",
       "   'beetle',\n",
       "   ',',\n",
       "   'the',\n",
       "   '``',\n",
       "   'blue',\n",
       "   'Lundy',\n",
       "   'cabbage',\n",
       "   'flea',\n",
       "   'beetle',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   'is',\n",
       "   'a',\n",
       "   'short-winged',\n",
       "   'form',\n",
       "   'of',\n",
       "   'the',\n",
       "   'widespread',\n",
       "   '``',\n",
       "   'P.',\n",
       "   'napi',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '302'},\n",
       " {'tokens': ['According',\n",
       "   'to',\n",
       "   'aviation',\n",
       "   'author',\n",
       "   'Michel',\n",
       "   'van',\n",
       "   'Pelt',\n",
       "   ',',\n",
       "   'the',\n",
       "   'limited',\n",
       "   'missile',\n",
       "   'armament',\n",
       "   'of',\n",
       "   'only',\n",
       "   'one',\n",
       "   'AA.20',\n",
       "   'was',\n",
       "   'a',\n",
       "   'major',\n",
       "   'point',\n",
       "   'of',\n",
       "   'criticism',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Durandal',\n",
       "   ',',\n",
       "   'and',\n",
       "   'contributed',\n",
       "   'to',\n",
       "   'its',\n",
       "   'cancellation',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '303'},\n",
       " {'tokens': ['His', 'feast', 'day', 'is', '19', 'May', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '304'},\n",
       " {'tokens': ['Shortly',\n",
       "   'after',\n",
       "   ',',\n",
       "   'the',\n",
       "   'band',\n",
       "   'reformed',\n",
       "   'as',\n",
       "   'Nocturnus',\n",
       "   'A.D',\n",
       "   '.',\n",
       "   ',',\n",
       "   'containing',\n",
       "   'every',\n",
       "   'member',\n",
       "   'from',\n",
       "   'After',\n",
       "   'Death',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 32, 32, 32, 0, 0, 0, 0, 0, 32, 32, 0],\n",
       "  'id': '305'},\n",
       " {'tokens': ['The',\n",
       "   'third',\n",
       "   'document',\n",
       "   'is',\n",
       "   'the',\n",
       "   'diary',\n",
       "   'of',\n",
       "   'Kalyanji',\n",
       "   'Mehta',\n",
       "   ',',\n",
       "   'brother',\n",
       "   'of',\n",
       "   'Harshram',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 54, 54, 0, 0, 0, 54, 0],\n",
       "  'id': '306'},\n",
       " {'tokens': ['Beyond',\n",
       "   'the',\n",
       "   'western',\n",
       "   'terminus',\n",
       "   'of',\n",
       "   'I-94',\n",
       "   ',',\n",
       "   'I-90',\n",
       "   'connects',\n",
       "   'westbound',\n",
       "   'I-94',\n",
       "   'travelers',\n",
       "   'to',\n",
       "   'points',\n",
       "   'west',\n",
       "   'such',\n",
       "   'as',\n",
       "   'Butte',\n",
       "   ',',\n",
       "   'Missoula',\n",
       "   ',',\n",
       "   'Coeur',\n",
       "   \"d'Alene\",\n",
       "   ',',\n",
       "   'Idaho',\n",
       "   ',',\n",
       "   'Spokane',\n",
       "   ',',\n",
       "   'Washington',\n",
       "   'and',\n",
       "   'Seattle',\n",
       "   ',',\n",
       "   'Washington',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   0,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '307'},\n",
       " {'tokens': ['Marriage',\n",
       "   'criteria',\n",
       "   'began',\n",
       "   'to',\n",
       "   'weigh',\n",
       "   'intelligence',\n",
       "   'and',\n",
       "   'education',\n",
       "   'as',\n",
       "   'desirable',\n",
       "   'attributes',\n",
       "   'in',\n",
       "   'a',\n",
       "   'wife',\n",
       "   ',',\n",
       "   'right',\n",
       "   'along',\n",
       "   'with',\n",
       "   'physical',\n",
       "   'attractiveness',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '308'},\n",
       " {'tokens': ['The',\n",
       "   'town',\n",
       "   'of',\n",
       "   'Hughesovka',\n",
       "   'was',\n",
       "   'renamed',\n",
       "   'Stalino',\n",
       "   'in',\n",
       "   '1924',\n",
       "   ',',\n",
       "   'and',\n",
       "   'then',\n",
       "   'Donetsk',\n",
       "   'in',\n",
       "   '1961',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 21, 0, 0, 21, 0, 0, 0, 0, 0, 21, 0, 0, 0],\n",
       "  'id': '309'},\n",
       " {'tokens': ['The',\n",
       "   'Eurocard',\n",
       "   'Open',\n",
       "   'was',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'tour',\n",
       "   \"'s\",\n",
       "   'Mercedes',\n",
       "   'Super',\n",
       "   '9',\n",
       "   '(',\n",
       "   'now',\n",
       "   'Masters',\n",
       "   ')',\n",
       "   'events',\n",
       "   'and',\n",
       "   'the',\n",
       "   'semi-final',\n",
       "   'came',\n",
       "   'down',\n",
       "   'to',\n",
       "   'a',\n",
       "   'third',\n",
       "   'set',\n",
       "   'tiebreak',\n",
       "   ',',\n",
       "   'but',\n",
       "   'the',\n",
       "   'Croatians',\n",
       "   'were',\n",
       "   'unable',\n",
       "   'to',\n",
       "   'defeat',\n",
       "   'Jacco',\n",
       "   'Eltingh',\n",
       "   'and',\n",
       "   'Paul',\n",
       "   'Haarhuis',\n",
       "   '.'],\n",
       "  'coarse_tags': [3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0],\n",
       "  'id': '310'},\n",
       " {'tokens': ['On',\n",
       "   'May',\n",
       "   '8',\n",
       "   ',',\n",
       "   '2005',\n",
       "   ',',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Bleed',\n",
       "   'Like',\n",
       "   'Me',\n",
       "   '``',\n",
       "   'music',\n",
       "   'video',\n",
       "   'was',\n",
       "   'playlisted',\n",
       "   'by',\n",
       "   'Fuse',\n",
       "   ',',\n",
       "   'and',\n",
       "   'a',\n",
       "   'week',\n",
       "   'later',\n",
       "   'by',\n",
       "   'MTVU',\n",
       "   'and',\n",
       "   'VH1',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   0,\n",
       "   31,\n",
       "   0],\n",
       "  'id': '311'},\n",
       " {'tokens': ['After',\n",
       "   'considering',\n",
       "   'several',\n",
       "   'options',\n",
       "   ',',\n",
       "   'they',\n",
       "   'try',\n",
       "   'to',\n",
       "   'make',\n",
       "   'a',\n",
       "   'short',\n",
       "   'film',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '312'},\n",
       " {'tokens': ['The',\n",
       "   'Painted',\n",
       "   'Desert',\n",
       "   'Visitor',\n",
       "   'Center',\n",
       "   ',',\n",
       "   'designed',\n",
       "   'by',\n",
       "   'modernist',\n",
       "   'architect',\n",
       "   'Richard',\n",
       "   'Neutra',\n",
       "   ',',\n",
       "   'is',\n",
       "   'part',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Painted',\n",
       "   'Desert',\n",
       "   'Community',\n",
       "   'Complex',\n",
       "   'Historic',\n",
       "   'District',\n",
       "   'listed',\n",
       "   'on',\n",
       "   'the',\n",
       "   'National',\n",
       "   'Register',\n",
       "   'of',\n",
       "   'Historic',\n",
       "   'Places',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   26,\n",
       "   26,\n",
       "   26,\n",
       "   26,\n",
       "   26,\n",
       "   26,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '313'},\n",
       " {'tokens': ['A',\n",
       "   'coup',\n",
       "   \"d'état\",\n",
       "   'by',\n",
       "   'Nikita',\n",
       "   'Khrushchev',\n",
       "   ',',\n",
       "   'with',\n",
       "   'help',\n",
       "   'from',\n",
       "   'Marshal',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Soviet',\n",
       "   'Union',\n",
       "   'Georgy',\n",
       "   'Zhukov',\n",
       "   'in',\n",
       "   'June',\n",
       "   '1953',\n",
       "   ',',\n",
       "   'removed',\n",
       "   'Beria',\n",
       "   'from',\n",
       "   'power',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '314'},\n",
       " {'tokens': ['Such',\n",
       "   'negative',\n",
       "   'stereotypes',\n",
       "   'have',\n",
       "   'persisted',\n",
       "   'into',\n",
       "   'modern',\n",
       "   'Russian',\n",
       "   'society',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 4, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 21, 0, 0],\n",
       "  'id': '315'},\n",
       " {'tokens': ['Plimpton',\n",
       "   'died',\n",
       "   'of',\n",
       "   'complications',\n",
       "   'resulting',\n",
       "   'from',\n",
       "   'pneumonia',\n",
       "   ',',\n",
       "   'at',\n",
       "   'Huntington',\n",
       "   'Hospital',\n",
       "   'on',\n",
       "   'Long',\n",
       "   'Island',\n",
       "   ',',\n",
       "   'on',\n",
       "   'July',\n",
       "   '30',\n",
       "   ',',\n",
       "   '1983',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   23,\n",
       "   23,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '316'},\n",
       " {'tokens': ['Although',\n",
       "   'his',\n",
       "   'stepfather',\n",
       "   'later',\n",
       "   'divorced',\n",
       "   'his',\n",
       "   'mother',\n",
       "   ',',\n",
       "   'Berryman',\n",
       "   'and',\n",
       "   'his',\n",
       "   'stepfather',\n",
       "   'stayed',\n",
       "   'on',\n",
       "   'good',\n",
       "   'terms',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 51, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '317'},\n",
       " {'tokens': ['Nance',\n",
       "   \"'s\",\n",
       "   'Gobi',\n",
       "   'crossing',\n",
       "   'was',\n",
       "   'profiled',\n",
       "   'by',\n",
       "   'Adventure',\n",
       "   'World',\n",
       "   'Magazine',\n",
       "   'where',\n",
       "   'he',\n",
       "   'credited',\n",
       "   'the',\n",
       "   'encouragement',\n",
       "   'of',\n",
       "   'fellow',\n",
       "   'runners',\n",
       "   'and',\n",
       "   'the',\n",
       "   'medical',\n",
       "   'team',\n",
       "   \"'s\",\n",
       "   'professionalism',\n",
       "   'for',\n",
       "   'enabling',\n",
       "   'him',\n",
       "   'to',\n",
       "   'finish',\n",
       "   'the',\n",
       "   '250',\n",
       "   'km',\n",
       "   'footrace',\n",
       "   'despite',\n",
       "   'injuring',\n",
       "   'his',\n",
       "   'knee',\n",
       "   'halfway',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [52,\n",
       "   52,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '318'},\n",
       " {'tokens': ['Dispensing',\n",
       "   'with',\n",
       "   'the',\n",
       "   'Board',\n",
       "   'of',\n",
       "   'Higher',\n",
       "   'Education',\n",
       "   'as',\n",
       "   'the',\n",
       "   'governing',\n",
       "   'body',\n",
       "   'of',\n",
       "   'the',\n",
       "   'institution',\n",
       "   ',',\n",
       "   'OHSU',\n",
       "   'adopted',\n",
       "   'a',\n",
       "   'Board',\n",
       "   'of',\n",
       "   'Directors',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0],\n",
       "  'id': '319'},\n",
       " {'tokens': ['A',\n",
       "   'British',\n",
       "   'Army',\n",
       "   'expeditionary',\n",
       "   'force',\n",
       "   ',',\n",
       "   'under',\n",
       "   'Major',\n",
       "   'General',\n",
       "   'Sir',\n",
       "   'James',\n",
       "   'Outram',\n",
       "   ',',\n",
       "   '1st',\n",
       "   'Baronet',\n",
       "   ',',\n",
       "   'which',\n",
       "   'included',\n",
       "   'General',\n",
       "   'Stalker',\n",
       "   'commanding',\n",
       "   'a',\n",
       "   'division',\n",
       "   'of',\n",
       "   'the',\n",
       "   '78th',\n",
       "   'Highlanders',\n",
       "   'or',\n",
       "   'Ross-Shire',\n",
       "   'Buffs',\n",
       "   'advanced',\n",
       "   'from',\n",
       "   'Bushehr',\n",
       "   'to',\n",
       "   'Boorzgoon',\n",
       "   'and',\n",
       "   'defeated',\n",
       "   'the',\n",
       "   'forces',\n",
       "   'of',\n",
       "   'Khanlar',\n",
       "   'Mirza',\n",
       "   'and',\n",
       "   'occupy',\n",
       "   'Bushehr',\n",
       "   'and',\n",
       "   'Lengeh',\n",
       "   'port',\n",
       "   'cities',\n",
       "   'as',\n",
       "   'well',\n",
       "   'as',\n",
       "   'Boorzgoon',\n",
       "   'and',\n",
       "   'Khorramshahr',\n",
       "   ',',\n",
       "   'Khark',\n",
       "   'Islalnd',\n",
       "   'and',\n",
       "   'Ahwaz',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   57,\n",
       "   57,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   57,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   57,\n",
       "   57,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   23,\n",
       "   23,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '320'},\n",
       " {'tokens': ['``',\n",
       "   'Congress',\n",
       "   '``',\n",
       "   'was',\n",
       "   'dismasted',\n",
       "   'only',\n",
       "   'a',\n",
       "   'few',\n",
       "   'days',\n",
       "   'out',\n",
       "   ',',\n",
       "   'and',\n",
       "   '``',\n",
       "   'Essex',\n",
       "   '``',\n",
       "   'was',\n",
       "   'obliged',\n",
       "   'to',\n",
       "   'continue',\n",
       "   'her',\n",
       "   'voyage',\n",
       "   'alone',\n",
       "   ',',\n",
       "   'making',\n",
       "   'her',\n",
       "   'mark',\n",
       "   'as',\n",
       "   'the',\n",
       "   'first',\n",
       "   'US',\n",
       "   'man-of-war',\n",
       "   'to',\n",
       "   'double',\n",
       "   'the',\n",
       "   'Cape',\n",
       "   'of',\n",
       "   'Good',\n",
       "   'Hope',\n",
       "   ',',\n",
       "   'both',\n",
       "   'in',\n",
       "   'March',\n",
       "   'and',\n",
       "   'in',\n",
       "   'August',\n",
       "   '1800',\n",
       "   'prior',\n",
       "   'to',\n",
       "   'successfully',\n",
       "   'completing',\n",
       "   'her',\n",
       "   'convoy',\n",
       "   'mission',\n",
       "   'in',\n",
       "   'November',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   63,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   63,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '321'},\n",
       " {'tokens': ['In',\n",
       "   'Tanca',\n",
       "   ',',\n",
       "   'about',\n",
       "   'of',\n",
       "   'rain',\n",
       "   'fell',\n",
       "   'in',\n",
       "   '30',\n",
       "   'minutes',\n",
       "   ',',\n",
       "   'resulting',\n",
       "   'in',\n",
       "   'flash',\n",
       "   'flooding',\n",
       "   'that',\n",
       "   'washed',\n",
       "   'out',\n",
       "   'a',\n",
       "   'road',\n",
       "   'and',\n",
       "   'damaged',\n",
       "   'a',\n",
       "   'business',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '322'},\n",
       " {'tokens': ['Every',\n",
       "   'five',\n",
       "   'years',\n",
       "   'the',\n",
       "   'ARBA',\n",
       "   'publishes',\n",
       "   'a',\n",
       "   'detailed',\n",
       "   'guide',\n",
       "   'entitled',\n",
       "   '``',\n",
       "   'Standard',\n",
       "   'of',\n",
       "   'Perfection',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 6, 6, 6, 0, 0],\n",
       "  'id': '323'},\n",
       " {'tokens': ['It',\n",
       "   'is',\n",
       "   'approximately',\n",
       "   'long',\n",
       "   'and',\n",
       "   'wide',\n",
       "   'and',\n",
       "   'connects',\n",
       "   'Newark',\n",
       "   'Bay',\n",
       "   'with',\n",
       "   'Upper',\n",
       "   'New',\n",
       "   'York',\n",
       "   'Bay',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 4, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 22, 22, 0, 22, 22, 22, 22, 0],\n",
       "  'id': '324'},\n",
       " {'tokens': ['While',\n",
       "   'the',\n",
       "   'name',\n",
       "   \"'s\",\n",
       "   'origin',\n",
       "   ',',\n",
       "   'honoring',\n",
       "   'Seth',\n",
       "   'Warner',\n",
       "   ',',\n",
       "   'is',\n",
       "   'clear',\n",
       "   ',',\n",
       "   'the',\n",
       "   'charter',\n",
       "   'does',\n",
       "   'nothing',\n",
       "   'to',\n",
       "   'specify',\n",
       "   'precise',\n",
       "   'usage',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '325'},\n",
       " {'tokens': ['Panhypopituitarism',\n",
       "   'and',\n",
       "   'hypothyroidism',\n",
       "   'have',\n",
       "   'each',\n",
       "   'been',\n",
       "   'diagnosed',\n",
       "   'in',\n",
       "   'a',\n",
       "   'handful',\n",
       "   'of',\n",
       "   'individuals',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 43, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '326'},\n",
       " {'tokens': ['This',\n",
       "   'Gull',\n",
       "   'is',\n",
       "   'currently',\n",
       "   'the',\n",
       "   'only',\n",
       "   'airworthy',\n",
       "   'example',\n",
       "   'of',\n",
       "   'either',\n",
       "   'the',\n",
       "   'Gull',\n",
       "   '1',\n",
       "   'or',\n",
       "   'Gull',\n",
       "   'III',\n",
       "   'left',\n",
       "   'in',\n",
       "   'Britain',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0, 8, 8, 0, 0, 4, 0],\n",
       "  'fine_tags': [0,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '327'},\n",
       " {'tokens': ['American', 'reviews', 'were', 'also', 'mixed', '.'],\n",
       "  'coarse_tags': [4, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [21, 0, 0, 0, 0, 0],\n",
       "  'id': '328'},\n",
       " {'tokens': ['The',\n",
       "   'image',\n",
       "   'of',\n",
       "   'Obbatinewat',\n",
       "   'shown',\n",
       "   'on',\n",
       "   'this',\n",
       "   'page',\n",
       "   'was',\n",
       "   'used',\n",
       "   'as',\n",
       "   'the',\n",
       "   'logo',\n",
       "   'of',\n",
       "   'The',\n",
       "   'National',\n",
       "   'Shawmut',\n",
       "   'Bank',\n",
       "   'of',\n",
       "   'Boston',\n",
       "   ',',\n",
       "   'later',\n",
       "   'known',\n",
       "   'as',\n",
       "   'Shawmut',\n",
       "   'Bank',\n",
       "   ',',\n",
       "   'until',\n",
       "   '1995',\n",
       "   'when',\n",
       "   'it',\n",
       "   'merged',\n",
       "   'with',\n",
       "   'Fleet',\n",
       "   'Financial',\n",
       "   'Group',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   0],\n",
       "  'id': '329'},\n",
       " {'tokens': ['Kennedy', 'received', 'a', 'B.A', '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0],\n",
       "  'fine_tags': [54, 0, 0, 0, 0],\n",
       "  'id': '330'},\n",
       " {'tokens': ['But',\n",
       "   'in',\n",
       "   '2016',\n",
       "   ',',\n",
       "   'the',\n",
       "   'three-tome',\n",
       "   '``',\n",
       "   'Animation',\n",
       "   '-',\n",
       "   'A',\n",
       "   'World',\n",
       "   'History',\n",
       "   '``',\n",
       "   'was',\n",
       "   'published',\n",
       "   'by',\n",
       "   'CRC',\n",
       "   'Press',\n",
       "   '(',\n",
       "   'Italian',\n",
       "   'version',\n",
       "   '``',\n",
       "   \"''\",\n",
       "   'Animazione',\n",
       "   '-',\n",
       "   'una',\n",
       "   'storia',\n",
       "   'globale',\n",
       "   '``',\n",
       "   ',',\n",
       "   \"''\",\n",
       "   'Milan',\n",
       "   ',',\n",
       "   'Utet',\n",
       "   ',',\n",
       "   '2017',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   46,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '331'},\n",
       " {'tokens': ['His',\n",
       "   'conducting',\n",
       "   'debut',\n",
       "   'was',\n",
       "   'in',\n",
       "   '1966',\n",
       "   'when',\n",
       "   'he',\n",
       "   'became',\n",
       "   'artistic',\n",
       "   'director',\n",
       "   'and',\n",
       "   'conductor',\n",
       "   'of',\n",
       "   'the',\n",
       "   'award-winning',\n",
       "   'New',\n",
       "   'York',\n",
       "   'Youth',\n",
       "   'Symphony',\n",
       "   ',',\n",
       "   'and',\n",
       "   'in',\n",
       "   '1968',\n",
       "   ',',\n",
       "   'Walter',\n",
       "   'Susskind',\n",
       "   'named',\n",
       "   'him',\n",
       "   'the',\n",
       "   'assistant',\n",
       "   'conductor',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Saint',\n",
       "   'Louis',\n",
       "   'Symphony',\n",
       "   'Orchestra',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   0],\n",
       "  'id': '332'},\n",
       " {'tokens': ['On',\n",
       "   'January',\n",
       "   '11',\n",
       "   ',',\n",
       "   '2012',\n",
       "   ',',\n",
       "   'Bill',\n",
       "   'Haslam',\n",
       "   'endorsed',\n",
       "   'Mitt',\n",
       "   'Romney',\n",
       "   'for',\n",
       "   'the',\n",
       "   'Republican',\n",
       "   'nomination',\n",
       "   'in',\n",
       "   'the',\n",
       "   '2012',\n",
       "   'United',\n",
       "   'States',\n",
       "   'presidential',\n",
       "   'election',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   55,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '333'},\n",
       " {'tokens': ['A',\n",
       "   'proposed',\n",
       "   'rescue',\n",
       "   'package',\n",
       "   'fell',\n",
       "   'through',\n",
       "   'on',\n",
       "   '13',\n",
       "   'June',\n",
       "   'when',\n",
       "   'staff',\n",
       "   'were',\n",
       "   'laid',\n",
       "   'off',\n",
       "   'and',\n",
       "   'it',\n",
       "   'was',\n",
       "   'announced',\n",
       "   'that',\n",
       "   'the',\n",
       "   'airline',\n",
       "   \"'s\",\n",
       "   'assets',\n",
       "   'would',\n",
       "   'be',\n",
       "   'sold',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '334'},\n",
       " {'tokens': ['Embuscade',\n",
       "   '(',\n",
       "   '``',\n",
       "   'Ambush',\n",
       "   '``',\n",
       "   ')',\n",
       "   'was',\n",
       "   'a',\n",
       "   '32-gun',\n",
       "   'frigate',\n",
       "   '.'],\n",
       "  'coarse_tags': [8, 0, 0, 8, 0, 0, 0, 0, 8, 8, 0],\n",
       "  'fine_tags': [63, 0, 0, 63, 0, 0, 0, 0, 63, 63, 0],\n",
       "  'id': '335'},\n",
       " {'tokens': ['In',\n",
       "   'between',\n",
       "   'are',\n",
       "   'the',\n",
       "   'neoclassical',\n",
       "   'Saint',\n",
       "   'Matthew',\n",
       "   'Church',\n",
       "   ',',\n",
       "   'built',\n",
       "   'in',\n",
       "   '1845',\n",
       "   'by',\n",
       "   'Friedrich',\n",
       "   'August',\n",
       "   'Stüler',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Gemäldegalerie',\n",
       "   'as',\n",
       "   'well',\n",
       "   'as',\n",
       "   'the',\n",
       "   'new',\n",
       "   'branch',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Berlin',\n",
       "   'State',\n",
       "   'Library',\n",
       "   '(',\n",
       "   '``',\n",
       "   'Staatsbibliothek',\n",
       "   '``',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   0,\n",
       "   0,\n",
       "   10,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '336'},\n",
       " {'tokens': ['``',\n",
       "   'Free',\n",
       "   'Fallin',\n",
       "   'Tropical',\n",
       "   'Mojito',\n",
       "   'Remix',\n",
       "   '(',\n",
       "   'John',\n",
       "   'Mayer',\n",
       "   'Tribute',\n",
       "   ')',\n",
       "   '``',\n",
       "   'was',\n",
       "   'produced',\n",
       "   'with',\n",
       "   'fellow',\n",
       "   'tropical',\n",
       "   'house',\n",
       "   'producer',\n",
       "   'Nelsaan',\n",
       "   'and',\n",
       "   'was',\n",
       "   'released',\n",
       "   'on',\n",
       "   'Matoma',\n",
       "   \"'s\",\n",
       "   '23rd',\n",
       "   'birthday',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '337'},\n",
       " {'tokens': ['The',\n",
       "   'competition',\n",
       "   'was',\n",
       "   'held',\n",
       "   'at',\n",
       "   'Scotiabank',\n",
       "   'Place',\n",
       "   'on',\n",
       "   'January',\n",
       "   '28',\n",
       "   ',',\n",
       "   '2012',\n",
       "   'between',\n",
       "   '7pm',\n",
       "   'and',\n",
       "   '10pm',\n",
       "   'local',\n",
       "   'time',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 13, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '338'},\n",
       " {'tokens': ['Nearest',\n",
       "   'Railway',\n",
       "   'Station',\n",
       "   'is',\n",
       "   'Nagapattinam',\n",
       "   'about',\n",
       "   '7',\n",
       "   'km'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 2, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 11, 0, 0, 0],\n",
       "  'id': '339'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'survived',\n",
       "   'by',\n",
       "   'his',\n",
       "   'wife',\n",
       "   ',',\n",
       "   'Irma',\n",
       "   ',',\n",
       "   'and',\n",
       "   'his',\n",
       "   'brother',\n",
       "   ',',\n",
       "   'Sam',\n",
       "   'Steiner',\n",
       "   ',',\n",
       "   'who',\n",
       "   'was',\n",
       "   'a',\n",
       "   'manager',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Carnegie',\n",
       "   'Deli',\n",
       "   'at',\n",
       "   'the',\n",
       "   'time',\n",
       "   'of',\n",
       "   'Leo',\n",
       "   \"'s\",\n",
       "   'death',\n",
       "   'and',\n",
       "   'another',\n",
       "   'brother',\n",
       "   'Robert',\n",
       "   ',',\n",
       "   'a',\n",
       "   'Stock',\n",
       "   'Broker',\n",
       "   'in',\n",
       "   'Lakewood',\n",
       "   ',',\n",
       "   'NJ',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   12,\n",
       "   12,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '340'},\n",
       " {'tokens': ['Döndrup',\n",
       "   'studied',\n",
       "   'Tibetan',\n",
       "   'language',\n",
       "   'and',\n",
       "   'literature',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Qinghai',\n",
       "   'Nationalities',\n",
       "   'Institute',\n",
       "   'in',\n",
       "   'Xining',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Northwest',\n",
       "   'Nationalities',\n",
       "   'Institute',\n",
       "   'in',\n",
       "   'Lanzhou',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [56,\n",
       "   0,\n",
       "   46,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '341'},\n",
       " {'tokens': ['Nearly',\n",
       "   'two',\n",
       "   'weeks',\n",
       "   'later',\n",
       "   ',',\n",
       "   'Roy',\n",
       "   'Halladay',\n",
       "   'threw',\n",
       "   'a',\n",
       "   'perfect',\n",
       "   'game',\n",
       "   'against',\n",
       "   'Florida',\n",
       "   ',',\n",
       "   'which',\n",
       "   'was',\n",
       "   'the',\n",
       "   'first',\n",
       "   'one',\n",
       "   'thrown',\n",
       "   'against',\n",
       "   'the',\n",
       "   'Marlins',\n",
       "   'in',\n",
       "   'franchise',\n",
       "   'history',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '342'},\n",
       " {'tokens': ['A',\n",
       "   'full',\n",
       "   'list',\n",
       "   'can',\n",
       "   'be',\n",
       "   'seen',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Jewish',\n",
       "   'Encyclopedia',\n",
       "   'entry',\n",
       "   'for',\n",
       "   '``',\n",
       "   'Hapax',\n",
       "   'Legomena',\n",
       "   '.',\n",
       "   \"''\"],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '343'},\n",
       " {'tokens': ['In',\n",
       "   '1989',\n",
       "   ',',\n",
       "   'Kieff',\n",
       "   'became',\n",
       "   'Chief',\n",
       "   'of',\n",
       "   'Infectious',\n",
       "   'Disease',\n",
       "   'at',\n",
       "   'Harvard',\n",
       "   'Medical',\n",
       "   'School',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Brigham',\n",
       "   'and',\n",
       "   'Women',\n",
       "   '’',\n",
       "   's',\n",
       "   'Hospital',\n",
       "   ';',\n",
       "   'a',\n",
       "   'position',\n",
       "   'he',\n",
       "   'served',\n",
       "   'for',\n",
       "   '25',\n",
       "   'years',\n",
       "   'until',\n",
       "   'his',\n",
       "   'recruitment',\n",
       "   'of',\n",
       "   'Daniel',\n",
       "   'Kuritzkes',\n",
       "   'to',\n",
       "   'undertake',\n",
       "   'leadership',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Clinical',\n",
       "   'Infectious',\n",
       "   'Disease',\n",
       "   'Division',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0],\n",
       "  'id': '344'},\n",
       " {'tokens': ['On',\n",
       "   '20',\n",
       "   'January',\n",
       "   'Company',\n",
       "   'L',\n",
       "   ',',\n",
       "   '3/9',\n",
       "   'Marines',\n",
       "   'reoccupied',\n",
       "   'Firebase',\n",
       "   'Tun',\n",
       "   'Tavern',\n",
       "   '(',\n",
       "   ')',\n",
       "   'and',\n",
       "   'on',\n",
       "   'the',\n",
       "   '21st',\n",
       "   'Company',\n",
       "   'A',\n",
       "   ',',\n",
       "   '1st',\n",
       "   'Battalion',\n",
       "   ',',\n",
       "   '9th',\n",
       "   'Marines',\n",
       "   'reoccupied',\n",
       "   'Firebase',\n",
       "   'Shiloh',\n",
       "   '(',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '345'},\n",
       " {'tokens': ['On',\n",
       "   '29',\n",
       "   'June',\n",
       "   '1941',\n",
       "   '``',\n",
       "   'Frikorps',\n",
       "   'Danmark',\n",
       "   '``',\n",
       "   '(',\n",
       "   'Free',\n",
       "   'Corps',\n",
       "   'Denmark',\n",
       "   ')',\n",
       "   'was',\n",
       "   'founded',\n",
       "   'as',\n",
       "   'a',\n",
       "   'corps',\n",
       "   'of',\n",
       "   'Danish',\n",
       "   'volunteers',\n",
       "   'to',\n",
       "   'fight',\n",
       "   'against',\n",
       "   'the',\n",
       "   'Soviet',\n",
       "   'Union',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '346'},\n",
       " {'tokens': ['In',\n",
       "   'the',\n",
       "   'new',\n",
       "   'version',\n",
       "   ',',\n",
       "   'Paulson',\n",
       "   'starred',\n",
       "   'opposite',\n",
       "   'Bobby',\n",
       "   'Cannavale',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 0, 0, 7, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 50, 0, 0, 50, 50, 0],\n",
       "  'id': '347'},\n",
       " {'tokens': ['LMS',\n",
       "   'Railway',\n",
       "   'wanted',\n",
       "   'to',\n",
       "   'invest',\n",
       "   'in',\n",
       "   'transport',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Scottish',\n",
       "   'islands',\n",
       "   'where',\n",
       "   'rail',\n",
       "   'could',\n",
       "   \"n't\",\n",
       "   'reach',\n",
       "   '.'],\n",
       "  'coarse_tags': [4, 4, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [27, 27, 0, 0, 0, 0, 0, 0, 0, 23, 23, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '348'},\n",
       " {'tokens': ['These', 'include', ':'],\n",
       "  'coarse_tags': [0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0],\n",
       "  'id': '349'},\n",
       " {'tokens': ['The',\n",
       "   'Catholic',\n",
       "   'Church',\n",
       "   'in',\n",
       "   'Norway',\n",
       "   'is',\n",
       "   'almost',\n",
       "   'as',\n",
       "   'old',\n",
       "   'as',\n",
       "   'the',\n",
       "   'kingdom',\n",
       "   'itself',\n",
       "   ',',\n",
       "   'dating',\n",
       "   'from',\n",
       "   'approximately',\n",
       "   '900',\n",
       "   'A.D.',\n",
       "   ',',\n",
       "   'with',\n",
       "   'the',\n",
       "   'first',\n",
       "   'Christian',\n",
       "   'monarchs',\n",
       "   ',',\n",
       "   'Haakon',\n",
       "   'I',\n",
       "   'from',\n",
       "   '934',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '350'},\n",
       " {'tokens': ['In',\n",
       "   '1986',\n",
       "   'the',\n",
       "   'Communist',\n",
       "   'Party',\n",
       "   'of',\n",
       "   'National',\n",
       "   'Liberation',\n",
       "   ',',\n",
       "   'a',\n",
       "   'secessionist',\n",
       "   'splinter',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Galician',\n",
       "   'Galician',\n",
       "   'People',\n",
       "   \"'s\",\n",
       "   'Union',\n",
       "   ',',\n",
       "   'was',\n",
       "   'expelled',\n",
       "   'from',\n",
       "   'the',\n",
       "   'BNG',\n",
       "   'for',\n",
       "   'having',\n",
       "   'supported',\n",
       "   'the',\n",
       "   'candidacy',\n",
       "   'of',\n",
       "   'Herri',\n",
       "   'Batasuna',\n",
       "   'during',\n",
       "   'the',\n",
       "   'Elections',\n",
       "   'to',\n",
       "   'the',\n",
       "   'European',\n",
       "   'Parliament',\n",
       "   'European',\n",
       "   'Parliament',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   4,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   21,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '351'},\n",
       " {'tokens': ['The',\n",
       "   'lower',\n",
       "   'reaches',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Onkaparinga',\n",
       "   'River',\n",
       "   'were',\n",
       "   'inhabited',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Kaurna',\n",
       "   'Aboriginal',\n",
       "   'people',\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'name',\n",
       "   'of',\n",
       "   'the',\n",
       "   'river',\n",
       "   'is',\n",
       "   'taken',\n",
       "   'from',\n",
       "   'the',\n",
       "   'Kaurna',\n",
       "   'name',\n",
       "   'meaning',\n",
       "   'chief',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '352'},\n",
       " {'tokens': ['When',\n",
       "   'the',\n",
       "   'theme',\n",
       "   'of',\n",
       "   'interplanetary',\n",
       "   'colonization',\n",
       "   'first',\n",
       "   'entered',\n",
       "   'SF',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Asteroid',\n",
       "   'Belt',\n",
       "   'was',\n",
       "   'quite',\n",
       "   'low',\n",
       "   'on',\n",
       "   'the',\n",
       "   'list',\n",
       "   'of',\n",
       "   'desirable',\n",
       "   'real',\n",
       "   'estate',\n",
       "   ',',\n",
       "   'far',\n",
       "   'behind',\n",
       "   'such',\n",
       "   'planets',\n",
       "   'as',\n",
       "   'Mars',\n",
       "   'and',\n",
       "   'Venus',\n",
       "   '(',\n",
       "   'often',\n",
       "   'conceived',\n",
       "   'as',\n",
       "   'a',\n",
       "   'kind',\n",
       "   'of',\n",
       "   'paradise',\n",
       "   'planet',\n",
       "   ',',\n",
       "   'until',\n",
       "   'probes',\n",
       "   'in',\n",
       "   'the',\n",
       "   '1960s',\n",
       "   'revealed',\n",
       "   'uninhabitable',\n",
       "   'temperatures',\n",
       "   'with',\n",
       "   'a',\n",
       "   'deadly',\n",
       "   'carbon',\n",
       "   'dioxide',\n",
       "   'and',\n",
       "   'sulfur',\n",
       "   'atmosphere',\n",
       "   'under',\n",
       "   'its',\n",
       "   'clouds',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   41,\n",
       "   41,\n",
       "   0,\n",
       "   41,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '353'},\n",
       " {'tokens': ['At',\n",
       "   'the',\n",
       "   'battle',\n",
       "   ',',\n",
       "   'Balian',\n",
       "   'won',\n",
       "   'fame',\n",
       "   'defending',\n",
       "   'a',\n",
       "   'pass',\n",
       "   'from',\n",
       "   'the',\n",
       "   'Lombards',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 57, 0, 0, 0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '354'},\n",
       " {'tokens': ['Advancing',\n",
       "   'under',\n",
       "   'a',\n",
       "   'cover',\n",
       "   'of',\n",
       "   'artillery',\n",
       "   'and',\n",
       "   'machine',\n",
       "   'gun',\n",
       "   'fire',\n",
       "   ',',\n",
       "   'the',\n",
       "   'battalion',\n",
       "   'captured',\n",
       "   'a',\n",
       "   'section',\n",
       "   'of',\n",
       "   'the',\n",
       "   'German',\n",
       "   'line',\n",
       "   'known',\n",
       "   'as',\n",
       "   'the',\n",
       "   \"'\",\n",
       "   'Blue',\n",
       "   'Line',\n",
       "   \"'\",\n",
       "   'between',\n",
       "   'Polygon',\n",
       "   'Wood',\n",
       "   'and',\n",
       "   'a',\n",
       "   'position',\n",
       "   'known',\n",
       "   'as',\n",
       "   'the',\n",
       "   'Iron',\n",
       "   'Cross',\n",
       "   'Redoubt',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0],\n",
       "  'id': '355'},\n",
       " {'tokens': ['Then-premier',\n",
       "   'Frank',\n",
       "   'Hsieh',\n",
       "   'authorized',\n",
       "   'Chen',\n",
       "   \"'s\",\n",
       "   'resignation',\n",
       "   'on',\n",
       "   'September',\n",
       "   '12',\n",
       "   ',',\n",
       "   'and',\n",
       "   'replaced',\n",
       "   'him',\n",
       "   'with',\n",
       "   'former',\n",
       "   'vice',\n",
       "   'premier',\n",
       "   'Yeh',\n",
       "   'Chu-lan',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0],\n",
       "  'id': '356'},\n",
       " {'tokens': ['Owing',\n",
       "   'to',\n",
       "   'the',\n",
       "   'different',\n",
       "   'headings',\n",
       "   'taken',\n",
       "   'by',\n",
       "   'the',\n",
       "   'two',\n",
       "   'planes',\n",
       "   ',',\n",
       "   'TWA',\n",
       "   \"'s\",\n",
       "   'crossing',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Painted',\n",
       "   'Desert',\n",
       "   'line',\n",
       "   ',',\n",
       "   'assuming',\n",
       "   'no',\n",
       "   'further',\n",
       "   'course',\n",
       "   'changes',\n",
       "   ',',\n",
       "   'would',\n",
       "   'be',\n",
       "   'at',\n",
       "   'a',\n",
       "   '13-degree',\n",
       "   'angle',\n",
       "   'relative',\n",
       "   'to',\n",
       "   'that',\n",
       "   'of',\n",
       "   'the',\n",
       "   'United',\n",
       "   'flight',\n",
       "   ',',\n",
       "   'with',\n",
       "   'the',\n",
       "   'Constellation',\n",
       "   'to',\n",
       "   'the',\n",
       "   'left',\n",
       "   'of',\n",
       "   'the',\n",
       "   'DC-7',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0],\n",
       "  'id': '357'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'a',\n",
       "   'brother',\n",
       "   'of',\n",
       "   'Moravian',\n",
       "   'leader',\n",
       "   'and',\n",
       "   'musical',\n",
       "   'composer',\n",
       "   'Christian',\n",
       "   'Ignatius',\n",
       "   'Latrobe',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 7, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 51, 51, 51, 0],\n",
       "  'id': '358'},\n",
       " {'tokens': ['CikA',\n",
       "   'is',\n",
       "   'a',\n",
       "   'major',\n",
       "   'factor',\n",
       "   'in',\n",
       "   'the',\n",
       "   'input',\n",
       "   'pathway',\n",
       "   'and',\n",
       "   'causes',\n",
       "   'KaiC',\n",
       "   'dependent',\n",
       "   'cell',\n",
       "   'elongation',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0],\n",
       "  'fine_tags': [40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 40, 0, 0, 0, 0],\n",
       "  'id': '359'},\n",
       " {'tokens': ['Because',\n",
       "   'of',\n",
       "   'its',\n",
       "   'proximity',\n",
       "   'to',\n",
       "   'Kordofan',\n",
       "   'and',\n",
       "   'the',\n",
       "   'presence',\n",
       "   'of',\n",
       "   'a',\n",
       "   'railway',\n",
       "   'line',\n",
       "   'through',\n",
       "   'it',\n",
       "   'to',\n",
       "   'Wau',\n",
       "   ',',\n",
       "   'it',\n",
       "   'suffered',\n",
       "   'extensively',\n",
       "   'in',\n",
       "   'the',\n",
       "   '1983–2005',\n",
       "   'civil',\n",
       "   'war',\n",
       "   'in',\n",
       "   'southern',\n",
       "   'Sudan',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '360'},\n",
       " {'tokens': ['Howard',\n",
       "   'Aircraft',\n",
       "   'Corporation',\n",
       "   'was',\n",
       "   'a',\n",
       "   'small',\n",
       "   'United',\n",
       "   'States',\n",
       "   'aircraft',\n",
       "   'manufacturer',\n",
       "   'in',\n",
       "   'the',\n",
       "   '1930s',\n",
       "   'and',\n",
       "   '1940s',\n",
       "   '.'],\n",
       "  'coarse_tags': [5, 5, 5, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [28, 28, 28, 0, 0, 0, 28, 28, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '361'},\n",
       " {'tokens': ['The',\n",
       "   'Airbus',\n",
       "   'order',\n",
       "   'was',\n",
       "   'amended',\n",
       "   'again',\n",
       "   'in',\n",
       "   '2016',\n",
       "   ',',\n",
       "   'removing',\n",
       "   'an',\n",
       "   'A330',\n",
       "   'and',\n",
       "   'four',\n",
       "   'A320s',\n",
       "   'and',\n",
       "   'including',\n",
       "   'four',\n",
       "   'Airbus',\n",
       "   'A320neos',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   0],\n",
       "  'id': '362'},\n",
       " {'tokens': ['Others',\n",
       "   'are',\n",
       "   'associated',\n",
       "   'with',\n",
       "   'star',\n",
       "   'forming',\n",
       "   'regions',\n",
       "   'including',\n",
       "   'T',\n",
       "   'Tauri',\n",
       "   'stars',\n",
       "   'and',\n",
       "   'Herbig–Haro',\n",
       "   'objects',\n",
       "   ',',\n",
       "   'which',\n",
       "   'are',\n",
       "   'caused',\n",
       "   'by',\n",
       "   'the',\n",
       "   'interaction',\n",
       "   'of',\n",
       "   'jets',\n",
       "   'with',\n",
       "   'the',\n",
       "   'interstellar',\n",
       "   'medium',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   38,\n",
       "   38,\n",
       "   0,\n",
       "   38,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '363'},\n",
       " {'tokens': ['The',\n",
       "   'tandem',\n",
       "   'won',\n",
       "   'the',\n",
       "   '2002',\n",
       "   'Australian',\n",
       "   'Open',\n",
       "   ',',\n",
       "   'the',\n",
       "   '2004',\n",
       "   'US',\n",
       "   'Open',\n",
       "   'and',\n",
       "   'the',\n",
       "   '2007',\n",
       "   'French',\n",
       "   'Open',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 21, 0, 0, 0, 0, 21, 0, 0],\n",
       "  'id': '364'},\n",
       " {'tokens': [')',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Lagerstroemia',\n",
       "   '``',\n",
       "   '(',\n",
       "   '56',\n",
       "   ')',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Nesaea',\n",
       "   '``',\n",
       "   '(',\n",
       "   '50',\n",
       "   ')',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Rotala',\n",
       "   '``',\n",
       "   '(',\n",
       "   '45',\n",
       "   ')',\n",
       "   ',',\n",
       "   'and',\n",
       "   '``',\n",
       "   'Lythrum',\n",
       "   '``',\n",
       "   '(',\n",
       "   '35',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '365'},\n",
       " {'tokens': ['This',\n",
       "   'game',\n",
       "   'feature',\n",
       "   'a',\n",
       "   'rare',\n",
       "   'safety',\n",
       "   'scored',\n",
       "   'when',\n",
       "   'Rams',\n",
       "   'tackle',\n",
       "   'John',\n",
       "   'Williams',\n",
       "   'held',\n",
       "   'Bronco',\n",
       "   'LB',\n",
       "   'Larry',\n",
       "   'Evans',\n",
       "   'in',\n",
       "   'the',\n",
       "   'end',\n",
       "   'zone',\n",
       "   'in',\n",
       "   'the',\n",
       "   '1st',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '366'},\n",
       " {'tokens': ['and',\n",
       "   'is',\n",
       "   'consistently',\n",
       "   'ranked',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Most',\n",
       "   'Wired',\n",
       "   \"''\",\n",
       "   'Hospitals',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '367'},\n",
       " {'tokens': ['Dastjerdeh',\n",
       "   '(',\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'village',\n",
       "   'in',\n",
       "   'Jolgeh',\n",
       "   'Rural',\n",
       "   'District',\n",
       "   ',',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Central',\n",
       "   'District',\n",
       "   'of',\n",
       "   'Golpayegan',\n",
       "   'County',\n",
       "   ',',\n",
       "   'Isfahan',\n",
       "   'Province',\n",
       "   ',',\n",
       "   'Iran',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '368'},\n",
       " {'tokens': ['Little',\n",
       "   'is',\n",
       "   'known',\n",
       "   'about',\n",
       "   '``',\n",
       "   'Cochlosoma',\n",
       "   '``',\n",
       "   'life',\n",
       "   'cycles',\n",
       "   'and',\n",
       "   'much',\n",
       "   'of',\n",
       "   'what',\n",
       "   'is',\n",
       "   'known',\n",
       "   'has',\n",
       "   'been',\n",
       "   'observed',\n",
       "   'in',\n",
       "   '``',\n",
       "   'C.',\n",
       "   'anatis',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '369'},\n",
       " {'tokens': ['For',\n",
       "   '2007',\n",
       "   ',',\n",
       "   'Arden',\n",
       "   'signed',\n",
       "   'Bruno',\n",
       "   'Senna',\n",
       "   ',',\n",
       "   'nephew',\n",
       "   'of',\n",
       "   'triple',\n",
       "   'F1',\n",
       "   'champion',\n",
       "   'Ayrton',\n",
       "   'Senna',\n",
       "   ',',\n",
       "   'and',\n",
       "   'A1',\n",
       "   'Team',\n",
       "   'South',\n",
       "   'Africa',\n",
       "   'driver',\n",
       "   'Adrian',\n",
       "   'Zaugg',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0],\n",
       "  'id': '370'},\n",
       " {'tokens': ['13', '.'],\n",
       "  'coarse_tags': [0, 0],\n",
       "  'fine_tags': [0, 0],\n",
       "  'id': '371'},\n",
       " {'tokens': ['He',\n",
       "   'became',\n",
       "   'a',\n",
       "   'member',\n",
       "   'of',\n",
       "   'the',\n",
       "   'inner',\n",
       "   'circle',\n",
       "   'of',\n",
       "   'Boris',\n",
       "   'Yeltsin',\n",
       "   ',',\n",
       "   'and',\n",
       "   'was',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'leaders',\n",
       "   'of',\n",
       "   'his',\n",
       "   'campaign',\n",
       "   'staff',\n",
       "   'in',\n",
       "   '1996',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '372'},\n",
       " {'tokens': ['In',\n",
       "   '1987',\n",
       "   ',',\n",
       "   'astronomer',\n",
       "   'R.',\n",
       "   'Brent',\n",
       "   'Tully',\n",
       "   'of',\n",
       "   'the',\n",
       "   'University',\n",
       "   'of',\n",
       "   'Hawaii',\n",
       "   \"'s\",\n",
       "   'Institute',\n",
       "   'of',\n",
       "   'Astronomy',\n",
       "   'identified',\n",
       "   'what',\n",
       "   'he',\n",
       "   'called',\n",
       "   'the',\n",
       "   'Pisces–Cetus',\n",
       "   'Supercluster',\n",
       "   'Complex',\n",
       "   ',',\n",
       "   'a',\n",
       "   'structure',\n",
       "   'one',\n",
       "   'billion',\n",
       "   'light-years',\n",
       "   'long',\n",
       "   'and',\n",
       "   '150',\n",
       "   'million',\n",
       "   'light-years',\n",
       "   'across',\n",
       "   'in',\n",
       "   'which',\n",
       "   ',',\n",
       "   'he',\n",
       "   'claimed',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Local',\n",
       "   'Supercluster',\n",
       "   'was',\n",
       "   'embedded',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   56,\n",
       "   56,\n",
       "   56,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   38,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '373'},\n",
       " {'tokens': ['The',\n",
       "   'hydroelectric',\n",
       "   'station',\n",
       "   'is',\n",
       "   'located',\n",
       "   'in',\n",
       "   'this',\n",
       "   'secondary',\n",
       "   'channel',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '374'},\n",
       " {'tokens': ['The',\n",
       "   'blue',\n",
       "   'colour',\n",
       "   'stands',\n",
       "   'for',\n",
       "   'the',\n",
       "   'sea',\n",
       "   ',',\n",
       "   'white',\n",
       "   'symbolizes',\n",
       "   'the',\n",
       "   'colour',\n",
       "   'of',\n",
       "   'the',\n",
       "   'sand',\n",
       "   ',',\n",
       "   'and',\n",
       "   'black',\n",
       "   'stands',\n",
       "   'for',\n",
       "   'the',\n",
       "   'Norderney',\n",
       "   'sea',\n",
       "   'sign',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '375'},\n",
       " {'tokens': ['The',\n",
       "   'three',\n",
       "   'different',\n",
       "   'parts',\n",
       "   'of',\n",
       "   'the',\n",
       "   'novel',\n",
       "   'were',\n",
       "   'originally',\n",
       "   'to',\n",
       "   'be',\n",
       "   'titled',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Sea',\n",
       "   'When',\n",
       "   'Young',\n",
       "   '``',\n",
       "   ',',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Sea',\n",
       "   'When',\n",
       "   'Absent',\n",
       "   '``',\n",
       "   'and',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Sea',\n",
       "   'in',\n",
       "   'Being',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '376'},\n",
       " {'tokens': ['By',\n",
       "   'late',\n",
       "   'June',\n",
       "   ',',\n",
       "   'Yakovlev',\n",
       "   'had',\n",
       "   'decided',\n",
       "   'to',\n",
       "   'use',\n",
       "   'a',\n",
       "   'more',\n",
       "   'aerodynamically',\n",
       "   'efficient',\n",
       "   '``',\n",
       "   'tubular',\n",
       "   \"''\",\n",
       "   'layout',\n",
       "   'with',\n",
       "   'the',\n",
       "   'engine',\n",
       "   'buried',\n",
       "   'in',\n",
       "   'the',\n",
       "   'center',\n",
       "   'of',\n",
       "   'the',\n",
       "   'fuselage',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '377'},\n",
       " {'tokens': ['The',\n",
       "   'Kiss',\n",
       "   'lost',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Gladiators',\n",
       "   '56-52',\n",
       "   'in',\n",
       "   'front',\n",
       "   'of',\n",
       "   '4,692',\n",
       "   'fans',\n",
       "   'in',\n",
       "   'San',\n",
       "   'Diego',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0],\n",
       "  'fine_tags': [0, 37, 0, 0, 0, 37, 0, 0, 0, 0, 0, 0, 0, 21, 21, 0],\n",
       "  'id': '378'},\n",
       " {'tokens': ['Research',\n",
       "   'conducted',\n",
       "   'by',\n",
       "   '``',\n",
       "   'Alvin',\n",
       "   '``',\n",
       "   'has',\n",
       "   'been',\n",
       "   'featured',\n",
       "   'in',\n",
       "   'nearly',\n",
       "   '2,000',\n",
       "   'scientific',\n",
       "   'papers',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '379'},\n",
       " {'tokens': ['Ely',\n",
       "   'died',\n",
       "   'at',\n",
       "   'his',\n",
       "   'Oregon',\n",
       "   'residence',\n",
       "   'on',\n",
       "   'April',\n",
       "   '28',\n",
       "   ',',\n",
       "   '2015',\n",
       "   'at',\n",
       "   'the',\n",
       "   'age',\n",
       "   'of',\n",
       "   '71',\n",
       "   ',',\n",
       "   'having',\n",
       "   'long',\n",
       "   'suffered',\n",
       "   'from',\n",
       "   'an',\n",
       "   'unknown',\n",
       "   'illness',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '380'},\n",
       " {'tokens': ['The',\n",
       "   'poem',\n",
       "   'highlights',\n",
       "   'the',\n",
       "   'importance',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Tajik',\n",
       "   'language',\n",
       "   'in',\n",
       "   'maintaining',\n",
       "   'the',\n",
       "   'Tajik',\n",
       "   'nation',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 6, 6, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 46, 46, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '381'},\n",
       " {'tokens': ['Among',\n",
       "   'the',\n",
       "   'buildings',\n",
       "   'of',\n",
       "   'a',\n",
       "   'civil',\n",
       "   'nature',\n",
       "   'can',\n",
       "   'be',\n",
       "   'mentioned',\n",
       "   'the',\n",
       "   'Hacienda',\n",
       "   'Sin',\n",
       "   'Nombre',\n",
       "   '(',\n",
       "   'With',\n",
       "   'No',\n",
       "   'Name',\n",
       "   ')',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Hacienda',\n",
       "   'del',\n",
       "   'Burro',\n",
       "   'de',\n",
       "   'Oro',\n",
       "   '(',\n",
       "   'Golden',\n",
       "   'Donkey',\n",
       "   ')',\n",
       "   'and',\n",
       "   'the',\n",
       "   'nursing',\n",
       "   'home',\n",
       "   'of',\n",
       "   'San',\n",
       "   'José',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0],\n",
       "  'id': '382'},\n",
       " {'tokens': ['Charles',\n",
       "   'Engelhard',\n",
       "   'was',\n",
       "   'a',\n",
       "   'major',\n",
       "   'contributor',\n",
       "   'to',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'Democratic',\n",
       "   'Party',\n",
       "   'and',\n",
       "   'in',\n",
       "   'the',\n",
       "   '1960',\n",
       "   'presidential',\n",
       "   'election',\n",
       "   'organized',\n",
       "   'the',\n",
       "   'National',\n",
       "   'Committee',\n",
       "   'of',\n",
       "   'Business',\n",
       "   'and',\n",
       "   'Professional',\n",
       "   'Men',\n",
       "   'and',\n",
       "   'Women',\n",
       "   'for',\n",
       "   'Kennedy',\n",
       "   'and',\n",
       "   'Johnson',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   0],\n",
       "  'id': '383'},\n",
       " {'tokens': ['This',\n",
       "   'was',\n",
       "   'followed',\n",
       "   'by',\n",
       "   'release',\n",
       "   'in',\n",
       "   'a',\n",
       "   'further',\n",
       "   '26',\n",
       "   'countries',\n",
       "   'in',\n",
       "   'March',\n",
       "   'and',\n",
       "   'April',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '384'},\n",
       " {'tokens': ['The',\n",
       "   'Innuitian',\n",
       "   'Mountains',\n",
       "   \"'\",\n",
       "   'present',\n",
       "   'form',\n",
       "   'was',\n",
       "   'shaped',\n",
       "   'during',\n",
       "   'the',\n",
       "   'Innuitian',\n",
       "   'orogeny',\n",
       "   'in',\n",
       "   'the',\n",
       "   'middle',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Mesozoic',\n",
       "   'Era',\n",
       "   'when',\n",
       "   'the',\n",
       "   'North',\n",
       "   'American',\n",
       "   'Plate',\n",
       "   'moved',\n",
       "   'northward',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   24,\n",
       "   24,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '385'},\n",
       " {'tokens': ['Mridangam',\n",
       "   'is',\n",
       "   'used',\n",
       "   'as',\n",
       "   'an',\n",
       "   'accompanying',\n",
       "   'instrument',\n",
       "   'in',\n",
       "   'Yakshagana',\n",
       "   'Himmela',\n",
       "   '(',\n",
       "   'orchestra',\n",
       "   ')',\n",
       "   'where',\n",
       "   'it',\n",
       "   'is',\n",
       "   'called',\n",
       "   'the',\n",
       "   'maddale',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 35, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '386'},\n",
       " {'tokens': ['This',\n",
       "   'move',\n",
       "   'reflected',\n",
       "   'the',\n",
       "   'lack',\n",
       "   'of',\n",
       "   'internal',\n",
       "   'democracy',\n",
       "   'within',\n",
       "   'the',\n",
       "   'party',\n",
       "   ',',\n",
       "   'which',\n",
       "   'was',\n",
       "   'increasingly',\n",
       "   'referred',\n",
       "   'to',\n",
       "   'as',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Bhutto',\n",
       "   'Family',\n",
       "   'Party',\n",
       "   '``',\n",
       "   '(',\n",
       "   'BFP',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '387'},\n",
       " {'tokens': ['Annobón',\n",
       "   ',',\n",
       "   'Bioko',\n",
       "   'Norte',\n",
       "   'and',\n",
       "   'Bioko',\n",
       "   'Sur',\n",
       "   'are',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Insular',\n",
       "   'Region',\n",
       "   ';',\n",
       "   'the',\n",
       "   'other',\n",
       "   'five',\n",
       "   'provinces',\n",
       "   'are',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Continental',\n",
       "   'Region',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [23,\n",
       "   0,\n",
       "   23,\n",
       "   23,\n",
       "   0,\n",
       "   23,\n",
       "   23,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '388'},\n",
       " {'tokens': ['She',\n",
       "   'was',\n",
       "   'the',\n",
       "   'overall',\n",
       "   'winner',\n",
       "   'of',\n",
       "   'the',\n",
       "   'first-ever',\n",
       "   'Olympic',\n",
       "   'Trials',\n",
       "   'for',\n",
       "   'the',\n",
       "   'U.S.',\n",
       "   'Women',\n",
       "   \"'s\",\n",
       "   'Olympic',\n",
       "   'Biathlon',\n",
       "   'Team',\n",
       "   'in',\n",
       "   '1992',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '389'},\n",
       " {'tokens': ['(',\n",
       "   'He',\n",
       "   'died',\n",
       "   'because',\n",
       "   'of',\n",
       "   'complications',\n",
       "   'resulting',\n",
       "   'from',\n",
       "   'an',\n",
       "   'injury',\n",
       "   'that',\n",
       "   'he',\n",
       "   'received',\n",
       "   'in',\n",
       "   'a',\n",
       "   'car',\n",
       "   'crash',\n",
       "   '.',\n",
       "   ')'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '390'},\n",
       " {'tokens': ['Friday', \"'s\", 'by', 'mid-2016', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0],\n",
       "  'id': '391'},\n",
       " {'tokens': ['A',\n",
       "   'second',\n",
       "   'UK',\n",
       "   'touring',\n",
       "   'production',\n",
       "   'starring',\n",
       "   'comedian',\n",
       "   'Rufus',\n",
       "   'Hound',\n",
       "   'in',\n",
       "   'the',\n",
       "   'lead',\n",
       "   'role',\n",
       "   ',',\n",
       "   'began',\n",
       "   '25',\n",
       "   'October',\n",
       "   '2012',\n",
       "   'at',\n",
       "   'Curve',\n",
       "   'in',\n",
       "   'Leicester',\n",
       "   ',',\n",
       "   'on',\n",
       "   'a',\n",
       "   'run',\n",
       "   'through',\n",
       "   '4',\n",
       "   'November',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '392'},\n",
       " {'tokens': ['Dadoo',\n",
       "   'was',\n",
       "   'banned',\n",
       "   'from',\n",
       "   'attending',\n",
       "   'all',\n",
       "   'gatherings',\n",
       "   'and',\n",
       "   'ordered',\n",
       "   'to',\n",
       "   'resign',\n",
       "   'from',\n",
       "   'the',\n",
       "   'SAIC',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Defiance',\n",
       "   'Campaign',\n",
       "   'planning',\n",
       "   'committee',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   19,\n",
       "   19,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '393'},\n",
       " {'tokens': ['The',\n",
       "   'Ferals',\n",
       "   'was',\n",
       "   'an',\n",
       "   'Australian',\n",
       "   'children',\n",
       "   \"'s\",\n",
       "   'comedy',\n",
       "   'television',\n",
       "   'series',\n",
       "   'which',\n",
       "   'screened',\n",
       "   'on',\n",
       "   'the',\n",
       "   'ABC',\n",
       "   'from',\n",
       "   '1994',\n",
       "   'to',\n",
       "   '1995',\n",
       "   '.'],\n",
       "  'coarse_tags': [1, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [1, 1, 0, 0, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 0, 0, 0, 0, 0],\n",
       "  'id': '394'},\n",
       " {'tokens': ['It',\n",
       "   'is',\n",
       "   'only',\n",
       "   'certain',\n",
       "   'that',\n",
       "   'it',\n",
       "   'antecedes',\n",
       "   'Herodotus',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 56, 0],\n",
       "  'id': '395'},\n",
       " {'tokens': ['The',\n",
       "   'main',\n",
       "   'industry',\n",
       "   'was',\n",
       "   'the',\n",
       "   'manufacture',\n",
       "   'of',\n",
       "   'roofing',\n",
       "   'clay',\n",
       "   'tiles',\n",
       "   'by',\n",
       "   'several',\n",
       "   'companies',\n",
       "   'engaged',\n",
       "   'in',\n",
       "   'that',\n",
       "   'business',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '396'},\n",
       " {'tokens': ['The',\n",
       "   'addition',\n",
       "   'of',\n",
       "   'GM3',\n",
       "   'to',\n",
       "   'bladder',\n",
       "   'cancer',\n",
       "   'cells',\n",
       "   'also',\n",
       "   'decreases',\n",
       "   'their',\n",
       "   'cell',\n",
       "   'adhesion',\n",
       "   'and',\n",
       "   'inhibits',\n",
       "   'tumor',\n",
       "   'growth',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 6, 0, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 40, 0, 43, 43, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '397'},\n",
       " {'tokens': ['Somerset',\n",
       "   'Christian',\n",
       "   'College',\n",
       "   'was',\n",
       "   'established',\n",
       "   'on',\n",
       "   'March',\n",
       "   '23',\n",
       "   ',',\n",
       "   '2001',\n",
       "   '.'],\n",
       "  'coarse_tags': [5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [29, 29, 29, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '398'},\n",
       " {'tokens': ['A',\n",
       "   'few',\n",
       "   'officers',\n",
       "   'were',\n",
       "   'issued',\n",
       "   'with',\n",
       "   'Lee-Enfield',\n",
       "   'sniper-rifles',\n",
       "   'with',\n",
       "   'telescopic',\n",
       "   'sights',\n",
       "   ',',\n",
       "   'converted',\n",
       "   'to',\n",
       "   'use',\n",
       "   '7.62',\n",
       "   'mm',\n",
       "   'ammunition',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 66, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '399'},\n",
       " {'tokens': ['NESN',\n",
       "   'has',\n",
       "   'carried',\n",
       "   'regional',\n",
       "   'Atlantic',\n",
       "   'Coast',\n",
       "   'Conference',\n",
       "   'college',\n",
       "   'basketball',\n",
       "   'games',\n",
       "   'since',\n",
       "   'Boston',\n",
       "   'College',\n",
       "   'joined',\n",
       "   'the',\n",
       "   'conference',\n",
       "   ',',\n",
       "   'including',\n",
       "   'games',\n",
       "   'distributed',\n",
       "   'for',\n",
       "   'national',\n",
       "   'broadcast',\n",
       "   'for',\n",
       "   'and',\n",
       "   'by',\n",
       "   'Fox',\n",
       "   'Sports',\n",
       "   'Networks',\n",
       "   '.'],\n",
       "  'coarse_tags': [5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   36,\n",
       "   36,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   31,\n",
       "   31,\n",
       "   0],\n",
       "  'id': '400'},\n",
       " {'tokens': ['In',\n",
       "   'film',\n",
       "   ',',\n",
       "   'Donald',\n",
       "   'MacKinnon',\n",
       "   'portrayed',\n",
       "   'a',\n",
       "   'cameo',\n",
       "   'as',\n",
       "   'Colossus',\n",
       "   'in',\n",
       "   '``',\n",
       "   'X-Men',\n",
       "   '.',\n",
       "   \"''\"],\n",
       "  'coarse_tags': [0, 0, 0, 7, 7, 0, 0, 0, 0, 7, 0, 0, 1, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 50, 50, 0, 0, 0, 0, 54, 0, 0, 2, 0, 0],\n",
       "  'id': '401'},\n",
       " {'tokens': ['Interference',\n",
       "   'with',\n",
       "   'lipid',\n",
       "   'metabolism',\n",
       "   'is',\n",
       "   'postulated',\n",
       "   'as',\n",
       "   'pathophysiology',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '402'},\n",
       " {'tokens': ['In',\n",
       "   'the',\n",
       "   'present',\n",
       "   'day',\n",
       "   ',',\n",
       "   'Siya',\n",
       "   'attempts',\n",
       "   'to',\n",
       "   'save',\n",
       "   'Ram',\n",
       "   'from',\n",
       "   'Mohini',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 54, 0, 0, 0, 54, 0, 54, 0],\n",
       "  'id': '403'},\n",
       " {'tokens': ['Owned',\n",
       "   'by',\n",
       "   'Amarillo',\n",
       "   'College',\n",
       "   '(',\n",
       "   'via',\n",
       "   'the',\n",
       "   'Amarillo',\n",
       "   'Junior',\n",
       "   'College',\n",
       "   'District',\n",
       "   ')',\n",
       "   ',',\n",
       "   'it',\n",
       "   'is',\n",
       "   'sister',\n",
       "   'to',\n",
       "   'National',\n",
       "   'Public',\n",
       "   'Radio',\n",
       "   '(',\n",
       "   'NPR',\n",
       "   ')',\n",
       "   'member',\n",
       "   'station',\n",
       "   'KACV-FM',\n",
       "   '(',\n",
       "   '89.9',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   31,\n",
       "   31,\n",
       "   0,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '404'},\n",
       " {'tokens': ['The',\n",
       "   'Egyptian',\n",
       "   'Expeditionary',\n",
       "   'Force',\n",
       "   '(',\n",
       "   'EEF',\n",
       "   ')',\n",
       "   'went',\n",
       "   'over',\n",
       "   'to',\n",
       "   'the',\n",
       "   'offensive',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Sinai',\n",
       "   'Desert',\n",
       "   'in',\n",
       "   'August',\n",
       "   ',',\n",
       "   'winning',\n",
       "   'the',\n",
       "   'Battle',\n",
       "   'of',\n",
       "   'Romani',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   0],\n",
       "  'id': '405'},\n",
       " {'tokens': ['On',\n",
       "   '2',\n",
       "   'November',\n",
       "   '1914',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Ottoman',\n",
       "   'Empire',\n",
       "   'opened',\n",
       "   'the',\n",
       "   'Middle',\n",
       "   'Eastern',\n",
       "   'theater',\n",
       "   'of',\n",
       "   'World',\n",
       "   'War',\n",
       "   'I',\n",
       "   'by',\n",
       "   'entering',\n",
       "   'hostilities',\n",
       "   'on',\n",
       "   'the',\n",
       "   'side',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Central',\n",
       "   'Powers',\n",
       "   'and',\n",
       "   'against',\n",
       "   'the',\n",
       "   'Allies',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0],\n",
       "  'id': '406'},\n",
       " {'tokens': ['The',\n",
       "   'acceleration',\n",
       "   'due',\n",
       "   'to',\n",
       "   'gravity',\n",
       "   'on',\n",
       "   'the',\n",
       "   'surface',\n",
       "   'of',\n",
       "   'Churyumov–Gerasimenko',\n",
       "   'has',\n",
       "   'been',\n",
       "   'estimated',\n",
       "   'for',\n",
       "   'simulation',\n",
       "   'purposes',\n",
       "   'at',\n",
       "   '10−3',\n",
       "   'm/s',\n",
       "   ',',\n",
       "   'or',\n",
       "   'about',\n",
       "   '1/10000',\n",
       "   'of',\n",
       "   'that',\n",
       "   'on',\n",
       "   'Earth',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '407'},\n",
       " {'tokens': ['The',\n",
       "   'series',\n",
       "   'was',\n",
       "   'awarded',\n",
       "   'the',\n",
       "   '1992',\n",
       "   'Kodansha',\n",
       "   'Manga',\n",
       "   'Award',\n",
       "   'for',\n",
       "   'general',\n",
       "   'manga',\n",
       "   'and',\n",
       "   'the',\n",
       "   '1998',\n",
       "   'Tezuka',\n",
       "   'Osamu',\n",
       "   'Cultural',\n",
       "   'Prize',\n",
       "   'Award',\n",
       "   'for',\n",
       "   'Excellence',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '408'},\n",
       " {'tokens': ['After',\n",
       "   'the',\n",
       "   'war',\n",
       "   'he',\n",
       "   'became',\n",
       "   'a',\n",
       "   'successful',\n",
       "   'business',\n",
       "   'executive',\n",
       "   'and',\n",
       "   'chief',\n",
       "   'financial',\n",
       "   'officer',\n",
       "   'for',\n",
       "   'BASF',\n",
       "   ',',\n",
       "   'and',\n",
       "   'held',\n",
       "   'a',\n",
       "   'senior-level',\n",
       "   'position',\n",
       "   'with',\n",
       "   'Mercedes-Benz',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0],\n",
       "  'id': '409'},\n",
       " {'tokens': ['The',\n",
       "   'film',\n",
       "   'became',\n",
       "   'the',\n",
       "   'only',\n",
       "   'international',\n",
       "   'version',\n",
       "   'of',\n",
       "   'Tolstoy',\n",
       "   \"'s\",\n",
       "   '``',\n",
       "   'Anna',\n",
       "   'Karenina',\n",
       "   '``',\n",
       "   'filmed',\n",
       "   'entirely',\n",
       "   'in',\n",
       "   'Russia',\n",
       "   ',',\n",
       "   'at',\n",
       "   'locations',\n",
       "   'in',\n",
       "   'Saint',\n",
       "   'Petersburg',\n",
       "   'and',\n",
       "   'Moscow',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '410'},\n",
       " {'tokens': ['The',\n",
       "   'last',\n",
       "   'position',\n",
       "   'occupied',\n",
       "   'by',\n",
       "   'Lin',\n",
       "   \"'s\",\n",
       "   'forces',\n",
       "   'was',\n",
       "   'the',\n",
       "   'tropical',\n",
       "   'island',\n",
       "   'of',\n",
       "   'Hainan',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 55, 0, 0, 0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '411'},\n",
       " {'tokens': ['The',\n",
       "   'Soyuz',\n",
       "   'spacecraft',\n",
       "   'brought',\n",
       "   'two',\n",
       "   'visiting',\n",
       "   'crew',\n",
       "   'members',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Salyut',\n",
       "   '6',\n",
       "   'space',\n",
       "   'station',\n",
       "   ',',\n",
       "   'one',\n",
       "   'of',\n",
       "   'whom',\n",
       "   'was',\n",
       "   'an',\n",
       "   'Intercosmos',\n",
       "   'cosmonaut',\n",
       "   'from',\n",
       "   'Cuba',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   62,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '412'},\n",
       " {'tokens': ['However',\n",
       "   ',',\n",
       "   'Buddah',\n",
       "   'head',\n",
       "   'Neil',\n",
       "   'Bogart',\n",
       "   'liked',\n",
       "   'the',\n",
       "   'demo',\n",
       "   'enough',\n",
       "   'that',\n",
       "   'he',\n",
       "   'released',\n",
       "   'the',\n",
       "   'record',\n",
       "   '``',\n",
       "   'as',\n",
       "   'is',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   'with',\n",
       "   'Levine',\n",
       "   \"'s\",\n",
       "   'vocals',\n",
       "   'intact',\n",
       "   'and',\n",
       "   'no',\n",
       "   'input',\n",
       "   'at',\n",
       "   'all',\n",
       "   'from',\n",
       "   'the',\n",
       "   'touring',\n",
       "   'version',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Ohio',\n",
       "   'Express',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0],\n",
       "  'id': '413'},\n",
       " {'tokens': ['He',\n",
       "   'returned',\n",
       "   'to',\n",
       "   'the',\n",
       "   'United',\n",
       "   'Kingdom',\n",
       "   'four',\n",
       "   'years',\n",
       "   'later',\n",
       "   'with',\n",
       "   'the',\n",
       "   '1986',\n",
       "   'Kangaroo',\n",
       "   'Tour',\n",
       "   'and',\n",
       "   'participated',\n",
       "   'in',\n",
       "   'all',\n",
       "   'six',\n",
       "   'Test',\n",
       "   'matches',\n",
       "   ',',\n",
       "   'against',\n",
       "   'Papua',\n",
       "   'New',\n",
       "   'Guinea',\n",
       "   ',',\n",
       "   'Great',\n",
       "   'Britain',\n",
       "   'and',\n",
       "   'France',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '414'},\n",
       " {'tokens': ['Just',\n",
       "   'over',\n",
       "   'a',\n",
       "   'month',\n",
       "   'later',\n",
       "   'an',\n",
       "   'Air',\n",
       "   'India',\n",
       "   'employee',\n",
       "   'in',\n",
       "   'Melbourne',\n",
       "   'was',\n",
       "   'stabbed',\n",
       "   '.',\n",
       "   ')'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 4, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 28, 28, 0, 0, 21, 0, 0, 0, 0],\n",
       "  'id': '415'},\n",
       " {'tokens': ['In',\n",
       "   '2019',\n",
       "   ',',\n",
       "   'he',\n",
       "   'was',\n",
       "   'awarded',\n",
       "   'the',\n",
       "   'General',\n",
       "   'James',\n",
       "   'E.',\n",
       "   'Hill',\n",
       "   'Lifetime',\n",
       "   'Space',\n",
       "   'Achievement',\n",
       "   'Award',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 39, 39, 39, 39, 39, 39, 39, 39, 0],\n",
       "  'id': '416'},\n",
       " {'tokens': ['It',\n",
       "   'is',\n",
       "   '2',\n",
       "   'km',\n",
       "   'from',\n",
       "   'the',\n",
       "   'central',\n",
       "   'bus',\n",
       "   'station',\n",
       "   ',',\n",
       "   '5',\n",
       "   'km',\n",
       "   'from',\n",
       "   'Pallipalayam',\n",
       "   'and',\n",
       "   '5',\n",
       "   'km',\n",
       "   'from',\n",
       "   'Erode',\n",
       "   'Junction',\n",
       "   'railway',\n",
       "   'station',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0],\n",
       "  'id': '417'},\n",
       " {'tokens': ['The',\n",
       "   'Megatherium',\n",
       "   'Club',\n",
       "   'was',\n",
       "   'founded',\n",
       "   'by',\n",
       "   'William',\n",
       "   'Stimpson',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 5, 5, 0, 0, 0, 7, 7, 0],\n",
       "  'fine_tags': [0, 32, 32, 0, 0, 0, 56, 56, 0],\n",
       "  'id': '418'},\n",
       " {'tokens': ['``',\n",
       "   'Play',\n",
       "   'US',\n",
       "   '``',\n",
       "   'gave',\n",
       "   'it',\n",
       "   'three',\n",
       "   'stars',\n",
       "   'out',\n",
       "   'of',\n",
       "   'five',\n",
       "   'and',\n",
       "   'said',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Hardcore',\n",
       "   'RPG',\n",
       "   'fans',\n",
       "   'should',\n",
       "   'add',\n",
       "   'another',\n",
       "   'star',\n",
       "   'to',\n",
       "   'the',\n",
       "   'score',\n",
       "   'and',\n",
       "   'reserve',\n",
       "   'a',\n",
       "   'copy',\n",
       "   'immediately',\n",
       "   '.',\n",
       "   \"''\"],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   31,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '419'},\n",
       " {'tokens': ['Prior',\n",
       "   'to',\n",
       "   'deployment',\n",
       "   'in',\n",
       "   'Afghanistan',\n",
       "   ',',\n",
       "   'Sasha',\n",
       "   'and',\n",
       "   'Rowe',\n",
       "   'were',\n",
       "   'well',\n",
       "   'known',\n",
       "   'to',\n",
       "   'the',\n",
       "   'other',\n",
       "   'members',\n",
       "   'of',\n",
       "   'the',\n",
       "   '104',\n",
       "   'Working',\n",
       "   'Dog',\n",
       "   'Unit',\n",
       "   ',',\n",
       "   'based',\n",
       "   'at',\n",
       "   'North',\n",
       "   'Luffenham',\n",
       "   ',',\n",
       "   'Rutland',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '420'},\n",
       " {'tokens': ['An',\n",
       "   'exact',\n",
       "   'cognate',\n",
       "   'outside',\n",
       "   'of',\n",
       "   'Hebrew',\n",
       "   'is',\n",
       "   'found',\n",
       "   'in',\n",
       "   'Ugaritic',\n",
       "   '``',\n",
       "   'ʾlhm',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   'the',\n",
       "   'family',\n",
       "   'of',\n",
       "   'El',\n",
       "   ',',\n",
       "   'the',\n",
       "   'creator',\n",
       "   'god',\n",
       "   'and',\n",
       "   'chief',\n",
       "   'deity',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Canaanite',\n",
       "   'pantheon',\n",
       "   ',',\n",
       "   'in',\n",
       "   'Biblical',\n",
       "   'Aramaic',\n",
       "   '``',\n",
       "   'ʼĔlāhā',\n",
       "   \"''\",\n",
       "   'and',\n",
       "   'later',\n",
       "   'Syriac',\n",
       "   '``',\n",
       "   'Alaha',\n",
       "   \"''\",\n",
       "   '(',\n",
       "   '``',\n",
       "   'God',\n",
       "   \"''\",\n",
       "   ')',\n",
       "   ',',\n",
       "   'and',\n",
       "   'in',\n",
       "   'Arabic',\n",
       "   '``',\n",
       "   'ʾilāh',\n",
       "   \"''\",\n",
       "   '(',\n",
       "   '``',\n",
       "   'god',\n",
       "   ',',\n",
       "   'deity',\n",
       "   \"''\",\n",
       "   ')',\n",
       "   '(',\n",
       "   'or',\n",
       "   '``',\n",
       "   'Allah',\n",
       "   \"''\",\n",
       "   'as',\n",
       "   '``',\n",
       "   'The',\n",
       "   '[',\n",
       "   'single',\n",
       "   ']',\n",
       "   'God',\n",
       "   \"''\",\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   45,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '421'},\n",
       " {'tokens': ['Although',\n",
       "   'the',\n",
       "   'power',\n",
       "   'of',\n",
       "   'Athens',\n",
       "   'was',\n",
       "   'broken',\n",
       "   ',',\n",
       "   'it',\n",
       "   'made',\n",
       "   'something',\n",
       "   'of',\n",
       "   'a',\n",
       "   'recovery',\n",
       "   'as',\n",
       "   'a',\n",
       "   'result',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Corinthian',\n",
       "   'War',\n",
       "   'and',\n",
       "   'continued',\n",
       "   'to',\n",
       "   'play',\n",
       "   'an',\n",
       "   'active',\n",
       "   'role',\n",
       "   'in',\n",
       "   'Greek',\n",
       "   'politics',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '422'},\n",
       " {'tokens': ['In',\n",
       "   '2014',\n",
       "   'Collegium',\n",
       "   '1704',\n",
       "   'led',\n",
       "   'by',\n",
       "   'Luks',\n",
       "   'collaborated',\n",
       "   'with',\n",
       "   'Bejun',\n",
       "   'Mehta',\n",
       "   'on',\n",
       "   'a',\n",
       "   'DVD',\n",
       "   'of',\n",
       "   'Gluck',\n",
       "   '’',\n",
       "   's',\n",
       "   'opera',\n",
       "   '``',\n",
       "   'Orfeo',\n",
       "   'ed',\n",
       "   'Euridice',\n",
       "   '``',\n",
       "   'with',\n",
       "   'the',\n",
       "   'stage',\n",
       "   'director',\n",
       "   'Ondřej',\n",
       "   'Havelka',\n",
       "   ',',\n",
       "   'and',\n",
       "   'with',\n",
       "   'Rolando',\n",
       "   'Villazón',\n",
       "   'on',\n",
       "   'the',\n",
       "   'making',\n",
       "   'of',\n",
       "   'the',\n",
       "   'BBC',\n",
       "   '2',\n",
       "   'documentary',\n",
       "   '``',\n",
       "   'Mozart',\n",
       "   'in',\n",
       "   'Prague',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   53,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '423'},\n",
       " {'tokens': ['It',\n",
       "   'reached',\n",
       "   'from',\n",
       "   'the',\n",
       "   'Frentani',\n",
       "   'Mountains',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Fortore',\n",
       "   'valley',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 4, 4, 0, 0, 4, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 24, 24, 0, 0, 25, 25, 0],\n",
       "  'id': '424'},\n",
       " {'tokens': ['On',\n",
       "   'the',\n",
       "   'surface',\n",
       "   ',',\n",
       "   'the',\n",
       "   'novel',\n",
       "   'presents',\n",
       "   'a',\n",
       "   'post-apocalyptic',\n",
       "   'adventure',\n",
       "   'tale',\n",
       "   'entitled',\n",
       "   '``',\n",
       "   'Lord',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Swastika',\n",
       "   '``',\n",
       "   ',',\n",
       "   'written',\n",
       "   'by',\n",
       "   'an',\n",
       "   'alternate-history',\n",
       "   'Adolf',\n",
       "   'Hitler',\n",
       "   'shortly',\n",
       "   'before',\n",
       "   'his',\n",
       "   'death',\n",
       "   'in',\n",
       "   '1953',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '425'},\n",
       " {'tokens': ['These',\n",
       "   'measurements',\n",
       "   'have',\n",
       "   'been',\n",
       "   'made',\n",
       "   'in',\n",
       "   'concert',\n",
       "   'with',\n",
       "   'energy',\n",
       "   'balance',\n",
       "   'to',\n",
       "   'identify',\n",
       "   'the',\n",
       "   'cause',\n",
       "   'of',\n",
       "   'the',\n",
       "   'rapid',\n",
       "   'retreat',\n",
       "   'and',\n",
       "   'mass',\n",
       "   'balance',\n",
       "   'loss',\n",
       "   'of',\n",
       "   'these',\n",
       "   'tropical',\n",
       "   'glaciers',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '426'},\n",
       " {'tokens': ['In',\n",
       "   '2012',\n",
       "   ',',\n",
       "   'she',\n",
       "   'was',\n",
       "   'named',\n",
       "   'one',\n",
       "   'of',\n",
       "   '``',\n",
       "   'Seattle',\n",
       "   'Magazine',\n",
       "   '``',\n",
       "   \"'s\",\n",
       "   'Spotlight',\n",
       "   'Award',\n",
       "   'winners',\n",
       "   ',',\n",
       "   'while',\n",
       "   'the',\n",
       "   'following',\n",
       "   'year',\n",
       "   ',',\n",
       "   'she',\n",
       "   'was',\n",
       "   'named',\n",
       "   'a',\n",
       "   'Distinguished',\n",
       "   'Visiting',\n",
       "   'Poet',\n",
       "   'at',\n",
       "   'Seattle',\n",
       "   'University',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '427'},\n",
       " {'tokens': ['A',\n",
       "   'very',\n",
       "   'unusual',\n",
       "   'Dino',\n",
       "   'Quattrovalvole',\n",
       "   'was',\n",
       "   'used',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Lancia',\n",
       "   'Thema',\n",
       "   '8.32',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 8, 8, 0, 0, 0, 0, 8, 8, 8, 0],\n",
       "  'fine_tags': [0, 0, 0, 62, 62, 0, 0, 0, 0, 59, 59, 59, 0],\n",
       "  'id': '428'},\n",
       " {'tokens': ['He',\n",
       "   'authored',\n",
       "   'the',\n",
       "   'JI',\n",
       "   'bomb',\n",
       "   'manual',\n",
       "   ',',\n",
       "   'used',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Bali',\n",
       "   'bombing',\n",
       "   'and',\n",
       "   'the',\n",
       "   '2003',\n",
       "   'Marriott',\n",
       "   'Hotel',\n",
       "   'bombing',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   66,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   0],\n",
       "  'id': '429'},\n",
       " {'tokens': ['Feinberg',\n",
       "   'highlighted',\n",
       "   'the',\n",
       "   'series',\n",
       "   \"'\",\n",
       "   'directors',\n",
       "   ',',\n",
       "   'saying',\n",
       "   ':',\n",
       "   '``',\n",
       "   'A',\n",
       "   'Sundance-friendly',\n",
       "   'gallery',\n",
       "   'of',\n",
       "   'directors',\n",
       "   'including',\n",
       "   'Tom',\n",
       "   'McCarthy',\n",
       "   ',',\n",
       "   'Gregg',\n",
       "   'Araki',\n",
       "   'and',\n",
       "   'Carl',\n",
       "   'Franklin',\n",
       "   'keeps',\n",
       "   'the',\n",
       "   'performances',\n",
       "   'grounded',\n",
       "   'and',\n",
       "   'the',\n",
       "   'extremes',\n",
       "   'from',\n",
       "   'feeling',\n",
       "   'exploitative',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   'while',\n",
       "   'Gilbert',\n",
       "   'of',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Boston',\n",
       "   'Globe',\n",
       "   '``',\n",
       "   'praised',\n",
       "   'the',\n",
       "   'storytelling',\n",
       "   ':',\n",
       "   '``',\n",
       "   'The',\n",
       "   'storytelling',\n",
       "   'techniques',\n",
       "   'are',\n",
       "   'powerful',\n",
       "   '...',\n",
       "   '[',\n",
       "   'as',\n",
       "   'it',\n",
       "   ']',\n",
       "   'builds',\n",
       "   'on',\n",
       "   'the',\n",
       "   'world',\n",
       "   'established',\n",
       "   'in',\n",
       "   'the',\n",
       "   'previous',\n",
       "   'hour',\n",
       "   ',',\n",
       "   'as',\n",
       "   'we',\n",
       "   'continually',\n",
       "   'encounter',\n",
       "   'new',\n",
       "   'facets',\n",
       "   'of',\n",
       "   'Hannah',\n",
       "   \"'s\",\n",
       "   'life',\n",
       "   'and',\n",
       "   'new',\n",
       "   'characters',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   53,\n",
       "   53,\n",
       "   0,\n",
       "   53,\n",
       "   53,\n",
       "   0,\n",
       "   53,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '430'},\n",
       " {'tokens': ['The',\n",
       "   'airline',\n",
       "   'operates',\n",
       "   'the',\n",
       "   'route',\n",
       "   'on',\n",
       "   'a',\n",
       "   'public',\n",
       "   'service',\n",
       "   'obligation',\n",
       "   'contract',\n",
       "   'with',\n",
       "   'the',\n",
       "   'Ministry',\n",
       "   'of',\n",
       "   'Transport',\n",
       "   'and',\n",
       "   'Communications',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 30, 30, 30, 30, 0],\n",
       "  'id': '431'},\n",
       " {'tokens': ['Restrained',\n",
       "   'by',\n",
       "   'her',\n",
       "   'contract',\n",
       "   ',',\n",
       "   \"O'Neil\",\n",
       "   'struggled',\n",
       "   'with',\n",
       "   'sponsors',\n",
       "   'at',\n",
       "   'the',\n",
       "   'time',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 52, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '432'},\n",
       " {'tokens': ['D',\n",
       "   'at',\n",
       "   'the',\n",
       "   'University',\n",
       "   'of',\n",
       "   'Hawaii',\n",
       "   'at',\n",
       "   'Manoa',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 5, 5, 5, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 29, 29, 29, 0, 21, 0],\n",
       "  'id': '433'},\n",
       " {'tokens': ['The', 'pass', 'is', 'close', 'to', 'town', 'of', 'Khab', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 25, 0],\n",
       "  'id': '434'},\n",
       " {'tokens': ['``',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Jews',\n",
       "   'on',\n",
       "   'Broadway',\n",
       "   ':',\n",
       "   'An',\n",
       "   'Historical',\n",
       "   'Survey',\n",
       "   'of',\n",
       "   'Performers',\n",
       "   ',',\n",
       "   'Playwrights',\n",
       "   ',',\n",
       "   'Composers',\n",
       "   ',',\n",
       "   'Lyricists',\n",
       "   'and',\n",
       "   'Producers',\n",
       "   '``',\n",
       "   ',',\n",
       "   '``',\n",
       "   'and',\n",
       "   'Black',\n",
       "   'Broadway',\n",
       "   ':',\n",
       "   'African',\n",
       "   'Americans',\n",
       "   'on',\n",
       "   'the',\n",
       "   'Great',\n",
       "   'White',\n",
       "   'Way',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '435'},\n",
       " {'tokens': ['The',\n",
       "   'southern',\n",
       "   'part',\n",
       "   'of',\n",
       "   'the',\n",
       "   'mouth',\n",
       "   'of',\n",
       "   'King',\n",
       "   'George',\n",
       "   'Sound',\n",
       "   'lies',\n",
       "   'Flinder',\n",
       "   \"'s\",\n",
       "   'trench',\n",
       "   ',',\n",
       "   'which',\n",
       "   'used',\n",
       "   'to',\n",
       "   'be',\n",
       "   'of',\n",
       "   'significance',\n",
       "   'to',\n",
       "   'the',\n",
       "   'local',\n",
       "   'shellfish',\n",
       "   'industry',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '436'},\n",
       " {'tokens': ['As',\n",
       "   'of',\n",
       "   '2020',\n",
       "   'it',\n",
       "   'is',\n",
       "   'estimated',\n",
       "   'to',\n",
       "   'be',\n",
       "   'just',\n",
       "   'under',\n",
       "   '5',\n",
       "   'million',\n",
       "   'according',\n",
       "   'to',\n",
       "   'the',\n",
       "   'country',\n",
       "   \"'s\",\n",
       "   'Central',\n",
       "   'Statistics',\n",
       "   'Office'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '437'},\n",
       " {'tokens': ['Luckily',\n",
       "   ',',\n",
       "   'Spitzer',\n",
       "   'Space',\n",
       "   'Telescope',\n",
       "   'and',\n",
       "   'Chandra',\n",
       "   'X-ray',\n",
       "   'Observatory',\n",
       "   'were',\n",
       "   'already',\n",
       "   'scheduled',\n",
       "   'for',\n",
       "   'simultaneous',\n",
       "   'observations',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 8, 8, 8, 0, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 62, 62, 62, 0, 62, 62, 62, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '438'},\n",
       " {'tokens': ['On',\n",
       "   'his',\n",
       "   'first',\n",
       "   'eleven',\n",
       "   'debut',\n",
       "   'against',\n",
       "   'Wellington',\n",
       "   'Phoenix',\n",
       "   ',',\n",
       "   'his',\n",
       "   'sixth',\n",
       "   'appearance',\n",
       "   'for',\n",
       "   'Queensland',\n",
       "   ',',\n",
       "   'he',\n",
       "   'scored',\n",
       "   'in',\n",
       "   'the',\n",
       "   'opening',\n",
       "   'minutes',\n",
       "   'of',\n",
       "   'the',\n",
       "   'game',\n",
       "   'and',\n",
       "   'set',\n",
       "   'up',\n",
       "   'a',\n",
       "   'first',\n",
       "   'half',\n",
       "   'added-time',\n",
       "   'goal',\n",
       "   'for',\n",
       "   'fellow',\n",
       "   'youngster',\n",
       "   'and',\n",
       "   'close',\n",
       "   'friend',\n",
       "   'Robbie',\n",
       "   'Kruse',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0],\n",
       "  'id': '439'},\n",
       " {'tokens': ['Once',\n",
       "   'one',\n",
       "   'of',\n",
       "   'Virginia',\n",
       "   '’',\n",
       "   's',\n",
       "   'best-known',\n",
       "   'resorts',\n",
       "   ',',\n",
       "   'Panorama',\n",
       "   'most',\n",
       "   'recently',\n",
       "   'operated',\n",
       "   'as',\n",
       "   'a',\n",
       "   'restaurant',\n",
       "   'destination',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Shenandoah',\n",
       "   'National',\n",
       "   'Park',\n",
       "   'and',\n",
       "   'was',\n",
       "   'run',\n",
       "   'by',\n",
       "   'Aramark',\n",
       "   'Parks',\n",
       "   'and',\n",
       "   'Resorts',\n",
       "   ',',\n",
       "   'the',\n",
       "   'commercial',\n",
       "   'vendor',\n",
       "   'inside',\n",
       "   'SNP',\n",
       "   'that',\n",
       "   'operated',\n",
       "   'sister',\n",
       "   'resorts',\n",
       "   'Big',\n",
       "   'Meadows',\n",
       "   'and',\n",
       "   'Skyland',\n",
       "   'Resort',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   26,\n",
       "   26,\n",
       "   26,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   26,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   0],\n",
       "  'id': '440'},\n",
       " {'tokens': ['Two',\n",
       "   'thirds',\n",
       "   'of',\n",
       "   'women',\n",
       "   'respond',\n",
       "   'to',\n",
       "   'trastuzumab',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '441'},\n",
       " {'tokens': ['X',\n",
       "   'window',\n",
       "   'managers',\n",
       "   'also',\n",
       "   'have',\n",
       "   'the',\n",
       "   'ability',\n",
       "   'to',\n",
       "   're-parent',\n",
       "   'applications',\n",
       "   ',',\n",
       "   'meaning',\n",
       "   'that',\n",
       "   ',',\n",
       "   'while',\n",
       "   'initially',\n",
       "   'all',\n",
       "   'applications',\n",
       "   'are',\n",
       "   'adopted',\n",
       "   'by',\n",
       "   'the',\n",
       "   'root',\n",
       "   'window',\n",
       "   '(',\n",
       "   'essentially',\n",
       "   'the',\n",
       "   'whole',\n",
       "   'screen',\n",
       "   ')',\n",
       "   ',',\n",
       "   'an',\n",
       "   'application',\n",
       "   'started',\n",
       "   'within',\n",
       "   'the',\n",
       "   'root',\n",
       "   'window',\n",
       "   'can',\n",
       "   'be',\n",
       "   'adopted',\n",
       "   'by',\n",
       "   '(',\n",
       "   'i.e.',\n",
       "   ',',\n",
       "   'put',\n",
       "   'inside',\n",
       "   'of',\n",
       "   ')',\n",
       "   'another',\n",
       "   'window',\n",
       "   '.'],\n",
       "  'coarse_tags': [8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [64,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '442'},\n",
       " {'tokens': ['Little',\n",
       "   'Rissington',\n",
       "   'became',\n",
       "   'the',\n",
       "   'largest',\n",
       "   'military',\n",
       "   'contingency',\n",
       "   'hospital',\n",
       "   'in',\n",
       "   'Europe',\n",
       "   '.'],\n",
       "  'coarse_tags': [2, 2, 0, 0, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [8, 8, 0, 0, 0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '443'},\n",
       " {'tokens': ['Latifah',\n",
       "   'has',\n",
       "   'received',\n",
       "   'one',\n",
       "   'award',\n",
       "   'from',\n",
       "   'three',\n",
       "   'nominations',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [51, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '444'},\n",
       " {'tokens': ['Unlike',\n",
       "   'the',\n",
       "   'previous',\n",
       "   'Game',\n",
       "   'Boy',\n",
       "   'Advance',\n",
       "   'models',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Game',\n",
       "   'Boy',\n",
       "   'Micro',\n",
       "   'is',\n",
       "   'unable',\n",
       "   'to',\n",
       "   'support',\n",
       "   'Game',\n",
       "   'Boy',\n",
       "   'and',\n",
       "   'Game',\n",
       "   'Boy',\n",
       "   'Color',\n",
       "   'titles',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '445'},\n",
       " {'tokens': ['Carbon',\n",
       "   'monoxide',\n",
       "   'poisoning',\n",
       "   'is',\n",
       "   'the',\n",
       "   'most',\n",
       "   'common',\n",
       "   'type',\n",
       "   'of',\n",
       "   'fatal',\n",
       "   'air',\n",
       "   'poisoning',\n",
       "   'in',\n",
       "   'many',\n",
       "   'countries',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [41, 41, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '446'},\n",
       " {'tokens': ['She', 'owns', 'a', 'Ms.', 'Pac-Man', 'machine', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 8, 8, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 61, 61, 0, 0],\n",
       "  'id': '447'},\n",
       " {'tokens': ['Septic',\n",
       "   'shock',\n",
       "   'is',\n",
       "   'a',\n",
       "   'result',\n",
       "   'of',\n",
       "   'a',\n",
       "   'systemic',\n",
       "   'response',\n",
       "   'to',\n",
       "   'infection',\n",
       "   'or',\n",
       "   'multiple',\n",
       "   'infectious',\n",
       "   'causes',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [43, 43, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '448'},\n",
       " {'tokens': ['His',\n",
       "   'first',\n",
       "   'national',\n",
       "   'story',\n",
       "   'as',\n",
       "   'a',\n",
       "   'news',\n",
       "   'reporter',\n",
       "   'was',\n",
       "   'his',\n",
       "   'coverage',\n",
       "   'of',\n",
       "   'the',\n",
       "   '1994',\n",
       "   'Watts',\n",
       "   'Bar',\n",
       "   'Nuclear',\n",
       "   'Generating',\n",
       "   'Station',\n",
       "   'protest',\n",
       "   'by',\n",
       "   'the',\n",
       "   'radical',\n",
       "   'environmental',\n",
       "   'group',\n",
       "   'Earth',\n",
       "   'First',\n",
       "   'for',\n",
       "   'WVLT-TV',\n",
       "   'in',\n",
       "   'Knoxville',\n",
       "   ',',\n",
       "   'which',\n",
       "   'resulted',\n",
       "   'in',\n",
       "   'numerous',\n",
       "   'arrests',\n",
       "   ',',\n",
       "   'police',\n",
       "   'actions',\n",
       "   'and',\n",
       "   'national',\n",
       "   'media',\n",
       "   'coverage',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   19,\n",
       "   19,\n",
       "   19,\n",
       "   19,\n",
       "   19,\n",
       "   19,\n",
       "   19,\n",
       "   19,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   31,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '449'},\n",
       " {'tokens': ['The',\n",
       "   'Allan',\n",
       "   'Cup',\n",
       "   'was',\n",
       "   'chosen',\n",
       "   'to',\n",
       "   'represent',\n",
       "   'the',\n",
       "   'CAHA',\n",
       "   'championship',\n",
       "   'of',\n",
       "   'a',\n",
       "   'provincial',\n",
       "   'playoffs',\n",
       "   'system',\n",
       "   ',',\n",
       "   'although',\n",
       "   'the',\n",
       "   'cup',\n",
       "   'remained',\n",
       "   'under',\n",
       "   'the',\n",
       "   'control',\n",
       "   'of',\n",
       "   'its',\n",
       "   'trustees',\n",
       "   'according',\n",
       "   'to',\n",
       "   'the',\n",
       "   'deed',\n",
       "   'of',\n",
       "   'gift',\n",
       "   'from',\n",
       "   'H.',\n",
       "   'Montagu',\n",
       "   'Allan',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0],\n",
       "  'id': '450'},\n",
       " {'tokens': ['The',\n",
       "   'original',\n",
       "   'cyclic',\n",
       "   'rate',\n",
       "   'of',\n",
       "   'fire',\n",
       "   'of',\n",
       "   'the',\n",
       "   'early',\n",
       "   'prototype',\n",
       "   'model',\n",
       "   'was',\n",
       "   '1,500',\n",
       "   'rounds',\n",
       "   'per',\n",
       "   'minute',\n",
       "   '(',\n",
       "   'RPM',\n",
       "   ')',\n",
       "   'and',\n",
       "   'was',\n",
       "   'later',\n",
       "   'decreased',\n",
       "   'to',\n",
       "   '900',\n",
       "   'rounds',\n",
       "   'per',\n",
       "   'minute',\n",
       "   '(',\n",
       "   'RPM',\n",
       "   ')',\n",
       "   'for',\n",
       "   'the',\n",
       "   'production',\n",
       "   'model',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '451'},\n",
       " {'tokens': ['That',\n",
       "   'year',\n",
       "   'in',\n",
       "   'spring',\n",
       "   'training',\n",
       "   ',',\n",
       "   'despite',\n",
       "   'a',\n",
       "   'team',\n",
       "   'reservation',\n",
       "   'Weintraub',\n",
       "   'and',\n",
       "   'Harry',\n",
       "   'Danning',\n",
       "   'were',\n",
       "   'once',\n",
       "   'refused',\n",
       "   'entry',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Flamingo',\n",
       "   'Hotel',\n",
       "   'in',\n",
       "   'Miami',\n",
       "   'Beach',\n",
       "   ',',\n",
       "   'Florida',\n",
       "   ',',\n",
       "   'which',\n",
       "   'had',\n",
       "   'a',\n",
       "   '``',\n",
       "   'No',\n",
       "   'Jews',\n",
       "   \"''\",\n",
       "   'policy',\n",
       "   ',',\n",
       "   'but',\n",
       "   'they',\n",
       "   'were',\n",
       "   'allowed',\n",
       "   'to',\n",
       "   'stay',\n",
       "   'when',\n",
       "   'Giants',\n",
       "   'manager',\n",
       "   'Bill',\n",
       "   'Terry',\n",
       "   'threatened',\n",
       "   'he',\n",
       "   'would',\n",
       "   'take',\n",
       "   'the',\n",
       "   'whole',\n",
       "   'team',\n",
       "   'to',\n",
       "   'another',\n",
       "   'hotel',\n",
       "   'if',\n",
       "   'his',\n",
       "   'Jewish',\n",
       "   'ballplayers',\n",
       "   'were',\n",
       "   'not',\n",
       "   'allowed',\n",
       "   'in',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   9,\n",
       "   9,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '452'},\n",
       " {'tokens': ['It',\n",
       "   'is',\n",
       "   'also',\n",
       "   'rumoured',\n",
       "   'that',\n",
       "   'either',\n",
       "   'him',\n",
       "   'or',\n",
       "   'one',\n",
       "   'of',\n",
       "   'his',\n",
       "   '7',\n",
       "   'children',\n",
       "   'owns',\n",
       "   'the',\n",
       "   'world',\n",
       "   \"'s\",\n",
       "   'most',\n",
       "   'expensive',\n",
       "   'new',\n",
       "   'car',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Rolls',\n",
       "   'Royce',\n",
       "   'Sweptail',\n",
       "   ',',\n",
       "   'costing',\n",
       "   'around',\n",
       "   '$',\n",
       "   '12.8',\n",
       "   'million',\n",
       "   ',',\n",
       "   'along',\n",
       "   'with',\n",
       "   'some',\n",
       "   'other',\n",
       "   'extremely',\n",
       "   'rare',\n",
       "   'automobiles',\n",
       "   'like',\n",
       "   'two',\n",
       "   'Ferrari',\n",
       "   'F12',\n",
       "   'TRS',\n",
       "   ',',\n",
       "   'a',\n",
       "   'Ferrari',\n",
       "   'F50',\n",
       "   'GT',\n",
       "   ',',\n",
       "   'an',\n",
       "   'Aston',\n",
       "   'Martin',\n",
       "   'One-77',\n",
       "   ',',\n",
       "   'a',\n",
       "   'Ferrari',\n",
       "   'F40',\n",
       "   'LM',\n",
       "   ',',\n",
       "   'a',\n",
       "   'Ferrari',\n",
       "   'FXX',\n",
       "   'and',\n",
       "   'FXX',\n",
       "   'K',\n",
       "   ',',\n",
       "   'two',\n",
       "   'McLaren',\n",
       "   'F1',\n",
       "   'GTR',\n",
       "   'LTs',\n",
       "   ',',\n",
       "   'and',\n",
       "   'a',\n",
       "   'Mercedes',\n",
       "   'McLaren',\n",
       "   'SLR',\n",
       "   'Stirling',\n",
       "   'Moss',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   42,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   0],\n",
       "  'id': '453'},\n",
       " {'tokens': ['The',\n",
       "   'tendency',\n",
       "   'had',\n",
       "   'its',\n",
       "   'main',\n",
       "   'base',\n",
       "   'in',\n",
       "   'Navarre',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '454'},\n",
       " {'tokens': ['Carp',\n",
       "   ',',\n",
       "   'rainbow',\n",
       "   'trout',\n",
       "   ',',\n",
       "   'cherry',\n",
       "   'salmon',\n",
       "   ',',\n",
       "   '``',\n",
       "   'iwana',\n",
       "   '``',\n",
       "   '(',\n",
       "   'char',\n",
       "   ')',\n",
       "   ',',\n",
       "   '``',\n",
       "   'ugui',\n",
       "   '``',\n",
       "   '(',\n",
       "   'big-scaled',\n",
       "   'redfin',\n",
       "   ')',\n",
       "   'and',\n",
       "   'ayu',\n",
       "   'all',\n",
       "   'inhabit',\n",
       "   'Tama',\n",
       "   'River',\n",
       "   'in',\n",
       "   'sufficient',\n",
       "   'numbers',\n",
       "   'for',\n",
       "   'limited',\n",
       "   'commercial',\n",
       "   'fishing',\n",
       "   'to',\n",
       "   'take',\n",
       "   'place',\n",
       "   'in',\n",
       "   'upstream',\n",
       "   'areas',\n",
       "   '.'],\n",
       "  'coarse_tags': [6,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [48,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '455'},\n",
       " {'tokens': ['He', 'went', 'to', 'Stanford', 'University', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 5, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 29, 29, 0],\n",
       "  'id': '456'},\n",
       " {'tokens': ['Gough',\n",
       "   'Island',\n",
       "   'was',\n",
       "   'formally',\n",
       "   'claimed',\n",
       "   'in',\n",
       "   '1938',\n",
       "   'for',\n",
       "   'Britain',\n",
       "   ',',\n",
       "   'during',\n",
       "   'a',\n",
       "   'visit',\n",
       "   'by',\n",
       "   'HMS',\n",
       "   '``',\n",
       "   'Milford',\n",
       "   \"''\",\n",
       "   'of',\n",
       "   'the',\n",
       "   'Royal',\n",
       "   'Navy',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [23,\n",
       "   23,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   63,\n",
       "   63,\n",
       "   63,\n",
       "   63,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0],\n",
       "  'id': '457'},\n",
       " {'tokens': ['The',\n",
       "   'event',\n",
       "   'never',\n",
       "   'happened',\n",
       "   'because',\n",
       "   'it',\n",
       "   'coincided',\n",
       "   'with',\n",
       "   'the',\n",
       "   'beginning',\n",
       "   'of',\n",
       "   'the',\n",
       "   '2003',\n",
       "   'invasion',\n",
       "   'of',\n",
       "   'Iraq',\n",
       "   'in',\n",
       "   'March',\n",
       "   '2003',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0],\n",
       "  'id': '458'},\n",
       " {'tokens': ['Four',\n",
       "   'of',\n",
       "   'these',\n",
       "   'members',\n",
       "   'would',\n",
       "   'not',\n",
       "   'be',\n",
       "   'returned',\n",
       "   'to',\n",
       "   'the',\n",
       "   'new',\n",
       "   'council',\n",
       "   'the',\n",
       "   'aldermen',\n",
       "   'were',\n",
       "   'not',\n",
       "   're-elected',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '459'},\n",
       " {'tokens': ['The',\n",
       "   'Country',\n",
       "   'Music',\n",
       "   'Awards',\n",
       "   'of',\n",
       "   'Australia',\n",
       "   '(',\n",
       "   'CMAA',\n",
       "   ')',\n",
       "   'is',\n",
       "   'an',\n",
       "   'annual',\n",
       "   'awards',\n",
       "   'night',\n",
       "   'held',\n",
       "   'in',\n",
       "   'January',\n",
       "   'during',\n",
       "   'the',\n",
       "   'Tamworth',\n",
       "   'Country',\n",
       "   'Music',\n",
       "   'Festival',\n",
       "   'and',\n",
       "   'celebrates',\n",
       "   'recording',\n",
       "   'excellence',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Australian',\n",
       "   'country',\n",
       "   'music',\n",
       "   'industry',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '460'},\n",
       " {'tokens': ['Arthur',\n",
       "   'perished',\n",
       "   'on',\n",
       "   'Glastonbury',\n",
       "   'Tor',\n",
       "   'in',\n",
       "   '1539',\n",
       "   ',',\n",
       "   'hung',\n",
       "   ',',\n",
       "   'drawn',\n",
       "   'and',\n",
       "   'quartered',\n",
       "   'alongside',\n",
       "   'his',\n",
       "   'master',\n",
       "   ',',\n",
       "   'Richard',\n",
       "   'Whiting',\n",
       "   ',',\n",
       "   'the',\n",
       "   'last',\n",
       "   'Abbot',\n",
       "   'of',\n",
       "   'Glastonbury',\n",
       "   ',',\n",
       "   'during',\n",
       "   'the',\n",
       "   'dissolution',\n",
       "   'of',\n",
       "   'the',\n",
       "   'monasteries',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   24,\n",
       "   24,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '461'},\n",
       " {'tokens': ['Paul', 'Strong', 'Head', 'Teacher', '1986', '-2011', '.'],\n",
       "  'coarse_tags': [7, 7, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [54, 54, 0, 0, 0, 0, 0],\n",
       "  'id': '462'},\n",
       " {'tokens': ['He',\n",
       "   'previously',\n",
       "   'worked',\n",
       "   'for',\n",
       "   'the',\n",
       "   'company',\n",
       "   'as',\n",
       "   'Tiger',\n",
       "   'Mask',\n",
       "   'W',\n",
       "   ',',\n",
       "   'the',\n",
       "   'protagonist',\n",
       "   'of',\n",
       "   'the',\n",
       "   'anime',\n",
       "   'of',\n",
       "   'the',\n",
       "   'same',\n",
       "   'name',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '463'},\n",
       " {'tokens': ['Scheer',\n",
       "   'therefore',\n",
       "   'began',\n",
       "   'working',\n",
       "   'for',\n",
       "   'NASA',\n",
       "   'as',\n",
       "   'a',\n",
       "   'consultant',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 5, 0, 0, 0, 0],\n",
       "  'fine_tags': [51, 0, 0, 0, 0, 32, 0, 0, 0, 0],\n",
       "  'id': '464'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'the',\n",
       "   'Director',\n",
       "   'of',\n",
       "   'Central',\n",
       "   'Board',\n",
       "   'of',\n",
       "   'State',\n",
       "   'Bank',\n",
       "   'of',\n",
       "   'India',\n",
       "   'that',\n",
       "   'has',\n",
       "   'over',\n",
       "   '13000',\n",
       "   'branches',\n",
       "   'and',\n",
       "   'business',\n",
       "   'of',\n",
       "   'nearly',\n",
       "   'Rs',\n",
       "   '25',\n",
       "   'lac',\n",
       "   'crore',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   42,\n",
       "   42,\n",
       "   0],\n",
       "  'id': '465'},\n",
       " {'tokens': ['The',\n",
       "   '``',\n",
       "   'RuneQuest',\n",
       "   'II',\n",
       "   '``',\n",
       "   'game',\n",
       "   'system',\n",
       "   'has',\n",
       "   'been',\n",
       "   'retitled',\n",
       "   '``',\n",
       "   'Legend',\n",
       "   '``',\n",
       "   ',',\n",
       "   'and',\n",
       "   'contains',\n",
       "   'no',\n",
       "   'Gloranthan',\n",
       "   'material',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 5, 0, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '466'},\n",
       " {'tokens': ['This',\n",
       "   'was',\n",
       "   'because',\n",
       "   'Myers',\n",
       "   'also',\n",
       "   'hosted',\n",
       "   'a',\n",
       "   'talk-show',\n",
       "   'for',\n",
       "   'Fox',\n",
       "   'Sports',\n",
       "   'Radio',\n",
       "   ',',\n",
       "   'resulting',\n",
       "   'in',\n",
       "   'him',\n",
       "   'having',\n",
       "   'to',\n",
       "   'return',\n",
       "   'to',\n",
       "   'Los',\n",
       "   'Angeles',\n",
       "   'to',\n",
       "   'begin',\n",
       "   'the',\n",
       "   'following',\n",
       "   'week',\n",
       "   \"'s\",\n",
       "   'shows',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   31,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '467'},\n",
       " {'tokens': ['The',\n",
       "   'effectiveness',\n",
       "   'of',\n",
       "   'the',\n",
       "   'tower',\n",
       "   ',',\n",
       "   'when',\n",
       "   'properly',\n",
       "   'supplied',\n",
       "   'and',\n",
       "   'defended',\n",
       "   ',',\n",
       "   'impressed',\n",
       "   'the',\n",
       "   'British',\n",
       "   ',',\n",
       "   'who',\n",
       "   'copied',\n",
       "   'the',\n",
       "   'design',\n",
       "   'for',\n",
       "   'what',\n",
       "   'they',\n",
       "   'would',\n",
       "   'call',\n",
       "   'Martello',\n",
       "   'towers',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0],\n",
       "  'id': '468'},\n",
       " {'tokens': ['The',\n",
       "   'ballroom',\n",
       "   'had',\n",
       "   'opened',\n",
       "   'shortly',\n",
       "   'before',\n",
       "   'this',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '469'},\n",
       " {'tokens': ['Millennium',\n",
       "   'Park',\n",
       "   \"'s\",\n",
       "   'Cloud',\n",
       "   'Gate',\n",
       "   'sculpture',\n",
       "   'and',\n",
       "   'fountain',\n",
       "   \"'s\",\n",
       "   'two',\n",
       "   'towers',\n",
       "   'incorporate',\n",
       "   'LED',\n",
       "   'facial',\n",
       "   'images',\n",
       "   '.'],\n",
       "  'coarse_tags': [4, 4, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0],\n",
       "  'fine_tags': [26, 26, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 62, 0, 0, 0],\n",
       "  'id': '470'},\n",
       " {'tokens': ['By',\n",
       "   '1918',\n",
       "   'the',\n",
       "   'NZAOC',\n",
       "   'had',\n",
       "   'grown',\n",
       "   'to',\n",
       "   'include',\n",
       "   'a',\n",
       "   'New',\n",
       "   'Zealand',\n",
       "   'Ordnance',\n",
       "   'Corps',\n",
       "   'Section',\n",
       "   ',',\n",
       "   'consisting',\n",
       "   'of',\n",
       "   '3',\n",
       "   'Officer',\n",
       "   'and',\n",
       "   '53',\n",
       "   'ORs',\n",
       "   'under',\n",
       "   'the',\n",
       "   'control',\n",
       "   'of',\n",
       "   'the',\n",
       "   'NZEF',\n",
       "   'Administrative',\n",
       "   'Headquarters',\n",
       "   'in',\n",
       "   'London',\n",
       "   ',',\n",
       "   'with',\n",
       "   'the',\n",
       "   'New',\n",
       "   'Zealand',\n",
       "   'Ordnance',\n",
       "   'Base',\n",
       "   'Depot',\n",
       "   'at',\n",
       "   'Farringdon',\n",
       "   'Street',\n",
       "   ',',\n",
       "   'London',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '471'},\n",
       " {'tokens': ['This',\n",
       "   'ended',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   \"'\",\n",
       "   'participation',\n",
       "   'in',\n",
       "   'the',\n",
       "   'conflict',\n",
       "   'until',\n",
       "   '1859',\n",
       "   ',',\n",
       "   'when',\n",
       "   'Commodore',\n",
       "   'Josiah',\n",
       "   'Tattnall',\n",
       "   'in',\n",
       "   'the',\n",
       "   'chartered',\n",
       "   'steamship',\n",
       "   '``',\n",
       "   'Towey',\n",
       "   'Wan',\n",
       "   '``',\n",
       "   'participated',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Battle',\n",
       "   'of',\n",
       "   'Taku',\n",
       "   'Forts',\n",
       "   ',',\n",
       "   'which',\n",
       "   'was',\n",
       "   'ultimately',\n",
       "   'unsuccessful',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   63,\n",
       "   63,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '472'},\n",
       " {'tokens': ['Don',\n",
       "   'Carlos',\n",
       "   'Harvey',\n",
       "   '(',\n",
       "   'December',\n",
       "   '12',\n",
       "   ',',\n",
       "   '1911',\n",
       "   '–',\n",
       "   'April',\n",
       "   '23',\n",
       "   ',',\n",
       "   '1963',\n",
       "   ')',\n",
       "   'was',\n",
       "   'an',\n",
       "   'American',\n",
       "   'television',\n",
       "   'and',\n",
       "   'film',\n",
       "   'actor',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [50,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '473'},\n",
       " {'tokens': ['The',\n",
       "   'centre',\n",
       "   'offers',\n",
       "   'the',\n",
       "   'following',\n",
       "   'programmes',\n",
       "   'with',\n",
       "   'Chandana',\n",
       "   'Das',\n",
       "   ',',\n",
       "   'HOD',\n",
       "   ',',\n",
       "   'Philosophy',\n",
       "   'as',\n",
       "   'its',\n",
       "   'present',\n",
       "   'co-ordinator',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 56, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '474'},\n",
       " {'tokens': ['The',\n",
       "   'Wave',\n",
       "   'Federation',\n",
       "   'Protocol',\n",
       "   '(',\n",
       "   'formerly',\n",
       "   'Google',\n",
       "   'Wave',\n",
       "   'Federation',\n",
       "   'Protocol',\n",
       "   ')',\n",
       "   'is',\n",
       "   'an',\n",
       "   'open',\n",
       "   'protocol',\n",
       "   ',',\n",
       "   'extension',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Extensible',\n",
       "   'Messaging',\n",
       "   'and',\n",
       "   'Presence',\n",
       "   'Protocol',\n",
       "   '(',\n",
       "   'XMPP',\n",
       "   ')',\n",
       "   'that',\n",
       "   'is',\n",
       "   'used',\n",
       "   'in',\n",
       "   'Apache',\n",
       "   'Wave',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   0,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   64,\n",
       "   0],\n",
       "  'id': '475'},\n",
       " {'tokens': ['In',\n",
       "   'the',\n",
       "   'UK',\n",
       "   ',',\n",
       "   'in',\n",
       "   'October',\n",
       "   '2011',\n",
       "   ',',\n",
       "   'more',\n",
       "   'than',\n",
       "   '200',\n",
       "   'protesters',\n",
       "   'blockaded',\n",
       "   'the',\n",
       "   'Hinkley',\n",
       "   'Point',\n",
       "   'C',\n",
       "   'nuclear',\n",
       "   'power',\n",
       "   'station',\n",
       "   'site',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0],\n",
       "  'id': '476'},\n",
       " {'tokens': ['Jellyfish',\n",
       "   'in',\n",
       "   'large',\n",
       "   'quantities',\n",
       "   'can',\n",
       "   'fill',\n",
       "   'and',\n",
       "   'split',\n",
       "   'fishing',\n",
       "   'nets',\n",
       "   'and',\n",
       "   'crush',\n",
       "   'captured',\n",
       "   'fish',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [48, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '477'},\n",
       " {'tokens': ['His',\n",
       "   'last',\n",
       "   'match',\n",
       "   'was',\n",
       "   'in',\n",
       "   '2006',\n",
       "   ',',\n",
       "   'when',\n",
       "   'he',\n",
       "   'played',\n",
       "   'for',\n",
       "   'Lashings',\n",
       "   'cricket',\n",
       "   'club',\n",
       "   ',',\n",
       "   'a',\n",
       "   'club',\n",
       "   'in',\n",
       "   'England',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 37, 0, 0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '478'},\n",
       " {'tokens': ['In',\n",
       "   'the',\n",
       "   'first',\n",
       "   'years',\n",
       "   'it',\n",
       "   'was',\n",
       "   'known',\n",
       "   'as',\n",
       "   'the',\n",
       "   'RAP',\n",
       "   'Pirates',\n",
       "   ',',\n",
       "   'but',\n",
       "   'after',\n",
       "   'a',\n",
       "   'few',\n",
       "   'years',\n",
       "   'the',\n",
       "   'club',\n",
       "   'changed',\n",
       "   'its',\n",
       "   'name',\n",
       "   'according',\n",
       "   'to',\n",
       "   'American',\n",
       "   'tradition',\n",
       "   '(',\n",
       "   'first',\n",
       "   'city',\n",
       "   'name',\n",
       "   ',',\n",
       "   'then',\n",
       "   'franchise',\n",
       "   'name',\n",
       "   ')',\n",
       "   'and',\n",
       "   'became',\n",
       "   'the',\n",
       "   'Amsterdam',\n",
       "   'Pirates',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0],\n",
       "  'id': '479'},\n",
       " {'tokens': ['Public',\n",
       "   'dissent',\n",
       "   'continually',\n",
       "   'grew',\n",
       "   'over',\n",
       "   'the',\n",
       "   'next',\n",
       "   'few',\n",
       "   'years',\n",
       "   ',',\n",
       "   'surviving',\n",
       "   'a',\n",
       "   'coup',\n",
       "   'attempt',\n",
       "   'in',\n",
       "   'December',\n",
       "   '1974',\n",
       "   ',',\n",
       "   'and',\n",
       "   'narrowly',\n",
       "   'escaped',\n",
       "   'assassination',\n",
       "   'in',\n",
       "   'February',\n",
       "   '1976.',\n",
       "   'International',\n",
       "   'support',\n",
       "   'was',\n",
       "   'waning',\n",
       "   'during',\n",
       "   'this',\n",
       "   'period',\n",
       "   'as',\n",
       "   'well',\n",
       "   ',',\n",
       "   'so',\n",
       "   'in',\n",
       "   'response',\n",
       "   'Bokassa',\n",
       "   'dissolved',\n",
       "   'the',\n",
       "   'republican',\n",
       "   'government',\n",
       "   'and',\n",
       "   'established',\n",
       "   'the',\n",
       "   'Central',\n",
       "   'African',\n",
       "   'Revolutionary',\n",
       "   'Council',\n",
       "   'in',\n",
       "   'September',\n",
       "   '1976',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '480'},\n",
       " {'tokens': ['Legacy',\n",
       "   'Christian',\n",
       "   'Academy',\n",
       "   ',',\n",
       "   'formerly',\n",
       "   'Xenia',\n",
       "   'Christian',\n",
       "   'School',\n",
       "   ',',\n",
       "   'is',\n",
       "   'a',\n",
       "   'private',\n",
       "   ',',\n",
       "   'non-denominational',\n",
       "   'Christian',\n",
       "   'school',\n",
       "   'in',\n",
       "   'Xenia',\n",
       "   ',',\n",
       "   'Ohio',\n",
       "   ',',\n",
       "   'United',\n",
       "   'States',\n",
       "   '.'],\n",
       "  'coarse_tags': [5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '481'},\n",
       " {'tokens': ['Being',\n",
       "   'a',\n",
       "   'single-coil',\n",
       "   'design',\n",
       "   ',',\n",
       "   'the',\n",
       "   'tone',\n",
       "   'of',\n",
       "   'a',\n",
       "   'P-9',\n",
       "   '0',\n",
       "   'is',\n",
       "   'somewhat',\n",
       "   'brighter',\n",
       "   'and',\n",
       "   'more',\n",
       "   'transparent',\n",
       "   'than',\n",
       "   'a',\n",
       "   'humbucker',\n",
       "   ',',\n",
       "   'though',\n",
       "   'not',\n",
       "   'quite',\n",
       "   'as',\n",
       "   'crisp',\n",
       "   'and',\n",
       "   'snappy',\n",
       "   'as',\n",
       "   'Fender',\n",
       "   \"'s\",\n",
       "   'single-coil',\n",
       "   'pickups',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '482'},\n",
       " {'tokens': ['The',\n",
       "   'total',\n",
       "   'area',\n",
       "   'of',\n",
       "   'Udupi',\n",
       "   'is',\n",
       "   'with',\n",
       "   'a',\n",
       "   'population',\n",
       "   'density',\n",
       "   'of',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '483'},\n",
       " {'tokens': ['give',\n",
       "   'options',\n",
       "   'either',\n",
       "   'for',\n",
       "   'short',\n",
       "   'walks',\n",
       "   '–',\n",
       "   'such',\n",
       "   'as',\n",
       "   'Dawlish',\n",
       "   'to',\n",
       "   'Paignton',\n",
       "   '–',\n",
       "   'or',\n",
       "   'for',\n",
       "   'longer',\n",
       "   'walks',\n",
       "   'over',\n",
       "   'several',\n",
       "   'days',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '484'},\n",
       " {'tokens': ['In',\n",
       "   'the',\n",
       "   '2006',\n",
       "   'general',\n",
       "   'elections',\n",
       "   'Behmen',\n",
       "   'was',\n",
       "   'elected',\n",
       "   'member',\n",
       "   'of',\n",
       "   'the',\n",
       "   'House',\n",
       "   'of',\n",
       "   'Representatives',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Federation',\n",
       "   'of',\n",
       "   'Bosnia',\n",
       "   'and',\n",
       "   'Herzegovina',\n",
       "   'entity',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '485'},\n",
       " {'tokens': ['The',\n",
       "   'Yellowstone',\n",
       "   'Park',\n",
       "   'bison',\n",
       "   'herd',\n",
       "   'was',\n",
       "   'the',\n",
       "   'last',\n",
       "   'free-ranging',\n",
       "   'bison',\n",
       "   'herd',\n",
       "   'in',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'and',\n",
       "   'the',\n",
       "   'only',\n",
       "   'place',\n",
       "   'where',\n",
       "   'they',\n",
       "   'did',\n",
       "   'not',\n",
       "   'go',\n",
       "   'locally',\n",
       "   'extinct',\n",
       "   ',',\n",
       "   'so',\n",
       "   'they',\n",
       "   'have',\n",
       "   'become',\n",
       "   'at',\n",
       "   'least',\n",
       "   'part',\n",
       "   'of',\n",
       "   'the',\n",
       "   'foundation',\n",
       "   'stock',\n",
       "   'for',\n",
       "   'many',\n",
       "   'other',\n",
       "   'herds',\n",
       "   ',',\n",
       "   'including',\n",
       "   'the',\n",
       "   'Wind',\n",
       "   'Cave',\n",
       "   'bison',\n",
       "   'herd',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   4,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   6,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   26,\n",
       "   26,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   26,\n",
       "   26,\n",
       "   48,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '486'},\n",
       " {'tokens': ['who', 'often', 'hunted', 'alone', 'in', 'his', 'Nieuport', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 8, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 58, 0],\n",
       "  'id': '487'},\n",
       " {'tokens': ['In',\n",
       "   'his',\n",
       "   '1941',\n",
       "   '``',\n",
       "   'Child',\n",
       "   'Language',\n",
       "   ',',\n",
       "   'Aphasia',\n",
       "   ',',\n",
       "   'and',\n",
       "   'Universals',\n",
       "   'of',\n",
       "   'Language',\n",
       "   '``',\n",
       "   ',',\n",
       "   'Jakobson',\n",
       "   'suggested',\n",
       "   'that',\n",
       "   'phonological',\n",
       "   'markedness',\n",
       "   'played',\n",
       "   'a',\n",
       "   'role',\n",
       "   'in',\n",
       "   'language',\n",
       "   'acquisition',\n",
       "   'and',\n",
       "   'loss',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '488'},\n",
       " {'tokens': ['Rail',\n",
       "   'transport',\n",
       "   'in',\n",
       "   'Oslo',\n",
       "   'started',\n",
       "   'in',\n",
       "   '1854',\n",
       "   ',',\n",
       "   'with',\n",
       "   'the',\n",
       "   'opening',\n",
       "   'of',\n",
       "   'Hoved',\n",
       "   'Line',\n",
       "   'to',\n",
       "   'Eidsvoll',\n",
       "   ',',\n",
       "   'through',\n",
       "   'Groruddalen',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 4, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '489'},\n",
       " {'tokens': ['A',\n",
       "   'gift',\n",
       "   'shop',\n",
       "   'is',\n",
       "   'located',\n",
       "   'in',\n",
       "   'the',\n",
       "   'park',\n",
       "   'selling',\n",
       "   'Waldameer',\n",
       "   'souvenirs',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 26, 0, 0],\n",
       "  'id': '490'},\n",
       " {'tokens': ['On',\n",
       "   '28',\n",
       "   'April',\n",
       "   '1940',\n",
       "   'he',\n",
       "   'scored',\n",
       "   'again',\n",
       "   ',',\n",
       "   'while',\n",
       "   'playing',\n",
       "   'for',\n",
       "   'a',\n",
       "   'League',\n",
       "   'of',\n",
       "   'Ireland',\n",
       "   'XI',\n",
       "   ',',\n",
       "   'in',\n",
       "   'a',\n",
       "   '3–2',\n",
       "   'defeat',\n",
       "   'against',\n",
       "   'a',\n",
       "   'Scottish',\n",
       "   'League',\n",
       "   'XI',\n",
       "   'at',\n",
       "   'Dalymount',\n",
       "   'Park',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   36,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   36,\n",
       "   36,\n",
       "   0,\n",
       "   26,\n",
       "   26,\n",
       "   0],\n",
       "  'id': '491'},\n",
       " {'tokens': ['Charles',\n",
       "   'Knowlton',\n",
       "   ',',\n",
       "   'D.',\n",
       "   'M.',\n",
       "   'Bennett',\n",
       "   ',',\n",
       "   'and',\n",
       "   'Robert',\n",
       "   'G.',\n",
       "   'Ingersoll',\n",
       "   'were',\n",
       "   'influential',\n",
       "   'freethinkers',\n",
       "   'of',\n",
       "   'the',\n",
       "   'period',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 7, 0, 7, 7, 7, 0, 0, 7, 7, 7, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [54, 54, 0, 54, 54, 54, 0, 0, 54, 54, 54, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '492'},\n",
       " {'tokens': ['This',\n",
       "   'building',\n",
       "   'was',\n",
       "   'extensively',\n",
       "   'upgraded',\n",
       "   'in',\n",
       "   '1939',\n",
       "   'with',\n",
       "   'a',\n",
       "   'distinctive',\n",
       "   'art-deco',\n",
       "   'facade',\n",
       "   'designed',\n",
       "   'by',\n",
       "   'architect',\n",
       "   'William',\n",
       "   'G.',\n",
       "   'Bennett',\n",
       "   'to',\n",
       "   'coincide',\n",
       "   'with',\n",
       "   'the',\n",
       "   'construction',\n",
       "   'of',\n",
       "   'the',\n",
       "   'current',\n",
       "   'bridge',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '493'},\n",
       " {'tokens': ['Remained',\n",
       "   'in',\n",
       "   'Air',\n",
       "   'Training',\n",
       "   'Command',\n",
       "   'providing',\n",
       "   'initial',\n",
       "   'flight',\n",
       "   'training',\n",
       "   'first',\n",
       "   'at',\n",
       "   'Laredo',\n",
       "   'AFB',\n",
       "   ',',\n",
       "   'then',\n",
       "   'at',\n",
       "   'Moody',\n",
       "   'AFB',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 5, 5, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0],\n",
       "  'id': '494'},\n",
       " {'tokens': ['He',\n",
       "   'is',\n",
       "   'also',\n",
       "   'primarily',\n",
       "   'a',\n",
       "   'Chicago',\n",
       "   'Bears',\n",
       "   'football',\n",
       "   'fan',\n",
       "   'in',\n",
       "   'the',\n",
       "   'NFL',\n",
       "   ',',\n",
       "   'but',\n",
       "   'in',\n",
       "   'his',\n",
       "   'childhood',\n",
       "   'and',\n",
       "   'adolescence',\n",
       "   'was',\n",
       "   'a',\n",
       "   'fan',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Pittsburgh',\n",
       "   'Steelers',\n",
       "   ',',\n",
       "   'and',\n",
       "   'rooted',\n",
       "   'for',\n",
       "   'them',\n",
       "   'ahead',\n",
       "   'of',\n",
       "   'their',\n",
       "   'victory',\n",
       "   'in',\n",
       "   'Super',\n",
       "   'Bowl',\n",
       "   'XLIII',\n",
       "   '12',\n",
       "   'days',\n",
       "   'after',\n",
       "   'he',\n",
       "   'took',\n",
       "   'office',\n",
       "   'as',\n",
       "   'president',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '495'},\n",
       " {'tokens': ['The',\n",
       "   'Leahy–Smith',\n",
       "   'America',\n",
       "   'Invents',\n",
       "   'Act',\n",
       "   '(',\n",
       "   'AIA',\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'United',\n",
       "   'States',\n",
       "   'federal',\n",
       "   'statute',\n",
       "   'that',\n",
       "   'was',\n",
       "   'passed',\n",
       "   'by',\n",
       "   'Congress',\n",
       "   'and',\n",
       "   'was',\n",
       "   'signed',\n",
       "   'into',\n",
       "   'law',\n",
       "   'by',\n",
       "   'President',\n",
       "   'Barack',\n",
       "   'Obama',\n",
       "   'on',\n",
       "   'September',\n",
       "   '16',\n",
       "   ',',\n",
       "   '2011',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '496'},\n",
       " {'tokens': ['Delayed',\n",
       "   'bleeding',\n",
       "   'may',\n",
       "   'also',\n",
       "   'occur',\n",
       "   'at',\n",
       "   'the',\n",
       "   'site',\n",
       "   'of',\n",
       "   'polyp',\n",
       "   'removal',\n",
       "   'up',\n",
       "   'to',\n",
       "   'a',\n",
       "   'week',\n",
       "   'after',\n",
       "   'the',\n",
       "   'procedure',\n",
       "   ',',\n",
       "   'and',\n",
       "   'a',\n",
       "   'repeat',\n",
       "   'procedure',\n",
       "   'can',\n",
       "   'then',\n",
       "   'be',\n",
       "   'performed',\n",
       "   'to',\n",
       "   'treat',\n",
       "   'the',\n",
       "   'bleeding',\n",
       "   'site',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   43,\n",
       "   43,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '497'},\n",
       " {'tokens': ['He',\n",
       "   'first',\n",
       "   'spoke',\n",
       "   'and',\n",
       "   'wrote',\n",
       "   'about',\n",
       "   'the',\n",
       "   'concept',\n",
       "   'in',\n",
       "   '1922',\n",
       "   ',',\n",
       "   'at',\n",
       "   'least',\n",
       "   'a',\n",
       "   'decade',\n",
       "   'before',\n",
       "   'Ansel',\n",
       "   'Adams',\n",
       "   'began',\n",
       "   'utilizing',\n",
       "   'the',\n",
       "   'term',\n",
       "   ',',\n",
       "   'and',\n",
       "   'he',\n",
       "   'continued',\n",
       "   'to',\n",
       "   'expand',\n",
       "   'upon',\n",
       "   'this',\n",
       "   'idea',\n",
       "   'both',\n",
       "   'in',\n",
       "   'writing',\n",
       "   'and',\n",
       "   'in',\n",
       "   'his',\n",
       "   'teachings',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '498'},\n",
       " {'tokens': ['He',\n",
       "   'served',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Battle',\n",
       "   'of',\n",
       "   'Vicksburg',\n",
       "   '(',\n",
       "   'May',\n",
       "   '18',\n",
       "   '–',\n",
       "   'July',\n",
       "   '4',\n",
       "   ',',\n",
       "   '1863',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 15, 15, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '499'},\n",
       " {'tokens': ['The',\n",
       "   'ground',\n",
       "   'has',\n",
       "   'been',\n",
       "   'the',\n",
       "   'scene',\n",
       "   'of',\n",
       "   '29',\n",
       "   'Test',\n",
       "   'and',\n",
       "   '13',\n",
       "   'ODI',\n",
       "   'centuries.',\n",
       "   '&',\n",
       "   'lt',\n",
       "   ';',\n",
       "   'ref',\n",
       "   'name=',\n",
       "   \"''\",\n",
       "   'Statsguru',\n",
       "   ':',\n",
       "   'Test',\n",
       "   'matches',\n",
       "   '/',\n",
       "   'Batting',\n",
       "   'records',\n",
       "   '/',\n",
       "   'Innings',\n",
       "   'by',\n",
       "   'innings',\n",
       "   'list',\n",
       "   \"''\",\n",
       "   '&',\n",
       "   'gt',\n",
       "   ';',\n",
       "   '&',\n",
       "   'lt',\n",
       "   ';',\n",
       "   '/ref',\n",
       "   '&',\n",
       "   'gt',\n",
       "   ';',\n",
       "   '&',\n",
       "   'lt',\n",
       "   ';',\n",
       "   'ref',\n",
       "   'name=',\n",
       "   \"''\",\n",
       "   'Statsguru',\n",
       "   ':',\n",
       "   'One-Day',\n",
       "   'Internationals',\n",
       "   '/',\n",
       "   'Batting',\n",
       "   'records',\n",
       "   '/',\n",
       "   'Innings',\n",
       "   'by',\n",
       "   'innings',\n",
       "   'list',\n",
       "   \"''\",\n",
       "   '&',\n",
       "   'gt',\n",
       "   ';',\n",
       "   '&',\n",
       "   'lt',\n",
       "   ';',\n",
       "   '/ref',\n",
       "   '&',\n",
       "   'gt',\n",
       "   ';'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '500'},\n",
       " {'tokens': ['It',\n",
       "   'was',\n",
       "   'founded',\n",
       "   'in',\n",
       "   'Baldwin',\n",
       "   'Park',\n",
       "   ',',\n",
       "   'California',\n",
       "   ',',\n",
       "   'in',\n",
       "   '1948',\n",
       "   'by',\n",
       "   'Harry',\n",
       "   'Snyder',\n",
       "   'and',\n",
       "   'Esther',\n",
       "   'Snyder',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 7, 7, 0, 7, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 26, 26, 0, 21, 0, 0, 0, 0, 54, 54, 0, 54, 54, 0],\n",
       "  'id': '501'},\n",
       " {'tokens': ['The',\n",
       "   '``',\n",
       "   'Landsknecht',\n",
       "   \"''\",\n",
       "   'often',\n",
       "   'assumed',\n",
       "   'the',\n",
       "   'multi-coloured',\n",
       "   'and',\n",
       "   'striped',\n",
       "   'clothing',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Swiss',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '502'},\n",
       " {'tokens': ['Born',\n",
       "   'in',\n",
       "   'Brockton',\n",
       "   ',',\n",
       "   'Massachusetts',\n",
       "   ',',\n",
       "   'the',\n",
       "   'son',\n",
       "   'of',\n",
       "   'Elmer',\n",
       "   'and',\n",
       "   'Ethel',\n",
       "   '(',\n",
       "   '``',\n",
       "   'née',\n",
       "   \"''\",\n",
       "   'Lewis',\n",
       "   ')',\n",
       "   'Dunham',\n",
       "   ',',\n",
       "   'he',\n",
       "   'attended',\n",
       "   'local',\n",
       "   'schools',\n",
       "   'and',\n",
       "   'took',\n",
       "   'lessons',\n",
       "   'on',\n",
       "   'the',\n",
       "   'valve',\n",
       "   'trombone',\n",
       "   'at',\n",
       "   'the',\n",
       "   'age',\n",
       "   'of',\n",
       "   '7',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '503'},\n",
       " {'tokens': ['Books',\n",
       "   'may',\n",
       "   'be',\n",
       "   'added',\n",
       "   'to',\n",
       "   'the',\n",
       "   'device',\n",
       "   'with',\n",
       "   'the',\n",
       "   'Kobo',\n",
       "   'Desktop',\n",
       "   'app',\n",
       "   'or',\n",
       "   'third',\n",
       "   'party',\n",
       "   'apps',\n",
       "   'such',\n",
       "   'as',\n",
       "   'Calibre',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 8, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 64, 64, 0, 0, 0, 0, 0, 0, 0, 64, 0],\n",
       "  'id': '504'},\n",
       " {'tokens': ['In',\n",
       "   'patches',\n",
       "   'of',\n",
       "   'shrubs',\n",
       "   ',',\n",
       "   'Chinese',\n",
       "   'bulbul',\n",
       "   'can',\n",
       "   'commonly',\n",
       "   'be',\n",
       "   'seen',\n",
       "   'feeding',\n",
       "   'on',\n",
       "   'berries',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 48, 48, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '505'},\n",
       " {'tokens': ['Many',\n",
       "   'trading',\n",
       "   'ports',\n",
       "   'with',\n",
       "   'links',\n",
       "   'to',\n",
       "   'Roman',\n",
       "   'communities',\n",
       "   'have',\n",
       "   'been',\n",
       "   'identified',\n",
       "   'in',\n",
       "   'India',\n",
       "   'and',\n",
       "   'Sri',\n",
       "   'Lanka',\n",
       "   'along',\n",
       "   'the',\n",
       "   'route',\n",
       "   'used',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Roman',\n",
       "   'mission',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '506'},\n",
       " {'tokens': ['After',\n",
       "   'the',\n",
       "   'war',\n",
       "   'he',\n",
       "   'was',\n",
       "   'awarded',\n",
       "   'a',\n",
       "   'bar',\n",
       "   'to',\n",
       "   'the',\n",
       "   'DSO',\n",
       "   ',',\n",
       "   'and',\n",
       "   'served',\n",
       "   'as',\n",
       "   'commanding',\n",
       "   'officer',\n",
       "   'No',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '507'},\n",
       " {'tokens': ['It',\n",
       "   'is',\n",
       "   'built',\n",
       "   'around',\n",
       "   'a',\n",
       "   'sample',\n",
       "   'of',\n",
       "   '``',\n",
       "   'Soul',\n",
       "   'Power',\n",
       "   '74',\n",
       "   \"''\",\n",
       "   'by',\n",
       "   'Maceo',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Macks',\n",
       "   ',',\n",
       "   'and',\n",
       "   'was',\n",
       "   'noted',\n",
       "   'for',\n",
       "   'its',\n",
       "   'heavy',\n",
       "   'use',\n",
       "   'of',\n",
       "   'saxophone',\n",
       "   'and',\n",
       "   'horn',\n",
       "   'instrumentation',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '508'},\n",
       " {'tokens': ['Two',\n",
       "   'years',\n",
       "   'later',\n",
       "   ',',\n",
       "   'Montenegro',\n",
       "   'disputed',\n",
       "   'the',\n",
       "   'Youth',\n",
       "   'World',\n",
       "   'Cup',\n",
       "   'in',\n",
       "   'Spain',\n",
       "   ',',\n",
       "   'where',\n",
       "   'Argentin',\n",
       "   'a',\n",
       "   'finished',\n",
       "   '7th',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 7, 0, 0, 3, 3, 3, 0, 4, 0, 0, 4, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 52, 0, 0, 20, 20, 20, 0, 21, 0, 0, 21, 0, 0, 0, 0],\n",
       "  'id': '509'},\n",
       " {'tokens': ['The',\n",
       "   'Toronto',\n",
       "   'Blue',\n",
       "   'Jays',\n",
       "   'claimed',\n",
       "   'Maile',\n",
       "   'off',\n",
       "   'waivers',\n",
       "   'on',\n",
       "   'April',\n",
       "   '6',\n",
       "   ',',\n",
       "   '2017',\n",
       "   'On',\n",
       "   'April',\n",
       "   '28',\n",
       "   ',',\n",
       "   'Maile',\n",
       "   'was',\n",
       "   'recalled',\n",
       "   'from',\n",
       "   'the',\n",
       "   'Triple-A',\n",
       "   'Buffalo',\n",
       "   'Bisons',\n",
       "   'after',\n",
       "   'Jarrod',\n",
       "   'Saltalamacchia',\n",
       "   'was',\n",
       "   'designated',\n",
       "   'for',\n",
       "   'assignment',\n",
       "   '.'],\n",
       "  'coarse_tags': [5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [37,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '510'},\n",
       " {'tokens': ['One',\n",
       "   'historian',\n",
       "   'has',\n",
       "   'written',\n",
       "   'that',\n",
       "   '``',\n",
       "   'Grey',\n",
       "   'was',\n",
       "   'widely',\n",
       "   'acknowledged',\n",
       "   'as',\n",
       "   'a',\n",
       "   'key',\n",
       "   'player',\n",
       "   'in',\n",
       "   'spearheading',\n",
       "   'the',\n",
       "   'campaigns',\n",
       "   'that',\n",
       "   'culminated',\n",
       "   'in',\n",
       "   'this',\n",
       "   'victory',\n",
       "   '.',\n",
       "   \"''\"],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '511'},\n",
       " {'tokens': ['Philip',\n",
       "   'died',\n",
       "   'near',\n",
       "   'Saint-Flour',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Auvergne',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 4, 0, 0, 4, 0],\n",
       "  'fine_tags': [54, 0, 0, 21, 0, 0, 21, 0],\n",
       "  'id': '512'},\n",
       " {'tokens': ['In',\n",
       "   '1894',\n",
       "   'electric',\n",
       "   'trams',\n",
       "   'were',\n",
       "   'in',\n",
       "   'service',\n",
       "   'by',\n",
       "   'Kristiania',\n",
       "   'Elektriske',\n",
       "   'Sporvei',\n",
       "   '(',\n",
       "   'KES',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 0, 5, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 28, 28, 28, 0, 28, 0, 0],\n",
       "  'id': '513'},\n",
       " {'tokens': ['She',\n",
       "   \"'s\",\n",
       "   'a',\n",
       "   'playable',\n",
       "   'character',\n",
       "   'in',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Samurai',\n",
       "   'Warriors',\n",
       "   '``',\n",
       "   'series',\n",
       "   'of',\n",
       "   'games',\n",
       "   ',',\n",
       "   'armed',\n",
       "   'with',\n",
       "   'darkness',\n",
       "   'and',\n",
       "   'later',\n",
       "   'changed',\n",
       "   'to',\n",
       "   'Four',\n",
       "   'Bladed',\n",
       "   'Hoops',\n",
       "   'chained',\n",
       "   'to',\n",
       "   'another',\n",
       "   ',',\n",
       "   'where',\n",
       "   'her',\n",
       "   'story',\n",
       "   'is',\n",
       "   'fleshed',\n",
       "   'out',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   66,\n",
       "   66,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '514'},\n",
       " {'tokens': ['Following',\n",
       "   'the',\n",
       "   'closure',\n",
       "   'of',\n",
       "   'Nicosia',\n",
       "   'Airport',\n",
       "   ',',\n",
       "   'a',\n",
       "   'new',\n",
       "   'airport',\n",
       "   'in',\n",
       "   'Larnaca',\n",
       "   'was',\n",
       "   'opened',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Republic',\n",
       "   'of',\n",
       "   'Cyprus',\n",
       "   'in',\n",
       "   '1975',\n",
       "   ',',\n",
       "   'while',\n",
       "   'Northern',\n",
       "   'Cyprus',\n",
       "   'established',\n",
       "   'Ercan',\n",
       "   'International',\n",
       "   'Airport',\n",
       "   'in',\n",
       "   '2004',\n",
       "   ',',\n",
       "   'both',\n",
       "   'on',\n",
       "   'former',\n",
       "   'RAF',\n",
       "   'airfields',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   23,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   23,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '515'},\n",
       " {'tokens': ['Following',\n",
       "   'the',\n",
       "   '1929',\n",
       "   'stock',\n",
       "   'market',\n",
       "   'crash',\n",
       "   ',',\n",
       "   'the',\n",
       "   'school',\n",
       "   \"'s\",\n",
       "   'formerly',\n",
       "   'full',\n",
       "   'coffers',\n",
       "   'were',\n",
       "   'now',\n",
       "   'nearly',\n",
       "   'empty',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '516'},\n",
       " {'tokens': [\"O'Shaughnessy\",\n",
       "   'made',\n",
       "   'his',\n",
       "   'List',\n",
       "   'A',\n",
       "   'debut',\n",
       "   'on',\n",
       "   '1',\n",
       "   'June',\n",
       "   '1980',\n",
       "   ',',\n",
       "   'in',\n",
       "   'a',\n",
       "   'John',\n",
       "   'Player',\n",
       "   'League',\n",
       "   'for',\n",
       "   'Lancashire',\n",
       "   'against',\n",
       "   'Warwickshire',\n",
       "   'at',\n",
       "   'Aigburth',\n",
       "   ',',\n",
       "   'though',\n",
       "   'his',\n",
       "   'contribution',\n",
       "   'was',\n",
       "   'minimal',\n",
       "   'as',\n",
       "   'he',\n",
       "   'was',\n",
       "   'dismissed',\n",
       "   'for',\n",
       "   'one',\n",
       "   'and',\n",
       "   'neither',\n",
       "   'bowled',\n",
       "   'nor',\n",
       "   'held',\n",
       "   'a',\n",
       "   'catch',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   36,\n",
       "   36,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '517'},\n",
       " {'tokens': ['On',\n",
       "   'October',\n",
       "   '21',\n",
       "   ',',\n",
       "   '2020',\n",
       "   ',',\n",
       "   'Jones',\n",
       "   'was',\n",
       "   'confirmed',\n",
       "   'to',\n",
       "   'drive',\n",
       "   'the',\n",
       "   'Richard',\n",
       "   'Petty',\n",
       "   'Motorsports',\n",
       "   'No',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 8, 8, 8, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 52, 0, 0, 0, 0, 0, 59, 59, 59, 0, 0],\n",
       "  'id': '518'},\n",
       " {'tokens': ['The',\n",
       "   'single',\n",
       "   'did',\n",
       "   'not',\n",
       "   'perform',\n",
       "   'well',\n",
       "   ',',\n",
       "   'reaching',\n",
       "   'only',\n",
       "   'number',\n",
       "   '44',\n",
       "   'on',\n",
       "   'the',\n",
       "   'U.S',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '519'},\n",
       " {'tokens': ['He', 'held', 'the', 'living', 'at', 'Cornwood', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '520'},\n",
       " {'tokens': ['Dobolyi', 'was', 'an', 'MEP', 'from', '2004', 'to', '2009', '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [55, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '521'},\n",
       " {'tokens': ['Douglas',\n",
       "   'advised',\n",
       "   'the',\n",
       "   'President',\n",
       "   'regarding',\n",
       "   'a',\n",
       "   'course',\n",
       "   'of',\n",
       "   'action',\n",
       "   'in',\n",
       "   'response',\n",
       "   'to',\n",
       "   'The',\n",
       "   'Soviet',\n",
       "   'Union',\n",
       "   '’',\n",
       "   's',\n",
       "   'launch',\n",
       "   'of',\n",
       "   'Sputnik',\n",
       "   'I',\n",
       "   'in',\n",
       "   'October',\n",
       "   '1957',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '522'},\n",
       " {'tokens': ['Cornwall',\n",
       "   'enjoyed',\n",
       "   'a',\n",
       "   'level',\n",
       "   'of',\n",
       "   'self-government',\n",
       "   'until',\n",
       "   '1753',\n",
       "   'through',\n",
       "   'its',\n",
       "   'Stannary',\n",
       "   'Parliament',\n",
       "   '.'],\n",
       "  'coarse_tags': [4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0],\n",
       "  'fine_tags': [21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 30, 0],\n",
       "  'id': '523'},\n",
       " {'tokens': ['The',\n",
       "   'Legislature',\n",
       "   'was',\n",
       "   'to',\n",
       "   'meet',\n",
       "   'for',\n",
       "   'the',\n",
       "   'regular',\n",
       "   'session',\n",
       "   'on',\n",
       "   'January',\n",
       "   '3',\n",
       "   ',',\n",
       "   '1792',\n",
       "   ',',\n",
       "   'at',\n",
       "   'Federal',\n",
       "   'Hall',\n",
       "   'in',\n",
       "   'New',\n",
       "   'York',\n",
       "   'City',\n",
       "   ';',\n",
       "   'both',\n",
       "   'Houses',\n",
       "   'assembled',\n",
       "   'a',\n",
       "   'quorum',\n",
       "   'two',\n",
       "   'days',\n",
       "   'later',\n",
       "   ';',\n",
       "   'and',\n",
       "   'adjourned',\n",
       "   'on',\n",
       "   'April',\n",
       "   '12',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '524'},\n",
       " {'tokens': ['The',\n",
       "   'LVG',\n",
       "   'G.I',\n",
       "   'was',\n",
       "   'a',\n",
       "   'three-seat',\n",
       "   'biplane',\n",
       "   'equipped',\n",
       "   'with',\n",
       "   'two',\n",
       "   'Benz',\n",
       "   'Bz.III',\n",
       "   'engines',\n",
       "   'driving',\n",
       "   'handed',\n",
       "   'propellers',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 58, 58, 0, 0, 0, 0, 0, 0, 0, 62, 62, 0, 0, 0, 0, 0],\n",
       "  'id': '525'},\n",
       " {'tokens': ['The',\n",
       "   'Nanticoke',\n",
       "   'language',\n",
       "   'was',\n",
       "   'distinct',\n",
       "   'from',\n",
       "   'the',\n",
       "   'Algonquian',\n",
       "   'languages',\n",
       "   'spoken',\n",
       "   'by',\n",
       "   'tribes',\n",
       "   'on',\n",
       "   'the',\n",
       "   'Western',\n",
       "   'Shore',\n",
       "   'of',\n",
       "   'Maryland',\n",
       "   'and',\n",
       "   'along',\n",
       "   'the',\n",
       "   'Potomac',\n",
       "   'River',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   22,\n",
       "   0],\n",
       "  'id': '526'},\n",
       " {'tokens': ['Conamara',\n",
       "   'Theas',\n",
       "   ',',\n",
       "   'which',\n",
       "   'is',\n",
       "   'Irish',\n",
       "   'for',\n",
       "   'South',\n",
       "   'Connemara',\n",
       "   ',',\n",
       "   'is',\n",
       "   'however',\n",
       "   'today',\n",
       "   'the',\n",
       "   'western',\n",
       "   'Irish-',\n",
       "   'speaking',\n",
       "   'regions',\n",
       "   'County',\n",
       "   'Galway',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '527'},\n",
       " {'tokens': ['Kehychivka',\n",
       "   'Raion',\n",
       "   '(',\n",
       "   ')',\n",
       "   'was',\n",
       "   'a',\n",
       "   'raion',\n",
       "   '(',\n",
       "   'district',\n",
       "   ')',\n",
       "   'in',\n",
       "   'Kharkiv',\n",
       "   'Oblast',\n",
       "   'of',\n",
       "   'Ukraine',\n",
       "   '.'],\n",
       "  'coarse_tags': [4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0],\n",
       "  'fine_tags': [21, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 21, 0, 21, 0],\n",
       "  'id': '528'},\n",
       " {'tokens': ['This',\n",
       "   'was',\n",
       "   'Pardubice',\n",
       "   \"'s\",\n",
       "   'first',\n",
       "   'title',\n",
       "   'in',\n",
       "   '16',\n",
       "   'years',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 5, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 37, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '529'},\n",
       " {'tokens': ['Through',\n",
       "   'the',\n",
       "   'following',\n",
       "   'years',\n",
       "   'it',\n",
       "   'was',\n",
       "   'supported',\n",
       "   'by',\n",
       "   'advertising',\n",
       "   'and',\n",
       "   'sponsorship',\n",
       "   ',',\n",
       "   'including',\n",
       "   'by',\n",
       "   'Flextronics',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 0],\n",
       "  'id': '530'},\n",
       " {'tokens': ['It',\n",
       "   'took',\n",
       "   'place',\n",
       "   'on',\n",
       "   'June',\n",
       "   '28',\n",
       "   ',',\n",
       "   '2009',\n",
       "   ',',\n",
       "   'at',\n",
       "   'the',\n",
       "   'ARCO',\n",
       "   'Arena',\n",
       "   'in',\n",
       "   'Sacramento',\n",
       "   ',',\n",
       "   'California',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 4, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 13, 0, 21, 0, 21, 0],\n",
       "  'id': '531'},\n",
       " {'tokens': ['She',\n",
       "   'was',\n",
       "   'the',\n",
       "   'resident',\n",
       "   'director',\n",
       "   'for',\n",
       "   'the',\n",
       "   'Pittsburgh',\n",
       "   'Civic',\n",
       "   'Light',\n",
       "   'Opera',\n",
       "   'from',\n",
       "   '1981',\n",
       "   'to',\n",
       "   '1989',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 14, 14, 14, 14, 0, 0, 0, 0, 0],\n",
       "  'id': '532'},\n",
       " {'tokens': ['In',\n",
       "   '2012',\n",
       "   'Marcus',\n",
       "   '&',\n",
       "   'amp',\n",
       "   ';',\n",
       "   'Martinus',\n",
       "   'were',\n",
       "   'contestants',\n",
       "   'on',\n",
       "   'the',\n",
       "   'eleventh',\n",
       "   'season',\n",
       "   'of',\n",
       "   '``',\n",
       "   'Melodi',\n",
       "   'Grand',\n",
       "   'Prix',\n",
       "   'Junior',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '533'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'educated',\n",
       "   'at',\n",
       "   'Sheffield',\n",
       "   'Central',\n",
       "   'Secondary',\n",
       "   'School',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 5, 5, 5, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 29, 29, 29, 29, 0],\n",
       "  'id': '534'},\n",
       " {'tokens': [\"'\",\n",
       "   'is',\n",
       "   'the',\n",
       "   'third',\n",
       "   'installment',\n",
       "   'of',\n",
       "   'the',\n",
       "   'series',\n",
       "   'and',\n",
       "   'was',\n",
       "   'released',\n",
       "   'in',\n",
       "   'Spanish',\n",
       "   'theaters',\n",
       "   'on',\n",
       "   '30',\n",
       "   'March',\n",
       "   '2012',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '535'},\n",
       " {'tokens': ['Barrett',\n",
       "   'served',\n",
       "   'in',\n",
       "   'the',\n",
       "   'State',\n",
       "   'Senate',\n",
       "   'once',\n",
       "   'before',\n",
       "   ',',\n",
       "   'in',\n",
       "   '1987–1994',\n",
       "   ',',\n",
       "   'representing',\n",
       "   'another',\n",
       "   'district',\n",
       "   '(',\n",
       "   'Cambridge',\n",
       "   ',',\n",
       "   'Belmont',\n",
       "   ',',\n",
       "   'Watertown',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Allston-Brighton',\n",
       "   'neighborhood',\n",
       "   'of',\n",
       "   'Boston',\n",
       "   ')',\n",
       "   ',',\n",
       "   'before',\n",
       "   'moving',\n",
       "   'to',\n",
       "   'his',\n",
       "   'present',\n",
       "   'home',\n",
       "   'in',\n",
       "   'suburban',\n",
       "   'Lexington',\n",
       "   '17',\n",
       "   'years',\n",
       "   'ago',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '536'},\n",
       " {'tokens': ['Shortly',\n",
       "   'after',\n",
       "   'that',\n",
       "   ',',\n",
       "   'Aruba',\n",
       "   'began',\n",
       "   'to',\n",
       "   'issue',\n",
       "   'its',\n",
       "   'own',\n",
       "   'currency',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Aruban',\n",
       "   'florin',\n",
       "   ',',\n",
       "   'which',\n",
       "   'replaced',\n",
       "   'the',\n",
       "   'Netherlands',\n",
       "   'Antillean',\n",
       "   'guilder',\n",
       "   'at',\n",
       "   'par',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   23,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   42,\n",
       "   42,\n",
       "   42,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   42,\n",
       "   42,\n",
       "   42,\n",
       "   42,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '537'},\n",
       " {'tokens': ['The',\n",
       "   'villages',\n",
       "   'surrounding',\n",
       "   'the',\n",
       "   'city',\n",
       "   'produce',\n",
       "   'high',\n",
       "   'yields',\n",
       "   'of',\n",
       "   'cotton',\n",
       "   ',',\n",
       "   'wheat',\n",
       "   ',',\n",
       "   'paddy',\n",
       "   'and',\n",
       "   'seed',\n",
       "   'oil',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '538'},\n",
       " {'tokens': ['That',\n",
       "   'was',\n",
       "   'never',\n",
       "   'an',\n",
       "   'argument',\n",
       "   'made',\n",
       "   'in',\n",
       "   'the',\n",
       "   \"'90s\",\n",
       "   '.',\n",
       "   \"''\"],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '539'},\n",
       " {'tokens': ['Vestfjorden',\n",
       "   'is',\n",
       "   'a',\n",
       "   'large',\n",
       "   'firth',\n",
       "   'between',\n",
       "   'the',\n",
       "   'Lofoten',\n",
       "   'islands',\n",
       "   'and',\n",
       "   'the',\n",
       "   'mainland',\n",
       "   'of',\n",
       "   'Nordland',\n",
       "   'county',\n",
       "   'in',\n",
       "   'Norway',\n",
       "   '.'],\n",
       "  'coarse_tags': [4, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 4, 4, 0, 4, 0],\n",
       "  'fine_tags': [22, 0, 0, 0, 0, 0, 0, 23, 23, 0, 0, 0, 0, 21, 21, 0, 21, 0],\n",
       "  'id': '540'},\n",
       " {'tokens': ['Anzac',\n",
       "   'Day',\n",
       "   ',',\n",
       "   'commemorating',\n",
       "   'the',\n",
       "   'Australian',\n",
       "   'and',\n",
       "   'New',\n",
       "   'Zealand',\n",
       "   'Army',\n",
       "   'Corps',\n",
       "   '(',\n",
       "   'ANZAC',\n",
       "   ')',\n",
       "   ',',\n",
       "   'celebrates',\n",
       "   'this',\n",
       "   'defining',\n",
       "   'moment',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '541'},\n",
       " {'tokens': ['Thus',\n",
       "   ',',\n",
       "   'a',\n",
       "   'depressed',\n",
       "   'alpha',\n",
       "   'angle',\n",
       "   'could',\n",
       "   'be',\n",
       "   'treated',\n",
       "   'with',\n",
       "   'cryoprecipitate',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 0],\n",
       "  'id': '542'},\n",
       " {'tokens': ['Matthew',\n",
       "   'Libatíque',\n",
       "   '(',\n",
       "   'born',\n",
       "   'July',\n",
       "   '19',\n",
       "   ',',\n",
       "   '1968',\n",
       "   ')',\n",
       "   'is',\n",
       "   'an',\n",
       "   'American',\n",
       "   'cinematographer',\n",
       "   'who',\n",
       "   'is',\n",
       "   'known',\n",
       "   'for',\n",
       "   'his',\n",
       "   'work',\n",
       "   'with',\n",
       "   'director',\n",
       "   'Darren',\n",
       "   'Aronofsky',\n",
       "   'on',\n",
       "   'the',\n",
       "   'films',\n",
       "   '``',\n",
       "   'Pi',\n",
       "   '``',\n",
       "   '(',\n",
       "   '1998',\n",
       "   ')',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Requiem',\n",
       "   'for',\n",
       "   'a',\n",
       "   'Dream',\n",
       "   '``',\n",
       "   '(',\n",
       "   '2000',\n",
       "   ')',\n",
       "   ',',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Fountain',\n",
       "   '``',\n",
       "   '(',\n",
       "   '2006',\n",
       "   ')',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Black',\n",
       "   'Swan',\n",
       "   '``',\n",
       "   '(',\n",
       "   '2010',\n",
       "   ')',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Noah',\n",
       "   '``',\n",
       "   '(',\n",
       "   '2014',\n",
       "   ')',\n",
       "   'and',\n",
       "   '``',\n",
       "   'Mother',\n",
       "   '!',\n",
       "   \"''\"],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   53,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '543'},\n",
       " {'tokens': ['This',\n",
       "   'is',\n",
       "   'located',\n",
       "   'roughly',\n",
       "   'midway',\n",
       "   'between',\n",
       "   'Delta',\n",
       "   'Draconis',\n",
       "   'and',\n",
       "   'Zeta',\n",
       "   'Draconis',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 6, 6, 0, 6, 6, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 38, 38, 0, 41, 41, 0],\n",
       "  'id': '544'},\n",
       " {'tokens': ['Under',\n",
       "   'his',\n",
       "   'command',\n",
       "   'were',\n",
       "   'the',\n",
       "   'twenty',\n",
       "   'German',\n",
       "   'and',\n",
       "   'two',\n",
       "   'Romanian',\n",
       "   'divisions',\n",
       "   'encircled',\n",
       "   'at',\n",
       "   'Stalingrad',\n",
       "   ',',\n",
       "   'Adam',\n",
       "   \"'s\",\n",
       "   'battle',\n",
       "   'groups',\n",
       "   'formed',\n",
       "   'along',\n",
       "   'the',\n",
       "   'Chir',\n",
       "   'River',\n",
       "   'and',\n",
       "   'on',\n",
       "   'the',\n",
       "   'Don',\n",
       "   'bridgehead',\n",
       "   ',',\n",
       "   'plus',\n",
       "   'the',\n",
       "   'remains',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Romanian',\n",
       "   '3rd',\n",
       "   'Army',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '545'},\n",
       " {'tokens': ['No',\n",
       "   'dealer',\n",
       "   'is',\n",
       "   'licensed',\n",
       "   'to',\n",
       "   'sell',\n",
       "   'it',\n",
       "   'at',\n",
       "   'a',\n",
       "   'lower',\n",
       "   'price',\n",
       "   ',',\n",
       "   'and',\n",
       "   'a',\n",
       "   'sale',\n",
       "   'at',\n",
       "   'a',\n",
       "   'lower',\n",
       "   'price',\n",
       "   'will',\n",
       "   'be',\n",
       "   'treated',\n",
       "   'as',\n",
       "   'an',\n",
       "   'infringement',\n",
       "   'of',\n",
       "   'the',\n",
       "   'copyright',\n",
       "   \"''\",\n",
       "   'printed',\n",
       "   'immediately',\n",
       "   'below',\n",
       "   'the',\n",
       "   'copyright',\n",
       "   'notice',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '546'},\n",
       " {'tokens': ['Morini',\n",
       "   'Franco',\n",
       "   'Motori',\n",
       "   'spa',\n",
       "   'was',\n",
       "   'founded',\n",
       "   'in',\n",
       "   '1954',\n",
       "   'by',\n",
       "   'Franco',\n",
       "   'Morini',\n",
       "   ',',\n",
       "   'Alfonso',\n",
       "   \"'s\",\n",
       "   'nephew',\n",
       "   '.'],\n",
       "  'coarse_tags': [5, 5, 5, 5, 0, 0, 0, 0, 0, 7, 7, 0, 7, 0, 0, 0],\n",
       "  'fine_tags': [28, 28, 28, 28, 0, 0, 0, 0, 0, 54, 54, 0, 54, 0, 0, 0],\n",
       "  'id': '547'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'later',\n",
       "   'named',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Western',\n",
       "   'Suburbs',\n",
       "   'Magpies',\n",
       "   'Team',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Eighties',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 37, 37, 37, 37, 0, 0, 0, 0],\n",
       "  'id': '548'},\n",
       " {'tokens': ['In',\n",
       "   'one',\n",
       "   'place',\n",
       "   'the',\n",
       "   'land',\n",
       "   'is',\n",
       "   'stated',\n",
       "   'to',\n",
       "   'have',\n",
       "   'been',\n",
       "   'created',\n",
       "   'by',\n",
       "   'Paraśurāma',\n",
       "   'by',\n",
       "   'shooting',\n",
       "   'an',\n",
       "   'arrow',\n",
       "   ',',\n",
       "   'while',\n",
       "   'in',\n",
       "   'another',\n",
       "   'place',\n",
       "   'the',\n",
       "   'land',\n",
       "   'is',\n",
       "   'created',\n",
       "   'by',\n",
       "   'throwing',\n",
       "   'an',\n",
       "   'axe',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '549'},\n",
       " {'tokens': ['Another',\n",
       "   'is',\n",
       "   'tied',\n",
       "   'to',\n",
       "   'the',\n",
       "   'common',\n",
       "   'height',\n",
       "   'of',\n",
       "   'tables',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '550'},\n",
       " {'tokens': ['Finally',\n",
       "   ',',\n",
       "   'in',\n",
       "   'October',\n",
       "   '2007',\n",
       "   ',',\n",
       "   'Angius',\n",
       "   'and',\n",
       "   'his',\n",
       "   'group',\n",
       "   'left',\n",
       "   'SD',\n",
       "   'to',\n",
       "   'found',\n",
       "   'the',\n",
       "   'Socialist',\n",
       "   'Party',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 5, 0, 0, 0, 5, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 54, 0, 0, 0, 0, 33, 0, 0, 0, 33, 33, 0],\n",
       "  'id': '551'},\n",
       " {'tokens': ['The',\n",
       "   'Pruteț',\n",
       "   'is',\n",
       "   'a',\n",
       "   'right',\n",
       "   'tributary',\n",
       "   'of',\n",
       "   'the',\n",
       "   'river',\n",
       "   'Prut',\n",
       "   'in',\n",
       "   'Romania',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0],\n",
       "  'fine_tags': [0, 22, 0, 0, 0, 0, 0, 0, 0, 22, 0, 21, 0],\n",
       "  'id': '552'},\n",
       " {'tokens': ['Short',\n",
       "   'of',\n",
       "   'the',\n",
       "   '40',\n",
       "   '%',\n",
       "   'margin',\n",
       "   'required',\n",
       "   'to',\n",
       "   'avoid',\n",
       "   'a',\n",
       "   'second',\n",
       "   'primary',\n",
       "   'election',\n",
       "   ',',\n",
       "   'Kathy',\n",
       "   'Taft',\n",
       "   'of',\n",
       "   'Pitt',\n",
       "   'County',\n",
       "   'called',\n",
       "   'for',\n",
       "   'a',\n",
       "   'runoff',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '553'},\n",
       " {'tokens': ['He',\n",
       "   'taught',\n",
       "   'commercial',\n",
       "   'and',\n",
       "   'theatrical',\n",
       "   'art',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Westminster',\n",
       "   'School',\n",
       "   'of',\n",
       "   'Art',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 29, 29, 0, 0, 0],\n",
       "  'id': '554'},\n",
       " {'tokens': ['The',\n",
       "   'Mongols',\n",
       "   'established',\n",
       "   'the',\n",
       "   'Yam',\n",
       "   '(',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Örtöö',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   '``',\n",
       "   'checkpoint',\n",
       "   \"''\",\n",
       "   ')',\n",
       "   ',',\n",
       "   'the',\n",
       "   'first',\n",
       "   'system',\n",
       "   'of',\n",
       "   'communication',\n",
       "   'that',\n",
       "   'connected',\n",
       "   'the',\n",
       "   'Far',\n",
       "   'East',\n",
       "   'and',\n",
       "   'the',\n",
       "   'West',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '555'},\n",
       " {'tokens': ['Route',\n",
       "   '90',\n",
       "   'Business',\n",
       "   '(',\n",
       "   'Westbank',\n",
       "   'Expressway',\n",
       "   ')',\n",
       "   'interchange',\n",
       "   'east',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Broad',\n",
       "   'Street',\n",
       "   'Overpass',\n",
       "   'of',\n",
       "   'US',\n",
       "   '90',\n",
       "   'B',\n",
       "   '(',\n",
       "   'Pontchartrain',\n",
       "   'Expressway',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '556'},\n",
       " {'tokens': ['Alongside',\n",
       "   'his',\n",
       "   'role',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Council',\n",
       "   'of',\n",
       "   'State',\n",
       "   ',',\n",
       "   'Alain',\n",
       "   'Seban',\n",
       "   'served',\n",
       "   'on',\n",
       "   'the',\n",
       "   'board',\n",
       "   'of',\n",
       "   'the',\n",
       "   'pension',\n",
       "   'fund',\n",
       "   'for',\n",
       "   'National',\n",
       "   'Paris',\n",
       "   'Opera',\n",
       "   'staff',\n",
       "   'and',\n",
       "   'on',\n",
       "   'the',\n",
       "   'board',\n",
       "   'of',\n",
       "   'the',\n",
       "   'pension',\n",
       "   'fund',\n",
       "   'for',\n",
       "   'Comédie',\n",
       "   'Française',\n",
       "   'staff',\n",
       "   ',',\n",
       "   'and',\n",
       "   'as',\n",
       "   'was',\n",
       "   'an',\n",
       "   'alternate',\n",
       "   'member',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Polling',\n",
       "   'Commission',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   14,\n",
       "   14,\n",
       "   14,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0],\n",
       "  'id': '557'},\n",
       " {'tokens': ['Molybdenum',\n",
       "   'sulfide',\n",
       "   ',',\n",
       "   'the',\n",
       "   'basic',\n",
       "   'ingredient',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Liqui',\n",
       "   'Moly',\n",
       "   'Oil',\n",
       "   'additive',\n",
       "   ',',\n",
       "   'was',\n",
       "   'discovered',\n",
       "   'in',\n",
       "   'the',\n",
       "   'shops',\n",
       "   'of',\n",
       "   'the',\n",
       "   'US',\n",
       "   'Army',\n",
       "   'in',\n",
       "   'post-war',\n",
       "   'Germany',\n",
       "   '.'],\n",
       "  'coarse_tags': [6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [41,\n",
       "   41,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   41,\n",
       "   41,\n",
       "   41,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '558'},\n",
       " {'tokens': ['The',\n",
       "   'exhibition',\n",
       "   'continues',\n",
       "   'in',\n",
       "   'the',\n",
       "   'adjacent',\n",
       "   'building',\n",
       "   ',',\n",
       "   'telling',\n",
       "   'the',\n",
       "   'story',\n",
       "   'of',\n",
       "   'Finnish',\n",
       "   'Defence',\n",
       "   'Forces',\n",
       "   'in',\n",
       "   'the',\n",
       "   'post-war',\n",
       "   'period',\n",
       "   'up',\n",
       "   'to',\n",
       "   'the',\n",
       "   'present',\n",
       "   'day'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '559'},\n",
       " {'tokens': ['``', 'Come', 'on', ',', 'James', '.', \"''\"],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '560'},\n",
       " {'tokens': ['To',\n",
       "   'the',\n",
       "   'west',\n",
       "   'is',\n",
       "   'Shalford',\n",
       "   'Junction',\n",
       "   ',',\n",
       "   'from',\n",
       "   'Charing',\n",
       "   'Cross',\n",
       "   ',',\n",
       "   'where',\n",
       "   'the',\n",
       "   'North',\n",
       "   'Downs',\n",
       "   'Line',\n",
       "   'meets',\n",
       "   'the',\n",
       "   'Portsmouth',\n",
       "   'Direct',\n",
       "   'Line',\n",
       "   'from',\n",
       "   'Waterloo',\n",
       "   '(',\n",
       "   'via',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '561'},\n",
       " {'tokens': ['The',\n",
       "   'UPCUSA',\n",
       "   ',',\n",
       "   'under',\n",
       "   'the',\n",
       "   'leadership',\n",
       "   'of',\n",
       "   'Eugene',\n",
       "   'Carson',\n",
       "   'Blake',\n",
       "   ',',\n",
       "   'the',\n",
       "   'denomination',\n",
       "   \"'s\",\n",
       "   'stated',\n",
       "   'clerk',\n",
       "   ',',\n",
       "   'joined',\n",
       "   'the',\n",
       "   'Presbyterian',\n",
       "   'Church',\n",
       "   'in',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Episcopalians',\n",
       "   ',',\n",
       "   'the',\n",
       "   'United',\n",
       "   'Methodists',\n",
       "   'and',\n",
       "   'the',\n",
       "   'United',\n",
       "   'Church',\n",
       "   'of',\n",
       "   'Christ',\n",
       "   'in',\n",
       "   'meetings',\n",
       "   'of',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Consultation',\n",
       "   'on',\n",
       "   'Church',\n",
       "   'Union',\n",
       "   '``',\n",
       "   'and',\n",
       "   'adopted',\n",
       "   'the',\n",
       "   'Confession',\n",
       "   'of',\n",
       "   '1967',\n",
       "   ',',\n",
       "   'which',\n",
       "   'had',\n",
       "   'a',\n",
       "   'more',\n",
       "   'neo-orthodox',\n",
       "   'understanding',\n",
       "   'of',\n",
       "   'Scripture',\n",
       "   'and',\n",
       "   'called',\n",
       "   'for',\n",
       "   'a',\n",
       "   'commitment',\n",
       "   'to',\n",
       "   'social',\n",
       "   'action',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '562'},\n",
       " {'tokens': ['During',\n",
       "   'his',\n",
       "   'time',\n",
       "   'at',\n",
       "   'Oklahoma',\n",
       "   'State',\n",
       "   ',',\n",
       "   'Low',\n",
       "   'was',\n",
       "   'strongly',\n",
       "   'involved',\n",
       "   'with',\n",
       "   'the',\n",
       "   'construction',\n",
       "   'of',\n",
       "   'the',\n",
       "   'present',\n",
       "   'Edmon',\n",
       "   'Low',\n",
       "   'Library',\n",
       "   'building',\n",
       "   ',',\n",
       "   'the',\n",
       "   'main',\n",
       "   'library',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Oklahoma',\n",
       "   'State',\n",
       "   'University',\n",
       "   'System',\n",
       "   ',',\n",
       "   'named',\n",
       "   'after',\n",
       "   'his',\n",
       "   'contributions',\n",
       "   'to',\n",
       "   'the',\n",
       "   'university',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '563'},\n",
       " {'tokens': ['Pro-wrestler',\n",
       "   'Brian',\n",
       "   'Pillman',\n",
       "   'used',\n",
       "   '``',\n",
       "   'Do',\n",
       "   \"n't\",\n",
       "   'Bite',\n",
       "   'the',\n",
       "   'Hand',\n",
       "   'That',\n",
       "   'Feeds',\n",
       "   '``',\n",
       "   'as',\n",
       "   'his',\n",
       "   'theme',\n",
       "   'music',\n",
       "   ',',\n",
       "   'when',\n",
       "   'WCW',\n",
       "   'talent',\n",
       "   'went',\n",
       "   'on',\n",
       "   'tour',\n",
       "   'with',\n",
       "   'New',\n",
       "   'Japan',\n",
       "   'Pro',\n",
       "   'Wrestling',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0],\n",
       "  'id': '564'},\n",
       " {'tokens': ['He',\n",
       "   'is',\n",
       "   'currently',\n",
       "   'the',\n",
       "   'assistant',\n",
       "   'manager',\n",
       "   'of',\n",
       "   'Swonder',\n",
       "   'Ice',\n",
       "   'Arena',\n",
       "   'in',\n",
       "   'Evansville',\n",
       "   'Indiana',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 4, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 11, 11, 11, 0, 21, 21, 0],\n",
       "  'id': '565'},\n",
       " {'tokens': ['Poker',\n",
       "   ',',\n",
       "   'blackjack',\n",
       "   ',',\n",
       "   'and',\n",
       "   'baccarat',\n",
       "   'are',\n",
       "   'examples',\n",
       "   'of',\n",
       "   'comparing',\n",
       "   'card',\n",
       "   'games',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '566'},\n",
       " {'tokens': ['It',\n",
       "   'was',\n",
       "   'the',\n",
       "   'deadliest',\n",
       "   'aviation',\n",
       "   'accident',\n",
       "   'involving',\n",
       "   'an',\n",
       "   'ATR',\n",
       "   '42',\n",
       "   'until',\n",
       "   'Trigana',\n",
       "   'Air',\n",
       "   'Service',\n",
       "   'Flight',\n",
       "   '267',\n",
       "   'crashed',\n",
       "   'in',\n",
       "   'Papua',\n",
       "   ',',\n",
       "   'Indonesia',\n",
       "   ',',\n",
       "   'in',\n",
       "   '2015',\n",
       "   'with',\n",
       "   '54',\n",
       "   'deaths',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   16,\n",
       "   16,\n",
       "   16,\n",
       "   16,\n",
       "   16,\n",
       "   16,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '567'},\n",
       " {'tokens': ['Some',\n",
       "   'unwanted',\n",
       "   'isomers',\n",
       "   'are',\n",
       "   'formed',\n",
       "   'during',\n",
       "   'irradiation',\n",
       "   ':',\n",
       "   'these',\n",
       "   'are',\n",
       "   'removed',\n",
       "   'by',\n",
       "   'various',\n",
       "   'techniques',\n",
       "   ',',\n",
       "   'leaving',\n",
       "   'a',\n",
       "   'resin',\n",
       "   'which',\n",
       "   'melts',\n",
       "   'at',\n",
       "   'about',\n",
       "   'room',\n",
       "   'temperature',\n",
       "   'and',\n",
       "   'usually',\n",
       "   'has',\n",
       "   'a',\n",
       "   'potency',\n",
       "   'of',\n",
       "   '25,000,000',\n",
       "   'to',\n",
       "   '30,000,000',\n",
       "   'International',\n",
       "   'Units',\n",
       "   'per',\n",
       "   'gram',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '568'},\n",
       " {'tokens': ['The',\n",
       "   'TAIU-SWPA',\n",
       "   'moved',\n",
       "   'from',\n",
       "   'Australia',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Philippines',\n",
       "   'in',\n",
       "   'early',\n",
       "   '1945',\n",
       "   'and',\n",
       "   'gained',\n",
       "   'an',\n",
       "   'appreciation',\n",
       "   'of',\n",
       "   'the',\n",
       "   'state',\n",
       "   'of',\n",
       "   'enemy',\n",
       "   'technological',\n",
       "   'and',\n",
       "   'economic',\n",
       "   'development',\n",
       "   'essential',\n",
       "   'to',\n",
       "   'the',\n",
       "   'build-up',\n",
       "   'for',\n",
       "   'the',\n",
       "   'planned',\n",
       "   'invasion',\n",
       "   'of',\n",
       "   'Japan',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '569'},\n",
       " {'tokens': ['Bush',\n",
       "   'became',\n",
       "   'the',\n",
       "   'first',\n",
       "   'Republican',\n",
       "   'to',\n",
       "   'win',\n",
       "   'the',\n",
       "   'White',\n",
       "   'House',\n",
       "   'without',\n",
       "   'carrying',\n",
       "   'Oakland',\n",
       "   'County',\n",
       "   'since',\n",
       "   'Benjamin',\n",
       "   'Harrison',\n",
       "   'in',\n",
       "   '1888',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 4, 4, 0, 7, 7, 0, 0, 0],\n",
       "  'fine_tags': [55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '570'},\n",
       " {'tokens': ['From',\n",
       "   '2003',\n",
       "   'until',\n",
       "   '2006',\n",
       "   ',',\n",
       "   'Cheney',\n",
       "   'was',\n",
       "   'the',\n",
       "   'Chief',\n",
       "   'Operating',\n",
       "   'Officer',\n",
       "   'for',\n",
       "   'Business',\n",
       "   'Executives',\n",
       "   'for',\n",
       "   'National',\n",
       "   'Security',\n",
       "   ',',\n",
       "   'in',\n",
       "   'Washington',\n",
       "   ',',\n",
       "   'D.C',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '571'},\n",
       " {'tokens': ['From',\n",
       "   'the',\n",
       "   'beginning',\n",
       "   ',',\n",
       "   'Yancey',\n",
       "   'was',\n",
       "   'a',\n",
       "   'fixture',\n",
       "   'at',\n",
       "   'the',\n",
       "   'original',\n",
       "   'Fatburger',\n",
       "   ',',\n",
       "   'where',\n",
       "   'customers',\n",
       "   ',',\n",
       "   'who',\n",
       "   'included',\n",
       "   'entertainers',\n",
       "   'such',\n",
       "   'as',\n",
       "   'Redd',\n",
       "   'Foxx',\n",
       "   'and',\n",
       "   'Ray',\n",
       "   'Charles',\n",
       "   ',',\n",
       "   'could',\n",
       "   'custom-order',\n",
       "   'their',\n",
       "   'burgers',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   12,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '572'},\n",
       " {'tokens': ['In',\n",
       "   'the',\n",
       "   'wake',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Oklahoma',\n",
       "   'City',\n",
       "   'bombing',\n",
       "   'in',\n",
       "   '1995',\n",
       "   ',',\n",
       "   'the',\n",
       "   'government',\n",
       "   'classified',\n",
       "   'all',\n",
       "   'buildings',\n",
       "   'into',\n",
       "   'five',\n",
       "   'security',\n",
       "   'levels',\n",
       "   'and',\n",
       "   'established',\n",
       "   'minimum',\n",
       "   'security',\n",
       "   'requirements',\n",
       "   'for',\n",
       "   'them',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '573'},\n",
       " {'tokens': ['(',\n",
       "   'Lambda',\n",
       "   ')',\n",
       "   'λ',\n",
       "   'Caeli',\n",
       "   ',',\n",
       "   'at',\n",
       "   'magnitude',\n",
       "   '6.24',\n",
       "   ',',\n",
       "   'is',\n",
       "   'much',\n",
       "   'redder',\n",
       "   'and',\n",
       "   'farther',\n",
       "   'away',\n",
       "   ',',\n",
       "   'being',\n",
       "   'a',\n",
       "   'red',\n",
       "   'giant',\n",
       "   'around',\n",
       "   'from',\n",
       "   'Earth',\n",
       "   '.'],\n",
       "  'coarse_tags': [6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0],\n",
       "  'fine_tags': [38,\n",
       "   38,\n",
       "   38,\n",
       "   38,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0],\n",
       "  'id': '574'},\n",
       " {'tokens': ['Cruz',\n",
       "   'holds',\n",
       "   'a',\n",
       "   'number',\n",
       "   'of',\n",
       "   'school',\n",
       "   'records',\n",
       "   'and',\n",
       "   'league',\n",
       "   'honors',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '575'},\n",
       " {'tokens': ['With',\n",
       "   'running',\n",
       "   'powers',\n",
       "   ',',\n",
       "   'the',\n",
       "   'GWR',\n",
       "   'had',\n",
       "   'access',\n",
       "   'to',\n",
       "   'Liverpool',\n",
       "   'and',\n",
       "   'Manchester',\n",
       "   'as',\n",
       "   'well',\n",
       "   'as',\n",
       "   'Birkenhead',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 4, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 27, 0, 0, 0, 21, 0, 21, 0, 0, 0, 21, 0],\n",
       "  'id': '576'},\n",
       " {'tokens': ['The',\n",
       "   'movement',\n",
       "   'to',\n",
       "   'establish',\n",
       "   'Bundelkhand',\n",
       "   'as',\n",
       "   'a',\n",
       "   'separate',\n",
       "   'state',\n",
       "   'has',\n",
       "   'also',\n",
       "   'used',\n",
       "   'the',\n",
       "   'legend',\n",
       "   'of',\n",
       "   'Jhalkaribai',\n",
       "   'to',\n",
       "   'create',\n",
       "   'the',\n",
       "   'Bundeli',\n",
       "   'identity',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '577'},\n",
       " {'tokens': ['Roxana',\n",
       "   'is',\n",
       "   'served',\n",
       "   'by',\n",
       "   'Amtrak',\n",
       "   'in',\n",
       "   'Alton',\n",
       "   ',',\n",
       "   'St.',\n",
       "   'Louis',\n",
       "   'Regional',\n",
       "   'Airport',\n",
       "   '(',\n",
       "   'formerly',\n",
       "   'known',\n",
       "   'as',\n",
       "   'Civic',\n",
       "   'Memorial',\n",
       "   'Airport',\n",
       "   ')',\n",
       "   'in',\n",
       "   'Bethalto',\n",
       "   ',',\n",
       "   'and',\n",
       "   'Lambert-St.',\n",
       "   'Louis',\n",
       "   'International',\n",
       "   'Airport',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0],\n",
       "  'fine_tags': [21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'id': '578'},\n",
       " {'tokens': ['Air',\n",
       "   'engagements',\n",
       "   'are',\n",
       "   'handled',\n",
       "   'by',\n",
       "   'the',\n",
       "   'heat-seeking',\n",
       "   'Sidewinder',\n",
       "   'and',\n",
       "   'the',\n",
       "   'radar',\n",
       "   'guided',\n",
       "   'AMRAAM',\n",
       "   'missiles',\n",
       "   'along',\n",
       "   'with',\n",
       "   'the',\n",
       "   'M61',\n",
       "   'Vulcan',\n",
       "   'cannon',\n",
       "   'for',\n",
       "   'close',\n",
       "   'range',\n",
       "   'dogfighting',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   66,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '579'},\n",
       " {'tokens': ['After',\n",
       "   'his',\n",
       "   'death',\n",
       "   ',',\n",
       "   'Ralston',\n",
       "   \"'s\",\n",
       "   'log',\n",
       "   'cabin',\n",
       "   'studio',\n",
       "   'was',\n",
       "   'first',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'Rocky',\n",
       "   'Mountain',\n",
       "   'College',\n",
       "   'in',\n",
       "   'Billings',\n",
       "   'and',\n",
       "   'then',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Western',\n",
       "   'Heritage',\n",
       "   'Center',\n",
       "   'in',\n",
       "   '2005',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '580'},\n",
       " {'tokens': ['When',\n",
       "   'Maxie',\n",
       "   'does',\n",
       "   'not',\n",
       "   'believe',\n",
       "   'her',\n",
       "   ',',\n",
       "   'she',\n",
       "   'claims',\n",
       "   'she',\n",
       "   'heard',\n",
       "   'Danny',\n",
       "   'sing',\n",
       "   'once',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0],\n",
       "  'fine_tags': [0, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 51, 0, 0, 0],\n",
       "  'id': '581'},\n",
       " {'tokens': ['The',\n",
       "   'main',\n",
       "   'shrine',\n",
       "   'for',\n",
       "   'Ranganatha',\n",
       "   'is',\n",
       "   'in',\n",
       "   'the',\n",
       "   'innermost',\n",
       "   'courtyard',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 25, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '582'},\n",
       " {'tokens': ['However',\n",
       "   'poor',\n",
       "   'performances',\n",
       "   'returned',\n",
       "   'and',\n",
       "   'in',\n",
       "   'their',\n",
       "   'final',\n",
       "   'season',\n",
       "   'as',\n",
       "   'members',\n",
       "   'of',\n",
       "   'the',\n",
       "   'NSL',\n",
       "   'in',\n",
       "   '1989',\n",
       "   ',',\n",
       "   'after',\n",
       "   'the',\n",
       "   'club',\n",
       "   'changed',\n",
       "   'their',\n",
       "   'name',\n",
       "   'to',\n",
       "   'Melbourne',\n",
       "   'City',\n",
       "   'JUST',\n",
       "   'to',\n",
       "   'broaden',\n",
       "   'their',\n",
       "   'appeal',\n",
       "   'and',\n",
       "   'with',\n",
       "   'Schintler',\n",
       "   'Reserve',\n",
       "   'having',\n",
       "   'undergone',\n",
       "   'significant',\n",
       "   'renovations',\n",
       "   ',',\n",
       "   'the',\n",
       "   'club',\n",
       "   'were',\n",
       "   'demoted',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Victoria',\n",
       "   'State',\n",
       "   'League',\n",
       "   'along',\n",
       "   'with',\n",
       "   'fellow',\n",
       "   'Melbourne',\n",
       "   'club',\n",
       "   'Heidelberg',\n",
       "   'United',\n",
       "   'FC',\n",
       "   'after',\n",
       "   'finishing',\n",
       "   'second',\n",
       "   'bottom',\n",
       "   ',',\n",
       "   'recording',\n",
       "   'only',\n",
       "   'five',\n",
       "   'league',\n",
       "   'wins',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   36,\n",
       "   36,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '583'},\n",
       " {'tokens': ['There',\n",
       "   'he',\n",
       "   'subsequently',\n",
       "   'directed',\n",
       "   'plays',\n",
       "   'and',\n",
       "   'saw',\n",
       "   'his',\n",
       "   'first',\n",
       "   'comedy',\n",
       "   '``',\n",
       "   'Without',\n",
       "   'the',\n",
       "   'Prince',\n",
       "   '``',\n",
       "   'professionally',\n",
       "   'produced',\n",
       "   ',',\n",
       "   'and',\n",
       "   'shortly',\n",
       "   'after',\n",
       "   'presented',\n",
       "   'in',\n",
       "   'the',\n",
       "   'West',\n",
       "   'End',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Whitehall',\n",
       "   'Theatre',\n",
       "   'on',\n",
       "   '8',\n",
       "   'April',\n",
       "   '1940',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   14,\n",
       "   14,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '584'},\n",
       " {'tokens': ['Glial',\n",
       "   'scarring',\n",
       "   'is',\n",
       "   'a',\n",
       "   'consequence',\n",
       "   'of',\n",
       "   'several',\n",
       "   'neurodegenerative',\n",
       "   'conditions',\n",
       "   ',',\n",
       "   'as',\n",
       "   'well',\n",
       "   'as',\n",
       "   'injury',\n",
       "   'that',\n",
       "   'severs',\n",
       "   'neural',\n",
       "   'material',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [43, 43, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '585'},\n",
       " {'tokens': ['Roly',\n",
       "   'Poly',\n",
       "   'is',\n",
       "   'a',\n",
       "   'bay',\n",
       "   'mare',\n",
       "   'with',\n",
       "   'a',\n",
       "   'white',\n",
       "   'blaze',\n",
       "   'bred',\n",
       "   'in',\n",
       "   'Kentucky',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Misty',\n",
       "   'For',\n",
       "   'Me',\n",
       "   'Syndicate',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 6, 6, 6, 6, 0],\n",
       "  'fine_tags': [48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   48,\n",
       "   48,\n",
       "   0],\n",
       "  'id': '586'},\n",
       " {'tokens': ['He',\n",
       "   'then',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'London',\n",
       "   ',',\n",
       "   'where',\n",
       "   'from',\n",
       "   '1897',\n",
       "   'to',\n",
       "   '1899',\n",
       "   'he',\n",
       "   'was',\n",
       "   'an',\n",
       "   'assistant',\n",
       "   'first',\n",
       "   'to',\n",
       "   'Richard',\n",
       "   'Creed',\n",
       "   ',',\n",
       "   'then',\n",
       "   'to',\n",
       "   'William',\n",
       "   'Alfred',\n",
       "   'Pite',\n",
       "   ',',\n",
       "   'and',\n",
       "   'finally',\n",
       "   'to',\n",
       "   'Edwin',\n",
       "   'Landseer',\n",
       "   'Lutyens',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0],\n",
       "  'id': '587'},\n",
       " {'tokens': ['It',\n",
       "   'was',\n",
       "   'led',\n",
       "   'by',\n",
       "   'and',\n",
       "   'named',\n",
       "   'for',\n",
       "   'Colonel',\n",
       "   'Ahmed',\n",
       "   'ʻUrabi',\n",
       "   '(',\n",
       "   'also',\n",
       "   'spelled',\n",
       "   'Orabi',\n",
       "   'and',\n",
       "   'Arabi',\n",
       "   ')',\n",
       "   'and',\n",
       "   'sought',\n",
       "   'to',\n",
       "   'depose',\n",
       "   'the',\n",
       "   'Khedive',\n",
       "   'Tewfik',\n",
       "   'Pasha',\n",
       "   'and',\n",
       "   'end',\n",
       "   'British',\n",
       "   'and',\n",
       "   'French',\n",
       "   'influence',\n",
       "   'over',\n",
       "   'the',\n",
       "   'country',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '588'},\n",
       " {'tokens': ['Kwame',\n",
       "   'Kwei-Armah',\n",
       "   'has',\n",
       "   'been',\n",
       "   'Artistic',\n",
       "   'Director',\n",
       "   'since',\n",
       "   'February',\n",
       "   '2018',\n",
       "   ',',\n",
       "   'succeeding',\n",
       "   'David',\n",
       "   'Lan',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0],\n",
       "  'fine_tags': [51, 51, 0, 0, 0, 0, 0, 0, 0, 0, 0, 51, 51, 0],\n",
       "  'id': '589'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'commissioned',\n",
       "   'as',\n",
       "   'a',\n",
       "   'flight',\n",
       "   'lieutenant',\n",
       "   'and',\n",
       "   'was',\n",
       "   'assigned',\n",
       "   'to',\n",
       "   'No',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '590'},\n",
       " {'tokens': ['Motoring',\n",
       "   'Along',\n",
       "   'is',\n",
       "   'an',\n",
       "   'album',\n",
       "   'by',\n",
       "   'Al',\n",
       "   'Cohn',\n",
       "   'and',\n",
       "   'Zoot',\n",
       "   'Sims',\n",
       "   'recorded',\n",
       "   'in',\n",
       "   'Sweden',\n",
       "   'in',\n",
       "   '1974',\n",
       "   'for',\n",
       "   'the',\n",
       "   'Sonet',\n",
       "   'label',\n",
       "   '.'],\n",
       "  'coarse_tags': [1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '591'},\n",
       " {'tokens': ['If',\n",
       "   'qualified',\n",
       "   'through',\n",
       "   'multiple',\n",
       "   'methods',\n",
       "   ',',\n",
       "   'a',\n",
       "   'Premier',\n",
       "   'Event',\n",
       "   'or',\n",
       "   'Regional',\n",
       "   'Final',\n",
       "   'win',\n",
       "   'takes',\n",
       "   'precedence',\n",
       "   'over',\n",
       "   'Global',\n",
       "   'Leaderboard',\n",
       "   'place',\n",
       "   ',',\n",
       "   'which',\n",
       "   'in',\n",
       "   'turn',\n",
       "   'takes',\n",
       "   'precedence',\n",
       "   'over',\n",
       "   'a',\n",
       "   'Regional',\n",
       "   'Leaderboard',\n",
       "   'spot',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '592'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'a',\n",
       "   'son',\n",
       "   'of',\n",
       "   'Clearchus',\n",
       "   ',',\n",
       "   'who',\n",
       "   'had',\n",
       "   'assumed',\n",
       "   'the',\n",
       "   'tyranny',\n",
       "   'in',\n",
       "   'his',\n",
       "   'place',\n",
       "   'of',\n",
       "   'birth',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '593'},\n",
       " {'tokens': ['In',\n",
       "   'June',\n",
       "   '2012',\n",
       "   ',',\n",
       "   'it',\n",
       "   'was',\n",
       "   'announced',\n",
       "   'that',\n",
       "   'the',\n",
       "   'Reformed',\n",
       "   'Church',\n",
       "   'of',\n",
       "   'France',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Evangelical',\n",
       "   'Lutheran',\n",
       "   'Church',\n",
       "   'of',\n",
       "   'France',\n",
       "   'would',\n",
       "   'unite',\n",
       "   'to',\n",
       "   'form',\n",
       "   'the',\n",
       "   'United',\n",
       "   'Protestant',\n",
       "   'Church',\n",
       "   'of',\n",
       "   'France',\n",
       "   '(',\n",
       "   'Eglise',\n",
       "   'Protestante',\n",
       "   'unie',\n",
       "   'de',\n",
       "   'France',\n",
       "   'or',\n",
       "   'EPUF',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   0,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   34,\n",
       "   0,\n",
       "   34,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '594'},\n",
       " {'tokens': ['In',\n",
       "   '1844',\n",
       "   'he',\n",
       "   'obtained',\n",
       "   'his',\n",
       "   'agrégation',\n",
       "   'and',\n",
       "   'in',\n",
       "   '1849',\n",
       "   'became',\n",
       "   '``',\n",
       "   'médecin',\n",
       "   'des',\n",
       "   'hôpitaux',\n",
       "   \"''\",\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '595'},\n",
       " {'tokens': ['The',\n",
       "   '2010',\n",
       "   'FIFA',\n",
       "   'World',\n",
       "   'Cup',\n",
       "   'Final',\n",
       "   'was',\n",
       "   'a',\n",
       "   'football',\n",
       "   'match',\n",
       "   'that',\n",
       "   'took',\n",
       "   'place',\n",
       "   'on',\n",
       "   '11',\n",
       "   'July',\n",
       "   '2010',\n",
       "   'at',\n",
       "   'Soccer',\n",
       "   'City',\n",
       "   'in',\n",
       "   'Johannesburg',\n",
       "   ',',\n",
       "   'South',\n",
       "   'Africa',\n",
       "   ',',\n",
       "   'to',\n",
       "   'determine',\n",
       "   'the',\n",
       "   'winner',\n",
       "   'of',\n",
       "   'the',\n",
       "   '2010',\n",
       "   'FIFA',\n",
       "   'World',\n",
       "   'Cup',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '596'},\n",
       " {'tokens': [')',\n",
       "   ',',\n",
       "   'concerts',\n",
       "   '(',\n",
       "   'Tony',\n",
       "   'Bennett',\n",
       "   ',',\n",
       "   'Tommy',\n",
       "   'Tune',\n",
       "   ',',\n",
       "   'Debbie',\n",
       "   'Reynolds',\n",
       "   'etc',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 18, 18, 0, 18, 18, 0, 18, 18, 0, 0],\n",
       "  'id': '597'},\n",
       " {'tokens': ['Common',\n",
       "   'side',\n",
       "   'effects',\n",
       "   'include',\n",
       "   'heartburn',\n",
       "   'and',\n",
       "   'a',\n",
       "   'rash',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '598'},\n",
       " {'tokens': ['Ekey',\n",
       "   'turned',\n",
       "   'professional',\n",
       "   'in',\n",
       "   '2009',\n",
       "   ',',\n",
       "   'and',\n",
       "   'joined',\n",
       "   'the',\n",
       "   'Futures',\n",
       "   'Tour',\n",
       "   'on',\n",
       "   'July',\n",
       "   '14',\n",
       "   ',',\n",
       "   '2009',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [52, 0, 0, 0, 0, 0, 0, 0, 0, 20, 20, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '599'},\n",
       " {'tokens': ['His',\n",
       "   'mother',\n",
       "   ',',\n",
       "   'Hugh',\n",
       "   \"'s\",\n",
       "   'second',\n",
       "   'wife',\n",
       "   ',',\n",
       "   'was',\n",
       "   'Catherine',\n",
       "   'Maria',\n",
       "   '(',\n",
       "   'née',\n",
       "   'Anderson',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 7, 0, 0, 7, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 54, 0, 0, 0, 0, 0, 54, 54, 0, 0, 54, 0, 0],\n",
       "  'id': '600'},\n",
       " {'tokens': ['Later',\n",
       "   'in',\n",
       "   '2006',\n",
       "   ',',\n",
       "   'the',\n",
       "   'introduced',\n",
       "   'adult',\n",
       "   'eagles',\n",
       "   'hatched',\n",
       "   'chicks',\n",
       "   'on',\n",
       "   'the',\n",
       "   'islands',\n",
       "   'for',\n",
       "   'the',\n",
       "   'first',\n",
       "   'time',\n",
       "   'since',\n",
       "   'their',\n",
       "   'extinction',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '601'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'capped',\n",
       "   'Iraqi',\n",
       "   'League',\n",
       "   'title',\n",
       "   'for',\n",
       "   'Al-Mina',\n",
       "   \"'\",\n",
       "   'a',\n",
       "   'in',\n",
       "   '1978',\n",
       "   ',',\n",
       "   'and',\n",
       "   'appeared',\n",
       "   'at',\n",
       "   'the',\n",
       "   'World',\n",
       "   'Military',\n",
       "   'Cup',\n",
       "   '1977',\n",
       "   ',',\n",
       "   'He',\n",
       "   'played',\n",
       "   'matches',\n",
       "   'in',\n",
       "   'Pestabola',\n",
       "   'Merdeka',\n",
       "   '1977',\n",
       "   'in',\n",
       "   'Malaysia',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '602'},\n",
       " {'tokens': ['In',\n",
       "   'the',\n",
       "   'mid',\n",
       "   '2000s',\n",
       "   'Orkin',\n",
       "   'joined',\n",
       "   'Barts',\n",
       "   'and',\n",
       "   'The',\n",
       "   'London',\n",
       "   'School',\n",
       "   'of',\n",
       "   'Medicine',\n",
       "   'and',\n",
       "   'Dentistry',\n",
       "   'as',\n",
       "   'a',\n",
       "   'consultant',\n",
       "   'physician',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 7, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   56,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '603'},\n",
       " {'tokens': ['A',\n",
       "   'cast',\n",
       "   'album',\n",
       "   'was',\n",
       "   'released',\n",
       "   'on',\n",
       "   'Decca',\n",
       "   'Records',\n",
       "   'shortly',\n",
       "   'after',\n",
       "   'the',\n",
       "   'broadcast',\n",
       "   ',',\n",
       "   'featuring',\n",
       "   'several',\n",
       "   'songs',\n",
       "   'omitted',\n",
       "   'from',\n",
       "   'the',\n",
       "   'original',\n",
       "   'show',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '604'},\n",
       " {'tokens': ['This',\n",
       "   'was',\n",
       "   'the',\n",
       "   'first',\n",
       "   'seat',\n",
       "   'gained',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Conservatives',\n",
       "   'in',\n",
       "   'a',\n",
       "   'by-election',\n",
       "   'since',\n",
       "   'the',\n",
       "   '1982',\n",
       "   'Mitcham',\n",
       "   'and',\n",
       "   'Morden',\n",
       "   'by-election',\n",
       "   'and',\n",
       "   'the',\n",
       "   'first',\n",
       "   'seat',\n",
       "   'they',\n",
       "   'had',\n",
       "   'taken',\n",
       "   'from',\n",
       "   'Labour',\n",
       "   'in',\n",
       "   'a',\n",
       "   'by-election',\n",
       "   'since',\n",
       "   'the',\n",
       "   '1978',\n",
       "   'Ilford',\n",
       "   'North',\n",
       "   'by-election',\n",
       "   'thirty',\n",
       "   'years',\n",
       "   'earlier',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '605'},\n",
       " {'tokens': ['The',\n",
       "   'brand',\n",
       "   'is',\n",
       "   'available',\n",
       "   'in',\n",
       "   'four',\n",
       "   'variants',\n",
       "   'and',\n",
       "   'the',\n",
       "   'cigarette',\n",
       "   'is',\n",
       "   '84',\n",
       "   'mm',\n",
       "   'long',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '606'},\n",
       " {'tokens': ['Although',\n",
       "   'the',\n",
       "   'Tsarskoye',\n",
       "   'Selo',\n",
       "   'Railway',\n",
       "   ',',\n",
       "   'built',\n",
       "   'by',\n",
       "   'German',\n",
       "   'engineer',\n",
       "   'Franz',\n",
       "   'Anton',\n",
       "   'von',\n",
       "   'Gerstner',\n",
       "   'in',\n",
       "   '1837',\n",
       "   ',',\n",
       "   'was',\n",
       "   'Russia',\n",
       "   \"'s\",\n",
       "   'first',\n",
       "   'public',\n",
       "   'railway',\n",
       "   'line',\n",
       "   ',',\n",
       "   'the',\n",
       "   'cost',\n",
       "   'overruns',\n",
       "   'led',\n",
       "   'Tsar',\n",
       "   'Nicholas',\n",
       "   'I',\n",
       "   'and',\n",
       "   'his',\n",
       "   'advisors',\n",
       "   'to',\n",
       "   'doubt',\n",
       "   'Gerstner',\n",
       "   \"'s\",\n",
       "   'ability',\n",
       "   'to',\n",
       "   'execute',\n",
       "   'the',\n",
       "   'planned',\n",
       "   'St.',\n",
       "   'Petersburg–Moscow',\n",
       "   'line',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0],\n",
       "  'id': '607'},\n",
       " {'tokens': ['Ohnimus',\n",
       "   'married',\n",
       "   'Bernice',\n",
       "   'M.',\n",
       "   'Wemple',\n",
       "   'on',\n",
       "   'December',\n",
       "   '27',\n",
       "   ',',\n",
       "   '1943',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 7, 7, 7, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [54, 0, 54, 54, 54, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '608'},\n",
       " {'tokens': ['The',\n",
       "   'sphinx',\n",
       "   'is',\n",
       "   'said',\n",
       "   'to',\n",
       "   'date',\n",
       "   'to',\n",
       "   'the',\n",
       "   'time',\n",
       "   'of',\n",
       "   'Khafra',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 54, 0],\n",
       "  'id': '609'},\n",
       " {'tokens': ['Kal-7-dependent',\n",
       "   'regulation',\n",
       "   'of',\n",
       "   'spine',\n",
       "   'formation',\n",
       "   'occurs',\n",
       "   'through',\n",
       "   'its',\n",
       "   'activity',\n",
       "   'as',\n",
       "   'a',\n",
       "   'GDP',\n",
       "   '/',\n",
       "   'GTP',\n",
       "   'exchange',\n",
       "   'factor',\n",
       "   'for',\n",
       "   'Rac1',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 6, 0, 0, 0, 6, 0],\n",
       "  'fine_tags': [40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 40, 0, 40, 0, 0, 0, 40, 0],\n",
       "  'id': '610'},\n",
       " {'tokens': ['Monroe',\n",
       "   \"'s\",\n",
       "   'career',\n",
       "   'highlight',\n",
       "   'came',\n",
       "   'during',\n",
       "   'Super',\n",
       "   'Bowl',\n",
       "   'XIX',\n",
       "   'versus',\n",
       "   'the',\n",
       "   'Miami',\n",
       "   'Dolphins',\n",
       "   'when',\n",
       "   'he',\n",
       "   'caught',\n",
       "   'a',\n",
       "   '33-yard',\n",
       "   'touchdown',\n",
       "   'pass',\n",
       "   'from',\n",
       "   'Joe',\n",
       "   'Montana',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0],\n",
       "  'id': '611'},\n",
       " {'tokens': ['In',\n",
       "   'March',\n",
       "   '1796',\n",
       "   'Württemberg',\n",
       "   'was',\n",
       "   'promoted',\n",
       "   'to',\n",
       "   'Feldzeugmeister',\n",
       "   ',',\n",
       "   'but',\n",
       "   'after',\n",
       "   'he',\n",
       "   'was',\n",
       "   'defeated',\n",
       "   'by',\n",
       "   'the',\n",
       "   'French',\n",
       "   'at',\n",
       "   'Altenkirchen',\n",
       "   'that',\n",
       "   'June',\n",
       "   ',',\n",
       "   'Archduke',\n",
       "   'Charles',\n",
       "   ',',\n",
       "   'Duke',\n",
       "   'of',\n",
       "   'Teschen',\n",
       "   'removed',\n",
       "   'him',\n",
       "   'from',\n",
       "   'command',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '612'},\n",
       " {'tokens': ['It',\n",
       "   'was',\n",
       "   'announced',\n",
       "   'in',\n",
       "   '2019',\n",
       "   'that',\n",
       "   'Karpowicz',\n",
       "   \"'s\",\n",
       "   'villa',\n",
       "   'in',\n",
       "   'Wrocław',\n",
       "   'would',\n",
       "   'become',\n",
       "   'the',\n",
       "   'future',\n",
       "   'home',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Nobel',\n",
       "   'Laureate',\n",
       "   'Olga',\n",
       "   'Tokarczuk',\n",
       "   \"'s\",\n",
       "   'Foundation',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0],\n",
       "  'id': '613'},\n",
       " {'tokens': ['As',\n",
       "   'a',\n",
       "   'result',\n",
       "   ',',\n",
       "   'Allan',\n",
       "   'Nicholls',\n",
       "   're-wrote',\n",
       "   'the',\n",
       "   'role',\n",
       "   'of',\n",
       "   'Sheila',\n",
       "   'Shea',\n",
       "   'from',\n",
       "   'an',\n",
       "   'Earth',\n",
       "   'Mother',\n",
       "   'type',\n",
       "   'to',\n",
       "   'the',\n",
       "   'young',\n",
       "   'singer/groupie',\n",
       "   'played',\n",
       "   'by',\n",
       "   'Marta',\n",
       "   'Heflin',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0],\n",
       "  'id': '614'},\n",
       " {'tokens': ['Several',\n",
       "   'countries',\n",
       "   'have',\n",
       "   'issued',\n",
       "   'silver',\n",
       "   'certificates',\n",
       "   ',',\n",
       "   'including',\n",
       "   'Cuba',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Netherlands',\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 4, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 21, 0, 0, 0, 21, 21, 0],\n",
       "  'id': '615'},\n",
       " {'tokens': ['Since',\n",
       "   'the',\n",
       "   'neighbouring',\n",
       "   'London',\n",
       "   'Arena',\n",
       "   'has',\n",
       "   'been',\n",
       "   'demolished',\n",
       "   '(',\n",
       "   'in',\n",
       "   '2006',\n",
       "   ')',\n",
       "   'the',\n",
       "   'original',\n",
       "   'name',\n",
       "   'has',\n",
       "   'been',\n",
       "   'reinstated',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 27, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '616'},\n",
       " {'tokens': ['They',\n",
       "   'are',\n",
       "   'considered',\n",
       "   'to',\n",
       "   'be',\n",
       "   'among',\n",
       "   'the',\n",
       "   'most',\n",
       "   'notable',\n",
       "   'of',\n",
       "   'the',\n",
       "   'many',\n",
       "   'relics',\n",
       "   'of',\n",
       "   'the',\n",
       "   'church',\n",
       "   ';',\n",
       "   'they',\n",
       "   'are',\n",
       "   'mentioned',\n",
       "   'by',\n",
       "   'Pepin',\n",
       "   'the',\n",
       "   'Short',\n",
       "   'in',\n",
       "   'the',\n",
       "   'deed',\n",
       "   'of',\n",
       "   '762',\n",
       "   ',',\n",
       "   'and',\n",
       "   'he',\n",
       "   'is',\n",
       "   'said',\n",
       "   'to',\n",
       "   'have',\n",
       "   'received',\n",
       "   'them',\n",
       "   'from',\n",
       "   'Rome',\n",
       "   'as',\n",
       "   'a',\n",
       "   'gift',\n",
       "   'of',\n",
       "   'Pope',\n",
       "   'Zachary',\n",
       "   '(',\n",
       "   '741–752',\n",
       "   ')',\n",
       "   'and',\n",
       "   'Pope',\n",
       "   'Stephen',\n",
       "   'II',\n",
       "   '(',\n",
       "   '752–757',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '617'},\n",
       " {'tokens': ['It',\n",
       "   'is',\n",
       "   'extremely',\n",
       "   'long-lived',\n",
       "   ',',\n",
       "   'with',\n",
       "   'a',\n",
       "   'lifespan',\n",
       "   'of',\n",
       "   '2,700',\n",
       "   'years',\n",
       "   ',',\n",
       "   'and',\n",
       "   'develops',\n",
       "   'into',\n",
       "   'a',\n",
       "   'large',\n",
       "   'tree-like',\n",
       "   'colony',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '618'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'sent',\n",
       "   'to',\n",
       "   'officers',\n",
       "   \"'\",\n",
       "   'school',\n",
       "   'and',\n",
       "   'completed',\n",
       "   'the',\n",
       "   'training',\n",
       "   'as',\n",
       "   'a',\n",
       "   'junior',\n",
       "   'lieutenant',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '619'},\n",
       " {'tokens': ['The',\n",
       "   'music',\n",
       "   'video',\n",
       "   'for',\n",
       "   'the',\n",
       "   'song',\n",
       "   'premiered',\n",
       "   'on',\n",
       "   '9',\n",
       "   'December',\n",
       "   '2019',\n",
       "   ';',\n",
       "   'it',\n",
       "   'was',\n",
       "   'directed',\n",
       "   'by',\n",
       "   'Karena',\n",
       "   'Evans',\n",
       "   'and',\n",
       "   'shot',\n",
       "   'in',\n",
       "   'three',\n",
       "   'countries',\n",
       "   ':',\n",
       "   'South',\n",
       "   'Africa',\n",
       "   ',',\n",
       "   'Morocco',\n",
       "   'and',\n",
       "   'Ukraine',\n",
       "   'for',\n",
       "   'ubuntu',\n",
       "   'on',\n",
       "   'South',\n",
       "   'African',\n",
       "   'broadcaster',\n",
       "   '``',\n",
       "   'Soweto',\n",
       "   'TV',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   53,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '620'},\n",
       " {'tokens': ['Prior',\n",
       "   'to',\n",
       "   'Wu',\n",
       "   'Bai',\n",
       "   '&',\n",
       "   'amp',\n",
       "   ';',\n",
       "   'China',\n",
       "   'Blue',\n",
       "   \"'s\",\n",
       "   'achieving',\n",
       "   'widespread',\n",
       "   'popularity',\n",
       "   'in',\n",
       "   'Taiwan',\n",
       "   'in',\n",
       "   'the',\n",
       "   'mid-1990s',\n",
       "   ',',\n",
       "   'guitar-oriented',\n",
       "   'rock',\n",
       "   'music',\n",
       "   'was',\n",
       "   'unusual',\n",
       "   'in',\n",
       "   'the',\n",
       "   'country',\n",
       "   \"'s\",\n",
       "   'domestic',\n",
       "   'popular',\n",
       "   'music',\n",
       "   'scene',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '621'},\n",
       " {'tokens': ['On',\n",
       "   'February',\n",
       "   '27',\n",
       "   ',',\n",
       "   '1987',\n",
       "   ',',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'National',\n",
       "   'Park',\n",
       "   'Service',\n",
       "   'recognized',\n",
       "   'the',\n",
       "   'Giant',\n",
       "   'Dipper',\n",
       "   'as',\n",
       "   'a',\n",
       "   'National',\n",
       "   'Historic',\n",
       "   'Landmark',\n",
       "   'along',\n",
       "   'with',\n",
       "   'the',\n",
       "   'Looff',\n",
       "   'Carousel',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   0],\n",
       "  'id': '622'},\n",
       " {'tokens': ['For',\n",
       "   'this',\n",
       "   'matter',\n",
       "   'the',\n",
       "   'company',\n",
       "   'was',\n",
       "   'fined',\n",
       "   '£',\n",
       "   '19,800',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 6, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 42, 0, 0],\n",
       "  'id': '623'},\n",
       " {'tokens': ['They',\n",
       "   'began',\n",
       "   'to',\n",
       "   'trade',\n",
       "   'with',\n",
       "   'the',\n",
       "   'growing',\n",
       "   'population',\n",
       "   'of',\n",
       "   'white',\n",
       "   'colonists',\n",
       "   ',',\n",
       "   'and',\n",
       "   'speculated',\n",
       "   'in',\n",
       "   'lands',\n",
       "   ',',\n",
       "   'acquiring',\n",
       "   'large',\n",
       "   'tracts',\n",
       "   'in',\n",
       "   'both',\n",
       "   'Carolina',\n",
       "   'and',\n",
       "   'Georgia',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '624'},\n",
       " {'tokens': ['``',\n",
       "   \"Floo'ers\",\n",
       "   'O',\n",
       "   \"'\",\n",
       "   'The',\n",
       "   'Forest',\n",
       "   '``',\n",
       "   'is',\n",
       "   'Gaughan',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'interpretation',\n",
       "   'of',\n",
       "   '``',\n",
       "   'Flowers',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Forest',\n",
       "   '``',\n",
       "   ',',\n",
       "   'an',\n",
       "   'ancient',\n",
       "   'Scottish',\n",
       "   'folk',\n",
       "   'tune',\n",
       "   'commemorating',\n",
       "   'the',\n",
       "   'Scottish',\n",
       "   'defeat',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Battle',\n",
       "   'of',\n",
       "   'Flodden',\n",
       "   'in',\n",
       "   '1513',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   0],\n",
       "  'id': '625'},\n",
       " {'tokens': ['The',\n",
       "   'Stone',\n",
       "   'frigate',\n",
       "   'is',\n",
       "   'a',\n",
       "   'large',\n",
       "   'stone',\n",
       "   'building',\n",
       "   'originally',\n",
       "   'designed',\n",
       "   'to',\n",
       "   'hold',\n",
       "   'gear',\n",
       "   'and',\n",
       "   'rigging',\n",
       "   'from',\n",
       "   'British',\n",
       "   'warships',\n",
       "   'dismantled',\n",
       "   'to',\n",
       "   'comply',\n",
       "   'with',\n",
       "   'the',\n",
       "   'Rush–Bagot',\n",
       "   'Treaty',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   47,\n",
       "   47,\n",
       "   0],\n",
       "  'id': '626'},\n",
       " {'tokens': ['Specific',\n",
       "   'STATs',\n",
       "   'appear',\n",
       "   'to',\n",
       "   'bind',\n",
       "   'to',\n",
       "   'specific',\n",
       "   'importin',\n",
       "   'proteins',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 6, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 40, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '627'},\n",
       " {'tokens': ['After',\n",
       "   'the',\n",
       "   'British',\n",
       "   'Ultimatum',\n",
       "   'and',\n",
       "   'the',\n",
       "   'political',\n",
       "   'crisis',\n",
       "   'associated',\n",
       "   ',',\n",
       "   'he',\n",
       "   'was',\n",
       "   'involved',\n",
       "   'in',\n",
       "   'the',\n",
       "   'political',\n",
       "   'debate',\n",
       "   'in',\n",
       "   '1891',\n",
       "   ',',\n",
       "   'writing',\n",
       "   'some',\n",
       "   'best-sellers',\n",
       "   'that',\n",
       "   'had',\n",
       "   'huge',\n",
       "   'impact',\n",
       "   'in',\n",
       "   'public',\n",
       "   'opinion',\n",
       "   ',',\n",
       "   'contributing',\n",
       "   'to',\n",
       "   'the',\n",
       "   'discredit',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Portuguese',\n",
       "   'monarchy',\n",
       "   'and',\n",
       "   'the',\n",
       "   'success',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Portuguese',\n",
       "   'Republican',\n",
       "   'Party',\n",
       "   'in',\n",
       "   'the',\n",
       "   '1910',\n",
       "   'Portuguese',\n",
       "   'Revolution',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   0],\n",
       "  'id': '628'},\n",
       " {'tokens': ['The',\n",
       "   'brewery',\n",
       "   ',',\n",
       "   'like',\n",
       "   'the',\n",
       "   'Monastery',\n",
       "   ',',\n",
       "   'is',\n",
       "   'off',\n",
       "   'the',\n",
       "   'electrical',\n",
       "   'grid',\n",
       "   'and',\n",
       "   'is',\n",
       "   'powered',\n",
       "   'by',\n",
       "   'solar',\n",
       "   'panels',\n",
       "   'and',\n",
       "   'propane',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '629'},\n",
       " {'tokens': ['Its',\n",
       "   'only',\n",
       "   'underground',\n",
       "   'vestibule',\n",
       "   'is',\n",
       "   'located',\n",
       "   'on',\n",
       "   'the',\n",
       "   'corner',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Mikhail',\n",
       "   'Kutuzov',\n",
       "   'street',\n",
       "   'and',\n",
       "   'Lesya',\n",
       "   'Ukrainka',\n",
       "   'boulevard',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 0, 4, 4, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 25, 25, 0, 25, 25, 25, 0],\n",
       "  'id': '630'},\n",
       " {'tokens': ['However',\n",
       "   ',',\n",
       "   'they',\n",
       "   'held',\n",
       "   'aboriginal',\n",
       "   'title',\n",
       "   'and',\n",
       "   'claimed',\n",
       "   'the',\n",
       "   'lands',\n",
       "   'for',\n",
       "   'hunting',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '631'},\n",
       " {'tokens': ['Martin',\n",
       "   'Parr',\n",
       "   'and',\n",
       "   'Gerry',\n",
       "   'Badger',\n",
       "   'describe',\n",
       "   '``',\n",
       "   'Morire',\n",
       "   'di',\n",
       "   'classe',\n",
       "   '``',\n",
       "   'as',\n",
       "   'a',\n",
       "   '``',\n",
       "   'harrowing',\n",
       "   'portrayal',\n",
       "   'of',\n",
       "   'the',\n",
       "   'conditions',\n",
       "   'in',\n",
       "   'an',\n",
       "   'Italian',\n",
       "   'mental',\n",
       "   'asylum',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   'and',\n",
       "   'in',\n",
       "   'the',\n",
       "   'tradition',\n",
       "   'of',\n",
       "   'earlier',\n",
       "   '``',\n",
       "   'polemical',\n",
       "   'photo-documentary',\n",
       "   'books',\n",
       "   \"''\",\n",
       "   'combining',\n",
       "   'photography',\n",
       "   'and',\n",
       "   'text',\n",
       "   'such',\n",
       "   'as',\n",
       "   '``',\n",
       "   'An',\n",
       "   'American',\n",
       "   'Exodus',\n",
       "   '``',\n",
       "   '(',\n",
       "   '1939',\n",
       "   ')',\n",
       "   'by',\n",
       "   'Dorothea',\n",
       "   'Lange',\n",
       "   'and',\n",
       "   'Paul',\n",
       "   'S.',\n",
       "   'Taylor',\n",
       "   'and',\n",
       "   '``',\n",
       "   'Kan',\n",
       "   'vi',\n",
       "   'være',\n",
       "   'dette',\n",
       "   'Bekendt',\n",
       "   '?',\n",
       "   '``'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0],\n",
       "  'fine_tags': [51,\n",
       "   51,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0],\n",
       "  'id': '632'},\n",
       " {'tokens': ['The',\n",
       "   'Daily',\n",
       "   'Record',\n",
       "   'of',\n",
       "   'High',\n",
       "   'Water',\n",
       "   'Elevations',\n",
       "   'of',\n",
       "   'the',\n",
       "   'St.',\n",
       "   'Francis',\n",
       "   'Dam',\n",
       "   'shows',\n",
       "   'that',\n",
       "   'between',\n",
       "   'May',\n",
       "   '27',\n",
       "   'and',\n",
       "   'June',\n",
       "   '30',\n",
       "   'alone',\n",
       "   ',',\n",
       "   '7000',\n",
       "   'to',\n",
       "   '8000',\n",
       "   'acre-feet',\n",
       "   'of',\n",
       "   'water',\n",
       "   'was',\n",
       "   'withdrawn',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '633'},\n",
       " {'tokens': ['Fluid',\n",
       "   'replacement',\n",
       "   'is',\n",
       "   'limited',\n",
       "   ',',\n",
       "   'but',\n",
       "   'can',\n",
       "   'help',\n",
       "   'keep',\n",
       "   'internal',\n",
       "   'temperatures',\n",
       "   'cooler',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '634'},\n",
       " {'tokens': ['Also',\n",
       "   'in',\n",
       "   '2013',\n",
       "   ',',\n",
       "   'Innes',\n",
       "   'initiated',\n",
       "   'an',\n",
       "   'online',\n",
       "   'petition',\n",
       "   'calling',\n",
       "   'on',\n",
       "   'department',\n",
       "   'store',\n",
       "   'Myer',\n",
       "   'to',\n",
       "   'increase',\n",
       "   'its',\n",
       "   'employment',\n",
       "   'of',\n",
       "   'people',\n",
       "   'with',\n",
       "   'disability',\n",
       "   'to',\n",
       "   '10',\n",
       "   'per',\n",
       "   'cent',\n",
       "   'of',\n",
       "   'its',\n",
       "   'workforce',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '635'},\n",
       " {'tokens': ['``',\n",
       "   'Niels',\n",
       "   'Juel',\n",
       "   '``',\n",
       "   'became',\n",
       "   'the',\n",
       "   'flagship',\n",
       "   'of',\n",
       "   'the',\n",
       "   'gunnery',\n",
       "   'training',\n",
       "   'squadron',\n",
       "   'later',\n",
       "   'that',\n",
       "   'year',\n",
       "   'and',\n",
       "   'then',\n",
       "   'later',\n",
       "   'flagship',\n",
       "   'of',\n",
       "   'the',\n",
       "   'general',\n",
       "   'training',\n",
       "   'squadron',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   63,\n",
       "   63,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '636'},\n",
       " {'tokens': ['Representing',\n",
       "   'the',\n",
       "   'Iraqis',\n",
       "   ',',\n",
       "   'two',\n",
       "   'members',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Council',\n",
       "   'were',\n",
       "   'picked',\n",
       "   'to',\n",
       "   'join',\n",
       "   'the',\n",
       "   'delegation',\n",
       "   ':',\n",
       "   'Sassoon',\n",
       "   'Eskell',\n",
       "   'and',\n",
       "   'Jafar',\n",
       "   'Pasha',\n",
       "   'al-Askari',\n",
       "   ';',\n",
       "   'with',\n",
       "   'the',\n",
       "   'disliked',\n",
       "   'Sayid',\n",
       "   'Talib',\n",
       "   'left',\n",
       "   'behind',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '637'},\n",
       " {'tokens': ['In',\n",
       "   '1689',\n",
       "   'Stalmine',\n",
       "   'had',\n",
       "   'a',\n",
       "   'Presbyterian',\n",
       "   'meeting',\n",
       "   'house',\n",
       "   ',',\n",
       "   'which',\n",
       "   'in',\n",
       "   '1717',\n",
       "   'was',\n",
       "   'stated',\n",
       "   'to',\n",
       "   'be',\n",
       "   'located',\n",
       "   '``',\n",
       "   'very',\n",
       "   'near',\n",
       "   'to',\n",
       "   'the',\n",
       "   'chapel',\n",
       "   \"''\",\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   56,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '638'},\n",
       " {'tokens': ['The',\n",
       "   'National',\n",
       "   'Library',\n",
       "   'of',\n",
       "   'Laos',\n",
       "   '(',\n",
       "   'Lao',\n",
       "   'language',\n",
       "   ':',\n",
       "   'ຫໍສະໝຸດແຫ່ງຊາດ',\n",
       "   ')',\n",
       "   'is',\n",
       "   'in',\n",
       "   'Vientiane',\n",
       "   ',',\n",
       "   'Laos',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 2, 2, 2, 2, 0, 6, 6, 0, 0, 0, 0, 0, 4, 0, 4, 0],\n",
       "  'fine_tags': [0, 10, 10, 10, 10, 0, 46, 46, 0, 0, 0, 0, 0, 21, 0, 21, 0],\n",
       "  'id': '639'},\n",
       " {'tokens': ['She',\n",
       "   'served',\n",
       "   'as',\n",
       "   'minister',\n",
       "   'of',\n",
       "   'education',\n",
       "   'from',\n",
       "   '2002',\n",
       "   'to',\n",
       "   '2007',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '640'},\n",
       " {'tokens': ['Along',\n",
       "   'with',\n",
       "   'the',\n",
       "   'aircraft',\n",
       "   'and',\n",
       "   'helicopter',\n",
       "   'kits',\n",
       "   ',',\n",
       "   'VEB',\n",
       "   'Plasticart',\n",
       "   'also',\n",
       "   'produced',\n",
       "   'a',\n",
       "   'model',\n",
       "   'of',\n",
       "   'the',\n",
       "   'first',\n",
       "   'manned',\n",
       "   'spaceship',\n",
       "   'Vostok',\n",
       "   '3KA',\n",
       "   '(',\n",
       "   '1/25',\n",
       "   ')',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Soviet',\n",
       "   'Energia',\n",
       "   'rocket',\n",
       "   'with',\n",
       "   'Buran',\n",
       "   '(',\n",
       "   '1/288',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '641'},\n",
       " {'tokens': ['This',\n",
       "   'was',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Dodgers',\n",
       "   'most',\n",
       "   'successful',\n",
       "   'drafts',\n",
       "   'in',\n",
       "   'history',\n",
       "   'as',\n",
       "   'they',\n",
       "   'drafted',\n",
       "   'Steve',\n",
       "   'Garvey',\n",
       "   ',',\n",
       "   'Ron',\n",
       "   'Cey',\n",
       "   ',',\n",
       "   'Davey',\n",
       "   'Lopes',\n",
       "   'and',\n",
       "   'Bobby',\n",
       "   'Valentine',\n",
       "   'in',\n",
       "   'this',\n",
       "   'draft',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '642'},\n",
       " {'tokens': ['The',\n",
       "   'aircraft',\n",
       "   'also',\n",
       "   'carried',\n",
       "   'the',\n",
       "   'RAF',\n",
       "   'serial',\n",
       "   'number',\n",
       "   'XF629',\n",
       "   'allotted',\n",
       "   'to',\n",
       "   'this',\n",
       "   'aircraft',\n",
       "   'for',\n",
       "   'use',\n",
       "   'during',\n",
       "   'trooping',\n",
       "   'flights',\n",
       "   'only',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 5, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 32, 0, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '643'},\n",
       " {'tokens': ['SR',\n",
       "   'protein',\n",
       "   'SC35',\n",
       "   'has',\n",
       "   'the',\n",
       "   'ability',\n",
       "   'to',\n",
       "   'bind',\n",
       "   'to',\n",
       "   'the',\n",
       "   'largest',\n",
       "   'subunit',\n",
       "   'of',\n",
       "   'RNA',\n",
       "   'polymerase',\n",
       "   'II',\n",
       "   'at',\n",
       "   'the',\n",
       "   'phosphorylated',\n",
       "   'C-terminal',\n",
       "   'domain',\n",
       "   '.'],\n",
       "  'coarse_tags': [6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [40,\n",
       "   40,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '644'},\n",
       " {'tokens': ['In',\n",
       "   '2016',\n",
       "   'following',\n",
       "   'the',\n",
       "   'merger',\n",
       "   'with',\n",
       "   'Diabetes',\n",
       "   'ACT',\n",
       "   'the',\n",
       "   'organisation',\n",
       "   'became',\n",
       "   'known',\n",
       "   'as',\n",
       "   'Diabetes',\n",
       "   'NSW',\n",
       "   '&',\n",
       "   'amp',\n",
       "   ';',\n",
       "   'ACT',\n",
       "   '-',\n",
       "   'the',\n",
       "   'peak',\n",
       "   'consumer',\n",
       "   'body',\n",
       "   'for',\n",
       "   'diabetes',\n",
       "   'in',\n",
       "   'New',\n",
       "   'South',\n",
       "   'Wales',\n",
       "   'and',\n",
       "   'the',\n",
       "   'ACT',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   47,\n",
       "   47,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   43,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   0],\n",
       "  'id': '645'},\n",
       " {'tokens': ['Previous',\n",
       "   'occupants',\n",
       "   'of',\n",
       "   'the',\n",
       "   'building',\n",
       "   'included',\n",
       "   'the',\n",
       "   'Department',\n",
       "   'of',\n",
       "   'Homeland',\n",
       "   'Security',\n",
       "   'offices',\n",
       "   'for',\n",
       "   'U.S',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 30, 30, 30, 30, 30, 30, 30, 0],\n",
       "  'id': '646'},\n",
       " {'tokens': ['The',\n",
       "   'future',\n",
       "   'of',\n",
       "   'the',\n",
       "   'current',\n",
       "   'VA',\n",
       "   'hospital',\n",
       "   'building',\n",
       "   'and',\n",
       "   'site',\n",
       "   'is',\n",
       "   'to',\n",
       "   'be',\n",
       "   'determined',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '647'},\n",
       " {'tokens': ['More',\n",
       "   'heart',\n",
       "   'transplants',\n",
       "   'are',\n",
       "   'performed',\n",
       "   'at',\n",
       "   'Texas',\n",
       "   'Medical',\n",
       "   'Center',\n",
       "   'than',\n",
       "   'anywhere',\n",
       "   'else',\n",
       "   'in',\n",
       "   'the',\n",
       "   'world',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 6, 6, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 49, 49, 0, 0, 0, 25, 25, 25, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '648'},\n",
       " {'tokens': ['Samsung',\n",
       "   'started',\n",
       "   'pushing',\n",
       "   'Android',\n",
       "   '4.1.2',\n",
       "   'Jelly',\n",
       "   'Bean',\n",
       "   'to',\n",
       "   'the',\n",
       "   'international',\n",
       "   'version',\n",
       "   'of',\n",
       "   'the',\n",
       "   'S',\n",
       "   'III',\n",
       "   'in',\n",
       "   'December',\n",
       "   '2012',\n",
       "   '.'],\n",
       "  'coarse_tags': [5, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0],\n",
       "  'fine_tags': [28, 0, 0, 0, 0, 64, 64, 0, 0, 0, 0, 0, 0, 64, 64, 0, 0, 0, 0],\n",
       "  'id': '649'},\n",
       " {'tokens': ['Their',\n",
       "   'control',\n",
       "   'technology',\n",
       "   'corresponds',\n",
       "   'almost',\n",
       "   'completely',\n",
       "   'with',\n",
       "   'that',\n",
       "   'of',\n",
       "   'the',\n",
       "   'SBB-CFF-FFS',\n",
       "   'Re',\n",
       "   '460',\n",
       "   'class',\n",
       "   'of',\n",
       "   'locomotive',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 8, 8, 8, 8, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 59, 59, 59, 59, 59, 0],\n",
       "  'id': '650'},\n",
       " {'tokens': ['Later',\n",
       "   'in',\n",
       "   'the',\n",
       "   'century',\n",
       "   ',',\n",
       "   'Bishop',\n",
       "   'Richard',\n",
       "   'Foxe',\n",
       "   'of',\n",
       "   'Durham',\n",
       "   '(',\n",
       "   '1494–1501',\n",
       "   ')',\n",
       "   'had',\n",
       "   'the',\n",
       "   'castle',\n",
       "   \"'s\",\n",
       "   'defences',\n",
       "   'strengthened',\n",
       "   'once',\n",
       "   'more',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '651'},\n",
       " {'tokens': ['In',\n",
       "   '1992',\n",
       "   ',',\n",
       "   'another',\n",
       "   'film',\n",
       "   'adaptation',\n",
       "   'of',\n",
       "   'the',\n",
       "   'novel',\n",
       "   'was',\n",
       "   'made',\n",
       "   ',',\n",
       "   '``',\n",
       "   \"L'Atlantide\",\n",
       "   '``',\n",
       "   ',',\n",
       "   'directed',\n",
       "   'by',\n",
       "   'Bob',\n",
       "   'Swaim',\n",
       "   'and',\n",
       "   'starring',\n",
       "   'Tchéky',\n",
       "   'Karyo',\n",
       "   ',',\n",
       "   'Jean',\n",
       "   'Rochefort',\n",
       "   ',',\n",
       "   'Anna',\n",
       "   'Galiena',\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'famous',\n",
       "   'Spanish',\n",
       "   'actor',\n",
       "   ',',\n",
       "   'Fernando',\n",
       "   'Rey',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   53,\n",
       "   53,\n",
       "   0,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0],\n",
       "  'id': '652'},\n",
       " {'tokens': ['After',\n",
       "   'the',\n",
       "   'founding',\n",
       "   'of',\n",
       "   'the',\n",
       "   'state',\n",
       "   'of',\n",
       "   'Israel',\n",
       "   ',',\n",
       "   'he',\n",
       "   'became',\n",
       "   'a',\n",
       "   'professor',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Technion',\n",
       "   '(',\n",
       "   'Israel',\n",
       "   'Institute',\n",
       "   'of',\n",
       "   'Technology',\n",
       "   ')',\n",
       "   'in',\n",
       "   'Haifa',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '653'},\n",
       " {'tokens': ['Alastair',\n",
       "   'is',\n",
       "   'taken',\n",
       "   'to',\n",
       "   'Storn',\n",
       "   'Castle',\n",
       "   'to',\n",
       "   'recover',\n",
       "   'from',\n",
       "   'his',\n",
       "   'burns',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [54, 0, 0, 0, 11, 11, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '654'},\n",
       " {'tokens': ['His',\n",
       "   'Dimebolt',\n",
       "   'and',\n",
       "   'all',\n",
       "   'guitars',\n",
       "   'stolen',\n",
       "   'were',\n",
       "   'returned',\n",
       "   'to',\n",
       "   'him',\n",
       "   'by',\n",
       "   'a',\n",
       "   'woman',\n",
       "   'who',\n",
       "   'bought',\n",
       "   'a',\n",
       "   'storage',\n",
       "   'unit',\n",
       "   'which',\n",
       "   'belonged',\n",
       "   'to',\n",
       "   'who',\n",
       "   'stole',\n",
       "   'them',\n",
       "   ',',\n",
       "   'or',\n",
       "   'received',\n",
       "   'it',\n",
       "   'from',\n",
       "   'the',\n",
       "   'person',\n",
       "   'that',\n",
       "   'stole',\n",
       "   'them',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '655'},\n",
       " {'tokens': ['Haukdal',\n",
       "   'tried',\n",
       "   'unsuccessfully',\n",
       "   'to',\n",
       "   'represent',\n",
       "   'Iceland',\n",
       "   'in',\n",
       "   'Eurovision',\n",
       "   'again',\n",
       "   'in',\n",
       "   '2006',\n",
       "   'with',\n",
       "   'the',\n",
       "   'song',\n",
       "   '``',\n",
       "   'Mynd',\n",
       "   'Af',\n",
       "   'Þér',\n",
       "   '``',\n",
       "   '(',\n",
       "   '``',\n",
       "   'Picture',\n",
       "   'from',\n",
       "   'You',\n",
       "   '``',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '656'},\n",
       " {'tokens': ['In',\n",
       "   'images',\n",
       "   'taken',\n",
       "   'with',\n",
       "   'the',\n",
       "   'Very',\n",
       "   'Large',\n",
       "   'Telescope',\n",
       "   'imager',\n",
       "   'in',\n",
       "   '2017',\n",
       "   ',',\n",
       "   'a',\n",
       "   'bright',\n",
       "   'surface',\n",
       "   'feature',\n",
       "   'is',\n",
       "   'visible',\n",
       "   ',',\n",
       "   'as',\n",
       "   'well',\n",
       "   'as',\n",
       "   'at',\n",
       "   'least',\n",
       "   'two',\n",
       "   'dark',\n",
       "   'craters',\n",
       "   ',',\n",
       "   'which',\n",
       "   'have',\n",
       "   'been',\n",
       "   'informally',\n",
       "   'named',\n",
       "   'Serpens',\n",
       "   'and',\n",
       "   'Calix',\n",
       "   'after',\n",
       "   'the',\n",
       "   'Latin',\n",
       "   'words',\n",
       "   'for',\n",
       "   'snake',\n",
       "   'and',\n",
       "   'cup',\n",
       "   ',',\n",
       "   'respectively',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '657'},\n",
       " {'tokens': ['The',\n",
       "   'Inn',\n",
       "   \"'s\",\n",
       "   'hall',\n",
       "   'was',\n",
       "   'reconstructed',\n",
       "   'at',\n",
       "   'his',\n",
       "   'new',\n",
       "   'house',\n",
       "   'at',\n",
       "   'Mill',\n",
       "   'Hill',\n",
       "   '(',\n",
       "   'then',\n",
       "   'Middlesex',\n",
       "   ',',\n",
       "   'now',\n",
       "   'London',\n",
       "   ',',\n",
       "   'NW7',\n",
       "   ')',\n",
       "   'with',\n",
       "   'the',\n",
       "   'original',\n",
       "   'stained',\n",
       "   'glass',\n",
       "   'windows',\n",
       "   'from',\n",
       "   'the',\n",
       "   'hall',\n",
       "   'and',\n",
       "   'chapel',\n",
       "   'at',\n",
       "   'the',\n",
       "   'inn',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '658'},\n",
       " {'tokens': ['Among',\n",
       "   'the',\n",
       "   'new',\n",
       "   'candidates',\n",
       "   'were',\n",
       "   '17-time',\n",
       "   'All-Star',\n",
       "   'Warren',\n",
       "   'Spahn',\n",
       "   ',',\n",
       "   '10-time',\n",
       "   'All-Star',\n",
       "   'Whitey',\n",
       "   'Ford',\n",
       "   ',',\n",
       "   '9-time',\n",
       "   'All-Star',\n",
       "   'Smoky',\n",
       "   'Burgess',\n",
       "   ',',\n",
       "   '8-time',\n",
       "   'All-Star',\n",
       "   'Dick',\n",
       "   'Groat',\n",
       "   'and',\n",
       "   'Bill',\n",
       "   'Skowron',\n",
       "   ',',\n",
       "   '7-time',\n",
       "   'All-Star',\n",
       "   'Robin',\n",
       "   'Roberts',\n",
       "   'and',\n",
       "   '5-time',\n",
       "   'All-Star',\n",
       "   'Earl',\n",
       "   'Battey',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0],\n",
       "  'id': '659'},\n",
       " {'tokens': ['Swim',\n",
       "   'Miami',\n",
       "   'takes',\n",
       "   'place',\n",
       "   'in',\n",
       "   'April',\n",
       "   'annually',\n",
       "   '.'],\n",
       "  'coarse_tags': [3, 3, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [20, 20, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '660'},\n",
       " {'tokens': ['The',\n",
       "   'Institute',\n",
       "   'established',\n",
       "   'legal',\n",
       "   'associations',\n",
       "   'with',\n",
       "   'the',\n",
       "   'National',\n",
       "   'Scientific',\n",
       "   'and',\n",
       "   'Technical',\n",
       "   'Research',\n",
       "   'Council',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 32, 32, 32, 32, 32, 32, 0],\n",
       "  'id': '661'},\n",
       " {'tokens': ['From',\n",
       "   '1949',\n",
       "   'onwards',\n",
       "   ',',\n",
       "   'there',\n",
       "   'was',\n",
       "   'a',\n",
       "   'special',\n",
       "   'Team',\n",
       "   'prize',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '662'},\n",
       " {'tokens': ['In',\n",
       "   'Germany',\n",
       "   ',',\n",
       "   'there',\n",
       "   'was',\n",
       "   'another',\n",
       "   'occurrence',\n",
       "   'of',\n",
       "   'an',\n",
       "   'accessible',\n",
       "   'public',\n",
       "   'library',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '663'},\n",
       " {'tokens': ['The',\n",
       "   'article',\n",
       "   'described',\n",
       "   'him',\n",
       "   'as',\n",
       "   '``',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'most',\n",
       "   'successful',\n",
       "   'trial',\n",
       "   'lawyers',\n",
       "   'in',\n",
       "   'the',\n",
       "   'country',\n",
       "   \"''\",\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '664'},\n",
       " {'tokens': ['The',\n",
       "   'appearance',\n",
       "   'of',\n",
       "   'the',\n",
       "   'crown',\n",
       "   'was',\n",
       "   'last',\n",
       "   'modified',\n",
       "   'during',\n",
       "   '1897',\n",
       "   'by',\n",
       "   'the',\n",
       "   'court',\n",
       "   'jeweller',\n",
       "   'August',\n",
       "   'Heinrich',\n",
       "   'Kuhn',\n",
       "   'for',\n",
       "   'King',\n",
       "   'William',\n",
       "   'I',\n",
       "   'of',\n",
       "   'Württemberg',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '665'},\n",
       " {'tokens': ['Phillips',\n",
       "   'was',\n",
       "   'a',\n",
       "   'guest',\n",
       "   'on',\n",
       "   'an',\n",
       "   'episode',\n",
       "   'of',\n",
       "   'the',\n",
       "   'television',\n",
       "   'series',\n",
       "   '``',\n",
       "   'This',\n",
       "   'Is',\n",
       "   'Your',\n",
       "   'Life',\n",
       "   '``',\n",
       "   'that',\n",
       "   'aired',\n",
       "   'March',\n",
       "   '15',\n",
       "   ',',\n",
       "   '1950',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '666'},\n",
       " {'tokens': ['Light',\n",
       "   \"'s\",\n",
       "   'name',\n",
       "   'was',\n",
       "   'prominent',\n",
       "   'on',\n",
       "   'many',\n",
       "   'albums',\n",
       "   'both',\n",
       "   'as',\n",
       "   'musician',\n",
       "   'and',\n",
       "   'producer',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [51, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '667'},\n",
       " {'tokens': ['Thomson',\n",
       "   \"'s\",\n",
       "   'three',\n",
       "   'autobiographical',\n",
       "   'works',\n",
       "   'were',\n",
       "   ':',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Road',\n",
       "   'to',\n",
       "   'Dunfermline',\n",
       "   ':',\n",
       "   'The',\n",
       "   'Story',\n",
       "   'of',\n",
       "   'a',\n",
       "   'Thirty-Five',\n",
       "   'Years',\n",
       "   \"'\",\n",
       "   'Quest',\n",
       "   ',',\n",
       "   \"''\",\n",
       "   '``',\n",
       "   'Why',\n",
       "   'I',\n",
       "   'Believe',\n",
       "   '``',\n",
       "   'and',\n",
       "   '``',\n",
       "   'Personal',\n",
       "   'Encounters',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '668'},\n",
       " {'tokens': ['The',\n",
       "   'Saints',\n",
       "   'play',\n",
       "   'at',\n",
       "   'Appleton',\n",
       "   'Arena',\n",
       "   'and',\n",
       "   'are',\n",
       "   'part',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Eastern',\n",
       "   'College',\n",
       "   'Athletic',\n",
       "   'Conference',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 5, 0, 0, 2, 2, 0, 0, 0, 0, 0, 5, 5, 5, 5, 0],\n",
       "  'fine_tags': [0, 37, 0, 0, 13, 13, 0, 0, 0, 0, 0, 37, 37, 37, 37, 0],\n",
       "  'id': '669'},\n",
       " {'tokens': ['José',\n",
       "   'Alfonso',\n",
       "   'Cavada',\n",
       "   '(',\n",
       "   'February',\n",
       "   '4',\n",
       "   ',',\n",
       "   '1832',\n",
       "   '–',\n",
       "   'March',\n",
       "   '23',\n",
       "   ',',\n",
       "   '1909',\n",
       "   ')',\n",
       "   'was',\n",
       "   'Chilean',\n",
       "   'minister',\n",
       "   'of',\n",
       "   'foreign',\n",
       "   'affairs',\n",
       "   '(',\n",
       "   '1876–1878',\n",
       "   ')',\n",
       "   'and',\n",
       "   'finance',\n",
       "   '(',\n",
       "   '1880–1881',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [55,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '670'},\n",
       " {'tokens': ['This',\n",
       "   'led',\n",
       "   'to',\n",
       "   'Volvo',\n",
       "   'switching',\n",
       "   'the',\n",
       "   '``',\n",
       "   'F',\n",
       "   \"''\",\n",
       "   'to',\n",
       "   '``',\n",
       "   'V',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   'for',\n",
       "   'versatile',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '671'},\n",
       " {'tokens': ['Before',\n",
       "   'the',\n",
       "   'introduction',\n",
       "   'of',\n",
       "   'the',\n",
       "   'European',\n",
       "   'single',\n",
       "   'currency',\n",
       "   'on',\n",
       "   '1',\n",
       "   'January',\n",
       "   '1999',\n",
       "   'an',\n",
       "   'exchange',\n",
       "   'rate',\n",
       "   'of',\n",
       "   '1',\n",
       "   'Euro',\n",
       "   '=',\n",
       "   '1.95583',\n",
       "   'Deutsche',\n",
       "   'mark',\n",
       "   'was',\n",
       "   'calculated',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   42,\n",
       "   0,\n",
       "   0,\n",
       "   42,\n",
       "   42,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '672'},\n",
       " {'tokens': ['Known',\n",
       "   'as',\n",
       "   '``',\n",
       "   'sate',\n",
       "   \"''\",\n",
       "   'in',\n",
       "   'Malay',\n",
       "   '(',\n",
       "   'and',\n",
       "   'pronounced',\n",
       "   'similarly',\n",
       "   'to',\n",
       "   'the',\n",
       "   'English',\n",
       "   '``',\n",
       "   'satay',\n",
       "   \"''\",\n",
       "   ')',\n",
       "   ',',\n",
       "   'it',\n",
       "   'can',\n",
       "   'be',\n",
       "   'found',\n",
       "   'throughout',\n",
       "   'all',\n",
       "   'the',\n",
       "   'states',\n",
       "   'of',\n",
       "   'Malaysia',\n",
       "   'in',\n",
       "   'restaurants',\n",
       "   'and',\n",
       "   'on',\n",
       "   'the',\n",
       "   'street',\n",
       "   ',',\n",
       "   'with',\n",
       "   'hawkers',\n",
       "   'selling',\n",
       "   'satay',\n",
       "   'in',\n",
       "   'food',\n",
       "   'courts',\n",
       "   'and',\n",
       "   'Pasar',\n",
       "   'malam',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '673'},\n",
       " {'tokens': ['Reportedly',\n",
       "   ',',\n",
       "   'Big',\n",
       "   'Bill',\n",
       "   'Broonzy',\n",
       "   'thought',\n",
       "   'that',\n",
       "   'his',\n",
       "   'real',\n",
       "   'name',\n",
       "   'was',\n",
       "   'Robert',\n",
       "   'Alexander',\n",
       "   ',',\n",
       "   'though',\n",
       "   'Memphis',\n",
       "   'Slim',\n",
       "   'gave',\n",
       "   'his',\n",
       "   'name',\n",
       "   'as',\n",
       "   'Bob',\n",
       "   'Hudson',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   56,\n",
       "   56,\n",
       "   56,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   56,\n",
       "   56,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '674'},\n",
       " {'tokens': ['(', 'See', 'Northeast', 'Passage', '.', ')'],\n",
       "  'coarse_tags': [0, 4, 4, 4, 0, 0],\n",
       "  'fine_tags': [0, 27, 27, 27, 0, 0],\n",
       "  'id': '675'},\n",
       " {'tokens': ['Instead',\n",
       "   ',',\n",
       "   'Haig',\n",
       "   'began',\n",
       "   'to',\n",
       "   'plan',\n",
       "   'for',\n",
       "   'an',\n",
       "   'offensive',\n",
       "   'at',\n",
       "   'Albert',\n",
       "   ',',\n",
       "   'which',\n",
       "   'opened',\n",
       "   'on',\n",
       "   '21',\n",
       "   'August',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 57, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '676'},\n",
       " {'tokens': ['There',\n",
       "   'was',\n",
       "   'a',\n",
       "   'special',\n",
       "   'appearance',\n",
       "   'by',\n",
       "   'Green',\n",
       "   'Wing',\n",
       "   'cast',\n",
       "   'at',\n",
       "   'the',\n",
       "   'British',\n",
       "   'Film',\n",
       "   'Institute',\n",
       "   ',',\n",
       "   'on',\n",
       "   '17',\n",
       "   'January',\n",
       "   '2007',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '677'},\n",
       " {'tokens': ['The',\n",
       "   'town',\n",
       "   'is',\n",
       "   'linked',\n",
       "   'to',\n",
       "   'the',\n",
       "   'rest',\n",
       "   'of',\n",
       "   'the',\n",
       "   '``',\n",
       "   'comarca',\n",
       "   '``',\n",
       "   'and',\n",
       "   'to',\n",
       "   'Igualada',\n",
       "   'by',\n",
       "   'the',\n",
       "   'C-241',\n",
       "   'road',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 4, 4, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0],\n",
       "  'id': '678'},\n",
       " {'tokens': ['At',\n",
       "   'the',\n",
       "   'Vienna',\n",
       "   'Volksoper',\n",
       "   'two',\n",
       "   'premieres',\n",
       "   'followed',\n",
       "   ':',\n",
       "   'Pierre',\n",
       "   'Lacotte',\n",
       "   \"'s\",\n",
       "   '``',\n",
       "   'Coppélia',\n",
       "   '``',\n",
       "   ',',\n",
       "   'and',\n",
       "   'Vesna',\n",
       "   'Orlic',\n",
       "   \"'s\",\n",
       "   '``',\n",
       "   'Peter',\n",
       "   'Pan',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '679'},\n",
       " {'tokens': ['Buda',\n",
       "   'possibly',\n",
       "   'had',\n",
       "   'experience',\n",
       "   'with',\n",
       "   'dynamite',\n",
       "   'from',\n",
       "   'work',\n",
       "   'in',\n",
       "   'Michigan',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [54, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '680'},\n",
       " {'tokens': ['Most',\n",
       "   'of',\n",
       "   'its',\n",
       "   'patients',\n",
       "   'during',\n",
       "   'the',\n",
       "   'early',\n",
       "   'years',\n",
       "   'were',\n",
       "   'from',\n",
       "   'the',\n",
       "   'poor',\n",
       "   'and',\n",
       "   'mostly',\n",
       "   'Catholic',\n",
       "   'segments',\n",
       "   'of',\n",
       "   'society',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '681'},\n",
       " {'tokens': ['The',\n",
       "   'Sacramento',\n",
       "   'Surge',\n",
       "   'played',\n",
       "   'five',\n",
       "   'home',\n",
       "   'games',\n",
       "   'at',\n",
       "   'Hughes',\n",
       "   'Stadium',\n",
       "   ',',\n",
       "   'with',\n",
       "   'ticket',\n",
       "   'prices',\n",
       "   'ranging',\n",
       "   'from',\n",
       "   '$',\n",
       "   '40',\n",
       "   'to',\n",
       "   '$',\n",
       "   '100',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   13,\n",
       "   13,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '682'},\n",
       " {'tokens': ['The',\n",
       "   'grapes',\n",
       "   'are',\n",
       "   'used',\n",
       "   'to',\n",
       "   'make',\n",
       "   'wines',\n",
       "   'including',\n",
       "   'dry',\n",
       "   ',',\n",
       "   'sweet',\n",
       "   ',',\n",
       "   'icewine',\n",
       "   'but',\n",
       "   'is',\n",
       "   'famed',\n",
       "   'for',\n",
       "   'spicy',\n",
       "   'sparkling',\n",
       "   'wines',\n",
       "   'that',\n",
       "   'do',\n",
       "   'not',\n",
       "   'have',\n",
       "   'much',\n",
       "   'of',\n",
       "   'the',\n",
       "   'objectionable',\n",
       "   'foxiness',\n",
       "   'character',\n",
       "   'that',\n",
       "   'other',\n",
       "   '``',\n",
       "   'V.',\n",
       "   'labrusca',\n",
       "   '``',\n",
       "   'grapes',\n",
       "   'contribute',\n",
       "   'to',\n",
       "   'their',\n",
       "   'wines',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   60,\n",
       "   60,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '683'},\n",
       " {'tokens': ['Some',\n",
       "   'studies',\n",
       "   'have',\n",
       "   'shown',\n",
       "   'that',\n",
       "   '1',\n",
       "   'in',\n",
       "   'every',\n",
       "   '7',\n",
       "   'couples',\n",
       "   'will',\n",
       "   'fail',\n",
       "   'to',\n",
       "   'conceive',\n",
       "   'due',\n",
       "   'to',\n",
       "   'infertility',\n",
       "   'problems',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 43, 0, 0],\n",
       "  'id': '684'},\n",
       " {'tokens': ['Having',\n",
       "   'no',\n",
       "   'other',\n",
       "   'choice',\n",
       "   ',',\n",
       "   'Marston',\n",
       "   'sets',\n",
       "   'out',\n",
       "   'to',\n",
       "   'bring',\n",
       "   'three',\n",
       "   'members',\n",
       "   'of',\n",
       "   'his',\n",
       "   'former',\n",
       "   'gang',\n",
       "   'to',\n",
       "   'justice',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '685'},\n",
       " {'tokens': ['Schnittke',\n",
       "   'wrote',\n",
       "   'the',\n",
       "   'piece',\n",
       "   'to',\n",
       "   'a',\n",
       "   'commission',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Royal',\n",
       "   'Concertgebouw',\n",
       "   'Orchestra',\n",
       "   'for',\n",
       "   'its',\n",
       "   'centenary',\n",
       "   'in',\n",
       "   '1988',\n",
       "   ',',\n",
       "   'when',\n",
       "   'it',\n",
       "   'was',\n",
       "   'premiered',\n",
       "   'under',\n",
       "   'Riccardo',\n",
       "   'Chailly',\n",
       "   ',',\n",
       "   'the',\n",
       "   'same',\n",
       "   'forces',\n",
       "   'recording',\n",
       "   'it',\n",
       "   'soon',\n",
       "   'after',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '686'},\n",
       " {'tokens': ['The',\n",
       "   'complex',\n",
       "   'claimed',\n",
       "   '350,000',\n",
       "   'visitors',\n",
       "   'per',\n",
       "   'year',\n",
       "   'and',\n",
       "   'consisted',\n",
       "   'of',\n",
       "   '26',\n",
       "   'pools',\n",
       "   'plus',\n",
       "   'various',\n",
       "   'slides',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '687'},\n",
       " {'tokens': ['Two',\n",
       "   'years',\n",
       "   'later',\n",
       "   ',',\n",
       "   'Left',\n",
       "   'Hand',\n",
       "   'expanded',\n",
       "   'the',\n",
       "   'bottled',\n",
       "   'Nitro',\n",
       "   'series',\n",
       "   'with',\n",
       "   'Sawtooth',\n",
       "   'Nitro',\n",
       "   'and',\n",
       "   'Wake',\n",
       "   'Up',\n",
       "   'Dead',\n",
       "   'Nitro',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 5, 5, 0, 0, 0, 8, 0, 0, 8, 8, 0, 8, 8, 8, 8, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   62,\n",
       "   62,\n",
       "   0],\n",
       "  'id': '688'},\n",
       " {'tokens': ['The',\n",
       "   'Oregon',\n",
       "   'Canyon',\n",
       "   'Mountains',\n",
       "   'border',\n",
       "   'the',\n",
       "   'Trout',\n",
       "   'Creek',\n",
       "   'Mountains',\n",
       "   'on',\n",
       "   'the',\n",
       "   'east',\n",
       "   'along',\n",
       "   'the',\n",
       "   'Harney–Malheur',\n",
       "   'county',\n",
       "   'line',\n",
       "   '(',\n",
       "   'according',\n",
       "   'to',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'Geological',\n",
       "   'Survey',\n",
       "   \"'s\",\n",
       "   'definitions',\n",
       "   ')',\n",
       "   ',',\n",
       "   'while',\n",
       "   'the',\n",
       "   'Pueblo',\n",
       "   'Mountains',\n",
       "   'are',\n",
       "   'the',\n",
       "   'next',\n",
       "   'range',\n",
       "   'west',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Trout',\n",
       "   'Creek',\n",
       "   'Mountains',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   24,\n",
       "   24,\n",
       "   24,\n",
       "   0,\n",
       "   0,\n",
       "   24,\n",
       "   24,\n",
       "   24,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   24,\n",
       "   24,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   24,\n",
       "   24,\n",
       "   24,\n",
       "   0],\n",
       "  'id': '689'},\n",
       " {'tokens': ['It',\n",
       "   'ran',\n",
       "   'for',\n",
       "   '384',\n",
       "   'performances',\n",
       "   ',',\n",
       "   'transferring',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Hicks',\n",
       "   'Theatre',\n",
       "   'between',\n",
       "   '21',\n",
       "   'December',\n",
       "   '1908',\n",
       "   'and',\n",
       "   '15',\n",
       "   'February',\n",
       "   '1909',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '690'},\n",
       " {'tokens': ['In',\n",
       "   'the',\n",
       "   'Taiyuin',\n",
       "   'Rinnoji',\n",
       "   'temple',\n",
       "   ',',\n",
       "   'Raijin',\n",
       "   'and',\n",
       "   'Fujin',\n",
       "   'are',\n",
       "   'located',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Niten-mon',\n",
       "   'gate',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 2, 2, 0, 0, 6, 0, 6, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 11, 11, 0, 0, 45, 0, 45, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '691'},\n",
       " {'tokens': ['At',\n",
       "   'the',\n",
       "   'onset',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Constitutional',\n",
       "   'Revolution',\n",
       "   'of',\n",
       "   'Iran',\n",
       "   '(',\n",
       "   '1906–1911',\n",
       "   ')',\n",
       "   ',',\n",
       "   'Bahār',\n",
       "   'laid',\n",
       "   'down',\n",
       "   'his',\n",
       "   'position',\n",
       "   'of',\n",
       "   'Poet',\n",
       "   'Laureateship',\n",
       "   'and',\n",
       "   'joined',\n",
       "   'the',\n",
       "   'revolutionary',\n",
       "   'movement',\n",
       "   'for',\n",
       "   'establishing',\n",
       "   'the',\n",
       "   'parliamentary',\n",
       "   'system',\n",
       "   'of',\n",
       "   'democracy',\n",
       "   'in',\n",
       "   'Iran',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '692'},\n",
       " {'tokens': ['Pore',\n",
       "   'scored',\n",
       "   'with',\n",
       "   'the',\n",
       "   'penalty',\n",
       "   'kick',\n",
       "   'in',\n",
       "   'the',\n",
       "   '63rd',\n",
       "   'minute',\n",
       "   'for',\n",
       "   'his',\n",
       "   'league-leading',\n",
       "   'twelfth',\n",
       "   'goal',\n",
       "   'of',\n",
       "   'the',\n",
       "   'season',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '693'},\n",
       " {'tokens': ['The',\n",
       "   '311th',\n",
       "   'Armored',\n",
       "   'Cavalry',\n",
       "   'was',\n",
       "   'constituted',\n",
       "   'on',\n",
       "   '26',\n",
       "   'November',\n",
       "   '1948',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Organized',\n",
       "   'Reserve',\n",
       "   'Corps',\n",
       "   ',',\n",
       "   'and',\n",
       "   'partially',\n",
       "   'organized',\n",
       "   'on',\n",
       "   '17',\n",
       "   'December',\n",
       "   '1948',\n",
       "   'from',\n",
       "   'existing',\n",
       "   'units',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '694'},\n",
       " {'tokens': ['During',\n",
       "   'the',\n",
       "   'riots',\n",
       "   ',',\n",
       "   'at',\n",
       "   'least',\n",
       "   'one',\n",
       "   'Palestinian',\n",
       "   'was',\n",
       "   'killed',\n",
       "   'and',\n",
       "   'a',\n",
       "   'dozen',\n",
       "   'more',\n",
       "   'seriously',\n",
       "   'wounded',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '695'},\n",
       " {'tokens': ['The',\n",
       "   'Indian',\n",
       "   'Express',\n",
       "   'reported',\n",
       "   ',',\n",
       "   '``',\n",
       "   'The',\n",
       "   'ministry',\n",
       "   '(',\n",
       "   'of',\n",
       "   'education',\n",
       "   ')',\n",
       "   'has',\n",
       "   'concluded',\n",
       "   'that',\n",
       "   'there',\n",
       "   'was',\n",
       "   'a',\n",
       "   'socio-cultural',\n",
       "   'disconnect',\n",
       "   'between',\n",
       "   'the',\n",
       "   'questions',\n",
       "   'and',\n",
       "   'Indian',\n",
       "   'students',\n",
       "   '.'],\n",
       "  'coarse_tags': [5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [31,\n",
       "   31,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '696'},\n",
       " {'tokens': ['As',\n",
       "   'with',\n",
       "   'other',\n",
       "   'opioids',\n",
       "   ',',\n",
       "   'chronic',\n",
       "   'use',\n",
       "   'of',\n",
       "   'oxycodone',\n",
       "   '(',\n",
       "   'particularly',\n",
       "   'with',\n",
       "   'higher',\n",
       "   'doses',\n",
       "   ')',\n",
       "   'often',\n",
       "   'causes',\n",
       "   'concurrent',\n",
       "   'hypogonadism',\n",
       "   '(',\n",
       "   'low',\n",
       "   'sex',\n",
       "   'hormone',\n",
       "   'levels',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   49,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   43,\n",
       "   43,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '697'},\n",
       " {'tokens': ['DeFreitas',\n",
       "   'earned',\n",
       "   'a',\n",
       "   'Master',\n",
       "   'of',\n",
       "   'Visual',\n",
       "   'Studies',\n",
       "   'from',\n",
       "   'the',\n",
       "   'University',\n",
       "   'of',\n",
       "   'Toronto',\n",
       "   '(',\n",
       "   '2008',\n",
       "   ')',\n",
       "   ';',\n",
       "   'a',\n",
       "   'Bachelor',\n",
       "   'of',\n",
       "   'Education',\n",
       "   'from',\n",
       "   'York',\n",
       "   'University',\n",
       "   '(',\n",
       "   '2004',\n",
       "   ')',\n",
       "   'and',\n",
       "   'a',\n",
       "   'Bachelor',\n",
       "   'of',\n",
       "   'Art',\n",
       "   'and',\n",
       "   'Art',\n",
       "   'History',\n",
       "   'from',\n",
       "   'the',\n",
       "   'University',\n",
       "   'of',\n",
       "   'Toronto',\n",
       "   '(',\n",
       "   '2003',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [56,\n",
       "   0,\n",
       "   0,\n",
       "   44,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   44,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   44,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '698'},\n",
       " {'tokens': ['Pop',\n",
       "   'Works',\n",
       "   'and',\n",
       "   'other',\n",
       "   'recordings',\n",
       "   ':',\n",
       "   'Exploding',\n",
       "   'Galaxy',\n",
       "   '–',\n",
       "   '1968',\n",
       "   'pop',\n",
       "   'recording',\n",
       "   'did',\n",
       "   'well',\n",
       "   'on',\n",
       "   'the',\n",
       "   'British',\n",
       "   'pop',\n",
       "   'charts',\n",
       "   ',',\n",
       "   'used',\n",
       "   'the',\n",
       "   'pen',\n",
       "   'name',\n",
       "   'Paul',\n",
       "   'James',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0],\n",
       "  'id': '699'},\n",
       " {'tokens': ['Rumours',\n",
       "   'at',\n",
       "   'that',\n",
       "   'time',\n",
       "   'said',\n",
       "   'that',\n",
       "   'Ferdinand',\n",
       "   'Piech',\n",
       "   'himself',\n",
       "   'made',\n",
       "   'them',\n",
       "   'stay',\n",
       "   'away',\n",
       "   ',',\n",
       "   'using',\n",
       "   'his',\n",
       "   'influence',\n",
       "   'as',\n",
       "   'a',\n",
       "   'co-owner',\n",
       "   'of',\n",
       "   'Porsche',\n",
       "   'as',\n",
       "   'well',\n",
       "   'as',\n",
       "   'his',\n",
       "   'management',\n",
       "   'role',\n",
       "   'at',\n",
       "   'Volkswagen',\n",
       "   ',',\n",
       "   'which',\n",
       "   'would',\n",
       "   'develop',\n",
       "   'the',\n",
       "   'upcoming',\n",
       "   'SUV',\n",
       "   'VW',\n",
       "   'Touareg',\n",
       "   'in',\n",
       "   'cooperation',\n",
       "   'with',\n",
       "   'the',\n",
       "   'Porsche',\n",
       "   'Cayenne',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   0],\n",
       "  'id': '700'},\n",
       " {'tokens': ['However',\n",
       "   ',',\n",
       "   'for',\n",
       "   'some',\n",
       "   '300',\n",
       "   'years',\n",
       "   'until',\n",
       "   'the',\n",
       "   '19th',\n",
       "   'century',\n",
       "   ',',\n",
       "   'under',\n",
       "   'the',\n",
       "   'dual',\n",
       "   'kingdom',\n",
       "   'of',\n",
       "   'Denmark–Norway',\n",
       "   ',',\n",
       "   'Danish',\n",
       "   'was',\n",
       "   'the',\n",
       "   'language',\n",
       "   'of',\n",
       "   'religion',\n",
       "   ',',\n",
       "   'education',\n",
       "   ',',\n",
       "   'and',\n",
       "   'administration',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Faroe',\n",
       "   'Islands',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   23,\n",
       "   23,\n",
       "   0],\n",
       "  'id': '701'},\n",
       " {'tokens': ['The',\n",
       "   'characters',\n",
       "   'were',\n",
       "   'inspired',\n",
       "   'by',\n",
       "   'the',\n",
       "   'people',\n",
       "   'Saint-Exupéry',\n",
       "   'knew',\n",
       "   'while',\n",
       "   'working',\n",
       "   'in',\n",
       "   'South',\n",
       "   'America',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 54, 0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '702'},\n",
       " {'tokens': ['NIHL',\n",
       "   'can',\n",
       "   'affect',\n",
       "   'either',\n",
       "   'one',\n",
       "   'or',\n",
       "   'both',\n",
       "   'ears',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [43, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '703'},\n",
       " {'tokens': ['First',\n",
       "   ',',\n",
       "   'he',\n",
       "   'will',\n",
       "   'use',\n",
       "   'Banten',\n",
       "   \"'s\",\n",
       "   'forbidden',\n",
       "   'art',\n",
       "   'to',\n",
       "   'return',\n",
       "   'the',\n",
       "   'memories',\n",
       "   'everyone',\n",
       "   'in',\n",
       "   'Nabari',\n",
       "   'lost',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 54, 54, 0, 0, 0, 0, 0, 0, 0, 0, 25, 0, 0],\n",
       "  'id': '704'},\n",
       " {'tokens': ['The',\n",
       "   'Marriage',\n",
       "   'Charter',\n",
       "   'of',\n",
       "   'Empress',\n",
       "   'Theophanu',\n",
       "   '(',\n",
       "   'State',\n",
       "   'Archives',\n",
       "   'of',\n",
       "   'Wolfenbüttel',\n",
       "   ',',\n",
       "   '6',\n",
       "   'Urk',\n",
       "   '11',\n",
       "   ')',\n",
       "   'is',\n",
       "   'the',\n",
       "   'dower',\n",
       "   'document',\n",
       "   'for',\n",
       "   'the',\n",
       "   'Byzantine',\n",
       "   'princess',\n",
       "   'Theophanu',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   55,\n",
       "   0],\n",
       "  'id': '705'},\n",
       " {'tokens': ['This',\n",
       "   'vision',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Romanov',\n",
       "   'monarchy',\n",
       "   'left',\n",
       "   'him',\n",
       "   'unaware',\n",
       "   'of',\n",
       "   'the',\n",
       "   'state',\n",
       "   'of',\n",
       "   'his',\n",
       "   'country',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '706'},\n",
       " {'tokens': ['The',\n",
       "   'success',\n",
       "   'of',\n",
       "   '``',\n",
       "   'Dizzy',\n",
       "   'Prince',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Yolkfolk',\n",
       "   '``',\n",
       "   'prompted',\n",
       "   'Big',\n",
       "   'Red',\n",
       "   'Software',\n",
       "   'to',\n",
       "   'take',\n",
       "   'the',\n",
       "   'series',\n",
       "   'in',\n",
       "   'a',\n",
       "   'new',\n",
       "   'direction',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   61,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '707'},\n",
       " {'tokens': ['Maxim',\n",
       "   'made',\n",
       "   'use',\n",
       "   'of',\n",
       "   'a',\n",
       "   'number',\n",
       "   'of',\n",
       "   'suggestions',\n",
       "   'made',\n",
       "   'by',\n",
       "   'Austin',\n",
       "   'in',\n",
       "   'Maxim',\n",
       "   \"'s\",\n",
       "   'activities',\n",
       "   'at',\n",
       "   'his',\n",
       "   'works',\n",
       "   'in',\n",
       "   'Crayford',\n",
       "   ',',\n",
       "   'Kent',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '708'},\n",
       " {'tokens': ['Further',\n",
       "   'ingredient-related',\n",
       "   'lawsuits',\n",
       "   'have',\n",
       "   'been',\n",
       "   'brought',\n",
       "   'against',\n",
       "   'McDonald',\n",
       "   \"'s\",\n",
       "   'since',\n",
       "   '2006',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 28, 0, 0, 0, 0],\n",
       "  'id': '709'},\n",
       " {'tokens': ['The',\n",
       "   'Kingdom',\n",
       "   'of',\n",
       "   'Italy',\n",
       "   'invaded',\n",
       "   'the',\n",
       "   'Albanian',\n",
       "   'Kingdom',\n",
       "   'on',\n",
       "   '7',\n",
       "   'April',\n",
       "   '1939',\n",
       "   ',',\n",
       "   'and',\n",
       "   'deposed',\n",
       "   'its',\n",
       "   'monarch',\n",
       "   ',',\n",
       "   'King',\n",
       "   'Zog',\n",
       "   'I',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0],\n",
       "  'id': '710'},\n",
       " {'tokens': ['Lacking',\n",
       "   'a',\n",
       "   'vocalist',\n",
       "   'enables',\n",
       "   'the',\n",
       "   'band',\n",
       "   'to',\n",
       "   'avoid',\n",
       "   'the',\n",
       "   'verse-chorus-verse',\n",
       "   'songwriting',\n",
       "   'strategy',\n",
       "   'that',\n",
       "   'most',\n",
       "   'bands',\n",
       "   'with',\n",
       "   'singers',\n",
       "   'need',\n",
       "   'to',\n",
       "   'use',\n",
       "   'to',\n",
       "   'accommodate',\n",
       "   'the',\n",
       "   'lyrics',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '711'},\n",
       " {'tokens': ['In',\n",
       "   '1882',\n",
       "   ',',\n",
       "   'he',\n",
       "   'donated',\n",
       "   'of',\n",
       "   'land',\n",
       "   'east',\n",
       "   'of',\n",
       "   'the',\n",
       "   'city',\n",
       "   'for',\n",
       "   'the',\n",
       "   'purpose',\n",
       "   'of',\n",
       "   'creating',\n",
       "   'Wade',\n",
       "   'Park',\n",
       "   ',',\n",
       "   'which',\n",
       "   'was',\n",
       "   'named',\n",
       "   'in',\n",
       "   'his',\n",
       "   'honor',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   26,\n",
       "   26,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '712'},\n",
       " {'tokens': ['About',\n",
       "   '95',\n",
       "   'peaceful',\n",
       "   'demonstrators',\n",
       "   'were',\n",
       "   'arrested',\n",
       "   'inside',\n",
       "   'and',\n",
       "   'outside',\n",
       "   'of',\n",
       "   'Morrison',\n",
       "   \"'s\",\n",
       "   'that',\n",
       "   'week',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 12, 0, 0, 0],\n",
       "  'id': '713'},\n",
       " {'tokens': ['Panpipe',\n",
       "   'orchestras',\n",
       "   ',',\n",
       "   'which',\n",
       "   'are',\n",
       "   'well-known',\n",
       "   'on',\n",
       "   'Malaita',\n",
       "   'and',\n",
       "   'Guadalcanal',\n",
       "   'use',\n",
       "   'up',\n",
       "   'to',\n",
       "   'ten',\n",
       "   'performers',\n",
       "   'with',\n",
       "   'different',\n",
       "   'instrument',\n",
       "   ',',\n",
       "   'each',\n",
       "   'with',\n",
       "   'unique',\n",
       "   'tunings',\n",
       "   '.'],\n",
       "  'coarse_tags': [5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '714'},\n",
       " {'tokens': ['The',\n",
       "   'area',\n",
       "   ',',\n",
       "   'having',\n",
       "   'a',\n",
       "   'brief',\n",
       "   'hydroperiod',\n",
       "   ',',\n",
       "   'is',\n",
       "   'seasonally',\n",
       "   'submerged',\n",
       "   ',',\n",
       "   'with',\n",
       "   '``',\n",
       "   'Cladium',\n",
       "   'jamaicense',\n",
       "   '``',\n",
       "   '(',\n",
       "   'sawgrass',\n",
       "   ')',\n",
       "   'being',\n",
       "   'the',\n",
       "   'dominant',\n",
       "   'vegetation',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '715'},\n",
       " {'tokens': ['Wong',\n",
       "   'won',\n",
       "   'the',\n",
       "   'election',\n",
       "   'by',\n",
       "   '398',\n",
       "   'votes',\n",
       "   ',',\n",
       "   'wresting',\n",
       "   'the',\n",
       "   'seat',\n",
       "   'from',\n",
       "   'the',\n",
       "   'Barisan',\n",
       "   'Nasional',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0],\n",
       "  'fine_tags': [55, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 33, 33, 0],\n",
       "  'id': '716'},\n",
       " {'tokens': ['According',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Sinologist',\n",
       "   'and',\n",
       "   'historian',\n",
       "   'Joseph',\n",
       "   'Needham',\n",
       "   ',',\n",
       "   'some',\n",
       "   'early',\n",
       "   'Daoists',\n",
       "   'adapted',\n",
       "   'censers',\n",
       "   'for',\n",
       "   'the',\n",
       "   'religious',\n",
       "   'and',\n",
       "   'spiritual',\n",
       "   'use',\n",
       "   'of',\n",
       "   'cannabis',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   56,\n",
       "   56,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '717'},\n",
       " {'tokens': ['Texas',\n",
       "   'German',\n",
       "   'is',\n",
       "   'a',\n",
       "   'dialect',\n",
       "   'of',\n",
       "   'the',\n",
       "   'German',\n",
       "   'language',\n",
       "   'that',\n",
       "   'is',\n",
       "   'spoken',\n",
       "   'by',\n",
       "   'descendants',\n",
       "   'of',\n",
       "   'German',\n",
       "   'immigrants',\n",
       "   'who',\n",
       "   'settled',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Texas',\n",
       "   'Hill',\n",
       "   'Country',\n",
       "   'region',\n",
       "   'in',\n",
       "   'the',\n",
       "   'mid-19th',\n",
       "   'century',\n",
       "   '.'],\n",
       "  'coarse_tags': [6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [46,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '718'},\n",
       " {'tokens': ['A',\n",
       "   'novel',\n",
       "   'design',\n",
       "   'feature',\n",
       "   'was',\n",
       "   'his',\n",
       "   'use',\n",
       "   'of',\n",
       "   'a',\n",
       "   'Dodge',\n",
       "   'Flexidyne',\n",
       "   'Coupling',\n",
       "   'in',\n",
       "   'the',\n",
       "   'drive',\n",
       "   'train',\n",
       "   'to',\n",
       "   'dampen',\n",
       "   'torsional',\n",
       "   'vibrations',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '719'},\n",
       " {'tokens': ['In',\n",
       "   '1851',\n",
       "   'the',\n",
       "   'library',\n",
       "   'of',\n",
       "   'Owens',\n",
       "   'College',\n",
       "   'was',\n",
       "   'established',\n",
       "   'at',\n",
       "   'Cobden',\n",
       "   'House',\n",
       "   'on',\n",
       "   'Quay',\n",
       "   'Street',\n",
       "   ',',\n",
       "   'Manchester',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 4, 4, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 10, 10, 10, 10, 0, 0, 0, 11, 11, 0, 27, 27, 0, 21, 0],\n",
       "  'id': '720'},\n",
       " {'tokens': ['The',\n",
       "   '$',\n",
       "   '168.5',\n",
       "   'million',\n",
       "   'project',\n",
       "   'attracted',\n",
       "   'many',\n",
       "   'new',\n",
       "   'passengers',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 6, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 42, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '721'},\n",
       " {'tokens': ['along', 'with', '``', 'Delivery', '!'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0],\n",
       "  'id': '722'},\n",
       " {'tokens': ['On',\n",
       "   'April',\n",
       "   '9',\n",
       "   ',',\n",
       "   '2016',\n",
       "   'Mysterio',\n",
       "   'was',\n",
       "   'in',\n",
       "   'an',\n",
       "   'Aztec',\n",
       "   'Warfare',\n",
       "   'match',\n",
       "   'where',\n",
       "   'he',\n",
       "   'eliminated',\n",
       "   'Matanza',\n",
       "   'Cueto',\n",
       "   'after',\n",
       "   'Mysterio',\n",
       "   'was',\n",
       "   'eliminated',\n",
       "   'by',\n",
       "   'Johnny',\n",
       "   'Mundo',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0],\n",
       "  'id': '723'},\n",
       " {'tokens': ['Pemphigus',\n",
       "   '(',\n",
       "   'or',\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'rare',\n",
       "   'group',\n",
       "   'of',\n",
       "   'blistering',\n",
       "   'autoimmune',\n",
       "   'diseases',\n",
       "   'that',\n",
       "   'affect',\n",
       "   'the',\n",
       "   'skin',\n",
       "   'and',\n",
       "   'mucous',\n",
       "   'membranes',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 0, 0, 0, 0, 0, 0, 6, 6, 0],\n",
       "  'fine_tags': [43,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   43,\n",
       "   43,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   40,\n",
       "   0],\n",
       "  'id': '724'},\n",
       " {'tokens': ['The',\n",
       "   'State',\n",
       "   'Library',\n",
       "   'of',\n",
       "   'Victoria',\n",
       "   'Barrett',\n",
       "   'Reid',\n",
       "   'Scholarship',\n",
       "   'is',\n",
       "   'awarded',\n",
       "   'to',\n",
       "   'Victorian',\n",
       "   'public',\n",
       "   'library',\n",
       "   'employees',\n",
       "   'to',\n",
       "   'assist',\n",
       "   'with',\n",
       "   'professional',\n",
       "   'development',\n",
       "   'activities',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '725'},\n",
       " {'tokens': ['The',\n",
       "   'basalt',\n",
       "   'image',\n",
       "   'originally',\n",
       "   'was',\n",
       "   'stationed',\n",
       "   'at',\n",
       "   'Medinet-Habu',\n",
       "   'as',\n",
       "   'part',\n",
       "   'of',\n",
       "   'the',\n",
       "   'cultic',\n",
       "   'celebration',\n",
       "   'of',\n",
       "   'the',\n",
       "   'pharaonic',\n",
       "   '``',\n",
       "   'Sed-Festival',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   'but',\n",
       "   'was',\n",
       "   'transferred',\n",
       "   'at',\n",
       "   'some',\n",
       "   'point',\n",
       "   'to',\n",
       "   'Herakleopolis',\n",
       "   'and',\n",
       "   'the',\n",
       "   'temple',\n",
       "   'of',\n",
       "   'Herishef',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '726'},\n",
       " {'tokens': ['In',\n",
       "   'prison',\n",
       "   ',',\n",
       "   'she',\n",
       "   'suffers',\n",
       "   'unnecessary',\n",
       "   'torture',\n",
       "   'at',\n",
       "   'hands',\n",
       "   'of',\n",
       "   'police',\n",
       "   'and',\n",
       "   'finally',\n",
       "   'she',\n",
       "   'joins',\n",
       "   'rahman',\n",
       "   \"'s\",\n",
       "   'gang',\n",
       "   'and',\n",
       "   'uncovers',\n",
       "   'the',\n",
       "   'truth',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '727'},\n",
       " {'tokens': ['On',\n",
       "   '21',\n",
       "   'October',\n",
       "   ',',\n",
       "   'Barcelona',\n",
       "   'hosted',\n",
       "   'Ajax',\n",
       "   'and',\n",
       "   'got',\n",
       "   'first-half',\n",
       "   'goals',\n",
       "   'through',\n",
       "   'Neymar',\n",
       "   'and',\n",
       "   'Lionel',\n",
       "   'Messi',\n",
       "   ';',\n",
       "   'Anwar',\n",
       "   'El',\n",
       "   'Ghazi',\n",
       "   'scored',\n",
       "   'for',\n",
       "   'the',\n",
       "   'visitors',\n",
       "   'with',\n",
       "   'two',\n",
       "   'minutes',\n",
       "   'to',\n",
       "   'play',\n",
       "   'but',\n",
       "   'Sandro',\n",
       "   \"'s\",\n",
       "   'added-time',\n",
       "   'strike',\n",
       "   'confirmed',\n",
       "   'a',\n",
       "   '3–1',\n",
       "   'win',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '728'},\n",
       " {'tokens': ['Potter',\n",
       "   'is',\n",
       "   'also',\n",
       "   'a',\n",
       "   'practicing',\n",
       "   'lawyer',\n",
       "   'and',\n",
       "   'Chairman',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Political',\n",
       "   'Practice',\n",
       "   'Group',\n",
       "   'of',\n",
       "   'the',\n",
       "   'international',\n",
       "   'law',\n",
       "   'firm',\n",
       "   'Caplin',\n",
       "   'Drysdale',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0],\n",
       "  'id': '729'},\n",
       " {'tokens': ['In',\n",
       "   '1950',\n",
       "   'she',\n",
       "   'appeared',\n",
       "   'as',\n",
       "   'Hortense',\n",
       "   'Schneider',\n",
       "   'with',\n",
       "   'Fresnay',\n",
       "   'as',\n",
       "   'Jacques',\n",
       "   'Offenbach',\n",
       "   ',',\n",
       "   'in',\n",
       "   'Achard',\n",
       "   \"'s\",\n",
       "   'film',\n",
       "   '``',\n",
       "   'La',\n",
       "   'Valse',\n",
       "   'de',\n",
       "   'Paris',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   50,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '730'},\n",
       " {'tokens': ['These',\n",
       "   'clicks',\n",
       "   'are',\n",
       "   'more',\n",
       "   'similar',\n",
       "   'to',\n",
       "   'those',\n",
       "   'produced',\n",
       "   'by',\n",
       "   'some',\n",
       "   'dolphin',\n",
       "   'and',\n",
       "   'porpoise',\n",
       "   'species–such',\n",
       "   'as',\n",
       "   'the',\n",
       "   'hourglass',\n",
       "   'dolphin',\n",
       "   '(',\n",
       "   '``',\n",
       "   'Lagenorhynchus',\n",
       "   'cruciger',\n",
       "   '``',\n",
       "   ')',\n",
       "   ',',\n",
       "   'Hector',\n",
       "   \"'s\",\n",
       "   'dolphin',\n",
       "   '(',\n",
       "   '``',\n",
       "   'Cephalorhynchus',\n",
       "   'hectori',\n",
       "   '``',\n",
       "   ')',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Chilean',\n",
       "   'dolphin',\n",
       "   '(',\n",
       "   '``',\n",
       "   'Cephalorhynchus',\n",
       "   'eutropia',\n",
       "   '``',\n",
       "   ')',\n",
       "   ',',\n",
       "   'Commerson',\n",
       "   \"'s\",\n",
       "   'dolphin',\n",
       "   '(',\n",
       "   '``',\n",
       "   'Cephalorhynchus',\n",
       "   'commersonii',\n",
       "   '``',\n",
       "   ')',\n",
       "   ',',\n",
       "   'the',\n",
       "   'harbour',\n",
       "   'porpoise',\n",
       "   '(',\n",
       "   '``',\n",
       "   'Phocoena',\n",
       "   'phocoena',\n",
       "   '``',\n",
       "   ')',\n",
       "   ',',\n",
       "   'and',\n",
       "   'Dall',\n",
       "   \"'s\",\n",
       "   'porpoise',\n",
       "   '(',\n",
       "   '``',\n",
       "   'Phocoenoides',\n",
       "   'dalli',\n",
       "   '``',\n",
       "   ')',\n",
       "   '–than',\n",
       "   'to',\n",
       "   'those',\n",
       "   'of',\n",
       "   'other',\n",
       "   'deep-diving',\n",
       "   'whales',\n",
       "   ',',\n",
       "   'such',\n",
       "   'as',\n",
       "   'beaked',\n",
       "   'whales',\n",
       "   'and',\n",
       "   'the',\n",
       "   'sperm',\n",
       "   'whale',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0],\n",
       "  'id': '731'},\n",
       " {'tokens': ['The',\n",
       "   'eastern',\n",
       "   'Samoan',\n",
       "   'islands',\n",
       "   'became',\n",
       "   'territories',\n",
       "   'of',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'and',\n",
       "   'later',\n",
       "   'became',\n",
       "   'known',\n",
       "   'as',\n",
       "   'American',\n",
       "   'Samoa',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 4, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 4, 4, 0],\n",
       "  'fine_tags': [0, 0, 23, 0, 0, 0, 0, 0, 21, 21, 0, 0, 0, 0, 0, 21, 23, 0],\n",
       "  'id': '732'},\n",
       " {'tokens': ['He',\n",
       "   'subsequently',\n",
       "   'played',\n",
       "   'for',\n",
       "   'Sportivo',\n",
       "   'Belgrano',\n",
       "   'and',\n",
       "   'Sarmiento',\n",
       "   'de',\n",
       "   'Leones',\n",
       "   ',',\n",
       "   'retiring',\n",
       "   'with',\n",
       "   'the',\n",
       "   'latter',\n",
       "   'in',\n",
       "   '2013',\n",
       "   'at',\n",
       "   'the',\n",
       "   'age',\n",
       "   'of',\n",
       "   '38',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '733'},\n",
       " {'tokens': ['Fields',\n",
       "   'and',\n",
       "   'Williams',\n",
       "   'toured',\n",
       "   'with',\n",
       "   'Pink',\n",
       "   'Floyd',\n",
       "   'on',\n",
       "   'their',\n",
       "   '1974',\n",
       "   'French',\n",
       "   'Summer',\n",
       "   'Tour',\n",
       "   'and',\n",
       "   'British',\n",
       "   'Winter',\n",
       "   'Tour',\n",
       "   'later',\n",
       "   'that',\n",
       "   'year',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [51,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '734'},\n",
       " {'tokens': ['On',\n",
       "   'the',\n",
       "   'invasion',\n",
       "   'of',\n",
       "   'Joachim',\n",
       "   'Murat',\n",
       "   'during',\n",
       "   'The',\n",
       "   'Hundred',\n",
       "   'Days',\n",
       "   ',',\n",
       "   'they',\n",
       "   'fled',\n",
       "   'Modena',\n",
       "   'until',\n",
       "   '15',\n",
       "   'May',\n",
       "   '1815',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 7, 7, 0, 3, 3, 3, 0, 0, 0, 4, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 57, 57, 0, 15, 15, 15, 0, 0, 0, 21, 0, 0, 0, 0, 0],\n",
       "  'id': '735'},\n",
       " {'tokens': ['In',\n",
       "   '2007',\n",
       "   ',',\n",
       "   'a',\n",
       "   're-formed',\n",
       "   'Rhodes',\n",
       "   'Music',\n",
       "   'Corporation',\n",
       "   'introduced',\n",
       "   'a',\n",
       "   'reproduction',\n",
       "   'of',\n",
       "   'the',\n",
       "   'original',\n",
       "   'electric',\n",
       "   'piano',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Rhodes',\n",
       "   'Mark',\n",
       "   '7',\n",
       "   ',',\n",
       "   'housed',\n",
       "   'in',\n",
       "   'a',\n",
       "   'molded',\n",
       "   'plastic',\n",
       "   'enclosure',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '736'},\n",
       " {'tokens': ['It',\n",
       "   'was',\n",
       "   'released',\n",
       "   'in',\n",
       "   'Italy',\n",
       "   'under',\n",
       "   'the',\n",
       "   'title',\n",
       "   '``',\n",
       "   'Horror',\n",
       "   '``',\n",
       "   'as',\n",
       "   'chosen',\n",
       "   'by',\n",
       "   'producer',\n",
       "   'Italo',\n",
       "   'Zingarelli',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 4, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 7, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 21, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 54, 54, 0],\n",
       "  'id': '737'},\n",
       " {'tokens': ['in', '2013', 'and', '2014', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0],\n",
       "  'id': '738'},\n",
       " {'tokens': ['Another',\n",
       "   'vehicle',\n",
       "   'built',\n",
       "   'for',\n",
       "   'the',\n",
       "   'film',\n",
       "   'was',\n",
       "   'the',\n",
       "   'blue',\n",
       "   'Nissan',\n",
       "   'Skyline',\n",
       "   'GT-R',\n",
       "   'R34',\n",
       "   'owned',\n",
       "   'by',\n",
       "   'an',\n",
       "   'uncredited',\n",
       "   'owner',\n",
       "   'which',\n",
       "   'brought',\n",
       "   'a',\n",
       "   '241-mile',\n",
       "   'per',\n",
       "   'hour',\n",
       "   'top',\n",
       "   'speed',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Bayshore',\n",
       "   'Route',\n",
       "   'Highway',\n",
       "   'in',\n",
       "   'Japan',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '739'},\n",
       " {'tokens': ['Almost',\n",
       "   'all',\n",
       "   'of',\n",
       "   'the',\n",
       "   'indigenous',\n",
       "   'population',\n",
       "   'in',\n",
       "   'the',\n",
       "   'province',\n",
       "   'are',\n",
       "   'the',\n",
       "   'Mapuches',\n",
       "   'with',\n",
       "   'the',\n",
       "   'rest',\n",
       "   'being',\n",
       "   'small',\n",
       "   'in',\n",
       "   'number',\n",
       "   'where',\n",
       "   'their',\n",
       "   'few',\n",
       "   'descendants',\n",
       "   'live',\n",
       "   'in',\n",
       "   'the',\n",
       "   'neighbouring',\n",
       "   'provinces',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '740'},\n",
       " {'tokens': ['Phocas',\n",
       "   'is',\n",
       "   'developed',\n",
       "   'using',\n",
       "   'a',\n",
       "   '.NET',\n",
       "   'business',\n",
       "   'layer',\n",
       "   'with',\n",
       "   'HTML5+JavaScript',\n",
       "   'presentation',\n",
       "   'layer',\n",
       "   'accessible',\n",
       "   'via',\n",
       "   'standard',\n",
       "   'web',\n",
       "   'browsers',\n",
       "   '.'],\n",
       "  'coarse_tags': [8, 0, 0, 0, 0, 8, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [64, 0, 0, 0, 0, 64, 0, 0, 0, 64, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '741'},\n",
       " {'tokens': ['Visitors',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bay',\n",
       "   'should',\n",
       "   'know',\n",
       "   'that',\n",
       "   'the',\n",
       "   'only',\n",
       "   'places',\n",
       "   'to',\n",
       "   'stay',\n",
       "   'aside',\n",
       "   'from',\n",
       "   'tents',\n",
       "   'are',\n",
       "   'several',\n",
       "   'small',\n",
       "   'cabins',\n",
       "   'and',\n",
       "   'an',\n",
       "   'eating',\n",
       "   'area',\n",
       "   ',',\n",
       "   'called',\n",
       "   'the',\n",
       "   'Hallo',\n",
       "   'Bay',\n",
       "   'Camp',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0],\n",
       "  'id': '742'},\n",
       " {'tokens': ['Reportedly',\n",
       "   ',',\n",
       "   'the',\n",
       "   'designation',\n",
       "   'AGM-28C',\n",
       "   'was',\n",
       "   'reserved',\n",
       "   'for',\n",
       "   'this',\n",
       "   'version',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Hound',\n",
       "   'Dog',\n",
       "   'if',\n",
       "   'development',\n",
       "   'had',\n",
       "   'been',\n",
       "   'continued',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 66, 0, 0, 0, 0, 0, 0, 0, 66, 66, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '743'},\n",
       " {'tokens': ['Tyler',\n",
       "   'Pounds',\n",
       "   'Regional',\n",
       "   'Airport',\n",
       "   'offers',\n",
       "   'service',\n",
       "   'to',\n",
       "   'Dallas-Fort',\n",
       "   'Worth',\n",
       "   'International',\n",
       "   'Airport',\n",
       "   'via',\n",
       "   'American',\n",
       "   'Eagle',\n",
       "   'and',\n",
       "   'to',\n",
       "   'Houston',\n",
       "   \"'s\",\n",
       "   'George',\n",
       "   'Bush',\n",
       "   'Intercontinental',\n",
       "   'Airport',\n",
       "   'via',\n",
       "   'United',\n",
       "   'Express',\n",
       "   '.'],\n",
       "  'coarse_tags': [2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0],\n",
       "  'id': '744'},\n",
       " {'tokens': ['Rosemont',\n",
       "   'Copper',\n",
       "   'has',\n",
       "   'secured',\n",
       "   'the',\n",
       "   'following',\n",
       "   'major',\n",
       "   'permits',\n",
       "   'necessary',\n",
       "   'to',\n",
       "   'begin',\n",
       "   'construction',\n",
       "   'on',\n",
       "   'the',\n",
       "   'proposed',\n",
       "   'mine',\n",
       "   ':'],\n",
       "  'coarse_tags': [5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [28, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '745'},\n",
       " {'tokens': ['She',\n",
       "   'also',\n",
       "   'called',\n",
       "   'play-by-play',\n",
       "   'Stanford',\n",
       "   'baseball',\n",
       "   'for',\n",
       "   'the',\n",
       "   'campus',\n",
       "   'radio',\n",
       "   'station',\n",
       "   ',',\n",
       "   'including',\n",
       "   'the',\n",
       "   'College',\n",
       "   'World',\n",
       "   'Series',\n",
       "   ',',\n",
       "   'and',\n",
       "   'served',\n",
       "   'as',\n",
       "   'a',\n",
       "   'color',\n",
       "   'commentator',\n",
       "   'for',\n",
       "   'football',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '746'},\n",
       " {'tokens': ['This',\n",
       "   'newer',\n",
       "   'generation',\n",
       "   'camera',\n",
       "   'was',\n",
       "   'later',\n",
       "   'built',\n",
       "   'into',\n",
       "   'the',\n",
       "   '2020',\n",
       "   '27-inch',\n",
       "   'iMac',\n",
       "   'model',\n",
       "   'in',\n",
       "   'August',\n",
       "   '2020',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 62, 0, 0, 0, 0, 0],\n",
       "  'id': '747'},\n",
       " {'tokens': ['In',\n",
       "   'fact',\n",
       "   ',',\n",
       "   'when',\n",
       "   'applying',\n",
       "   'the',\n",
       "   'UNESCO',\n",
       "   'Framework',\n",
       "   'to',\n",
       "   'measure',\n",
       "   'language',\n",
       "   'vitality',\n",
       "   ',',\n",
       "   'this',\n",
       "   'dialect',\n",
       "   'fits',\n",
       "   'the',\n",
       "   'category',\n",
       "   'of',\n",
       "   '``',\n",
       "   'Severely',\n",
       "   'Endangered',\n",
       "   \"''\",\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '748'},\n",
       " {'tokens': ['Hibs',\n",
       "   'only',\n",
       "   'played',\n",
       "   'one',\n",
       "   'friendly',\n",
       "   'match',\n",
       "   'in',\n",
       "   'the',\n",
       "   '2006',\n",
       "   'pre-season',\n",
       "   ',',\n",
       "   'a',\n",
       "   '3–2',\n",
       "   'win',\n",
       "   'at',\n",
       "   'Easter',\n",
       "   'Road',\n",
       "   'against',\n",
       "   'Premier',\n",
       "   'League',\n",
       "   'side',\n",
       "   'Charlton',\n",
       "   'Athletic',\n",
       "   '.'],\n",
       "  'coarse_tags': [5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   36,\n",
       "   36,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0],\n",
       "  'id': '749'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'consecrated',\n",
       "   'as',\n",
       "   'a',\n",
       "   'bishop',\n",
       "   'by',\n",
       "   'Bishop',\n",
       "   'Lancelot',\n",
       "   'Goody',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 54, 54, 0],\n",
       "  'id': '750'},\n",
       " {'tokens': ['Tyler',\n",
       "   'studied',\n",
       "   'physics',\n",
       "   'at',\n",
       "   'the',\n",
       "   'University',\n",
       "   'of',\n",
       "   'Texas',\n",
       "   'in',\n",
       "   '1969–70',\n",
       "   'and',\n",
       "   'transferred',\n",
       "   'to',\n",
       "   'journalism',\n",
       "   'at',\n",
       "   'the',\n",
       "   'University',\n",
       "   'of',\n",
       "   'South',\n",
       "   'Carolina',\n",
       "   ',',\n",
       "   'graduating',\n",
       "   'in',\n",
       "   '1974',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '751'},\n",
       " {'tokens': ['Geneforge',\n",
       "   '3',\n",
       "   'is',\n",
       "   'the',\n",
       "   'third',\n",
       "   'video',\n",
       "   'game',\n",
       "   'in',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Geneforge',\n",
       "   '``',\n",
       "   'series',\n",
       "   'of',\n",
       "   'role-playing',\n",
       "   'video',\n",
       "   'games',\n",
       "   'created',\n",
       "   'by',\n",
       "   'Spiderweb',\n",
       "   'Software',\n",
       "   '.'],\n",
       "  'coarse_tags': [8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0],\n",
       "  'id': '752'},\n",
       " {'tokens': ['Francesco',\n",
       "   'Morosini',\n",
       "   'or',\n",
       "   'simply',\n",
       "   'Morosini',\n",
       "   'has',\n",
       "   'been',\n",
       "   'the',\n",
       "   'name',\n",
       "   'of',\n",
       "   'at',\n",
       "   'least',\n",
       "   'five',\n",
       "   'ships',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Italian',\n",
       "   'Navy',\n",
       "   ',',\n",
       "   'named',\n",
       "   'in',\n",
       "   'honour',\n",
       "   'of',\n",
       "   'Francesco',\n",
       "   'Morosini',\n",
       "   ':'],\n",
       "  'coarse_tags': [8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [63,\n",
       "   63,\n",
       "   0,\n",
       "   0,\n",
       "   63,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0],\n",
       "  'id': '753'},\n",
       " {'tokens': ['It',\n",
       "   'is',\n",
       "   'located',\n",
       "   '3',\n",
       "   'km',\n",
       "   'away',\n",
       "   'from',\n",
       "   'its',\n",
       "   'taluka',\n",
       "   '(',\n",
       "   'Padwa',\n",
       "   'block',\n",
       "   ')',\n",
       "   'headquarter',\n",
       "   'and',\n",
       "   '18',\n",
       "   'km',\n",
       "   'from',\n",
       "   'its',\n",
       "   'district',\n",
       "   'headquarter',\n",
       "   'Medininagar',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '754'},\n",
       " {'tokens': ['Despite',\n",
       "   'the',\n",
       "   'pain',\n",
       "   'and',\n",
       "   'swelling',\n",
       "   ',',\n",
       "   'Villa',\n",
       "   'insisted',\n",
       "   'on',\n",
       "   'going',\n",
       "   'ahead',\n",
       "   'with',\n",
       "   'the',\n",
       "   'fight',\n",
       "   'with',\n",
       "   'McLarnin',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 52, 0, 0, 0, 0, 0, 0, 0, 0, 52, 0],\n",
       "  'id': '755'},\n",
       " {'tokens': ['In',\n",
       "   '1634',\n",
       "   ',',\n",
       "   'the',\n",
       "   'battle',\n",
       "   'of',\n",
       "   'Nördlingen',\n",
       "   'took',\n",
       "   'place',\n",
       "   'between',\n",
       "   'the',\n",
       "   'Swedish',\n",
       "   'armies',\n",
       "   'and',\n",
       "   'those',\n",
       "   'of',\n",
       "   'the',\n",
       "   'German',\n",
       "   'empire',\n",
       "   'supported',\n",
       "   'by',\n",
       "   'Spanish',\n",
       "   'troops',\n",
       "   ',',\n",
       "   'the',\n",
       "   'latter',\n",
       "   'being',\n",
       "   'victorious',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '756'},\n",
       " {'tokens': ['then',\n",
       "   'moving',\n",
       "   'to',\n",
       "   'Real',\n",
       "   'Murcia',\n",
       "   'after',\n",
       "   'one',\n",
       "   'year',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 4, 4, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 21, 21, 0, 0, 0, 0],\n",
       "  'id': '757'},\n",
       " {'tokens': ['Shri',\n",
       "   'Peetambara',\n",
       "   'Peetha',\n",
       "   'is',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'most',\n",
       "   'famous',\n",
       "   'temples',\n",
       "   'of',\n",
       "   'Baglamukhi',\n",
       "   'which',\n",
       "   'was',\n",
       "   'established',\n",
       "   'by',\n",
       "   'Shree',\n",
       "   'Swami',\n",
       "   'Ji',\n",
       "   'in',\n",
       "   '1920s',\n",
       "   '.'],\n",
       "  'coarse_tags': [2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   45,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '758'},\n",
       " {'tokens': ['The',\n",
       "   'cancer',\n",
       "   'metastasized',\n",
       "   'and',\n",
       "   'she',\n",
       "   'died',\n",
       "   'on',\n",
       "   '27',\n",
       "   'July',\n",
       "   '2014',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '759'},\n",
       " {'tokens': ['Paul',\n",
       "   'Kornowski',\n",
       "   'was',\n",
       "   'born',\n",
       "   'in',\n",
       "   'Paris',\n",
       "   'to',\n",
       "   'a',\n",
       "   'non-observant',\n",
       "   'Jewish',\n",
       "   'family',\n",
       "   'who',\n",
       "   'had',\n",
       "   'emigrated',\n",
       "   'from',\n",
       "   'Poland',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 7, 0, 0, 0, 4, 0, 0, 0, 5, 5, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [54, 54, 0, 0, 0, 21, 0, 0, 0, 32, 32, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '760'},\n",
       " {'tokens': ['Klein',\n",
       "   'introduced',\n",
       "   'her',\n",
       "   'to',\n",
       "   'Wilhelm',\n",
       "   'Dörpfeld',\n",
       "   'who',\n",
       "   'invited',\n",
       "   'her',\n",
       "   'to',\n",
       "   'participate',\n",
       "   'in',\n",
       "   'his',\n",
       "   'archaeological',\n",
       "   'tours',\n",
       "   'in',\n",
       "   'Greece',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [56, 0, 0, 0, 56, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '761'},\n",
       " {'tokens': ['Future',\n",
       "   'Williams',\n",
       "   'engineer',\n",
       "   'Patrick',\n",
       "   'Head',\n",
       "   'noted',\n",
       "   'that',\n",
       "   'the',\n",
       "   '308D',\n",
       "   'had',\n",
       "   'significant',\n",
       "   'aerodynamic',\n",
       "   'issues',\n",
       "   'at',\n",
       "   'the',\n",
       "   'rear',\n",
       "   'of',\n",
       "   'the',\n",
       "   'car',\n",
       "   'which',\n",
       "   'hindered',\n",
       "   'performance',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   36,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '762'},\n",
       " {'tokens': ['Born',\n",
       "   'in',\n",
       "   'Kalundborg',\n",
       "   ',',\n",
       "   'Rørup',\n",
       "   'studied',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Royal',\n",
       "   'Danish',\n",
       "   'Academy',\n",
       "   'of',\n",
       "   'Fine',\n",
       "   'Arts',\n",
       "   'under',\n",
       "   'Ejnar',\n",
       "   'Nielsen',\n",
       "   'and',\n",
       "   'Sigurd',\n",
       "   'Wandel',\n",
       "   ',',\n",
       "   'graduating',\n",
       "   'in',\n",
       "   '1930',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   56,\n",
       "   56,\n",
       "   0,\n",
       "   56,\n",
       "   56,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '763'},\n",
       " {'tokens': ['Modern',\n",
       "   'humans',\n",
       "   'then',\n",
       "   'made',\n",
       "   'their',\n",
       "   'way',\n",
       "   'across',\n",
       "   'the',\n",
       "   'Bering',\n",
       "   'land',\n",
       "   'bridge',\n",
       "   'and',\n",
       "   'into',\n",
       "   'North',\n",
       "   'America',\n",
       "   'between',\n",
       "   '20,000-11,000',\n",
       "   'years',\n",
       "   'ago',\n",
       "   ',',\n",
       "   'after',\n",
       "   'the',\n",
       "   'Wisconsin',\n",
       "   'glaciation',\n",
       "   'had',\n",
       "   'retreated',\n",
       "   'but',\n",
       "   'before',\n",
       "   'the',\n",
       "   'Bering',\n",
       "   'land',\n",
       "   'bridge',\n",
       "   'became',\n",
       "   'inundated',\n",
       "   'by',\n",
       "   'the',\n",
       "   'sea',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '764'},\n",
       " {'tokens': ['In',\n",
       "   '1995',\n",
       "   ',',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'Environmental',\n",
       "   'Protection',\n",
       "   'Agency',\n",
       "   '(',\n",
       "   'EPA',\n",
       "   ')',\n",
       "   'removed',\n",
       "   'acetone',\n",
       "   'from',\n",
       "   'the',\n",
       "   'list',\n",
       "   'of',\n",
       "   '``',\n",
       "   'toxic',\n",
       "   'chemicals',\n",
       "   \"''\",\n",
       "   'maintained',\n",
       "   'under',\n",
       "   'Section',\n",
       "   '313',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Emergency',\n",
       "   'Planning',\n",
       "   'and',\n",
       "   'Community',\n",
       "   'Right',\n",
       "   'to',\n",
       "   'Know',\n",
       "   'Act',\n",
       "   '(',\n",
       "   'EPCRA',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   41,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   47,\n",
       "   0,\n",
       "   47,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '765'},\n",
       " {'tokens': ['After',\n",
       "   'the',\n",
       "   'victory',\n",
       "   ',',\n",
       "   'Israeli',\n",
       "   'human',\n",
       "   'rights',\n",
       "   'organizations',\n",
       "   'called',\n",
       "   'on',\n",
       "   'Hamas',\n",
       "   'to',\n",
       "   'stop',\n",
       "   'its',\n",
       "   'terror',\n",
       "   'campaign',\n",
       "   'against',\n",
       "   'civilians',\n",
       "   'and',\n",
       "   'to',\n",
       "   'eschew',\n",
       "   'violence',\n",
       "   'as',\n",
       "   'a',\n",
       "   'tool',\n",
       "   'to',\n",
       "   'achieve',\n",
       "   'a',\n",
       "   'political',\n",
       "   'solution',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '766'},\n",
       " {'tokens': ['He',\n",
       "   'assumed',\n",
       "   'senior',\n",
       "   'status',\n",
       "   'on',\n",
       "   'March',\n",
       "   '31',\n",
       "   ',',\n",
       "   '1940',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '767'},\n",
       " {'tokens': ['After',\n",
       "   'formalizing',\n",
       "   'his',\n",
       "   're-election',\n",
       "   'bid',\n",
       "   'in',\n",
       "   'October',\n",
       "   '2012',\n",
       "   ',',\n",
       "   'Trillanes',\n",
       "   'filed',\n",
       "   'his',\n",
       "   'certificate',\n",
       "   'of',\n",
       "   'candidacy',\n",
       "   'for',\n",
       "   '2013',\n",
       "   'elections',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Commission',\n",
       "   'on',\n",
       "   'Elections',\n",
       "   'main',\n",
       "   'office',\n",
       "   'in',\n",
       "   'Manila',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '768'},\n",
       " {'tokens': ['The',\n",
       "   'main',\n",
       "   'station',\n",
       "   'exit',\n",
       "   'is',\n",
       "   'connected',\n",
       "   'directly',\n",
       "   'to',\n",
       "   'basement',\n",
       "   'levels',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Izumi',\n",
       "   'Garden',\n",
       "   'Tower',\n",
       "   'building',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 11, 11, 0, 0],\n",
       "  'id': '769'},\n",
       " {'tokens': ['The',\n",
       "   'Nuclear',\n",
       "   'Decommissioning',\n",
       "   'Authority',\n",
       "   'assumed',\n",
       "   'responsibility',\n",
       "   'for',\n",
       "   'the',\n",
       "   'site',\n",
       "   'when',\n",
       "   'it',\n",
       "   'was',\n",
       "   'formed',\n",
       "   'on',\n",
       "   '1',\n",
       "   'April',\n",
       "   '2005',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 32, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '770'},\n",
       " {'tokens': ['``',\n",
       "   'Adidharam',\n",
       "   '``',\n",
       "   '(',\n",
       "   'Hindi',\n",
       "   ':',\n",
       "   'आदि',\n",
       "   'धर्म',\n",
       "   ')',\n",
       "   'by',\n",
       "   'Ram',\n",
       "   'Dayal',\n",
       "   'Munda',\n",
       "   'and',\n",
       "   'Ratan',\n",
       "   'Singh',\n",
       "   'Manki',\n",
       "   ',',\n",
       "   'in',\n",
       "   'Mundari',\n",
       "   'with',\n",
       "   'a',\n",
       "   'Hindi',\n",
       "   'translation',\n",
       "   ',',\n",
       "   'describes',\n",
       "   'Munda',\n",
       "   'rituals',\n",
       "   'and',\n",
       "   'customs',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '771'},\n",
       " {'tokens': ['He', 'was', 'elected', 'Chair', 'in', '1990', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '772'},\n",
       " {'tokens': ['The',\n",
       "   'main',\n",
       "   'starting',\n",
       "   'points',\n",
       "   'for',\n",
       "   'climbing',\n",
       "   'are',\n",
       "   'Osogovo',\n",
       "   'hut',\n",
       "   ',',\n",
       "   'Three',\n",
       "   'Beeches',\n",
       "   'hotel',\n",
       "   'and',\n",
       "   'the',\n",
       "   'village',\n",
       "   'of',\n",
       "   'Gyueshevo',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 2, 2, 2, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 11, 11, 11, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '773'},\n",
       " {'tokens': ['Hidden',\n",
       "   'behind',\n",
       "   'the',\n",
       "   'electrical',\n",
       "   'cabinet',\n",
       "   'doors',\n",
       "   'on',\n",
       "   'the',\n",
       "   'rear',\n",
       "   'wall',\n",
       "   'of',\n",
       "   'the',\n",
       "   'cab',\n",
       "   ',',\n",
       "   'the',\n",
       "   'GP60',\n",
       "   'concealed',\n",
       "   'a',\n",
       "   'trio',\n",
       "   'of',\n",
       "   'microprocessors',\n",
       "   'that',\n",
       "   'monitored',\n",
       "   'and',\n",
       "   'managed',\n",
       "   'a',\n",
       "   'host',\n",
       "   'of',\n",
       "   'engine',\n",
       "   ',',\n",
       "   'cooling',\n",
       "   'system',\n",
       "   'and',\n",
       "   'control',\n",
       "   'functions',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '774'},\n",
       " {'tokens': ['In',\n",
       "   'order',\n",
       "   'to',\n",
       "   'produce',\n",
       "   'this',\n",
       "   'action',\n",
       "   'they',\n",
       "   'have',\n",
       "   'to',\n",
       "   'penetrate',\n",
       "   'into',\n",
       "   'the',\n",
       "   'skin',\n",
       "   ',',\n",
       "   'and',\n",
       "   'this',\n",
       "   'is',\n",
       "   'in',\n",
       "   'contrast',\n",
       "   'to',\n",
       "   'the',\n",
       "   'assumptions',\n",
       "   'which',\n",
       "   'are',\n",
       "   'made',\n",
       "   'by',\n",
       "   'those',\n",
       "   'who',\n",
       "   'endorse',\n",
       "   'sunscreen',\n",
       "   'use',\n",
       "   '(',\n",
       "   'see',\n",
       "   'sunscreen',\n",
       "   'controversy',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '775'},\n",
       " {'tokens': ['The',\n",
       "   '1620',\n",
       "   'was',\n",
       "   'later',\n",
       "   'replaced',\n",
       "   'by',\n",
       "   'remote',\n",
       "   'access',\n",
       "   'to',\n",
       "   'a',\n",
       "   'DEC',\n",
       "   'System',\n",
       "   '10',\n",
       "   'then',\n",
       "   ',',\n",
       "   'later',\n",
       "   ',',\n",
       "   'an',\n",
       "   'on-site',\n",
       "   'PDP-11/40',\n",
       "   'running',\n",
       "   'the',\n",
       "   'RSTS/E',\n",
       "   'time',\n",
       "   'sharing',\n",
       "   'system',\n",
       "   ',',\n",
       "   'also',\n",
       "   'dedicated',\n",
       "   'to',\n",
       "   'the',\n",
       "   'students',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '776'},\n",
       " {'tokens': ['Their',\n",
       "   'arrests',\n",
       "   'were',\n",
       "   'protested',\n",
       "   'by',\n",
       "   '109',\n",
       "   'Members',\n",
       "   'of',\n",
       "   'Parliament',\n",
       "   'of',\n",
       "   'Bangladesh',\n",
       "   'Nationalist',\n",
       "   'Party',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 33, 33, 33, 33, 33, 0],\n",
       "  'id': '777'},\n",
       " {'tokens': ['The',\n",
       "   'initial',\n",
       "   'opportunities',\n",
       "   'which',\n",
       "   'led',\n",
       "   'to',\n",
       "   'the',\n",
       "   'success',\n",
       "   'and',\n",
       "   'recognition',\n",
       "   'he',\n",
       "   'enjoyed',\n",
       "   'were',\n",
       "   'due',\n",
       "   'to',\n",
       "   'Clara',\n",
       "   ',',\n",
       "   'who',\n",
       "   'introduced',\n",
       "   'him',\n",
       "   'to',\n",
       "   'both',\n",
       "   'Robert',\n",
       "   'Schumann',\n",
       "   'and',\n",
       "   'Felix',\n",
       "   'Mendelssohn',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0],\n",
       "  'id': '778'},\n",
       " {'tokens': ['This',\n",
       "   'includes',\n",
       "   'their',\n",
       "   'music',\n",
       "   'from',\n",
       "   '1964',\n",
       "   'to',\n",
       "   '1970',\n",
       "   ',',\n",
       "   'plus',\n",
       "   'any',\n",
       "   'compilations',\n",
       "   'made',\n",
       "   'thereafter',\n",
       "   'by',\n",
       "   'ABKCO',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 0],\n",
       "  'id': '779'},\n",
       " {'tokens': ['Malcolm',\n",
       "   \"'s\",\n",
       "   'long',\n",
       "   'reign',\n",
       "   'of',\n",
       "   '35',\n",
       "   'years',\n",
       "   'preceded',\n",
       "   'the',\n",
       "   'beginning',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Scoto-Norman',\n",
       "   'age',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0],\n",
       "  'fine_tags': [55, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0],\n",
       "  'id': '780'},\n",
       " {'tokens': ['The',\n",
       "   'river',\n",
       "   'Satluj',\n",
       "   'used',\n",
       "   'to',\n",
       "   'flow',\n",
       "   'through',\n",
       "   'a',\n",
       "   'narrow',\n",
       "   'gorge',\n",
       "   'between',\n",
       "   'two',\n",
       "   'hills',\n",
       "   ',',\n",
       "   'Naina',\n",
       "   'Devi',\n",
       "   'ki',\n",
       "   'dhar',\n",
       "   'and',\n",
       "   'Ramgarh',\n",
       "   'ki',\n",
       "   'dhar',\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'site',\n",
       "   'was',\n",
       "   'chosen',\n",
       "   'to',\n",
       "   'dam',\n",
       "   'the',\n",
       "   'river',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   24,\n",
       "   24,\n",
       "   24,\n",
       "   24,\n",
       "   0,\n",
       "   24,\n",
       "   24,\n",
       "   24,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '781'},\n",
       " {'tokens': ['In',\n",
       "   '2009',\n",
       "   ',',\n",
       "   'Graywolf',\n",
       "   'Press',\n",
       "   'moved',\n",
       "   'its',\n",
       "   'publishing',\n",
       "   'operations',\n",
       "   'to',\n",
       "   'the',\n",
       "   'historic',\n",
       "   'Warehouse',\n",
       "   'District',\n",
       "   'of',\n",
       "   'downtown',\n",
       "   'Minneapolis',\n",
       "   ',',\n",
       "   'Minnesota',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 0, 4, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '782'},\n",
       " {'tokens': ['The',\n",
       "   'Pacific',\n",
       "   'Motorway',\n",
       "   'cuts',\n",
       "   'through',\n",
       "   'the',\n",
       "   'suburb',\n",
       "   'with',\n",
       "   'an',\n",
       "   'exit',\n",
       "   'south',\n",
       "   'into',\n",
       "   'Vulture',\n",
       "   'Street',\n",
       "   'and',\n",
       "   'a',\n",
       "   'Stanley',\n",
       "   'Street',\n",
       "   'exit',\n",
       "   'for',\n",
       "   'vehicles',\n",
       "   'heading',\n",
       "   'north',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '783'},\n",
       " {'tokens': ['Meanwhile',\n",
       "   ',',\n",
       "   'Bill',\n",
       "   'Macatee',\n",
       "   'provided',\n",
       "   'a',\n",
       "   'report',\n",
       "   'on',\n",
       "   'Game',\n",
       "   '2',\n",
       "   'of',\n",
       "   'the',\n",
       "   'ALCS',\n",
       "   'during',\n",
       "   'the',\n",
       "   'pregame',\n",
       "   'of',\n",
       "   'the',\n",
       "   'NLCS',\n",
       "   'opener',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '784'},\n",
       " {'tokens': ['Two',\n",
       "   'years',\n",
       "   'later',\n",
       "   ',',\n",
       "   'on',\n",
       "   'March',\n",
       "   '15',\n",
       "   'and',\n",
       "   'March',\n",
       "   '16',\n",
       "   ',',\n",
       "   'the',\n",
       "   'first',\n",
       "   'Alpha',\n",
       "   'Beta',\n",
       "   'Alpha',\n",
       "   'national',\n",
       "   'convention',\n",
       "   'was',\n",
       "   'held',\n",
       "   'at',\n",
       "   'Northwestern',\n",
       "   'State',\n",
       "   'College',\n",
       "   'of',\n",
       "   'Louisiana',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0],\n",
       "  'id': '785'},\n",
       " {'tokens': ['He',\n",
       "   'produced',\n",
       "   'many',\n",
       "   'popular',\n",
       "   'shows',\n",
       "   'for',\n",
       "   'BAG',\n",
       "   'films',\n",
       "   'where',\n",
       "   'he',\n",
       "   'worked',\n",
       "   'for',\n",
       "   'fifteen',\n",
       "   'years',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 28, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '786'},\n",
       " {'tokens': ['His',\n",
       "   'funeral',\n",
       "   'in',\n",
       "   'Nashville',\n",
       "   ',',\n",
       "   'TN',\n",
       "   ',',\n",
       "   'was',\n",
       "   'attended',\n",
       "   'by',\n",
       "   'some',\n",
       "   '3,000',\n",
       "   'people',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 21, 0, 21, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '787'},\n",
       " {'tokens': ['He',\n",
       "   'currently',\n",
       "   'resides',\n",
       "   'in',\n",
       "   'Vancouver',\n",
       "   'and',\n",
       "   'coaches',\n",
       "   'middle',\n",
       "   'and',\n",
       "   'long',\n",
       "   'distance',\n",
       "   'running',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '788'},\n",
       " {'tokens': ['Damage',\n",
       "   'on',\n",
       "   'the',\n",
       "   'island',\n",
       "   'totaled',\n",
       "   '$',\n",
       "   '60.5',\n",
       "   'million',\n",
       "   ',',\n",
       "   'and',\n",
       "   'there',\n",
       "   'were',\n",
       "   '23',\n",
       "   'injuries',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 42, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '789'},\n",
       " {'tokens': ['Attendance',\n",
       "   'stats',\n",
       "   'are',\n",
       "   'calculated',\n",
       "   'by',\n",
       "   'averaging',\n",
       "   'each',\n",
       "   'team',\n",
       "   \"'s\",\n",
       "   'self-reported',\n",
       "   'home',\n",
       "   'attendances',\n",
       "   'from',\n",
       "   'the',\n",
       "   'historical',\n",
       "   'match',\n",
       "   'archive',\n",
       "   'at',\n",
       "   'United',\n",
       "   'Soccer',\n",
       "   'Leagues',\n",
       "   '(',\n",
       "   'USL',\n",
       "   ')',\n",
       "   ',',\n",
       "   'and',\n",
       "   'then',\n",
       "   'averaging',\n",
       "   'this',\n",
       "   'league-wide',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   36,\n",
       "   36,\n",
       "   0,\n",
       "   36,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '790'},\n",
       " {'tokens': ['To',\n",
       "   'the',\n",
       "   'south',\n",
       "   'in',\n",
       "   'the',\n",
       "   'outer',\n",
       "   'Firth',\n",
       "   'there',\n",
       "   'is',\n",
       "   'a',\n",
       "   'group',\n",
       "   'of',\n",
       "   'islands',\n",
       "   'off',\n",
       "   'East',\n",
       "   'Lothian',\n",
       "   'near',\n",
       "   'North',\n",
       "   'Berwick',\n",
       "   'and',\n",
       "   'Gullane',\n",
       "   ';',\n",
       "   'from',\n",
       "   'east',\n",
       "   'to',\n",
       "   'west',\n",
       "   'they',\n",
       "   'are',\n",
       "   'the',\n",
       "   'Bass',\n",
       "   'Rock',\n",
       "   '(',\n",
       "   'also',\n",
       "   'known',\n",
       "   'simply',\n",
       "   'as',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Bass',\n",
       "   '``',\n",
       "   ')',\n",
       "   ',',\n",
       "   'Craigleith',\n",
       "   ',',\n",
       "   'Lamb',\n",
       "   ',',\n",
       "   'Fidra',\n",
       "   'and',\n",
       "   'Eyebroughy',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   23,\n",
       "   23,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   23,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   23,\n",
       "   0,\n",
       "   23,\n",
       "   0,\n",
       "   23,\n",
       "   0,\n",
       "   23,\n",
       "   0],\n",
       "  'id': '791'},\n",
       " {'tokens': ['These',\n",
       "   'two',\n",
       "   'lines',\n",
       "   'share',\n",
       "   'the',\n",
       "   'same',\n",
       "   'double-tracks',\n",
       "   'for',\n",
       "   'most',\n",
       "   'of',\n",
       "   'their',\n",
       "   'routes',\n",
       "   ',',\n",
       "   'however',\n",
       "   ',',\n",
       "   'the',\n",
       "   'railway',\n",
       "   'was',\n",
       "   'initially',\n",
       "   'planned',\n",
       "   'to',\n",
       "   'have',\n",
       "   'four',\n",
       "   'tracks',\n",
       "   'along',\n",
       "   'its',\n",
       "   'length',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '792'},\n",
       " {'tokens': ['Kralj',\n",
       "   'had',\n",
       "   'appeared',\n",
       "   'on',\n",
       "   'stage',\n",
       "   'about',\n",
       "   '3,000',\n",
       "   'times',\n",
       "   ',',\n",
       "   'and',\n",
       "   'starred',\n",
       "   'in',\n",
       "   'over',\n",
       "   '200',\n",
       "   'films',\n",
       "   ',',\n",
       "   'TV',\n",
       "   'series',\n",
       "   'and',\n",
       "   'TV',\n",
       "   'films',\n",
       "   'gaining',\n",
       "   'huge',\n",
       "   'popularity',\n",
       "   'as',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'most',\n",
       "   'recognizable',\n",
       "   'Serbian',\n",
       "   'actors',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [50,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '793'},\n",
       " {'tokens': ['Five',\n",
       "   'of',\n",
       "   'the',\n",
       "   'ten',\n",
       "   'tallest',\n",
       "   'dams',\n",
       "   'in',\n",
       "   'the',\n",
       "   'U.S',\n",
       "   '.',\n",
       "   'are',\n",
       "   'located',\n",
       "   'in',\n",
       "   'California',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 21, 21, 0, 0, 0, 21, 0],\n",
       "  'id': '794'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'also',\n",
       "   'successful',\n",
       "   'on',\n",
       "   'the',\n",
       "   'European',\n",
       "   'Kermesse',\n",
       "   'circuit',\n",
       "   'including',\n",
       "   'in',\n",
       "   '1981',\n",
       "   'beating',\n",
       "   'Lucien',\n",
       "   'Van',\n",
       "   'Impe',\n",
       "   'at',\n",
       "   'Eeklo',\n",
       "   'in',\n",
       "   'Belgium',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '795'},\n",
       " {'tokens': ['A',\n",
       "   'Disintegrin',\n",
       "   'and',\n",
       "   'metalloproteinase',\n",
       "   'domain-containing',\n",
       "   'protein',\n",
       "   '10',\n",
       "   ',',\n",
       "   'also',\n",
       "   'known',\n",
       "   'as',\n",
       "   'ADAM10',\n",
       "   'or',\n",
       "   'CDw156',\n",
       "   'or',\n",
       "   'CD156c',\n",
       "   'is',\n",
       "   'a',\n",
       "   'protein',\n",
       "   'that',\n",
       "   'in',\n",
       "   'humans',\n",
       "   'is',\n",
       "   'encoded',\n",
       "   'by',\n",
       "   'the',\n",
       "   '``',\n",
       "   'ADAM10',\n",
       "   '``',\n",
       "   'gene',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '796'},\n",
       " {'tokens': ['Atropine',\n",
       "   ',',\n",
       "   'scopolamine',\n",
       "   ',',\n",
       "   'amitriptyline',\n",
       "   'or',\n",
       "   'glycopyrrolate',\n",
       "   'may',\n",
       "   'be',\n",
       "   'prescribed',\n",
       "   'when',\n",
       "   'people',\n",
       "   'with',\n",
       "   'ALS',\n",
       "   'begin',\n",
       "   'having',\n",
       "   'trouble',\n",
       "   'swallowing',\n",
       "   'their',\n",
       "   'saliva',\n",
       "   '(',\n",
       "   'sialorrhea',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [41,\n",
       "   0,\n",
       "   41,\n",
       "   0,\n",
       "   41,\n",
       "   0,\n",
       "   41,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   43,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '797'},\n",
       " {'tokens': ['on', 'a', '1.5-year', 'loan', 'contract', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0],\n",
       "  'id': '798'},\n",
       " {'tokens': ['The',\n",
       "   'series',\n",
       "   'marks',\n",
       "   'the',\n",
       "   'television',\n",
       "   'debut',\n",
       "   'of',\n",
       "   'Bollywood',\n",
       "   'actress',\n",
       "   'Tulip',\n",
       "   'Joshi',\n",
       "   'and',\n",
       "   'VJ',\n",
       "   'turned',\n",
       "   'actor',\n",
       "   'Yudhisthir',\n",
       "   'in',\n",
       "   'lead',\n",
       "   'roles',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 5, 0, 7, 7, 0, 7, 0, 0, 7, 0, 0, 0, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   50,\n",
       "   0,\n",
       "   0,\n",
       "   50,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '799'},\n",
       " {'tokens': ['A',\n",
       "   'large',\n",
       "   'scale',\n",
       "   'magnetic',\n",
       "   'field',\n",
       "   'was',\n",
       "   'discovered',\n",
       "   'in',\n",
       "   'the',\n",
       "   'region',\n",
       "   'which',\n",
       "   'is',\n",
       "   'perpendicular',\n",
       "   'to',\n",
       "   'the',\n",
       "   'main',\n",
       "   'cloud',\n",
       "   'filament',\n",
       "   ',',\n",
       "   'but',\n",
       "   'sub-filaments',\n",
       "   'tend',\n",
       "   'to',\n",
       "   'run',\n",
       "   'parallel',\n",
       "   'to',\n",
       "   'the',\n",
       "   'filament',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0],\n",
       "  'id': '800'},\n",
       " {'tokens': ['The',\n",
       "   'MDC1',\n",
       "   'protein',\n",
       "   'can',\n",
       "   'bind',\n",
       "   'to',\n",
       "   'the',\n",
       "   'n-terminus',\n",
       "   'of',\n",
       "   'p53',\n",
       "   'through',\n",
       "   'its',\n",
       "   'BRC1',\n",
       "   'domain',\n",
       "   'which',\n",
       "   'blocks',\n",
       "   'p53',\n",
       "   'transactivation',\n",
       "   'domain',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 6, 6, 0, 0, 0, 0, 0, 0, 6, 0, 0, 6, 0, 0, 0, 6, 0, 0, 0],\n",
       "  'fine_tags': [0,\n",
       "   40,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '801'},\n",
       " {'tokens': ['Following',\n",
       "   'the',\n",
       "   'battle',\n",
       "   ',',\n",
       "   'the',\n",
       "   'tank',\n",
       "   'driver',\n",
       "   'Dong',\n",
       "   'Laifu',\n",
       "   '(',\n",
       "   '董來扶',\n",
       "   ')',\n",
       "   'and',\n",
       "   'machine',\n",
       "   'gunner',\n",
       "   'Wu',\n",
       "   'Peilong',\n",
       "   '(',\n",
       "   '吳佩龍',\n",
       "   ')',\n",
       "   'were',\n",
       "   'commended',\n",
       "   'as',\n",
       "   '``',\n",
       "   'first',\n",
       "   'class',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'tank',\n",
       "   'designated',\n",
       "   'as',\n",
       "   '102',\n",
       "   'was',\n",
       "   'renamed',\n",
       "   '``',\n",
       "   'Gongchen',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   57,\n",
       "   57,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   57,\n",
       "   57,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '802'},\n",
       " {'tokens': ['In',\n",
       "   'the',\n",
       "   'filing',\n",
       "   'department',\n",
       "   ',',\n",
       "   'Lily',\n",
       "   'begins',\n",
       "   'an',\n",
       "   'affair',\n",
       "   'with',\n",
       "   'Jimmy',\n",
       "   'McCoy',\n",
       "   'Jr',\n",
       "   '.',\n",
       "   '(',\n",
       "   'John',\n",
       "   'Wayne',\n",
       "   ')',\n",
       "   ',',\n",
       "   'who',\n",
       "   'recommends',\n",
       "   'her',\n",
       "   'for',\n",
       "   'promotion',\n",
       "   'to',\n",
       "   'his',\n",
       "   'boss',\n",
       "   ',',\n",
       "   'Brody',\n",
       "   '(',\n",
       "   'Douglass',\n",
       "   'Dumbrille',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '803'},\n",
       " {'tokens': ['He',\n",
       "   ',',\n",
       "   'as',\n",
       "   'well',\n",
       "   'as',\n",
       "   'other',\n",
       "   'Montgomery',\n",
       "   'leaders',\n",
       "   ',',\n",
       "   'recognized',\n",
       "   'the',\n",
       "   'historical',\n",
       "   'significance',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Wright',\n",
       "   'Brother',\n",
       "   \"'s\",\n",
       "   'first',\n",
       "   'military',\n",
       "   'flying',\n",
       "   'school',\n",
       "   'and',\n",
       "   'the',\n",
       "   'potential',\n",
       "   'of',\n",
       "   'Maxwell',\n",
       "   'Field',\n",
       "   'to',\n",
       "   'the',\n",
       "   'local',\n",
       "   'economy',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '804'},\n",
       " {'tokens': ['The',\n",
       "   '2015',\n",
       "   'Big',\n",
       "   'Ten',\n",
       "   'Men',\n",
       "   \"'s\",\n",
       "   'Lacrosse',\n",
       "   'Tournament',\n",
       "   'took',\n",
       "   'place',\n",
       "   'April',\n",
       "   '30',\n",
       "   'to',\n",
       "   'May',\n",
       "   '2',\n",
       "   'at',\n",
       "   'Capital',\n",
       "   'One',\n",
       "   'Field',\n",
       "   'at',\n",
       "   'Byrd',\n",
       "   'Stadium',\n",
       "   'in',\n",
       "   'College',\n",
       "   'Park',\n",
       "   ',',\n",
       "   'Maryland',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   13,\n",
       "   13,\n",
       "   13,\n",
       "   0,\n",
       "   13,\n",
       "   13,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '805'},\n",
       " {'tokens': ['The',\n",
       "   'Brit',\n",
       "   'Awards',\n",
       "   'are',\n",
       "   'the',\n",
       "   'British',\n",
       "   'Phonographic',\n",
       "   'Industry',\n",
       "   \"'s\",\n",
       "   'annual',\n",
       "   'pop',\n",
       "   'music',\n",
       "   'awards',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 6, 6, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [39, 39, 39, 0, 0, 21, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '806'},\n",
       " {'tokens': ['Berger',\n",
       "   'enrolled',\n",
       "   'at',\n",
       "   'Harvard',\n",
       "   'College',\n",
       "   'in',\n",
       "   '1984',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 5, 5, 0, 0, 0],\n",
       "  'fine_tags': [51, 0, 0, 29, 29, 0, 0, 0],\n",
       "  'id': '807'},\n",
       " {'tokens': ['In',\n",
       "   'October',\n",
       "   'and',\n",
       "   'November',\n",
       "   ',',\n",
       "   'Jennings',\n",
       "   'travelled',\n",
       "   'to',\n",
       "   'Europe',\n",
       "   'with',\n",
       "   'the',\n",
       "   'Australian',\n",
       "   'team',\n",
       "   'for',\n",
       "   'the',\n",
       "   '2009',\n",
       "   'Four',\n",
       "   'Nations',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 0, 0, 4, 0, 0, 5, 5, 0, 0, 0, 3, 3, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 52, 0, 0, 21, 0, 0, 37, 37, 0, 0, 0, 20, 20, 0],\n",
       "  'id': '808'},\n",
       " {'tokens': ['In',\n",
       "   '1964',\n",
       "   'DEC',\n",
       "   'introduced',\n",
       "   'its',\n",
       "   'new',\n",
       "   'Flip',\n",
       "   'Chip',\n",
       "   'module',\n",
       "   'design',\n",
       "   ',',\n",
       "   'and',\n",
       "   'used',\n",
       "   'it',\n",
       "   'to',\n",
       "   're-implement',\n",
       "   'the',\n",
       "   'PDP-4',\n",
       "   'as',\n",
       "   'the',\n",
       "   'PDP-7',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   0],\n",
       "  'id': '809'},\n",
       " {'tokens': ['From',\n",
       "   'June',\n",
       "   '2005',\n",
       "   'to',\n",
       "   'April',\n",
       "   '2007',\n",
       "   ',',\n",
       "   'McGregor',\n",
       "   'starred',\n",
       "   'alongside',\n",
       "   'Jane',\n",
       "   'Krakowski',\n",
       "   ',',\n",
       "   'Douglas',\n",
       "   'Hodge',\n",
       "   'and',\n",
       "   'Jenna',\n",
       "   'Russell',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Donmar',\n",
       "   'Warehouse',\n",
       "   'revival',\n",
       "   'of',\n",
       "   '``',\n",
       "   'Guys',\n",
       "   'and',\n",
       "   'Dolls',\n",
       "   '``',\n",
       "   'after',\n",
       "   'it',\n",
       "   'transferred',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Piccadilly',\n",
       "   'Theatre',\n",
       "   'in',\n",
       "   'London',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   14,\n",
       "   14,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '810'},\n",
       " {'tokens': ['He',\n",
       "   'composed',\n",
       "   'myriad',\n",
       "   'incidental',\n",
       "   'dances',\n",
       "   'such',\n",
       "   'as',\n",
       "   'divertissements',\n",
       "   'and',\n",
       "   'variations',\n",
       "   ',',\n",
       "   'many',\n",
       "   'of',\n",
       "   'which',\n",
       "   'were',\n",
       "   'added',\n",
       "   'to',\n",
       "   'countless',\n",
       "   'other',\n",
       "   'works',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '811'},\n",
       " {'tokens': ['Ashurbanipal',\n",
       "   'identifies',\n",
       "   'three',\n",
       "   'groups',\n",
       "   'that',\n",
       "   'aided',\n",
       "   'his',\n",
       "   'brother',\n",
       "   ',',\n",
       "   'first',\n",
       "   'and',\n",
       "   'foremost',\n",
       "   'there',\n",
       "   'were',\n",
       "   'the',\n",
       "   'Chaldeans',\n",
       "   ',',\n",
       "   'Arameans',\n",
       "   'and',\n",
       "   'the',\n",
       "   'other',\n",
       "   'peoples',\n",
       "   'of',\n",
       "   'Babylonia',\n",
       "   ',',\n",
       "   'then',\n",
       "   'there',\n",
       "   'were',\n",
       "   'the',\n",
       "   'Elamites',\n",
       "   'and',\n",
       "   'lastly',\n",
       "   'the',\n",
       "   'kings',\n",
       "   'of',\n",
       "   'Gutium',\n",
       "   ',',\n",
       "   'Amurru',\n",
       "   'and',\n",
       "   'Meluhha',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '812'},\n",
       " {'tokens': ['He',\n",
       "   'scored',\n",
       "   'his',\n",
       "   'first',\n",
       "   'goal',\n",
       "   'for',\n",
       "   'his',\n",
       "   'new',\n",
       "   'team',\n",
       "   'on',\n",
       "   '23',\n",
       "   'December',\n",
       "   ',',\n",
       "   'replacing',\n",
       "   'Fabian',\n",
       "   'Delph',\n",
       "   'late',\n",
       "   'into',\n",
       "   'the',\n",
       "   'home',\n",
       "   'fixture',\n",
       "   'against',\n",
       "   'AFC',\n",
       "   'Bournemouth',\n",
       "   'and',\n",
       "   'scoring',\n",
       "   'the',\n",
       "   'final',\n",
       "   'goal',\n",
       "   'of',\n",
       "   'a',\n",
       "   '4–0',\n",
       "   'home',\n",
       "   'win',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '813'},\n",
       " {'tokens': ['The',\n",
       "   'Hotel',\n",
       "   'Sacher',\n",
       "   'Salzburg',\n",
       "   ',',\n",
       "   'Austria',\n",
       "   ',',\n",
       "   'is',\n",
       "   'Salzburg',\n",
       "   \"'s\",\n",
       "   'only',\n",
       "   'grand',\n",
       "   'hotel',\n",
       "   ',',\n",
       "   'a',\n",
       "   '5',\n",
       "   'star',\n",
       "   'deluxe',\n",
       "   'hotel',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 2, 2, 2, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 9, 9, 9, 0, 21, 0, 0, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '814'},\n",
       " {'tokens': ['Binding',\n",
       "   'and',\n",
       "   'activation',\n",
       "   'of',\n",
       "   'the',\n",
       "   'receptor',\n",
       "   'stimulates',\n",
       "   'Janus',\n",
       "   'protein',\n",
       "   'kinases',\n",
       "   ',',\n",
       "   'which',\n",
       "   'in',\n",
       "   'turn',\n",
       "   'phosphorylate',\n",
       "   'several',\n",
       "   'proteins',\n",
       "   ',',\n",
       "   'including',\n",
       "   'STAT1',\n",
       "   'and',\n",
       "   'STAT2',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   40,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   40,\n",
       "   0],\n",
       "  'id': '815'},\n",
       " {'tokens': ['Also',\n",
       "   'called',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Sand',\n",
       "   'City',\n",
       "   '``',\n",
       "   ',',\n",
       "   'it',\n",
       "   'was',\n",
       "   'originally',\n",
       "   'a',\n",
       "   'non-Mission',\n",
       "   'Amerindian',\n",
       "   'settlement',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 25, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '816'},\n",
       " {'tokens': ['Folic',\n",
       "   'acid',\n",
       "   'might',\n",
       "   'also',\n",
       "   'be',\n",
       "   'counter-productive',\n",
       "   'for',\n",
       "   'patients',\n",
       "   'taking',\n",
       "   '6-MP',\n",
       "   'and',\n",
       "   'related',\n",
       "   'drugs',\n",
       "   'that',\n",
       "   'inhibit',\n",
       "   'all',\n",
       "   'cell',\n",
       "   'division',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 6, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [49, 49, 0, 0, 0, 0, 0, 0, 0, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '817'},\n",
       " {'tokens': ['The',\n",
       "   'ÖBB',\n",
       "   'Class',\n",
       "   '2143',\n",
       "   'is',\n",
       "   'a',\n",
       "   'class',\n",
       "   'of',\n",
       "   'diesel-hydraulic',\n",
       "   'locomotives',\n",
       "   'operated',\n",
       "   'by',\n",
       "   'Austrian',\n",
       "   'Federal',\n",
       "   'Railways',\n",
       "   '(',\n",
       "   'ÖBB',\n",
       "   ')',\n",
       "   'in',\n",
       "   'Austria',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   62,\n",
       "   62,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '818'},\n",
       " {'tokens': ['Young',\n",
       "   'established',\n",
       "   'a',\n",
       "   'private',\n",
       "   'practice',\n",
       "   'in',\n",
       "   'Harley',\n",
       "   'Street',\n",
       "   ',',\n",
       "   'continuing',\n",
       "   'there',\n",
       "   'long',\n",
       "   'after',\n",
       "   'his',\n",
       "   'retirement',\n",
       "   'from',\n",
       "   'the',\n",
       "   'Middlesex',\n",
       "   'Hospital',\n",
       "   'in',\n",
       "   '1936',\n",
       "   ',',\n",
       "   'which',\n",
       "   'made',\n",
       "   'him',\n",
       "   'a',\n",
       "   'very',\n",
       "   'wealthy',\n",
       "   'man',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '819'},\n",
       " {'tokens': ['The',\n",
       "   'ironstone',\n",
       "   'quarry',\n",
       "   'ceased',\n",
       "   'operation',\n",
       "   'in',\n",
       "   '1877',\n",
       "   'but',\n",
       "   'the',\n",
       "   'limestone',\n",
       "   'quarry',\n",
       "   'continued',\n",
       "   'until',\n",
       "   '1900',\n",
       "   ',',\n",
       "   'the',\n",
       "   'stone',\n",
       "   'being',\n",
       "   'taken',\n",
       "   'on',\n",
       "   'the',\n",
       "   'tramway',\n",
       "   'to',\n",
       "   'limekilns',\n",
       "   'next',\n",
       "   'to',\n",
       "   'the',\n",
       "   'railway',\n",
       "   'at',\n",
       "   'Nether',\n",
       "   'Heyford',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '820'},\n",
       " {'tokens': ['The',\n",
       "   'film',\n",
       "   'spawned',\n",
       "   'three',\n",
       "   'direct-to-video',\n",
       "   'sequels',\n",
       "   'created',\n",
       "   'under',\n",
       "   'different',\n",
       "   'writers',\n",
       "   'and',\n",
       "   'a',\n",
       "   'new',\n",
       "   'director',\n",
       "   ',',\n",
       "   'with',\n",
       "   'Kam',\n",
       "   'Heskin',\n",
       "   'replacing',\n",
       "   'Julia',\n",
       "   'Stiles',\n",
       "   'in',\n",
       "   'the',\n",
       "   'role',\n",
       "   'of',\n",
       "   'Paige',\n",
       "   'Morgan',\n",
       "   ':',\n",
       "   \"'\",\n",
       "   '(',\n",
       "   '2006',\n",
       "   ')',\n",
       "   ',',\n",
       "   \"'\",\n",
       "   '(',\n",
       "   '2008',\n",
       "   ')',\n",
       "   ',',\n",
       "   'and',\n",
       "   '``',\n",
       "   \"''\",\n",
       "   '(',\n",
       "   '2010',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '821'},\n",
       " {'tokens': ['This',\n",
       "   'anomalous',\n",
       "   'growth',\n",
       "   'has',\n",
       "   'been',\n",
       "   'attributed',\n",
       "   'not',\n",
       "   'to',\n",
       "   'increased',\n",
       "   'rainfall',\n",
       "   'but',\n",
       "   'to',\n",
       "   'a',\n",
       "   'series',\n",
       "   'of',\n",
       "   'cool',\n",
       "   'years',\n",
       "   'caused',\n",
       "   'by',\n",
       "   'increased',\n",
       "   'southerly',\n",
       "   'air',\n",
       "   'flow',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Tasman',\n",
       "   'sea',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   22,\n",
       "   0],\n",
       "  'id': '822'},\n",
       " {'tokens': ['The',\n",
       "   'Virgin',\n",
       "   'Mary',\n",
       "   'is',\n",
       "   'shown',\n",
       "   'reading',\n",
       "   'one',\n",
       "   'in',\n",
       "   'such',\n",
       "   'famous',\n",
       "   'paintings',\n",
       "   'as',\n",
       "   'the',\n",
       "   'Ghent',\n",
       "   'Altarpiece',\n",
       "   'and',\n",
       "   'Mérode',\n",
       "   'Altarpiece',\n",
       "   ',',\n",
       "   'and',\n",
       "   'Saint',\n",
       "   'Catherine',\n",
       "   'reads',\n",
       "   'one',\n",
       "   'in',\n",
       "   'the',\n",
       "   'painting',\n",
       "   'with',\n",
       "   'Mary',\n",
       "   'Magdalene',\n",
       "   'by',\n",
       "   'Konrad',\n",
       "   'Witz',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0],\n",
       "  'id': '823'},\n",
       " {'tokens': ['However',\n",
       "   ',',\n",
       "   'when',\n",
       "   'Jogaila',\n",
       "   'failed',\n",
       "   'to',\n",
       "   'ratify',\n",
       "   'the',\n",
       "   'treaty',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Knights',\n",
       "   'invaded',\n",
       "   'Lithuania',\n",
       "   'in',\n",
       "   'the',\n",
       "   'summer',\n",
       "   'of',\n",
       "   '1383',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '824'},\n",
       " {'tokens': ['Two',\n",
       "   'traveling',\n",
       "   'exhibitions',\n",
       "   'are',\n",
       "   'also',\n",
       "   'being',\n",
       "   'developed',\n",
       "   'and',\n",
       "   'will',\n",
       "   'be',\n",
       "   'shown',\n",
       "   'at',\n",
       "   'museums',\n",
       "   'across',\n",
       "   'the',\n",
       "   'country',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '825'},\n",
       " {'tokens': ['He',\n",
       "   'now',\n",
       "   'runs',\n",
       "   'a',\n",
       "   '``',\n",
       "   'yakiniku',\n",
       "   '``',\n",
       "   'restaurant',\n",
       "   'in',\n",
       "   'Fukuoka',\n",
       "   'city',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 8, 0, 0, 0, 4, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 60, 0, 0, 0, 21, 0, 0],\n",
       "  'id': '826'},\n",
       " {'tokens': ['He',\n",
       "   'raced',\n",
       "   'on',\n",
       "   'the',\n",
       "   'Continent',\n",
       "   'for',\n",
       "   'nine',\n",
       "   'years',\n",
       "   ';',\n",
       "   'during',\n",
       "   'this',\n",
       "   'period',\n",
       "   'he',\n",
       "   'partied',\n",
       "   'hard',\n",
       "   'and',\n",
       "   'had',\n",
       "   'a',\n",
       "   'reputation',\n",
       "   'as',\n",
       "   'a',\n",
       "   'supplier',\n",
       "   'of',\n",
       "   'amphetamines',\n",
       "   'to',\n",
       "   'other',\n",
       "   'riders',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   41,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '827'},\n",
       " {'tokens': ['Bårjås',\n",
       "   'is',\n",
       "   'a',\n",
       "   'popular',\n",
       "   'scientific',\n",
       "   'journal',\n",
       "   'that',\n",
       "   'has',\n",
       "   'been',\n",
       "   'published',\n",
       "   'once',\n",
       "   'a',\n",
       "   'year',\n",
       "   'in',\n",
       "   'Lule',\n",
       "   'Sámi',\n",
       "   'and',\n",
       "   'Norwegian',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Árran',\n",
       "   'Lule',\n",
       "   'Sami',\n",
       "   'Center',\n",
       "   'and',\n",
       "   'museum',\n",
       "   'in',\n",
       "   'the',\n",
       "   'village',\n",
       "   'of',\n",
       "   'Drag',\n",
       "   'in',\n",
       "   'Tysfjord',\n",
       "   ',',\n",
       "   'Norway',\n",
       "   'since',\n",
       "   '1999',\n",
       "   '.'],\n",
       "  'coarse_tags': [1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '828'},\n",
       " {'tokens': ['Dragging',\n",
       "   'Canoe',\n",
       "   'once',\n",
       "   'again',\n",
       "   'led',\n",
       "   'his',\n",
       "   'people',\n",
       "   'further',\n",
       "   'down',\n",
       "   'the',\n",
       "   'Tennessee',\n",
       "   'River',\n",
       "   ',',\n",
       "   'establishing',\n",
       "   'five',\n",
       "   'new',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Lower',\n",
       "   'Cherokee',\n",
       "   \"''\",\n",
       "   'towns',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '829'},\n",
       " {'tokens': ['The',\n",
       "   'congregations',\n",
       "   'of',\n",
       "   'the',\n",
       "   'LCR',\n",
       "   'use',\n",
       "   'the',\n",
       "   'King',\n",
       "   'James',\n",
       "   'Version',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Bible',\n",
       "   'for',\n",
       "   'all',\n",
       "   'public',\n",
       "   'uses',\n",
       "   ',',\n",
       "   'the',\n",
       "   '1943',\n",
       "   '``',\n",
       "   'Blue',\n",
       "   \"''\",\n",
       "   'edition',\n",
       "   'of',\n",
       "   'Luther',\n",
       "   \"'s\",\n",
       "   'Small',\n",
       "   'Catechism',\n",
       "   'in',\n",
       "   'confirmation',\n",
       "   'instruction',\n",
       "   ',',\n",
       "   'and',\n",
       "   'The',\n",
       "   'Lutheran',\n",
       "   'Hymnal',\n",
       "   'of',\n",
       "   '1941',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '830'},\n",
       " {'tokens': ['This',\n",
       "   'was',\n",
       "   'followed',\n",
       "   'by',\n",
       "   'the',\n",
       "   'launch',\n",
       "   'of',\n",
       "   '``',\n",
       "   'GrandPrix+',\n",
       "   '``',\n",
       "   ',',\n",
       "   'an',\n",
       "   'e-magazine',\n",
       "   'developed',\n",
       "   'in',\n",
       "   'partnership',\n",
       "   'with',\n",
       "   'David',\n",
       "   'Tremayne',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 31, 31, 0],\n",
       "  'id': '831'},\n",
       " {'tokens': ['The',\n",
       "   'naval',\n",
       "   'variant',\n",
       "   ',',\n",
       "   'HHQ-9',\n",
       "   '(',\n",
       "   ')',\n",
       "   ',',\n",
       "   'appears',\n",
       "   'to',\n",
       "   'be',\n",
       "   'identical',\n",
       "   'to',\n",
       "   'the',\n",
       "   'land-based',\n",
       "   'variant',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '832'},\n",
       " {'tokens': ['They',\n",
       "   'participated',\n",
       "   'in',\n",
       "   'a',\n",
       "   'prayer',\n",
       "   'in',\n",
       "   'the',\n",
       "   'church',\n",
       "   ',',\n",
       "   'toured',\n",
       "   'an',\n",
       "   'exhibit',\n",
       "   'created',\n",
       "   'by',\n",
       "   'the',\n",
       "   'St.',\n",
       "   'Sava',\n",
       "   'Church',\n",
       "   'Historical',\n",
       "   'Society',\n",
       "   ',',\n",
       "   'viewed',\n",
       "   'a',\n",
       "   'performance',\n",
       "   'by',\n",
       "   'the',\n",
       "   'St.',\n",
       "   'Sava',\n",
       "   'Church',\n",
       "   'Children',\n",
       "   \"'s\",\n",
       "   'Choir',\n",
       "   ',',\n",
       "   'and',\n",
       "   'then',\n",
       "   'attended',\n",
       "   'a',\n",
       "   'special',\n",
       "   'humanitarian',\n",
       "   'fundraising',\n",
       "   'banquet',\n",
       "   'taking',\n",
       "   'place',\n",
       "   'in',\n",
       "   'the',\n",
       "   'event',\n",
       "   'center',\n",
       "   'at',\n",
       "   'St.',\n",
       "   'Sava',\n",
       "   'Church',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0],\n",
       "  'id': '833'},\n",
       " {'tokens': ['After',\n",
       "   'closing',\n",
       "   'in',\n",
       "   '2007',\n",
       "   ',',\n",
       "   'the',\n",
       "   'ride',\n",
       "   'was',\n",
       "   'demolished',\n",
       "   'and',\n",
       "   'sold',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Brazilian',\n",
       "   'theme',\n",
       "   'park',\n",
       "   'Beto',\n",
       "   'Carrero',\n",
       "   'World',\n",
       "   ',',\n",
       "   'but',\n",
       "   'was',\n",
       "   'never',\n",
       "   're-assembled',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   26,\n",
       "   26,\n",
       "   26,\n",
       "   26,\n",
       "   26,\n",
       "   26,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '834'},\n",
       " {'tokens': ['His',\n",
       "   'tenure',\n",
       "   'also',\n",
       "   'saw',\n",
       "   'the',\n",
       "   'annexation',\n",
       "   'of',\n",
       "   'Upper',\n",
       "   'Burma',\n",
       "   'in',\n",
       "   '1886',\n",
       "   ',',\n",
       "   'after',\n",
       "   'many',\n",
       "   'years',\n",
       "   'of',\n",
       "   'simmering',\n",
       "   'warfare',\n",
       "   'and',\n",
       "   'British',\n",
       "   'interventions',\n",
       "   'in',\n",
       "   'Burmese',\n",
       "   'politics',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '835'},\n",
       " {'tokens': ['Bryan',\n",
       "   'Cranston',\n",
       "   'reprised',\n",
       "   'his',\n",
       "   'role',\n",
       "   'as',\n",
       "   'Johnson',\n",
       "   'from',\n",
       "   'the',\n",
       "   '2014',\n",
       "   'Broadway',\n",
       "   'production',\n",
       "   'of',\n",
       "   'the',\n",
       "   'play',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 7, 0, 0, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [50, 50, 0, 0, 0, 0, 55, 0, 0, 0, 14, 0, 0, 0, 0, 0],\n",
       "  'id': '836'},\n",
       " {'tokens': ['In',\n",
       "   '1542',\n",
       "   ',',\n",
       "   'during',\n",
       "   'the',\n",
       "   'Reformation',\n",
       "   'in',\n",
       "   'Pfalz-Neuburg',\n",
       "   ',',\n",
       "   'it',\n",
       "   'was',\n",
       "   'placed',\n",
       "   'under',\n",
       "   'secular',\n",
       "   'administration',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 18, 18, 18, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '837'},\n",
       " {'tokens': ['The',\n",
       "   'river',\n",
       "   \"'s\",\n",
       "   'source',\n",
       "   'is',\n",
       "   'north-east',\n",
       "   'of',\n",
       "   'the',\n",
       "   'town',\n",
       "   'of',\n",
       "   'Waihi',\n",
       "   ',',\n",
       "   'close',\n",
       "   'to',\n",
       "   'the',\n",
       "   'shore',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Bay',\n",
       "   'of',\n",
       "   'Plenty',\n",
       "   ',',\n",
       "   'but',\n",
       "   'flows',\n",
       "   'west',\n",
       "   'rather',\n",
       "   'than',\n",
       "   'into',\n",
       "   'the',\n",
       "   'bay',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '838'},\n",
       " {'tokens': ['In',\n",
       "   '1984',\n",
       "   'VCCA',\n",
       "   'and',\n",
       "   'Associated',\n",
       "   'University',\n",
       "   'Presses',\n",
       "   'released',\n",
       "   'what',\n",
       "   'was',\n",
       "   'termed',\n",
       "   'the',\n",
       "   'first',\n",
       "   'work',\n",
       "   'published',\n",
       "   'by',\n",
       "   'an',\n",
       "   'artists',\n",
       "   \"'\",\n",
       "   'community',\n",
       "   ':',\n",
       "   '``',\n",
       "   'From',\n",
       "   'Mt',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   31,\n",
       "   31,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '839'},\n",
       " {'tokens': ['(',\n",
       "   'Other',\n",
       "   'peaks',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Stikine',\n",
       "   'Icecap',\n",
       "   'are',\n",
       "   'higher',\n",
       "   'than',\n",
       "   ',',\n",
       "   'but',\n",
       "   'they',\n",
       "   'have',\n",
       "   'relatively',\n",
       "   'low',\n",
       "   'topographic',\n",
       "   'prominence',\n",
       "   '.',\n",
       "   ')'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 25, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '840'},\n",
       " {'tokens': ['He',\n",
       "   'is',\n",
       "   'the',\n",
       "   'principal',\n",
       "   'timpanist',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Boston',\n",
       "   'Symphony',\n",
       "   'Orchestra',\n",
       "   ',',\n",
       "   'a',\n",
       "   'position',\n",
       "   'he',\n",
       "   'has',\n",
       "   'held',\n",
       "   'since',\n",
       "   '2003',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 35, 35, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '841'},\n",
       " {'tokens': ['The',\n",
       "   'Shuttle',\n",
       "   'was',\n",
       "   'not',\n",
       "   'launched',\n",
       "   'under',\n",
       "   'conditions',\n",
       "   'where',\n",
       "   'it',\n",
       "   'could',\n",
       "   'have',\n",
       "   'been',\n",
       "   'struck',\n",
       "   'by',\n",
       "   'lightning',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '842'},\n",
       " {'tokens': ['The',\n",
       "   'frets',\n",
       "   '(',\n",
       "   '2.3',\n",
       "   ')',\n",
       "   'are',\n",
       "   'thin',\n",
       "   'metal',\n",
       "   'strips',\n",
       "   'that',\n",
       "   'stop',\n",
       "   'the',\n",
       "   'string',\n",
       "   'at',\n",
       "   'the',\n",
       "   'correct',\n",
       "   'pitch',\n",
       "   'when',\n",
       "   'the',\n",
       "   'player',\n",
       "   'pushes',\n",
       "   'a',\n",
       "   'string',\n",
       "   'against',\n",
       "   'the',\n",
       "   'fingerboard',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '843'},\n",
       " {'tokens': ['On',\n",
       "   'December',\n",
       "   '2',\n",
       "   ',',\n",
       "   '1977',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Fort',\n",
       "   'De',\n",
       "   'Soto',\n",
       "   'batteries',\n",
       "   'were',\n",
       "   'placed',\n",
       "   'on',\n",
       "   'the',\n",
       "   'National',\n",
       "   'Register',\n",
       "   'of',\n",
       "   'Historic',\n",
       "   'Places',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0],\n",
       "  'id': '844'},\n",
       " {'tokens': ['The',\n",
       "   'New',\n",
       "   'Jersey',\n",
       "   'Higher',\n",
       "   'Education',\n",
       "   'Student',\n",
       "   'Assistance',\n",
       "   'Authority',\n",
       "   '(',\n",
       "   'NJHESAA',\n",
       "   ')',\n",
       "   'manages',\n",
       "   'these',\n",
       "   'programs',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 5, 5, 5, 5, 5, 5, 5, 0, 5, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 30, 30, 30, 30, 30, 30, 30, 0, 30, 0, 0, 0, 0, 0],\n",
       "  'id': '845'},\n",
       " {'tokens': ['According',\n",
       "   'to',\n",
       "   'the',\n",
       "   'narrative',\n",
       "   'in',\n",
       "   '1',\n",
       "   'Maccabees',\n",
       "   ',',\n",
       "   'Jonathan',\n",
       "   'Apphus',\n",
       "   'was',\n",
       "   'the',\n",
       "   'youngest',\n",
       "   'of',\n",
       "   'the',\n",
       "   'five',\n",
       "   'sons',\n",
       "   'of',\n",
       "   'Mattathias',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 1, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 6, 0, 54, 54, 0, 0, 0, 0, 0, 0, 0, 0, 54, 0],\n",
       "  'id': '846'},\n",
       " {'tokens': ['This',\n",
       "   'gene',\n",
       "   'encodes',\n",
       "   'a',\n",
       "   'subunit',\n",
       "   'of',\n",
       "   'mitochondrial',\n",
       "   'ATP',\n",
       "   'synthase',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 6, 6, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 40, 40, 0],\n",
       "  'id': '847'},\n",
       " {'tokens': ['He',\n",
       "   'has',\n",
       "   'worked',\n",
       "   'for',\n",
       "   'the',\n",
       "   'Federal',\n",
       "   'Bureau',\n",
       "   'of',\n",
       "   'Investigation',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Governor',\n",
       "   'of',\n",
       "   'Oklahoma',\n",
       "   'and',\n",
       "   'in',\n",
       "   'local',\n",
       "   'law',\n",
       "   'enforcement',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '848'},\n",
       " {'tokens': ['The',\n",
       "   '2007',\n",
       "   'Strauss',\n",
       "   'Canada',\n",
       "   'Cup',\n",
       "   'of',\n",
       "   'Curling',\n",
       "   'was',\n",
       "   'held',\n",
       "   'March',\n",
       "   '13-18',\n",
       "   ',',\n",
       "   '2007',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Interior',\n",
       "   'Savings',\n",
       "   'Centre',\n",
       "   'in',\n",
       "   'Kamloops',\n",
       "   ',',\n",
       "   'British',\n",
       "   'Columbia',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '849'},\n",
       " {'tokens': ['Todd',\n",
       "   'Franklin',\n",
       "   'Collins',\n",
       "   '(',\n",
       "   'born',\n",
       "   'May',\n",
       "   '27',\n",
       "   ',',\n",
       "   '1970',\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'former',\n",
       "   'National',\n",
       "   'Football',\n",
       "   'League',\n",
       "   'linebacker',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 0, 0],\n",
       "  'fine_tags': [52, 52, 52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 36, 36, 0, 0],\n",
       "  'id': '850'},\n",
       " {'tokens': ['One',\n",
       "   'Turkish',\n",
       "   'lira',\n",
       "   'is',\n",
       "   'subdivided',\n",
       "   'into',\n",
       "   'one',\n",
       "   'hundred',\n",
       "   '``',\n",
       "   'kuruş',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 6, 6, 0, 0, 0, 0, 0, 0, 6, 0, 0],\n",
       "  'fine_tags': [0, 42, 42, 0, 0, 0, 0, 0, 0, 42, 0, 0],\n",
       "  'id': '851'},\n",
       " {'tokens': ['But',\n",
       "   'for',\n",
       "   'an',\n",
       "   'unknown',\n",
       "   'reason',\n",
       "   ',',\n",
       "   'these',\n",
       "   'friends',\n",
       "   'suddenly',\n",
       "   'fell',\n",
       "   'from',\n",
       "   'favour',\n",
       "   'around',\n",
       "   'the',\n",
       "   'year',\n",
       "   '1050',\n",
       "   ',',\n",
       "   'and',\n",
       "   'presumably',\n",
       "   'on',\n",
       "   'this',\n",
       "   'occasion',\n",
       "   ',',\n",
       "   'Mauropous',\n",
       "   'was',\n",
       "   'appointed',\n",
       "   'metropolitan',\n",
       "   'of',\n",
       "   'Euchaita',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   56,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '852'},\n",
       " {'tokens': ['After',\n",
       "   'a',\n",
       "   'period',\n",
       "   'of',\n",
       "   'increasing',\n",
       "   'plantations',\n",
       "   'of',\n",
       "   'red',\n",
       "   'grape',\n",
       "   'varieties',\n",
       "   'the',\n",
       "   'balance',\n",
       "   'between',\n",
       "   'red',\n",
       "   'and',\n",
       "   'white',\n",
       "   'varieties',\n",
       "   'has',\n",
       "   'been',\n",
       "   'more',\n",
       "   'stable',\n",
       "   'in',\n",
       "   'the',\n",
       "   'last',\n",
       "   'few',\n",
       "   'years',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   60,\n",
       "   60,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '853'},\n",
       " {'tokens': ['Eta',\n",
       "   'Cephei',\n",
       "   '(',\n",
       "   'η',\n",
       "   'Cep',\n",
       "   ',',\n",
       "   'η',\n",
       "   'Cephei',\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'star',\n",
       "   'in',\n",
       "   'the',\n",
       "   'northern',\n",
       "   'circumpolar',\n",
       "   'constellation',\n",
       "   'of',\n",
       "   'Cepheus',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 6, 0, 6, 6, 0, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0],\n",
       "  'fine_tags': [38,\n",
       "   38,\n",
       "   0,\n",
       "   38,\n",
       "   38,\n",
       "   0,\n",
       "   38,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0],\n",
       "  'id': '854'},\n",
       " {'tokens': ['The',\n",
       "   '10th',\n",
       "   'Panzer',\n",
       "   'Division',\n",
       "   ',',\n",
       "   'like',\n",
       "   'the',\n",
       "   '2nd',\n",
       "   'Panzer',\n",
       "   'Division',\n",
       "   ',',\n",
       "   'had',\n",
       "   'detached',\n",
       "   'its',\n",
       "   'heavy',\n",
       "   'artillery',\n",
       "   'batteries',\n",
       "   'to',\n",
       "   'support',\n",
       "   'neighbouring',\n",
       "   'units',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '855'},\n",
       " {'tokens': ['Radio',\n",
       "   'announcer',\n",
       "   'Neil',\n",
       "   'Mitchell',\n",
       "   'described',\n",
       "   'the',\n",
       "   'hoax',\n",
       "   'as',\n",
       "   '``',\n",
       "   'immature',\n",
       "   \"''\",\n",
       "   'and',\n",
       "   'pondered',\n",
       "   'whether',\n",
       "   'it',\n",
       "   'demeaned',\n",
       "   'her',\n",
       "   'office',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 54, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '856'},\n",
       " {'tokens': ['The',\n",
       "   '2001',\n",
       "   'GDP',\n",
       "   'of',\n",
       "   'Hangzhou',\n",
       "   'was',\n",
       "   'RMB',\n",
       "   '156.8',\n",
       "   'billion',\n",
       "   ',',\n",
       "   'which',\n",
       "   'ranked',\n",
       "   'second',\n",
       "   'among',\n",
       "   'all',\n",
       "   'of',\n",
       "   'the',\n",
       "   'provincial',\n",
       "   'capitals',\n",
       "   'after',\n",
       "   'Guangzhou',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   42,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '857'},\n",
       " {'tokens': ['Patras',\n",
       "   'will',\n",
       "   'also',\n",
       "   'be',\n",
       "   'the',\n",
       "   'central',\n",
       "   'hub',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Ionia',\n",
       "   'Odos',\n",
       "   'highway',\n",
       "   ',',\n",
       "   'intended',\n",
       "   'to',\n",
       "   'bridge',\n",
       "   'western',\n",
       "   'Greece',\n",
       "   'from',\n",
       "   'Kalamata',\n",
       "   'to',\n",
       "   'Ioannina',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '858'},\n",
       " {'tokens': ['After',\n",
       "   'transferring',\n",
       "   'to',\n",
       "   'Ohio',\n",
       "   'State',\n",
       "   ',',\n",
       "   'he',\n",
       "   'continued',\n",
       "   'wrestling',\n",
       "   'and',\n",
       "   'was',\n",
       "   'a',\n",
       "   'walk-on',\n",
       "   'to',\n",
       "   'the',\n",
       "   'football',\n",
       "   'team',\n",
       "   'for',\n",
       "   'the',\n",
       "   '2014',\n",
       "   'season',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '859'},\n",
       " {'tokens': ['She',\n",
       "   'has',\n",
       "   'an',\n",
       "   'older',\n",
       "   'brother',\n",
       "   ',',\n",
       "   'Mark',\n",
       "   ',',\n",
       "   'who',\n",
       "   'is',\n",
       "   'also',\n",
       "   'a',\n",
       "   'curler',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 54, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '860'},\n",
       " {'tokens': ['The',\n",
       "   'group',\n",
       "   'members',\n",
       "   'said',\n",
       "   'that',\n",
       "   'they',\n",
       "   'were',\n",
       "   'law-abiding',\n",
       "   'religious',\n",
       "   'pilgrims',\n",
       "   'there',\n",
       "   'to',\n",
       "   'await',\n",
       "   'the',\n",
       "   'return',\n",
       "   'of',\n",
       "   'Jesus',\n",
       "   'but',\n",
       "   'had',\n",
       "   'no',\n",
       "   'plans',\n",
       "   'to',\n",
       "   'participate',\n",
       "   'in',\n",
       "   'any',\n",
       "   'illegal',\n",
       "   'activity',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   45,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '861'},\n",
       " {'tokens': ['Ōyama',\n",
       "   'was',\n",
       "   'well',\n",
       "   'versed',\n",
       "   'in',\n",
       "   'Japanese',\n",
       "   'and',\n",
       "   'Chinese',\n",
       "   'literature',\n",
       "   ',',\n",
       "   'and',\n",
       "   'agreed',\n",
       "   'to',\n",
       "   'find',\n",
       "   'a',\n",
       "   'suitable',\n",
       "   'Japanese',\n",
       "   'poem',\n",
       "   'that',\n",
       "   'could',\n",
       "   'be',\n",
       "   'set',\n",
       "   'to',\n",
       "   'music',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [57,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '862'},\n",
       " {'tokens': ['Bates',\n",
       "   'made',\n",
       "   'two',\n",
       "   'first-class',\n",
       "   'appearances',\n",
       "   'for',\n",
       "   'Nottinghamshire',\n",
       "   'in',\n",
       "   '1878',\n",
       "   ',',\n",
       "   'against',\n",
       "   'Derbyshire',\n",
       "   'at',\n",
       "   'Trent',\n",
       "   'Bridge',\n",
       "   'and',\n",
       "   'Yorkshire',\n",
       "   'at',\n",
       "   'Bramall',\n",
       "   'Lane',\n",
       "   ',',\n",
       "   'scoring',\n",
       "   'just',\n",
       "   '5',\n",
       "   'runs',\n",
       "   'in',\n",
       "   'his',\n",
       "   'two',\n",
       "   'matches',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '863'},\n",
       " {'tokens': ['Bounovoglia',\n",
       "   'however',\n",
       "   ',',\n",
       "   'made',\n",
       "   'an',\n",
       "   'appearance',\n",
       "   'in',\n",
       "   'the',\n",
       "   'FIFA',\n",
       "   'Club',\n",
       "   'World',\n",
       "   'Championship',\n",
       "   '2005',\n",
       "   'in',\n",
       "   'Japan',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 0, 0, 4, 0],\n",
       "  'fine_tags': [52, 0, 0, 0, 0, 0, 0, 0, 36, 36, 36, 36, 0, 0, 21, 0],\n",
       "  'id': '864'},\n",
       " {'tokens': ['Arnoldo',\n",
       "   'Vizcaíno',\n",
       "   'Rodríguez',\n",
       "   'is',\n",
       "   'a',\n",
       "   'Mexican',\n",
       "   'politician',\n",
       "   ',',\n",
       "   'founder',\n",
       "   'and',\n",
       "   'former',\n",
       "   'chairman',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Party',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Democratic',\n",
       "   'Revolution',\n",
       "   'chapter',\n",
       "   'in',\n",
       "   'the',\n",
       "   'state',\n",
       "   'of',\n",
       "   'Colima',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [55,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '865'},\n",
       " {'tokens': ['Next',\n",
       "   'Airports',\n",
       "   'are',\n",
       "   'in',\n",
       "   'Friedrichshafen',\n",
       "   'Airport',\n",
       "   '(',\n",
       "   '32',\n",
       "   'km',\n",
       "   ')',\n",
       "   'with',\n",
       "   'mostly',\n",
       "   'domestic',\n",
       "   'destinations',\n",
       "   'and',\n",
       "   'Zurich',\n",
       "   'Airport',\n",
       "   '(',\n",
       "   '100',\n",
       "   'km',\n",
       "   ')',\n",
       "   'with',\n",
       "   'international',\n",
       "   'destinations',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '866'},\n",
       " {'tokens': ['‡',\n",
       "   'The',\n",
       "   'list',\n",
       "   'of',\n",
       "   'file',\n",
       "   'formats',\n",
       "   'that',\n",
       "   'CorelDraw',\n",
       "   '10',\n",
       "   'to',\n",
       "   'X4',\n",
       "   'can',\n",
       "   'write',\n",
       "   'may',\n",
       "   'not',\n",
       "   'be',\n",
       "   'complete',\n",
       "   'in',\n",
       "   'this',\n",
       "   'table',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '867'},\n",
       " {'tokens': ['These',\n",
       "   'libraries',\n",
       "   'have',\n",
       "   'begun',\n",
       "   'digitizing',\n",
       "   'books',\n",
       "   'of',\n",
       "   'theirs',\n",
       "   'that',\n",
       "   'are',\n",
       "   'in',\n",
       "   'the',\n",
       "   'public',\n",
       "   'domain',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '868'},\n",
       " {'tokens': ['Lang',\n",
       "   'was',\n",
       "   'later',\n",
       "   'lampooned',\n",
       "   'in',\n",
       "   'Punch',\n",
       "   'for',\n",
       "   'a',\n",
       "   'lack',\n",
       "   'of',\n",
       "   '``',\n",
       "   'Christian',\n",
       "   'charity',\n",
       "   \"''\",\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [54, 0, 0, 0, 0, 31, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '869'},\n",
       " {'tokens': ['Kobayashi',\n",
       "   'ate',\n",
       "   '58.5',\n",
       "   'at',\n",
       "   'Crif',\n",
       "   'dog',\n",
       "   'classic',\n",
       "   ',',\n",
       "   'eating',\n",
       "   'a',\n",
       "   'different',\n",
       "   'type',\n",
       "   'hot',\n",
       "   'dog',\n",
       "   'from',\n",
       "   'Nathan',\n",
       "   \"'s\",\n",
       "   'Famous',\n",
       "   'Fourth',\n",
       "   'of',\n",
       "   'July',\n",
       "   'International',\n",
       "   'Hot',\n",
       "   'Dog',\n",
       "   'Eating',\n",
       "   'Contest',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   18,\n",
       "   0],\n",
       "  'id': '870'},\n",
       " {'tokens': ['It',\n",
       "   'was',\n",
       "   'bifurcated',\n",
       "   'in',\n",
       "   '2005',\n",
       "   'with',\n",
       "   'the',\n",
       "   'formation',\n",
       "   'of',\n",
       "   'Guru',\n",
       "   'Angad',\n",
       "   'Dev',\n",
       "   'Veterinary',\n",
       "   'and',\n",
       "   'Animal',\n",
       "   'Sciences',\n",
       "   'University',\n",
       "   '(',\n",
       "   'GADVASU',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   29,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '871'},\n",
       " {'tokens': ['Virtually',\n",
       "   'all',\n",
       "   'Egyptologists',\n",
       "   'and',\n",
       "   'scholars',\n",
       "   'currently',\n",
       "   'believe',\n",
       "   'that',\n",
       "   'the',\n",
       "   'face',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Sphinx',\n",
       "   'represents',\n",
       "   'the',\n",
       "   'likeness',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Pharaoh',\n",
       "   'Khafra',\n",
       "   ',',\n",
       "   'although',\n",
       "   'a',\n",
       "   'few',\n",
       "   'Egyptologists',\n",
       "   'and',\n",
       "   'interested',\n",
       "   'amateurs',\n",
       "   'have',\n",
       "   'proposed',\n",
       "   'several',\n",
       "   'different',\n",
       "   'hypotheses',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   45,\n",
       "   45,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '872'},\n",
       " {'tokens': ['The',\n",
       "   'terms',\n",
       "   'were',\n",
       "   'later',\n",
       "   'confirmed',\n",
       "   'by',\n",
       "   'the',\n",
       "   'March',\n",
       "   '1801',\n",
       "   'Treaty',\n",
       "   'of',\n",
       "   'Aranjuez',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 6, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 47, 47, 47, 0],\n",
       "  'id': '873'},\n",
       " {'tokens': ['Because',\n",
       "   'of',\n",
       "   'the',\n",
       "   'unfavourable',\n",
       "   'Dutch',\n",
       "   'climate',\n",
       "   ',',\n",
       "   'the',\n",
       "   'classic',\n",
       "   'international',\n",
       "   'grapes',\n",
       "   'Merlot',\n",
       "   'and',\n",
       "   'Cabernet',\n",
       "   'Sauvignon',\n",
       "   'are',\n",
       "   'not',\n",
       "   'planted',\n",
       "   'on',\n",
       "   'a',\n",
       "   'large',\n",
       "   'scale',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   60,\n",
       "   0,\n",
       "   60,\n",
       "   60,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '874'},\n",
       " {'tokens': ['The',\n",
       "   'Ariel',\n",
       "   'Awards',\n",
       "   'are',\n",
       "   'awarded',\n",
       "   'annually',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Mexican',\n",
       "   'Academy',\n",
       "   'of',\n",
       "   'Film',\n",
       "   'Arts',\n",
       "   'and',\n",
       "   'Sciences',\n",
       "   'in',\n",
       "   'Mexico',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 6, 6, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 4, 0],\n",
       "  'fine_tags': [39,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '875'},\n",
       " {'tokens': ['West',\n",
       "   'headed',\n",
       "   'the',\n",
       "   'USAF',\n",
       "   \"'s\",\n",
       "   'Project',\n",
       "   'Giza',\n",
       "   '(',\n",
       "   'also',\n",
       "   'known',\n",
       "   'as',\n",
       "   'the',\n",
       "   'Stargate',\n",
       "   'Project',\n",
       "   ')',\n",
       "   ',',\n",
       "   'the',\n",
       "   'forerunner',\n",
       "   'of',\n",
       "   'the',\n",
       "   'SGC',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [57,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '876'},\n",
       " {'tokens': ['The',\n",
       "   'Camellia',\n",
       "   'to',\n",
       "   'Carlingford',\n",
       "   'section',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Carlingford',\n",
       "   'railway',\n",
       "   'line',\n",
       "   'is',\n",
       "   'being',\n",
       "   'converted',\n",
       "   'to',\n",
       "   'light',\n",
       "   'rail',\n",
       "   'as',\n",
       "   'part',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Parramatta',\n",
       "   'Light',\n",
       "   'Rail',\n",
       "   'project',\n",
       "   'with',\n",
       "   'the',\n",
       "   'line',\n",
       "   'closed',\n",
       "   '5',\n",
       "   'January',\n",
       "   '2020',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   62,\n",
       "   62,\n",
       "   62,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '877'},\n",
       " {'tokens': ['During',\n",
       "   '2004',\n",
       "   'he',\n",
       "   'toured',\n",
       "   'Australia',\n",
       "   'and',\n",
       "   'Europe',\n",
       "   'performing',\n",
       "   'semi-improvised',\n",
       "   'music',\n",
       "   'to',\n",
       "   'some',\n",
       "   'of',\n",
       "   'these',\n",
       "   'films',\n",
       "   'under',\n",
       "   'the',\n",
       "   'banner',\n",
       "   'of',\n",
       "   'Music',\n",
       "   'for',\n",
       "   'Len',\n",
       "   'Lye',\n",
       "   '(',\n",
       "   'MFLL',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '878'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'subsequently',\n",
       "   'awarded',\n",
       "   'the',\n",
       "   'Medal',\n",
       "   'of',\n",
       "   'Honor',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 6, 6, 6, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 39, 39, 39, 0],\n",
       "  'id': '879'},\n",
       " {'tokens': ['The',\n",
       "   'absence',\n",
       "   'of',\n",
       "   'p21',\n",
       "   'or',\n",
       "   '14-3-3',\n",
       "   'can',\n",
       "   'not',\n",
       "   'sufficiently',\n",
       "   'inhibit',\n",
       "   'the',\n",
       "   'CyclinB-Cdc2',\n",
       "   'complex',\n",
       "   ',',\n",
       "   'thus',\n",
       "   'exhibiting',\n",
       "   'the',\n",
       "   'regulatory',\n",
       "   'control',\n",
       "   'of',\n",
       "   'p53',\n",
       "   'and',\n",
       "   'p21',\n",
       "   'in',\n",
       "   'the',\n",
       "   'G2',\n",
       "   'checkpoint',\n",
       "   'in',\n",
       "   'response',\n",
       "   'to',\n",
       "   'DNA',\n",
       "   'damage',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '880'},\n",
       " {'tokens': ['Musacchio',\n",
       "   'approached',\n",
       "   'structural',\n",
       "   'biology',\n",
       "   'during',\n",
       "   'his',\n",
       "   'Ph.D',\n",
       "   '.',\n",
       "   ',',\n",
       "   'contributing',\n",
       "   'to',\n",
       "   'the',\n",
       "   'determination',\n",
       "   'of',\n",
       "   'the',\n",
       "   'first',\n",
       "   'crystallographic',\n",
       "   'structures',\n",
       "   'of',\n",
       "   'the',\n",
       "   'SH3',\n",
       "   'and',\n",
       "   'PH',\n",
       "   'domains',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   44,\n",
       "   44,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '881'},\n",
       " {'tokens': ['After',\n",
       "   'the',\n",
       "   'race',\n",
       "   ',',\n",
       "   'jockey',\n",
       "   'Tony',\n",
       "   'McCoy',\n",
       "   'said',\n",
       "   ':',\n",
       "   '``',\n",
       "   'He',\n",
       "   'ran',\n",
       "   'OK',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 52, 52, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '882'},\n",
       " {'tokens': ['Barbera',\n",
       "   ',',\n",
       "   'Cabernet',\n",
       "   'Sauvignon',\n",
       "   ',',\n",
       "   'Cabernet',\n",
       "   'Franc',\n",
       "   ',',\n",
       "   'Chardonnay',\n",
       "   ',',\n",
       "   'Grenache',\n",
       "   ',',\n",
       "   'Merlot',\n",
       "   ',',\n",
       "   'Pinot',\n",
       "   'noir',\n",
       "   ',',\n",
       "   'Sauvignon',\n",
       "   'blanc',\n",
       "   'and',\n",
       "   'Syrah',\n",
       "   'are',\n",
       "   'the',\n",
       "   'leading',\n",
       "   'grape',\n",
       "   'varieties',\n",
       "   'planted',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   48,\n",
       "   48,\n",
       "   0,\n",
       "   48,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '883'},\n",
       " {'tokens': ['On',\n",
       "   '22',\n",
       "   'February',\n",
       "   '2019',\n",
       "   'it',\n",
       "   'was',\n",
       "   'announced',\n",
       "   'Chantal',\n",
       "   'Janzen',\n",
       "   'will',\n",
       "   'replace',\n",
       "   'van',\n",
       "   'Dijk',\n",
       "   'as',\n",
       "   'host',\n",
       "   'for',\n",
       "   'the',\n",
       "   'tenth',\n",
       "   'season',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '884'},\n",
       " {'tokens': ['during',\n",
       "   'the',\n",
       "   'reign',\n",
       "   'of',\n",
       "   'Empress',\n",
       "   'Suiko',\n",
       "   ',',\n",
       "   'who',\n",
       "   'invited',\n",
       "   'Ekan',\n",
       "   ',',\n",
       "   'a',\n",
       "   'high-ranking',\n",
       "   'prelate',\n",
       "   'from',\n",
       "   'Goguryeo',\n",
       "   'to',\n",
       "   'introduce',\n",
       "   'Buddhism',\n",
       "   'to',\n",
       "   'the',\n",
       "   'region',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '885'},\n",
       " {'tokens': ['Quincy',\n",
       "   'College',\n",
       "   'operates',\n",
       "   'an',\n",
       "   'articulation',\n",
       "   'agreement',\n",
       "   'with',\n",
       "   'Cambridge',\n",
       "   'College',\n",
       "   'for',\n",
       "   'four-year',\n",
       "   'baccalaureate',\n",
       "   'degrees',\n",
       "   'and',\n",
       "   'with',\n",
       "   'Excelsior',\n",
       "   'College',\n",
       "   'for',\n",
       "   'online',\n",
       "   'learning',\n",
       "   '.'],\n",
       "  'coarse_tags': [2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '886'},\n",
       " {'tokens': ['This',\n",
       "   'allows',\n",
       "   'it',\n",
       "   'to',\n",
       "   'be',\n",
       "   'processed',\n",
       "   'in',\n",
       "   'the',\n",
       "   'same',\n",
       "   'manner',\n",
       "   'as',\n",
       "   'many',\n",
       "   'polyesters',\n",
       "   ',',\n",
       "   'like',\n",
       "   'poly',\n",
       "   '(',\n",
       "   'lactic-co-glycolic',\n",
       "   'acid',\n",
       "   ')',\n",
       "   ',',\n",
       "   'through',\n",
       "   'processes',\n",
       "   'like',\n",
       "   'solvent',\n",
       "   'evaporation',\n",
       "   'and',\n",
       "   'emulsion',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   41,\n",
       "   41,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '887'},\n",
       " {'tokens': ['Upon',\n",
       "   'her',\n",
       "   'arrival',\n",
       "   ',',\n",
       "   'she',\n",
       "   'continued',\n",
       "   'her',\n",
       "   'journey',\n",
       "   'towards',\n",
       "   'British',\n",
       "   'Columbia',\n",
       "   'via',\n",
       "   'the',\n",
       "   'Canadian',\n",
       "   'Pacific',\n",
       "   'Railway',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 4, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 21, 0, 0, 27, 27, 27, 0],\n",
       "  'id': '888'},\n",
       " {'tokens': ['Grand',\n",
       "   'Central',\n",
       "   'finally',\n",
       "   'started',\n",
       "   'operating',\n",
       "   'in',\n",
       "   'December',\n",
       "   '2007',\n",
       "   'using',\n",
       "   'three',\n",
       "   'High',\n",
       "   'Speed',\n",
       "   'Trains',\n",
       "   '.'],\n",
       "  'coarse_tags': [5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 8, 0],\n",
       "  'fine_tags': [28, 28, 0, 0, 0, 0, 0, 0, 0, 0, 65, 65, 65, 0],\n",
       "  'id': '889'},\n",
       " {'tokens': ['``',\n",
       "   'Three',\n",
       "   'to',\n",
       "   'Get',\n",
       "   'Deadly',\n",
       "   '``',\n",
       "   'won',\n",
       "   'the',\n",
       "   '1998',\n",
       "   'Dilys',\n",
       "   'Award',\n",
       "   'presented',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Independent',\n",
       "   'Mystery',\n",
       "   'Booksellers',\n",
       "   'Association',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 1, 1, 1, 1, 0, 0, 0, 0, 6, 6, 0, 0, 0, 5, 5, 5, 5, 0],\n",
       "  'fine_tags': [0, 6, 6, 6, 6, 0, 0, 0, 0, 39, 39, 0, 0, 0, 32, 32, 32, 32, 0],\n",
       "  'id': '890'},\n",
       " {'tokens': ['After',\n",
       "   'a',\n",
       "   'junior',\n",
       "   'and',\n",
       "   'senior',\n",
       "   'football',\n",
       "   'career',\n",
       "   'in',\n",
       "   'Sault',\n",
       "   'Ste',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 52, 52, 0],\n",
       "  'id': '891'},\n",
       " {'tokens': ['She',\n",
       "   'was',\n",
       "   'nominated',\n",
       "   'that',\n",
       "   'same',\n",
       "   'year',\n",
       "   'to',\n",
       "   'the',\n",
       "   '35th',\n",
       "   'Young',\n",
       "   'Artist',\n",
       "   'Awards',\n",
       "   'in',\n",
       "   'the',\n",
       "   'category',\n",
       "   'of',\n",
       "   '``',\n",
       "   'Best',\n",
       "   'Performance',\n",
       "   'in',\n",
       "   'a',\n",
       "   'TV',\n",
       "   'Series',\n",
       "   '-',\n",
       "   'Guest',\n",
       "   'Starring',\n",
       "   'Young',\n",
       "   'Actress',\n",
       "   '17-21',\n",
       "   '``',\n",
       "   'for',\n",
       "   'her',\n",
       "   'appearance',\n",
       "   'in',\n",
       "   '``',\n",
       "   'R.',\n",
       "   'L.',\n",
       "   'Stine',\n",
       "   \"'s\",\n",
       "   'The',\n",
       "   'Haunting',\n",
       "   'Hour',\n",
       "   '``',\n",
       "   'and',\n",
       "   'in',\n",
       "   'the',\n",
       "   'category',\n",
       "   'of',\n",
       "   '``',\n",
       "   'Best',\n",
       "   'Performance',\n",
       "   'in',\n",
       "   'a',\n",
       "   'TV',\n",
       "   'Series',\n",
       "   '-',\n",
       "   'Recurring',\n",
       "   'Young',\n",
       "   'Actress',\n",
       "   '17-21',\n",
       "   '``',\n",
       "   'for',\n",
       "   'her',\n",
       "   'recurring',\n",
       "   'role',\n",
       "   'in',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Killing',\n",
       "   '``',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '892'},\n",
       " {'tokens': ['During',\n",
       "   'the',\n",
       "   '2004',\n",
       "   'election',\n",
       "   'campaign',\n",
       "   ',',\n",
       "   'Sullivan',\n",
       "   \"'s\",\n",
       "   'police',\n",
       "   'record',\n",
       "   'became',\n",
       "   'public',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '893'},\n",
       " {'tokens': ['He',\n",
       "   'threatens',\n",
       "   'with',\n",
       "   'lightning',\n",
       "   'and',\n",
       "   'storm',\n",
       "   ',',\n",
       "   'which',\n",
       "   'would',\n",
       "   'hurt',\n",
       "   'Prometheus',\n",
       "   'badly',\n",
       "   ';',\n",
       "   'an',\n",
       "   'eagle',\n",
       "   'sent',\n",
       "   'by',\n",
       "   'Zeus',\n",
       "   'would',\n",
       "   'come',\n",
       "   'to',\n",
       "   'eat',\n",
       "   'Prometheus',\n",
       "   \"'s\",\n",
       "   'liver',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   45,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   45,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   45,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '894'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'also',\n",
       "   'part',\n",
       "   'of',\n",
       "   'a',\n",
       "   'group',\n",
       "   'of',\n",
       "   'investors',\n",
       "   'who',\n",
       "   'built',\n",
       "   'the',\n",
       "   'Pierre',\n",
       "   'Hotel',\n",
       "   'in',\n",
       "   'Manhattan',\n",
       "   ',',\n",
       "   'which',\n",
       "   'opened',\n",
       "   'in',\n",
       "   '1930',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   9,\n",
       "   9,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '895'},\n",
       " {'tokens': ['State',\n",
       "   'Highways',\n",
       "   '6',\n",
       "   'and',\n",
       "   '9',\n",
       "   'intersect',\n",
       "   'at',\n",
       "   'the',\n",
       "   'southern',\n",
       "   'end',\n",
       "   'of',\n",
       "   'town',\n",
       "   ';',\n",
       "   'Highway',\n",
       "   '6',\n",
       "   'leads',\n",
       "   'north',\n",
       "   'to',\n",
       "   'Elk',\n",
       "   'City',\n",
       "   'and',\n",
       "   'south',\n",
       "   'to',\n",
       "   'Altus',\n",
       "   ',',\n",
       "   'while',\n",
       "   'Highway',\n",
       "   '9',\n",
       "   'leads',\n",
       "   'east',\n",
       "   'to',\n",
       "   'Hobart',\n",
       "   'and',\n",
       "   'west',\n",
       "   'then',\n",
       "   'south',\n",
       "   'to',\n",
       "   'Mangum',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '896'},\n",
       " {'tokens': ['Emperor',\n",
       "   'Xuan',\n",
       "   'commissioned',\n",
       "   'five',\n",
       "   'generals',\n",
       "   'and',\n",
       "   'coordinated',\n",
       "   'a',\n",
       "   'plan',\n",
       "   'with',\n",
       "   'Wusun',\n",
       "   'to',\n",
       "   'attack',\n",
       "   'Xiongnu',\n",
       "   'at',\n",
       "   'the',\n",
       "   'same',\n",
       "   'time',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 4, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [55, 55, 0, 0, 0, 0, 0, 0, 0, 0, 55, 0, 0, 21, 0, 0, 0, 0, 0],\n",
       "  'id': '897'},\n",
       " {'tokens': ['Main',\n",
       "   'actress',\n",
       "   ',',\n",
       "   'Arcelia',\n",
       "   'Ramírez',\n",
       "   ',',\n",
       "   'received',\n",
       "   'a',\n",
       "   'nomination',\n",
       "   'for',\n",
       "   'Best',\n",
       "   'Actress',\n",
       "   'at',\n",
       "   'the',\n",
       "   '60th',\n",
       "   'Ariel',\n",
       "   'Awards',\n",
       "   'for',\n",
       "   'this',\n",
       "   'film',\n",
       "   'and',\n",
       "   'won',\n",
       "   'the',\n",
       "   'Silver',\n",
       "   'Goddess',\n",
       "   'given',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Mexican',\n",
       "   'Journalists',\n",
       "   'Association',\n",
       "   'for',\n",
       "   'Best',\n",
       "   'Actress',\n",
       "   'at',\n",
       "   'the',\n",
       "   '47th',\n",
       "   'Diosas',\n",
       "   'de',\n",
       "   'Plata',\n",
       "   'award',\n",
       "   'ceremony',\n",
       "   'in',\n",
       "   '2018',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   50,\n",
       "   50,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '898'},\n",
       " {'tokens': ['The',\n",
       "   'Strykers',\n",
       "   'played',\n",
       "   '60',\n",
       "   'games',\n",
       "   'in',\n",
       "   'their',\n",
       "   'inaugural',\n",
       "   'season',\n",
       "   'against',\n",
       "   'six',\n",
       "   'other',\n",
       "   'teams',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Texas',\n",
       "   'Collegiate',\n",
       "   'League',\n",
       "   ',',\n",
       "   'including',\n",
       "   '30',\n",
       "   'home',\n",
       "   'games',\n",
       "   'at',\n",
       "   'The',\n",
       "   'Woodlands',\n",
       "   'Christian',\n",
       "   'Academy',\n",
       "   'in',\n",
       "   'the',\n",
       "   'season',\n",
       "   'that',\n",
       "   'began',\n",
       "   'on',\n",
       "   'June',\n",
       "   '1',\n",
       "   ',',\n",
       "   '2012',\n",
       "   '.'],\n",
       "  'coarse_tags': [5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   36,\n",
       "   36,\n",
       "   36,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '899'},\n",
       " {'tokens': ['Having',\n",
       "   'lost',\n",
       "   'her',\n",
       "   'jester-like',\n",
       "   'puppet',\n",
       "   ',',\n",
       "   'she',\n",
       "   'wrote',\n",
       "   'two',\n",
       "   'new',\n",
       "   'plays',\n",
       "   'and',\n",
       "   'performed',\n",
       "   'them',\n",
       "   'with',\n",
       "   'her',\n",
       "   'husband',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '900'},\n",
       " {'tokens': ['It',\n",
       "   'is',\n",
       "   'owned',\n",
       "   'and',\n",
       "   'operated',\n",
       "   'by',\n",
       "   'Dallas',\n",
       "   'Area',\n",
       "   'Rapid',\n",
       "   'Transit',\n",
       "   ',',\n",
       "   'whose',\n",
       "   'buses',\n",
       "   'mostly',\n",
       "   'serve',\n",
       "   'Dallas',\n",
       "   'Executive',\n",
       "   'Airport',\n",
       "   'and',\n",
       "   'Southwest',\n",
       "   'Center',\n",
       "   'Mall',\n",
       "   'within',\n",
       "   'this',\n",
       "   'transit',\n",
       "   'center',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '901'},\n",
       " {'tokens': ['When',\n",
       "   'Philip',\n",
       "   'of',\n",
       "   'Hesse',\n",
       "   'formed',\n",
       "   'the',\n",
       "   'Schmalkaldic',\n",
       "   'League',\n",
       "   'at',\n",
       "   'the',\n",
       "   'end',\n",
       "   'of',\n",
       "   '1530',\n",
       "   ',',\n",
       "   'the',\n",
       "   'four',\n",
       "   'cities',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Tetrapolitan',\n",
       "   'Confession',\n",
       "   'joined',\n",
       "   'on',\n",
       "   'the',\n",
       "   'basis',\n",
       "   'of',\n",
       "   'a',\n",
       "   'Lutheran',\n",
       "   'interpretation',\n",
       "   'of',\n",
       "   'that',\n",
       "   'confession',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   7,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   54,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   34,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '902'},\n",
       " {'tokens': ['Wahaha',\n",
       "   'branded',\n",
       "   'products',\n",
       "   'include',\n",
       "   'milk',\n",
       "   'drinks',\n",
       "   '(',\n",
       "   '19',\n",
       "   '%',\n",
       "   ')',\n",
       "   ',',\n",
       "   'soft',\n",
       "   'drinks',\n",
       "   ',',\n",
       "   'bottled',\n",
       "   'water',\n",
       "   '(',\n",
       "   '43',\n",
       "   '%',\n",
       "   ')',\n",
       "   ',',\n",
       "   'bottled',\n",
       "   'tea',\n",
       "   '(',\n",
       "   '19',\n",
       "   '%',\n",
       "   ')',\n",
       "   ',',\n",
       "   'fruit',\n",
       "   'juice',\n",
       "   '(',\n",
       "   '13',\n",
       "   '%',\n",
       "   ')',\n",
       "   ',',\n",
       "   'porridges',\n",
       "   'and',\n",
       "   'its',\n",
       "   'flagship',\n",
       "   'yoghurt',\n",
       "   'beverages',\n",
       "   '(',\n",
       "   '7',\n",
       "   '%',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [60,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '903'},\n",
       " {'tokens': ['5–0',\n",
       "   'and',\n",
       "   'clinch',\n",
       "   'their',\n",
       "   'seventh',\n",
       "   'consecutive',\n",
       "   'S',\n",
       "   'uper',\n",
       "   'League',\n",
       "   'Greece',\n",
       "   'title',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 20, 20, 20, 0, 0],\n",
       "  'id': '904'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'a',\n",
       "   'son',\n",
       "   'of',\n",
       "   'William',\n",
       "   'Winston',\n",
       "   'and',\n",
       "   'Mary',\n",
       "   'Cooper',\n",
       "   'of',\n",
       "   'Tuscumbia',\n",
       "   'Alabama',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 7, 0, 7, 7, 0, 4, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 54, 54, 0, 54, 54, 0, 21, 21, 0],\n",
       "  'id': '905'},\n",
       " {'tokens': ['Minoura',\n",
       "   'was',\n",
       "   'vice-speaker',\n",
       "   'of',\n",
       "   'the',\n",
       "   'House',\n",
       "   'of',\n",
       "   'Representatives',\n",
       "   'from',\n",
       "   'March',\n",
       "   '1904',\n",
       "   'to',\n",
       "   'December',\n",
       "   '1908',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '906'},\n",
       " {'tokens': ['She',\n",
       "   'came',\n",
       "   'to',\n",
       "   'notice',\n",
       "   'when',\n",
       "   'Chiswick',\n",
       "   'Records',\n",
       "   'released',\n",
       "   'an',\n",
       "   'EP',\n",
       "   'by',\n",
       "   'local',\n",
       "   'punk',\n",
       "   'rock',\n",
       "   'band',\n",
       "   'the',\n",
       "   'Drug',\n",
       "   'Addix',\n",
       "   '(',\n",
       "   'originally',\n",
       "   'called',\n",
       "   'Tooting',\n",
       "   'Fruities',\n",
       "   ')',\n",
       "   'with',\n",
       "   'MacColl',\n",
       "   'on',\n",
       "   'backing',\n",
       "   'vocals',\n",
       "   '(',\n",
       "   '``',\n",
       "   'The',\n",
       "   'Drug',\n",
       "   'Addix',\n",
       "   'Make',\n",
       "   'A',\n",
       "   'Record',\n",
       "   \"''\",\n",
       "   ')',\n",
       "   'under',\n",
       "   'the',\n",
       "   'pseudonym',\n",
       "   'Mandy',\n",
       "   'Doubt',\n",
       "   '(',\n",
       "   '1978',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   35,\n",
       "   35,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '907'},\n",
       " {'tokens': ['Goonhilly',\n",
       "   'Satellite',\n",
       "   'Earth',\n",
       "   'Station',\n",
       "   'is',\n",
       "   'a',\n",
       "   'large',\n",
       "   'radiocommunication',\n",
       "   'site',\n",
       "   'located',\n",
       "   'on',\n",
       "   'Goonhilly',\n",
       "   'Downs',\n",
       "   'near',\n",
       "   'Helston',\n",
       "   'on',\n",
       "   'the',\n",
       "   'Lizard',\n",
       "   'peninsula',\n",
       "   'in',\n",
       "   'Cornwall',\n",
       "   ',',\n",
       "   'England',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [25,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   23,\n",
       "   23,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '908'},\n",
       " {'tokens': ['In',\n",
       "   '2018',\n",
       "   ',',\n",
       "   'she',\n",
       "   'interviewed',\n",
       "   'former',\n",
       "   'US',\n",
       "   'president',\n",
       "   'Barack',\n",
       "   'Obama',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 4, 0, 7, 7, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 21, 0, 55, 55, 0],\n",
       "  'id': '909'},\n",
       " {'tokens': ['In',\n",
       "   'July',\n",
       "   '2007',\n",
       "   ',',\n",
       "   'Fender',\n",
       "   'released',\n",
       "   'the',\n",
       "   'Jim',\n",
       "   'Root',\n",
       "   'Telecaster',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 5, 0, 0, 8, 8, 8, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 28, 0, 0, 62, 62, 62, 0],\n",
       "  'id': '910'},\n",
       " {'tokens': ['The',\n",
       "   'film',\n",
       "   'was',\n",
       "   'remade',\n",
       "   'as',\n",
       "   '``',\n",
       "   'The',\n",
       "   '4',\n",
       "   'Horsemen',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Apocalypse',\n",
       "   '``',\n",
       "   '(',\n",
       "   '1962',\n",
       "   ')',\n",
       "   ',',\n",
       "   'with',\n",
       "   'the',\n",
       "   'setting',\n",
       "   'changed',\n",
       "   'to',\n",
       "   'World',\n",
       "   'War',\n",
       "   'II',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   0],\n",
       "  'id': '911'},\n",
       " {'tokens': ['In',\n",
       "   '2003',\n",
       "   ',',\n",
       "   'she',\n",
       "   'appeared',\n",
       "   'with',\n",
       "   'Tedd',\n",
       "   'Robinson',\n",
       "   'in',\n",
       "   '``',\n",
       "   'Lula',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Sailor',\n",
       "   '``',\n",
       "   'as',\n",
       "   'part',\n",
       "   'of',\n",
       "   'a',\n",
       "   'concert',\n",
       "   'of',\n",
       "   'duets',\n",
       "   'choreographed',\n",
       "   'by',\n",
       "   'Robinson',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   0],\n",
       "  'id': '912'},\n",
       " {'tokens': ['Epcot',\n",
       "   'at',\n",
       "   'Walt',\n",
       "   'Disney',\n",
       "   'World',\n",
       "   ',',\n",
       "   'which',\n",
       "   'is',\n",
       "   'owned',\n",
       "   'by',\n",
       "   'The',\n",
       "   'Walt',\n",
       "   'Disney',\n",
       "   'Company',\n",
       "   ',',\n",
       "   'is',\n",
       "   'highly',\n",
       "   'based',\n",
       "   'on',\n",
       "   'edutainment',\n",
       "   ';',\n",
       "   'the',\n",
       "   'park',\n",
       "   'features',\n",
       "   'attractions',\n",
       "   'that',\n",
       "   'teach',\n",
       "   'about',\n",
       "   'the',\n",
       "   'past',\n",
       "   ',',\n",
       "   'conservation',\n",
       "   ',',\n",
       "   'imagination',\n",
       "   ',',\n",
       "   'future',\n",
       "   'technologies',\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'world',\n",
       "   '.'],\n",
       "  'coarse_tags': [4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [26,\n",
       "   0,\n",
       "   26,\n",
       "   26,\n",
       "   26,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '913'},\n",
       " {'tokens': ['During',\n",
       "   'rare',\n",
       "   'perihelic',\n",
       "   'oppositions',\n",
       "   ',',\n",
       "   'Pallas',\n",
       "   'can',\n",
       "   'reach',\n",
       "   'a',\n",
       "   'magnitude',\n",
       "   'of',\n",
       "   '+6.4',\n",
       "   ',',\n",
       "   'right',\n",
       "   'on',\n",
       "   'the',\n",
       "   'edge',\n",
       "   'of',\n",
       "   'naked-eye',\n",
       "   'visibility',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   38,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '914'},\n",
       " {'tokens': ['An',\n",
       "   'initial',\n",
       "   'attempt',\n",
       "   'at',\n",
       "   'sugar',\n",
       "   'cane',\n",
       "   'production',\n",
       "   'in',\n",
       "   'the',\n",
       "   'early',\n",
       "   '1880s',\n",
       "   'at',\n",
       "   'Glen',\n",
       "   'Isla',\n",
       "   'plantation',\n",
       "   'failed',\n",
       "   'and',\n",
       "   'the',\n",
       "   'estate',\n",
       "   'was',\n",
       "   'subsequently',\n",
       "   'sold',\n",
       "   'and',\n",
       "   'subdivided',\n",
       "   'into',\n",
       "   'small',\n",
       "   'farms',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '915'},\n",
       " {'tokens': ['In',\n",
       "   'the',\n",
       "   'pilot',\n",
       "   'episode',\n",
       "   ',',\n",
       "   'Soleil',\n",
       "   'Moon',\n",
       "   'Frye',\n",
       "   'appeared',\n",
       "   'as',\n",
       "   'Robin',\n",
       "   'Carlucci',\n",
       "   ',',\n",
       "   'J',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 7, 7, 7, 0, 0, 7, 7, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 51, 51, 51, 0, 0, 54, 54, 0, 0, 0],\n",
       "  'id': '916'},\n",
       " {'tokens': ['A',\n",
       "   'few',\n",
       "   'hours',\n",
       "   'after',\n",
       "   'Bowman',\n",
       "   'left',\n",
       "   ',',\n",
       "   'Regan',\n",
       "   'Smith',\n",
       "   'joined',\n",
       "   'the',\n",
       "   'team',\n",
       "   'full-time',\n",
       "   'driving',\n",
       "   'the',\n",
       "   'No',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 7, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 52, 0, 0, 52, 52, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '917'},\n",
       " {'tokens': ['He',\n",
       "   'led',\n",
       "   'the',\n",
       "   'Tar',\n",
       "   'Heels',\n",
       "   'to',\n",
       "   'the',\n",
       "   '1978',\n",
       "   'College',\n",
       "   'World',\n",
       "   'Series',\n",
       "   'and',\n",
       "   'was',\n",
       "   'named',\n",
       "   'a',\n",
       "   'member',\n",
       "   'of',\n",
       "   'the',\n",
       "   'CWS',\n",
       "   'All-Tournament',\n",
       "   'Team',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   37,\n",
       "   0],\n",
       "  'id': '918'},\n",
       " {'tokens': ['``',\n",
       "   'Starship',\n",
       "   'Troopers',\n",
       "   'Online',\n",
       "   '``',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Magestorm',\n",
       "   '``',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Aliens',\n",
       "   'Online',\n",
       "   '``',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Splatterball',\n",
       "   '``',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Godzilla',\n",
       "   'Online',\n",
       "   '``',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Silent',\n",
       "   'Death',\n",
       "   'Online',\n",
       "   '``',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Darkness',\n",
       "   'Falls',\n",
       "   '``',\n",
       "   ',',\n",
       "   'and',\n",
       "   \"'\",\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   61,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '919'},\n",
       " {'tokens': ['It',\n",
       "   'can',\n",
       "   'also',\n",
       "   'phosphorylate',\n",
       "   'components',\n",
       "   'in',\n",
       "   'the',\n",
       "   'upstream',\n",
       "   'portion',\n",
       "   'of',\n",
       "   'the',\n",
       "   'MAPK',\n",
       "   'signalling',\n",
       "   'cascade',\n",
       "   'including',\n",
       "   'Ras',\n",
       "   ',',\n",
       "   'Sos',\n",
       "   ',',\n",
       "   'and',\n",
       "   'the',\n",
       "   'EGF',\n",
       "   'receptor',\n",
       "   'itself',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   40,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '920'},\n",
       " {'tokens': ['They',\n",
       "   'were',\n",
       "   'taken',\n",
       "   'into',\n",
       "   'captivity',\n",
       "   ',',\n",
       "   'but',\n",
       "   'Kingsley',\n",
       "   'died',\n",
       "   'soon',\n",
       "   'after',\n",
       "   'from',\n",
       "   'his',\n",
       "   'injuries',\n",
       "   ',',\n",
       "   'which',\n",
       "   'included',\n",
       "   'a',\n",
       "   'gunshot',\n",
       "   'wound',\n",
       "   'in',\n",
       "   'his',\n",
       "   'abdomen',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '921'},\n",
       " {'tokens': ['After',\n",
       "   'a',\n",
       "   'last',\n",
       "   'deployment',\n",
       "   'USS',\n",
       "   '``',\n",
       "   'John',\n",
       "   'F.',\n",
       "   'Kennedy',\n",
       "   '``',\n",
       "   'with',\n",
       "   'CVW-17',\n",
       "   'and',\n",
       "   'returning',\n",
       "   'to',\n",
       "   'NAS',\n",
       "   'Oceana',\n",
       "   'in',\n",
       "   'December',\n",
       "   '2004',\n",
       "   ',',\n",
       "   'VF-103',\n",
       "   'retired',\n",
       "   'their',\n",
       "   'F-14B',\n",
       "   'Tomcats',\n",
       "   'and',\n",
       "   'began',\n",
       "   'transition',\n",
       "   'to',\n",
       "   'the',\n",
       "   'F/A-18F',\n",
       "   'Super',\n",
       "   'Hornet',\n",
       "   'and',\n",
       "   'transfer',\n",
       "   'to',\n",
       "   'Carrier',\n",
       "   'Air',\n",
       "   'Wing',\n",
       "   'Seven',\n",
       "   '(',\n",
       "   'CVW-7',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   63,\n",
       "   63,\n",
       "   63,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '922'},\n",
       " {'tokens': ['Neil',\n",
       "   'served',\n",
       "   'as',\n",
       "   'an',\n",
       "   'East',\n",
       "   'Lothian',\n",
       "   'Councillor',\n",
       "   'for',\n",
       "   'a',\n",
       "   'decade',\n",
       "   'and',\n",
       "   'on',\n",
       "   'the',\n",
       "   'board',\n",
       "   'of',\n",
       "   'several',\n",
       "   'schools',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [55, 0, 0, 0, 21, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '923'},\n",
       " {'tokens': ['The',\n",
       "   'Tory',\n",
       "   'Party',\n",
       "   '(',\n",
       "   'Tories',\n",
       "   ')',\n",
       "   'is',\n",
       "   'the',\n",
       "   'party',\n",
       "   'of',\n",
       "   'reasoned',\n",
       "   'conservatism',\n",
       "   'at',\n",
       "   'Yale',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 5, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0],\n",
       "  'fine_tags': [0, 33, 33, 0, 33, 0, 0, 0, 0, 0, 0, 0, 0, 29, 0],\n",
       "  'id': '924'},\n",
       " {'tokens': ['The',\n",
       "   'name',\n",
       "   'was',\n",
       "   'derived',\n",
       "   'from',\n",
       "   'that',\n",
       "   'of',\n",
       "   'its',\n",
       "   'primary',\n",
       "   'escort',\n",
       "   'ship',\n",
       "   ',',\n",
       "   'the',\n",
       "   'heavy',\n",
       "   'cruiser',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '925'},\n",
       " {'tokens': ['The',\n",
       "   'programme',\n",
       "   'is',\n",
       "   'a',\n",
       "   'teatime',\n",
       "   'chat',\n",
       "   'show',\n",
       "   'consisting',\n",
       "   'of',\n",
       "   'a',\n",
       "   'mixture',\n",
       "   'of',\n",
       "   'celebrity',\n",
       "   'guests',\n",
       "   ',',\n",
       "   'comic',\n",
       "   'stunts',\n",
       "   ',',\n",
       "   'musical',\n",
       "   'performances',\n",
       "   ',',\n",
       "   'and',\n",
       "   'occasionally',\n",
       "   'viewer',\n",
       "   'competitions',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '926'},\n",
       " {'tokens': ['An',\n",
       "   'improved',\n",
       "   'model',\n",
       "   'of',\n",
       "   'the',\n",
       "   'aircraft',\n",
       "   ',',\n",
       "   'designated',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Falcon',\n",
       "   '200',\n",
       "   '``',\n",
       "   ',',\n",
       "   'was',\n",
       "   'developed',\n",
       "   ',',\n",
       "   'which',\n",
       "   'featured',\n",
       "   'more',\n",
       "   'advanced',\n",
       "   'jet',\n",
       "   'engines',\n",
       "   'and',\n",
       "   'other',\n",
       "   'major',\n",
       "   'improvements',\n",
       "   'to',\n",
       "   'increase',\n",
       "   'range',\n",
       "   ',',\n",
       "   'capacity',\n",
       "   'and',\n",
       "   'comfort',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '927'},\n",
       " {'tokens': ['The',\n",
       "   'store',\n",
       "   'is',\n",
       "   'located',\n",
       "   'at',\n",
       "   '35',\n",
       "   'Broad',\n",
       "   'Street',\n",
       "   'in',\n",
       "   'Red',\n",
       "   'Bank',\n",
       "   ',',\n",
       "   'New',\n",
       "   'Jersey',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 27, 27, 27, 27, 27, 27, 0, 21, 21, 0],\n",
       "  'id': '928'},\n",
       " {'tokens': ['The',\n",
       "   'koruna',\n",
       "   'was',\n",
       "   'subdivided',\n",
       "   'into',\n",
       "   '100',\n",
       "   '``',\n",
       "   'haliers',\n",
       "   '``',\n",
       "   '(',\n",
       "   'abbreviated',\n",
       "   'as',\n",
       "   '``',\n",
       "   'hal',\n",
       "   '.',\n",
       "   '``'],\n",
       "  'coarse_tags': [0, 6, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 6, 6, 6, 0],\n",
       "  'fine_tags': [0, 42, 0, 0, 0, 0, 0, 42, 0, 0, 0, 0, 42, 42, 42, 0],\n",
       "  'id': '929'},\n",
       " {'tokens': ['In',\n",
       "   '2011',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'House',\n",
       "   'Appropriations',\n",
       "   'Committee',\n",
       "   'eliminated',\n",
       "   'the',\n",
       "   'entire',\n",
       "   'budget',\n",
       "   'for',\n",
       "   'the',\n",
       "   'Learn',\n",
       "   'and',\n",
       "   'Serve',\n",
       "   'America',\n",
       "   'program',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '930'},\n",
       " {'tokens': ['While',\n",
       "   'imprisoned',\n",
       "   ',',\n",
       "   'Sela',\n",
       "   'filed',\n",
       "   'dozens',\n",
       "   'of',\n",
       "   'court',\n",
       "   'motions',\n",
       "   'every',\n",
       "   'year',\n",
       "   ',',\n",
       "   'most',\n",
       "   'of',\n",
       "   'which',\n",
       "   'focused',\n",
       "   'on',\n",
       "   'inconsequential',\n",
       "   'issues',\n",
       "   'and',\n",
       "   'were',\n",
       "   'rejected',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '931'},\n",
       " {'tokens': ['Plans', 'to', 'move', 'Wimbledon', 'F.C', '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0],\n",
       "  'id': '932'},\n",
       " {'tokens': ['Ngong',\n",
       "   'Ping',\n",
       "   'Cable',\n",
       "   'Car',\n",
       "   'is',\n",
       "   'a',\n",
       "   'long',\n",
       "   'bi-cable',\n",
       "   'gondola',\n",
       "   'lift',\n",
       "   'system',\n",
       "   '(',\n",
       "   'referred',\n",
       "   'to',\n",
       "   'by',\n",
       "   'its',\n",
       "   'operators',\n",
       "   'as',\n",
       "   'a',\n",
       "   '``',\n",
       "   'cable',\n",
       "   'car',\n",
       "   \"''\",\n",
       "   ')',\n",
       "   'linking',\n",
       "   'between',\n",
       "   'Tung',\n",
       "   'Chung',\n",
       "   '(',\n",
       "   'where',\n",
       "   'it',\n",
       "   'connects',\n",
       "   'the',\n",
       "   'MTR',\n",
       "   'Tung',\n",
       "   'Chung',\n",
       "   'station',\n",
       "   ')',\n",
       "   'and',\n",
       "   'Ngong',\n",
       "   'Ping',\n",
       "   '(',\n",
       "   'where',\n",
       "   'the',\n",
       "   'Po',\n",
       "   'Lin',\n",
       "   'Monastery',\n",
       "   'and',\n",
       "   'Tian',\n",
       "   'Tan',\n",
       "   'Buddha',\n",
       "   'are',\n",
       "   'located',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [11,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   11,\n",
       "   11,\n",
       "   11,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '933'},\n",
       " {'tokens': ['The',\n",
       "   'Benguela',\n",
       "   'railway',\n",
       "   ',',\n",
       "   'which',\n",
       "   'extended',\n",
       "   'west',\n",
       "   'through',\n",
       "   'Angola',\n",
       "   ',',\n",
       "   'was',\n",
       "   'essentially',\n",
       "   'closed',\n",
       "   'to',\n",
       "   'Zambian',\n",
       "   'traffic',\n",
       "   'by',\n",
       "   'the',\n",
       "   'late',\n",
       "   '1970s',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '934'},\n",
       " {'tokens': ['His',\n",
       "   'father',\n",
       "   'is',\n",
       "   'a',\n",
       "   'veteran',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Cuban',\n",
       "   'Missile',\n",
       "   'Crisis',\n",
       "   'in',\n",
       "   'October',\n",
       "   '1962',\n",
       "   ',',\n",
       "   'best',\n",
       "   'portrayed',\n",
       "   'in',\n",
       "   'the',\n",
       "   'film',\n",
       "   ',',\n",
       "   '``',\n",
       "   'Thirteen',\n",
       "   'Days',\n",
       "   '``',\n",
       "   '(',\n",
       "   '2000',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '935'},\n",
       " {'tokens': ['Its',\n",
       "   'original',\n",
       "   'name',\n",
       "   'would',\n",
       "   'later',\n",
       "   'be',\n",
       "   'applied',\n",
       "   'to',\n",
       "   'classmate',\n",
       "   'no',\n",
       "   '7018',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '936'},\n",
       " {'tokens': ['By',\n",
       "   '1890',\n",
       "   ',',\n",
       "   'a',\n",
       "   'small',\n",
       "   'community',\n",
       "   'had',\n",
       "   'formed',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '937'},\n",
       " {'tokens': ['The',\n",
       "   'show',\n",
       "   'was',\n",
       "   'positively',\n",
       "   'received',\n",
       "   'by',\n",
       "   'audiences',\n",
       "   'and',\n",
       "   'critics',\n",
       "   ',',\n",
       "   'and',\n",
       "   'won',\n",
       "   'or',\n",
       "   'received',\n",
       "   'nominations',\n",
       "   'for',\n",
       "   'several',\n",
       "   'awards',\n",
       "   'including',\n",
       "   'a',\n",
       "   'Juno',\n",
       "   'Award',\n",
       "   'in',\n",
       "   '1989',\n",
       "   'and',\n",
       "   'a',\n",
       "   'Gemini',\n",
       "   'Award',\n",
       "   'in',\n",
       "   '1994',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   39,\n",
       "   39,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '938'},\n",
       " {'tokens': ['In',\n",
       "   'early',\n",
       "   '2016',\n",
       "   ',',\n",
       "   'it',\n",
       "   'was',\n",
       "   'announced',\n",
       "   'that',\n",
       "   'Flybe',\n",
       "   'had',\n",
       "   'negotiated',\n",
       "   'a',\n",
       "   'six-year',\n",
       "   'agreement',\n",
       "   'with',\n",
       "   'SAS',\n",
       "   'Scandinavian',\n",
       "   'Airlines',\n",
       "   'to',\n",
       "   'fly',\n",
       "   '4',\n",
       "   'ATR',\n",
       "   '72–9',\n",
       "   'aircraft',\n",
       "   'on',\n",
       "   'their',\n",
       "   'behalf',\n",
       "   ',',\n",
       "   'starting',\n",
       "   'in',\n",
       "   'October',\n",
       "   '2016',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   28,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '939'},\n",
       " {'tokens': ['On',\n",
       "   '1',\n",
       "   'April',\n",
       "   '2010',\n",
       "   ',',\n",
       "   'NSW',\n",
       "   'reverted',\n",
       "   'to',\n",
       "   'the',\n",
       "   'identity',\n",
       "   'of',\n",
       "   '800',\n",
       "   'NAS',\n",
       "   ',',\n",
       "   'flying',\n",
       "   'the',\n",
       "   'Harrier',\n",
       "   'GR9',\n",
       "   'and',\n",
       "   'GR9A',\n",
       "   'variants',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   58,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '940'},\n",
       " {'tokens': ['Tsar',\n",
       "   'Nicholas',\n",
       "   'II',\n",
       "   'of',\n",
       "   'Russia',\n",
       "   'arrived',\n",
       "   'by',\n",
       "   'sea',\n",
       "   'at',\n",
       "   'Leith',\n",
       "   'with',\n",
       "   'his',\n",
       "   'family',\n",
       "   'and',\n",
       "   'suite',\n",
       "   'on',\n",
       "   'Tuesday',\n",
       "   '22',\n",
       "   'September',\n",
       "   '1896',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [55,\n",
       "   55,\n",
       "   55,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '941'},\n",
       " {'tokens': ['Melatonin',\n",
       "   'has',\n",
       "   'been',\n",
       "   'claimed',\n",
       "   'to',\n",
       "   'be',\n",
       "   'an',\n",
       "   'endogenous',\n",
       "   'ligand',\n",
       "   'for',\n",
       "   'ROR-α',\n",
       "   'while',\n",
       "   'CGP',\n",
       "   '52608',\n",
       "   'has',\n",
       "   'been',\n",
       "   'identified',\n",
       "   'as',\n",
       "   'a',\n",
       "   'ROR-α',\n",
       "   'selective',\n",
       "   'synthetic',\n",
       "   'ligand',\n",
       "   '.'],\n",
       "  'coarse_tags': [6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [49,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   41,\n",
       "   0,\n",
       "   41,\n",
       "   41,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   41,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '942'},\n",
       " {'tokens': ['The',\n",
       "   'city',\n",
       "   'extends',\n",
       "   'in',\n",
       "   'a',\n",
       "   'north–south',\n",
       "   'direction',\n",
       "   'on',\n",
       "   'the',\n",
       "   'west',\n",
       "   'bank',\n",
       "   'of',\n",
       "   'the',\n",
       "   'valley',\n",
       "   'formed',\n",
       "   'by',\n",
       "   'the',\n",
       "   'Raidāk',\n",
       "   'River',\n",
       "   ',',\n",
       "   'which',\n",
       "   'is',\n",
       "   'known',\n",
       "   'as',\n",
       "   'the',\n",
       "   'Wang',\n",
       "   'Chuu',\n",
       "   'or',\n",
       "   'Thimphu',\n",
       "   'Chuu',\n",
       "   'in',\n",
       "   'Bhutan',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   22,\n",
       "   22,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0],\n",
       "  'id': '943'},\n",
       " {'tokens': ['With',\n",
       "   'Club',\n",
       "   'Passim',\n",
       "   'in',\n",
       "   'Cambridge',\n",
       "   ',',\n",
       "   'Karim',\n",
       "   'Nagi',\n",
       "   'began',\n",
       "   'the',\n",
       "   'work',\n",
       "   'of',\n",
       "   'connecting',\n",
       "   'the',\n",
       "   'Arab-',\n",
       "   'American',\n",
       "   'diaspora',\n",
       "   'to',\n",
       "   'each',\n",
       "   'other',\n",
       "   'as',\n",
       "   'well',\n",
       "   'as',\n",
       "   'to',\n",
       "   'their',\n",
       "   'traditional',\n",
       "   'culture',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '944'},\n",
       " {'tokens': ['She',\n",
       "   'tells',\n",
       "   'him',\n",
       "   'that',\n",
       "   'even',\n",
       "   'if',\n",
       "   'he',\n",
       "   'wins',\n",
       "   ',',\n",
       "   '``',\n",
       "   'it',\n",
       "   \"'s\",\n",
       "   'ruined',\n",
       "   ',',\n",
       "   'for',\n",
       "   'me',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '945'},\n",
       " {'tokens': ['At',\n",
       "   'first',\n",
       "   ',',\n",
       "   'under',\n",
       "   'the',\n",
       "   'leadership',\n",
       "   'of',\n",
       "   ')',\n",
       "   ',',\n",
       "   'the',\n",
       "   'CFDT',\n",
       "   'presented',\n",
       "   'itself',\n",
       "   'as',\n",
       "   'a',\n",
       "   'social-democratic',\n",
       "   'confederation',\n",
       "   'close',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Unified',\n",
       "   'Socialist',\n",
       "   'Party',\n",
       "   '(',\n",
       "   '``',\n",
       "   'Parti',\n",
       "   'socialiste',\n",
       "   'unifié',\n",
       "   '``',\n",
       "   'or',\n",
       "   'PSU',\n",
       "   ')',\n",
       "   'which',\n",
       "   'was',\n",
       "   'led',\n",
       "   'by',\n",
       "   'Pierre',\n",
       "   'Mendès-France',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   33,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   33,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   55,\n",
       "   0],\n",
       "  'id': '946'},\n",
       " {'tokens': ['Discontinuation',\n",
       "   'of',\n",
       "   'heparin',\n",
       "   'is',\n",
       "   'critical',\n",
       "   'in',\n",
       "   'a',\n",
       "   'case',\n",
       "   'of',\n",
       "   'heparin-induced',\n",
       "   'thrombocytopenia',\n",
       "   '(',\n",
       "   'HIT',\n",
       "   ')',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 6, 0, 0, 0, 0, 0, 0, 6, 6, 0, 6, 0, 0],\n",
       "  'fine_tags': [0, 0, 40, 0, 0, 0, 0, 0, 0, 43, 43, 0, 43, 0, 0],\n",
       "  'id': '947'},\n",
       " {'tokens': ['It',\n",
       "   'had',\n",
       "   'a',\n",
       "   'limited',\n",
       "   'theatrical',\n",
       "   'release',\n",
       "   'on',\n",
       "   'October',\n",
       "   '31',\n",
       "   ',',\n",
       "   '2008',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '948'},\n",
       " {'tokens': ['It',\n",
       "   'flows',\n",
       "   'into',\n",
       "   'the',\n",
       "   'East',\n",
       "   'Branch',\n",
       "   'Delaware',\n",
       "   'River',\n",
       "   'southeast',\n",
       "   'of',\n",
       "   'Hancock',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 22, 22, 0, 0, 21, 0],\n",
       "  'id': '949'},\n",
       " {'tokens': ['ReiserFS',\n",
       "   'v3',\n",
       "   'images',\n",
       "   'should',\n",
       "   'not',\n",
       "   'be',\n",
       "   'stored',\n",
       "   'on',\n",
       "   'a',\n",
       "   'ReiserFS',\n",
       "   'v3',\n",
       "   'partition',\n",
       "   '(',\n",
       "   'e.g',\n",
       "   '.'],\n",
       "  'coarse_tags': [8, 8, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0],\n",
       "  'fine_tags': [64, 64, 0, 0, 0, 0, 0, 0, 0, 64, 64, 0, 0, 0, 0],\n",
       "  'id': '950'},\n",
       " {'tokens': ['This',\n",
       "   'paper',\n",
       "   'reports',\n",
       "   'a',\n",
       "   '10',\n",
       "   'step',\n",
       "   'synthesis',\n",
       "   'of',\n",
       "   '4-HO-5-MeO-DMT',\n",
       "   'from',\n",
       "   'ortho-vanillin',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 41, 0, 0, 0],\n",
       "  'id': '951'},\n",
       " {'tokens': ['Fond',\n",
       "   'of',\n",
       "   'his',\n",
       "   'looted',\n",
       "   'Browning',\n",
       "   'Hi-Power',\n",
       "   '9',\n",
       "   'mm',\n",
       "   'pistol',\n",
       "   'and',\n",
       "   'vintage',\n",
       "   'WW',\n",
       "   'II',\n",
       "   '``',\n",
       "   'Schmeisser',\n",
       "   \"''\",\n",
       "   'MP-40',\n",
       "   'submachine',\n",
       "   'gun',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 8, 0, 0, 0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   66,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15,\n",
       "   15,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   66,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '952'},\n",
       " {'tokens': ['The',\n",
       "   'Presbyterian',\n",
       "   'Church',\n",
       "   'in',\n",
       "   'Ireland',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Church',\n",
       "   'of',\n",
       "   'Scotland',\n",
       "   'have',\n",
       "   'been',\n",
       "   'closely',\n",
       "   'tied',\n",
       "   'in',\n",
       "   'the',\n",
       "   'past',\n",
       "   '.'],\n",
       "  'coarse_tags': [5, 5, 5, 0, 4, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [34, 34, 34, 0, 21, 0, 0, 34, 34, 34, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '953'},\n",
       " {'tokens': ['Construction',\n",
       "   'and',\n",
       "   'design',\n",
       "   'of',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Crown',\n",
       "   'Fountain',\n",
       "   '``',\n",
       "   'cost',\n",
       "   'US',\n",
       "   '$',\n",
       "   '17',\n",
       "   'million',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 6, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 42, 0, 0, 0],\n",
       "  'id': '954'},\n",
       " {'tokens': ['Bravo',\n",
       "   'acknowledged',\n",
       "   'that',\n",
       "   'the',\n",
       "   'ad',\n",
       "   'was',\n",
       "   'placed',\n",
       "   'in',\n",
       "   'error',\n",
       "   'and',\n",
       "   'no',\n",
       "   'additional',\n",
       "   'Applebee',\n",
       "   \"'s\",\n",
       "   'ads',\n",
       "   'ran',\n",
       "   'during',\n",
       "   'the',\n",
       "   'series',\n",
       "   '.'],\n",
       "  'coarse_tags': [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [31, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 28, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '955'},\n",
       " {'tokens': ['Representing',\n",
       "   'Brazil',\n",
       "   ',',\n",
       "   'he',\n",
       "   'won',\n",
       "   'the',\n",
       "   '``',\n",
       "   'gold',\n",
       "   'medal',\n",
       "   \"''\",\n",
       "   'at',\n",
       "   'the',\n",
       "   '1999',\n",
       "   'Pan',\n",
       "   'American',\n",
       "   'Games',\n",
       "   ',',\n",
       "   'in',\n",
       "   'Winnipeg',\n",
       "   ',',\n",
       "   'partnering',\n",
       "   'with',\n",
       "   'Paulo',\n",
       "   'Taiche',\n",
       "   'r',\n",
       "   ',',\n",
       "   'besting',\n",
       "   'the',\n",
       "   'Mexican',\n",
       "   'couple',\n",
       "   'Marco',\n",
       "   'Osorio',\n",
       "   'and',\n",
       "   'Óscar',\n",
       "   'Ortiz',\n",
       "   ',',\n",
       "   '7–6',\n",
       "   ',',\n",
       "   '6–2',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   52,\n",
       "   52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '956'},\n",
       " {'tokens': ['1939',\n",
       "   'legislation',\n",
       "   'repealed',\n",
       "   'the',\n",
       "   'requirement',\n",
       "   'that',\n",
       "   'FDIC',\n",
       "   '-insured',\n",
       "   'banks',\n",
       "   'join',\n",
       "   'the',\n",
       "   'Federal',\n",
       "   'Reserve',\n",
       "   'System',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 28, 0, 0, 0, 0, 30, 0, 0, 0],\n",
       "  'id': '957'},\n",
       " {'tokens': ['.'], 'coarse_tags': [0], 'fine_tags': [0], 'id': '958'},\n",
       " {'tokens': ['Deputy',\n",
       "   'Governor',\n",
       "   'A',\n",
       "   'is',\n",
       "   'also',\n",
       "   'named',\n",
       "   'as',\n",
       "   'the',\n",
       "   'person',\n",
       "   'who',\n",
       "   'supposedly',\n",
       "   'attempted',\n",
       "   'to',\n",
       "   'coerce',\n",
       "   'the',\n",
       "   '``',\n",
       "   'Chicago',\n",
       "   'Tribune',\n",
       "   '``',\n",
       "   'on',\n",
       "   'Blagojevich',\n",
       "   \"'s\",\n",
       "   'behalf',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '959'},\n",
       " {'tokens': ['Janus',\n",
       "   'kinase',\n",
       "   '2',\n",
       "   '(',\n",
       "   'commonly',\n",
       "   'called',\n",
       "   'JAK2',\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'non-receptor',\n",
       "   'tyrosine',\n",
       "   'kinase',\n",
       "   '.'],\n",
       "  'coarse_tags': [6, 6, 6, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [40, 40, 40, 0, 0, 0, 40, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '960'},\n",
       " {'tokens': ['The',\n",
       "   'same',\n",
       "   'night',\n",
       "   'marked',\n",
       "   'the',\n",
       "   'first',\n",
       "   'time',\n",
       "   'ever',\n",
       "   'on',\n",
       "   'the',\n",
       "   'show',\n",
       "   ',',\n",
       "   'where',\n",
       "   'no',\n",
       "   'callers',\n",
       "   'had',\n",
       "   'called',\n",
       "   'for',\n",
       "   'the',\n",
       "   'topic',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '961'},\n",
       " {'tokens': ['In',\n",
       "   'World',\n",
       "   'War',\n",
       "   'II',\n",
       "   ',',\n",
       "   'he',\n",
       "   'served',\n",
       "   'two',\n",
       "   'years',\n",
       "   'in',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'Navy',\n",
       "   'and',\n",
       "   'subsequently',\n",
       "   'became',\n",
       "   'an',\n",
       "   'independent',\n",
       "   'accountant',\n",
       "   'in',\n",
       "   'Hollywood',\n",
       "   ';',\n",
       "   'one',\n",
       "   'of',\n",
       "   'his',\n",
       "   'clients',\n",
       "   'was',\n",
       "   'movie',\n",
       "   'mogul',\n",
       "   'Samuel',\n",
       "   'Goldwyn',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0],\n",
       "  'id': '962'},\n",
       " {'tokens': ['Rank',\n",
       "   'and',\n",
       "   'file',\n",
       "   'defenders',\n",
       "   'were',\n",
       "   'massacred',\n",
       "   'or',\n",
       "   'drowned',\n",
       "   'in',\n",
       "   'the',\n",
       "   'river',\n",
       "   'after',\n",
       "   'they',\n",
       "   'had',\n",
       "   'left',\n",
       "   'Kodak',\n",
       "   'upon',\n",
       "   'capitulation',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0],\n",
       "  'id': '963'},\n",
       " {'tokens': ['Elisha',\n",
       "   'Avery',\n",
       "   'Crary',\n",
       "   '(',\n",
       "   'June',\n",
       "   '24',\n",
       "   ',',\n",
       "   '1905',\n",
       "   '–',\n",
       "   'April',\n",
       "   '28',\n",
       "   ',',\n",
       "   '1978',\n",
       "   ')',\n",
       "   'was',\n",
       "   'a',\n",
       "   'United',\n",
       "   'States',\n",
       "   'District',\n",
       "   'Judge',\n",
       "   'of',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'District',\n",
       "   'Court',\n",
       "   'for',\n",
       "   'the',\n",
       "   'Southern',\n",
       "   'District',\n",
       "   'of',\n",
       "   'California',\n",
       "   'and',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'District',\n",
       "   'Court',\n",
       "   'for',\n",
       "   'the',\n",
       "   'Central',\n",
       "   'District',\n",
       "   'of',\n",
       "   'California',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [54,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   30,\n",
       "   0],\n",
       "  'id': '964'},\n",
       " {'tokens': ['``',\n",
       "   'Crimson',\n",
       "   'Alliance',\n",
       "   '``',\n",
       "   'was',\n",
       "   'released',\n",
       "   'on',\n",
       "   'September',\n",
       "   '7',\n",
       "   ',',\n",
       "   '2011',\n",
       "   'on',\n",
       "   'Xbox',\n",
       "   'LIVE',\n",
       "   'Arcade',\n",
       "   'for',\n",
       "   'free',\n",
       "   'as',\n",
       "   'a',\n",
       "   'freemium',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   61,\n",
       "   61,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   64,\n",
       "   64,\n",
       "   64,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '965'},\n",
       " {'tokens': ['One',\n",
       "   'must',\n",
       "   'also',\n",
       "   'differentiate',\n",
       "   'ischemic',\n",
       "   'colitis',\n",
       "   ',',\n",
       "   'which',\n",
       "   'often',\n",
       "   'resolves',\n",
       "   'on',\n",
       "   'its',\n",
       "   'own',\n",
       "   ',',\n",
       "   'from',\n",
       "   'the',\n",
       "   'more',\n",
       "   'immediately',\n",
       "   'life-threatening',\n",
       "   'condition',\n",
       "   'of',\n",
       "   'acute',\n",
       "   'mesenteric',\n",
       "   'ischemia',\n",
       "   'of',\n",
       "   'the',\n",
       "   'small',\n",
       "   'bowel',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   43,\n",
       "   43,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   43,\n",
       "   43,\n",
       "   43,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '966'},\n",
       " {'tokens': ['In',\n",
       "   'August',\n",
       "   '1988',\n",
       "   'production',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'Florida',\n",
       "   'Keys',\n",
       "   ',',\n",
       "   'notably',\n",
       "   'Key',\n",
       "   'West',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 4, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 23, 23, 0, 0, 23, 23, 0],\n",
       "  'id': '967'},\n",
       " {'tokens': ['The',\n",
       "   'superstructure',\n",
       "   'of',\n",
       "   'the',\n",
       "   'powerhouse',\n",
       "   'is',\n",
       "   'constructed',\n",
       "   'of',\n",
       "   'welded',\n",
       "   'steel',\n",
       "   'framed',\n",
       "   'clad',\n",
       "   'in',\n",
       "   'precast',\n",
       "   'concrete',\n",
       "   'panels',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '968'},\n",
       " {'tokens': ['The',\n",
       "   'Main',\n",
       "   'Event',\n",
       "   'Super',\n",
       "   'Late',\n",
       "   \"'Outlaw\",\n",
       "   \"'\",\n",
       "   'Bodied',\n",
       "   'Series',\n",
       "   'Championships',\n",
       "   'XXVI',\n",
       "   '(',\n",
       "   '25',\n",
       "   ')',\n",
       "   'was',\n",
       "   'held',\n",
       "   'at',\n",
       "   'the',\n",
       "   'track',\n",
       "   'after',\n",
       "   'being',\n",
       "   'held',\n",
       "   'in',\n",
       "   'Columbus',\n",
       "   'in',\n",
       "   'previous',\n",
       "   'years',\n",
       "   '.'],\n",
       "  'coarse_tags': [3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '969'},\n",
       " {'tokens': ['After',\n",
       "   'relinquishing',\n",
       "   'the',\n",
       "   'last',\n",
       "   'of',\n",
       "   'its',\n",
       "   'P2V-5FS',\n",
       "   'aircraft',\n",
       "   'to',\n",
       "   'the',\n",
       "   'U.',\n",
       "   'S.',\n",
       "   'Naval',\n",
       "   'Reserve',\n",
       "   'in',\n",
       "   'October',\n",
       "   '1962',\n",
       "   ',',\n",
       "   'VP-8',\n",
       "   'became',\n",
       "   'the',\n",
       "   'first',\n",
       "   'operational',\n",
       "   'P-3A',\n",
       "   'Orion',\n",
       "   'squadron',\n",
       "   'in',\n",
       "   'the',\n",
       "   'U.S.',\n",
       "   'Navy',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   58,\n",
       "   58,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   0],\n",
       "  'id': '970'},\n",
       " {'tokens': ['arenaria', 'and', 'several', 'protected', 'animals', '.'],\n",
       "  'coarse_tags': [6, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [48, 0, 0, 0, 0, 0],\n",
       "  'id': '971'},\n",
       " {'tokens': ['The',\n",
       "   'team',\n",
       "   'is',\n",
       "   'mostly',\n",
       "   'made',\n",
       "   'up',\n",
       "   'by',\n",
       "   'teenage',\n",
       "   'players',\n",
       "   'built',\n",
       "   'around',\n",
       "   'a',\n",
       "   'nucleus',\n",
       "   'of',\n",
       "   'seasoned',\n",
       "   'veterans',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '972'},\n",
       " {'tokens': ['During',\n",
       "   'the',\n",
       "   'campaign',\n",
       "   ',',\n",
       "   'a',\n",
       "   'cartoon',\n",
       "   'in',\n",
       "   'the',\n",
       "   '``',\n",
       "   'New',\n",
       "   'Yorker',\n",
       "   '``',\n",
       "   'allegedly',\n",
       "   'caused',\n",
       "   'the',\n",
       "   'Obama',\n",
       "   'campaign',\n",
       "   'to',\n",
       "   'exclude',\n",
       "   'Lizza',\n",
       "   'from',\n",
       "   'Obama',\n",
       "   \"'s\",\n",
       "   'campaign',\n",
       "   'plane',\n",
       "   ',',\n",
       "   'with',\n",
       "   'a',\n",
       "   'lack',\n",
       "   'of',\n",
       "   'space',\n",
       "   'cited',\n",
       "   'as',\n",
       "   'the',\n",
       "   'reason',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   55,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '973'},\n",
       " {'tokens': ['Günther',\n",
       "   'Seiffert',\n",
       "   '(',\n",
       "   'born',\n",
       "   '18',\n",
       "   'October',\n",
       "   '1937',\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'former',\n",
       "   'racing',\n",
       "   'driver',\n",
       "   'from',\n",
       "   'Germany',\n",
       "   '.'],\n",
       "  'coarse_tags': [7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0],\n",
       "  'fine_tags': [52, 52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0],\n",
       "  'id': '974'},\n",
       " {'tokens': ['The', 'Warehouse', 'Theatre', 'opened', 'in', '1977', '.'],\n",
       "  'coarse_tags': [0, 2, 2, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 14, 14, 0, 0, 0, 0],\n",
       "  'id': '975'},\n",
       " {'tokens': ['The',\n",
       "   'contract',\n",
       "   'between',\n",
       "   'SMS',\n",
       "   'and',\n",
       "   'the',\n",
       "   'city',\n",
       "   'government',\n",
       "   'is',\n",
       "   'renewed',\n",
       "   'every',\n",
       "   'ten',\n",
       "   'years',\n",
       "   'and',\n",
       "   'includes',\n",
       "   'an',\n",
       "   'even',\n",
       "   'split',\n",
       "   'of',\n",
       "   'profits',\n",
       "   'between',\n",
       "   'the',\n",
       "   'two',\n",
       "   'parties',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   28,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '976'},\n",
       " {'tokens': ['The',\n",
       "   'attacks',\n",
       "   'had',\n",
       "   'been',\n",
       "   'poorly',\n",
       "   'coordinated',\n",
       "   ',',\n",
       "   'but',\n",
       "   'the',\n",
       "   'Devastator',\n",
       "   'was',\n",
       "   'immediately',\n",
       "   'withdrawn',\n",
       "   'from',\n",
       "   'front-line',\n",
       "   'service',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 58, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '977'},\n",
       " {'tokens': ['The',\n",
       "   'glacier',\n",
       "   'lies',\n",
       "   'in',\n",
       "   'the',\n",
       "   'southern',\n",
       "   'Kichatna',\n",
       "   'Mountains',\n",
       "   'above',\n",
       "   'Simpson',\n",
       "   'Pass',\n",
       "   ',',\n",
       "   'moving',\n",
       "   'south',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 24, 24, 0, 25, 25, 0, 0, 0, 0],\n",
       "  'id': '978'},\n",
       " {'tokens': ['He',\n",
       "   'has',\n",
       "   'written',\n",
       "   'Shathsthala',\n",
       "   'Jnana',\n",
       "   'Saramrutha',\n",
       "   ',',\n",
       "   'containing',\n",
       "   '701',\n",
       "   'Vachanas',\n",
       "   '(',\n",
       "   'Poems',\n",
       "   ')',\n",
       "   'which',\n",
       "   'are',\n",
       "   'directing',\n",
       "   'Sthalas',\n",
       "   '(',\n",
       "   'route',\n",
       "   ')',\n",
       "   'to',\n",
       "   'Attain',\n",
       "   'Ikya',\n",
       "   'i.e',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   25,\n",
       "   25,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '979'},\n",
       " {'tokens': ['He',\n",
       "   'was',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'founders',\n",
       "   'of',\n",
       "   '``',\n",
       "   'Fenix',\n",
       "   '``',\n",
       "   'magazine',\n",
       "   'in',\n",
       "   '1990',\n",
       "   'and',\n",
       "   'its',\n",
       "   'chief',\n",
       "   'editor',\n",
       "   'from',\n",
       "   '1993',\n",
       "   'till',\n",
       "   'its',\n",
       "   'suspension',\n",
       "   'in',\n",
       "   '2001',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   31,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '980'},\n",
       " {'tokens': ['Gladys',\n",
       "   'May',\n",
       "   'Casely-Hayford',\n",
       "   '``',\n",
       "   'alias',\n",
       "   \"''\",\n",
       "   'Aquah',\n",
       "   'Laluah',\n",
       "   '(',\n",
       "   '11',\n",
       "   'May',\n",
       "   '1904',\n",
       "   '–',\n",
       "   'October',\n",
       "   '1950',\n",
       "   ')',\n",
       "   'was',\n",
       "   'a',\n",
       "   'Gold',\n",
       "   'Coast-born',\n",
       "   'Sierra',\n",
       "   'Leonean',\n",
       "   'writer',\n",
       "   ',',\n",
       "   'daughter',\n",
       "   'of',\n",
       "   'Adelaide',\n",
       "   'Casely-Hayford',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0],\n",
       "  'fine_tags': [51,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0],\n",
       "  'id': '981'},\n",
       " {'tokens': ['In',\n",
       "   '1991',\n",
       "   ',',\n",
       "   'a',\n",
       "   'four-rotor',\n",
       "   'Mazda',\n",
       "   '787B',\n",
       "   '(',\n",
       "   '2622',\n",
       "   'cc',\n",
       "   'actual',\n",
       "   ',',\n",
       "   'rated',\n",
       "   'by',\n",
       "   'FIA',\n",
       "   'formula',\n",
       "   'at',\n",
       "   '4708',\n",
       "   'cc',\n",
       "   ')',\n",
       "   'won',\n",
       "   'the',\n",
       "   '24',\n",
       "   'Hours',\n",
       "   'of',\n",
       "   'Le',\n",
       "   'Mans',\n",
       "   'auto',\n",
       "   'race',\n",
       "   'outright',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   59,\n",
       "   59,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '982'},\n",
       " {'tokens': ['Until',\n",
       "   'the',\n",
       "   '1970s',\n",
       "   ',',\n",
       "   'most',\n",
       "   'visitors',\n",
       "   'to',\n",
       "   'Oktoberfest',\n",
       "   'did',\n",
       "   'not',\n",
       "   'wear',\n",
       "   'traditional',\n",
       "   'tracht',\n",
       "   ';',\n",
       "   'it',\n",
       "   'was',\n",
       "   'common',\n",
       "   'to',\n",
       "   'wear',\n",
       "   'jeans',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '983'},\n",
       " {'tokens': ['The',\n",
       "   'CGI',\n",
       "   'was',\n",
       "   'produced',\n",
       "   'by',\n",
       "   'Koga',\n",
       "   \"'s\",\n",
       "   'CGI',\n",
       "   'studio',\n",
       "   'The',\n",
       "   'Fool',\n",
       "   'and',\n",
       "   'premiered',\n",
       "   'between',\n",
       "   '10:50',\n",
       "   'p.m.',\n",
       "   'and',\n",
       "   '11:30',\n",
       "   'p.m.',\n",
       "   '(',\n",
       "   'JST',\n",
       "   ')',\n",
       "   'on',\n",
       "   'December',\n",
       "   '31',\n",
       "   ',',\n",
       "   '2002',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '984'},\n",
       " {'tokens': ['The',\n",
       "   'by-election',\n",
       "   'was',\n",
       "   'called',\n",
       "   'for',\n",
       "   'Thursday',\n",
       "   ',',\n",
       "   '31',\n",
       "   'July',\n",
       "   '1997',\n",
       "   'and',\n",
       "   'was',\n",
       "   'the',\n",
       "   'first',\n",
       "   'by-election',\n",
       "   'of',\n",
       "   'the',\n",
       "   '1997-2001',\n",
       "   'parliament',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0],\n",
       "  'fine_tags': [0,\n",
       "   17,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   17,\n",
       "   0],\n",
       "  'id': '985'},\n",
       " {'tokens': ['Born',\n",
       "   'in',\n",
       "   'Salisbury',\n",
       "   ',',\n",
       "   'Rhodesia',\n",
       "   '(',\n",
       "   'now',\n",
       "   'Harare',\n",
       "   ',',\n",
       "   'Zimbabwe',\n",
       "   ')',\n",
       "   'Watson',\n",
       "   'was',\n",
       "   'educated',\n",
       "   'at',\n",
       "   'Oriel',\n",
       "   'Boys',\n",
       "   'High',\n",
       "   'School',\n",
       "   ',',\n",
       "   'Chisipite',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   29,\n",
       "   0,\n",
       "   29,\n",
       "   0],\n",
       "  'id': '986'},\n",
       " {'tokens': ['Karimov',\n",
       "   'scored',\n",
       "   'the',\n",
       "   'winning',\n",
       "   'goal',\n",
       "   'for',\n",
       "   'Khazar',\n",
       "   'Lankaran',\n",
       "   'in',\n",
       "   'the',\n",
       "   '2006–07',\n",
       "   'Azerbaijan',\n",
       "   'Cup',\n",
       "   'final',\n",
       "   'against',\n",
       "   'MKT',\n",
       "   'Araz',\n",
       "   ',',\n",
       "   'netting',\n",
       "   'in',\n",
       "   'the',\n",
       "   '90th',\n",
       "   'minute',\n",
       "   '.'],\n",
       "  'coarse_tags': [7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   3,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [52,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   20,\n",
       "   20,\n",
       "   0,\n",
       "   0,\n",
       "   37,\n",
       "   37,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '987'},\n",
       " {'tokens': ['Among',\n",
       "   'the',\n",
       "   'first',\n",
       "   'technology',\n",
       "   'to',\n",
       "   'be',\n",
       "   'added',\n",
       "   'to',\n",
       "   'the',\n",
       "   'institute',\n",
       "   ',',\n",
       "   'was',\n",
       "   'equipment',\n",
       "   'for',\n",
       "   'in',\n",
       "   'vivo',\n",
       "   'NMR',\n",
       "   'studies',\n",
       "   '(',\n",
       "   'which',\n",
       "   'nowadays',\n",
       "   'is',\n",
       "   'mainly',\n",
       "   'known',\n",
       "   'as',\n",
       "   'MRI',\n",
       "   ')',\n",
       "   'for',\n",
       "   'animal',\n",
       "   'studies',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   49,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   49,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '988'},\n",
       " {'tokens': ['On',\n",
       "   '13',\n",
       "   'June',\n",
       "   '1503',\n",
       "   ',',\n",
       "   'his',\n",
       "   'elder',\n",
       "   'daughter',\n",
       "   'Margaret',\n",
       "   'made',\n",
       "   'her',\n",
       "   'own',\n",
       "   'progress',\n",
       "   'to',\n",
       "   'Scotland',\n",
       "   ',',\n",
       "   'to',\n",
       "   'become',\n",
       "   'Queen',\n",
       "   'of',\n",
       "   'James',\n",
       "   'IV',\n",
       "   ',',\n",
       "   'whom',\n",
       "   'she',\n",
       "   'married',\n",
       "   'two',\n",
       "   'months',\n",
       "   'later',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   54,\n",
       "   54,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '989'},\n",
       " {'tokens': ['A',\n",
       "   'U.S.',\n",
       "   'court',\n",
       "   'rejected',\n",
       "   'the',\n",
       "   'lawsuit',\n",
       "   'blaming',\n",
       "   'UCC',\n",
       "   'for',\n",
       "   'causing',\n",
       "   'soil',\n",
       "   'and',\n",
       "   'water',\n",
       "   'pollution',\n",
       "   'around',\n",
       "   'the',\n",
       "   'site',\n",
       "   'of',\n",
       "   'the',\n",
       "   'plant',\n",
       "   'and',\n",
       "   'ruled',\n",
       "   'that',\n",
       "   'responsibility',\n",
       "   'for',\n",
       "   'remedial',\n",
       "   'measures',\n",
       "   'or',\n",
       "   'related',\n",
       "   'claims',\n",
       "   'rested',\n",
       "   'with',\n",
       "   'the',\n",
       "   'State',\n",
       "   'Government',\n",
       "   'and',\n",
       "   'not',\n",
       "   'with',\n",
       "   'UCC',\n",
       "   '.'],\n",
       "  'coarse_tags': [5,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   5,\n",
       "   0],\n",
       "  'fine_tags': [32,\n",
       "   32,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   30,\n",
       "   30,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   32,\n",
       "   0],\n",
       "  'id': '990'},\n",
       " {'tokens': ['It',\n",
       "   'plays',\n",
       "   'this',\n",
       "   'role',\n",
       "   'in',\n",
       "   'the',\n",
       "   'case',\n",
       "   'of',\n",
       "   'cabbage',\n",
       "   ',',\n",
       "   'baeckeoffe',\n",
       "   'or',\n",
       "   'risotto',\n",
       "   ',',\n",
       "   'and',\n",
       "   'in',\n",
       "   'the',\n",
       "   'gravy',\n",
       "   'in',\n",
       "   'the',\n",
       "   'preparation',\n",
       "   'of',\n",
       "   'white',\n",
       "   'meat',\n",
       "   'as',\n",
       "   'in',\n",
       "   'osso',\n",
       "   'buco',\n",
       "   'or',\n",
       "   'blanquette',\n",
       "   'de',\n",
       "   'veau',\n",
       "   '(',\n",
       "   'veal',\n",
       "   'stew',\n",
       "   ')',\n",
       "   ',',\n",
       "   'Chicken',\n",
       "   'with',\n",
       "   'morels',\n",
       "   'and',\n",
       "   'its',\n",
       "   'variants',\n",
       "   ',',\n",
       "   'Chicken',\n",
       "   'à',\n",
       "   'la',\n",
       "   'comtoise',\n",
       "   'and',\n",
       "   'Yellow',\n",
       "   'coq',\n",
       "   'au',\n",
       "   'vin',\n",
       "   ',',\n",
       "   'rabbit',\n",
       "   'or',\n",
       "   'with',\n",
       "   'charcuterie',\n",
       "   'such',\n",
       "   'as',\n",
       "   'diots',\n",
       "   'and',\n",
       "   'tripe',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   8,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   60,\n",
       "   60,\n",
       "   60,\n",
       "   60,\n",
       "   0,\n",
       "   60,\n",
       "   60,\n",
       "   60,\n",
       "   60,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '991'},\n",
       " {'tokens': ['Thickening',\n",
       "   'agents',\n",
       "   'can',\n",
       "   'also',\n",
       "   'be',\n",
       "   'used',\n",
       "   'when',\n",
       "   'a',\n",
       "   'medical',\n",
       "   'condition',\n",
       "   'such',\n",
       "   'as',\n",
       "   'dysphagia',\n",
       "   'causes',\n",
       "   'difficulty',\n",
       "   'in',\n",
       "   'swallowing',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 43, 0, 0, 0, 0, 0],\n",
       "  'id': '992'},\n",
       " {'tokens': ['After',\n",
       "   'a',\n",
       "   '11',\n",
       "   'year',\n",
       "   'hiatus',\n",
       "   ',',\n",
       "   'the',\n",
       "   'company',\n",
       "   'returned',\n",
       "   'to',\n",
       "   'production',\n",
       "   'in',\n",
       "   '2010',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '993'},\n",
       " {'tokens': ['96.1',\n",
       "   '%',\n",
       "   'of',\n",
       "   'all',\n",
       "   'residents',\n",
       "   '25',\n",
       "   'years',\n",
       "   'or',\n",
       "   'older',\n",
       "   'are',\n",
       "   'high',\n",
       "   'school',\n",
       "   'graduates',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '994'},\n",
       " {'tokens': ['Conventional',\n",
       "   'rail',\n",
       "   'services',\n",
       "   'continue',\n",
       "   'to',\n",
       "   'use',\n",
       "   'the',\n",
       "   'Lanxin',\n",
       "   'railway',\n",
       "   'eastwards',\n",
       "   'and',\n",
       "   'the',\n",
       "   'Northern',\n",
       "   'Xinjiang',\n",
       "   'Railway',\n",
       "   'westwards',\n",
       "   'across',\n",
       "   'the',\n",
       "   'rest',\n",
       "   'of',\n",
       "   'the',\n",
       "   'province',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '995'},\n",
       " {'tokens': ['Its',\n",
       "   'main',\n",
       "   'purpose',\n",
       "   'is',\n",
       "   'the',\n",
       "   'coordination',\n",
       "   'of',\n",
       "   'responses',\n",
       "   'to',\n",
       "   'different',\n",
       "   'neurotransmitters',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '996'},\n",
       " {'tokens': ['Relations',\n",
       "   'between',\n",
       "   'the',\n",
       "   'United',\n",
       "   'States',\n",
       "   'and',\n",
       "   'Cyprus',\n",
       "   'can',\n",
       "   'be',\n",
       "   'described',\n",
       "   'as',\n",
       "   'being',\n",
       "   'excellent',\n",
       "   'due',\n",
       "   'to',\n",
       "   'many',\n",
       "   'factors',\n",
       "   '.'],\n",
       "  'coarse_tags': [0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'fine_tags': [0, 0, 0, 21, 21, 0, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'id': '997'},\n",
       " {'tokens': ['This',\n",
       "   'growth',\n",
       "   'of',\n",
       "   'immigration',\n",
       "   'greatly',\n",
       "   'changed',\n",
       "   'the',\n",
       "   'national',\n",
       "   'image',\n",
       "   'regarding',\n",
       "   'the',\n",
       "   'Australian',\n",
       "   'way',\n",
       "   'of',\n",
       "   'life',\n",
       "   'which',\n",
       "   ',',\n",
       "   'before',\n",
       "   'the',\n",
       "   'war',\n",
       "   ',',\n",
       "   'had',\n",
       "   'been',\n",
       "   'dominated',\n",
       "   'by',\n",
       "   'Anglo-Saxons',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   4,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   6,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   21,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   46,\n",
       "   0],\n",
       "  'id': '998'},\n",
       " {'tokens': ['``',\n",
       "   'Dave',\n",
       "   'Steven',\n",
       "   \"'s\",\n",
       "   'The',\n",
       "   'Rocketeer',\n",
       "   ',',\n",
       "   'The',\n",
       "   'Complete',\n",
       "   'Adventures',\n",
       "   '``',\n",
       "   'would',\n",
       "   'contain',\n",
       "   'all-new',\n",
       "   'coloring',\n",
       "   'by',\n",
       "   'Laura',\n",
       "   'Martin',\n",
       "   'who',\n",
       "   'was',\n",
       "   'chosen',\n",
       "   'by',\n",
       "   'Dave',\n",
       "   'Stevens',\n",
       "   'before',\n",
       "   'his',\n",
       "   'untimely',\n",
       "   'death',\n",
       "   '.'],\n",
       "  'coarse_tags': [0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'fine_tags': [0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   51,\n",
       "   51,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'id': '999'},\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426cac0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
