{
    "predict_GPE_f1": 0.7519497856992294,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7202530509691314,
    "predict_GPE_recall": 0.7865647508452154,
    "predict_actor_f1": 0.6638790607912513,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.7015635622025833,
    "predict_actor_recall": 0.63003663003663,
    "predict_airplane_f1": 0.49388209121245824,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.44223107569721115,
    "predict_airplane_recall": 0.5591939546599496,
    "predict_airport_f1": 0.6176142697881828,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.5196998123827392,
    "predict_airport_recall": 0.760989010989011,
    "predict_artist/author_f1": 0.5404678677063727,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.505787619526925,
    "predict_artist/author_recall": 0.5802540415704388,
    "predict_astronomything_f1": 0.5727452271231073,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.5172413793103449,
    "predict_astronomything_recall": 0.6415929203539823,
    "predict_athlete_f1": 0.769388102948696,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7625,
    "predict_athlete_recall": 0.7764017887856897,
    "predict_attack/battle/war/militaryconflict_f1": 0.6161573880284638,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5705426356589147,
    "predict_attack/battle/war/militaryconflict_recall": 0.6696997270245678,
    "predict_award_f1": 0.4386973180076628,
    "predict_award_number": 941,
    "predict_award_precision": 0.3993025283347864,
    "predict_award_recall": 0.4867162592986185,
    "predict_biologything_f1": 0.5414952818775708,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.49557130203720107,
    "predict_biologything_recall": 0.5968,
    "predict_bodiesofwater_f1": 0.596938775510204,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.5934065934065934,
    "predict_bodiesofwater_recall": 0.6005132591958939,
    "predict_broadcastprogram_f1": 0.4536693847294292,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.4112903225806452,
    "predict_broadcastprogram_recall": 0.5057851239669422,
    "predict_car_f1": 0.5652173913043478,
    "predict_car_number": 688,
    "predict_car_precision": 0.516867469879518,
    "predict_car_recall": 0.623546511627907,
    "predict_chemicalthing_f1": 0.47220902612826604,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.4555453712190651,
    "predict_chemicalthing_recall": 0.490138067061144,
    "predict_company_f1": 0.5670939668352346,
    "predict_company_number": 3903,
    "predict_company_precision": 0.5241304347826087,
    "predict_company_recall": 0.6177299513194978,
    "predict_currency_f1": 0.6358574610244989,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.5727181544633901,
    "predict_currency_recall": 0.7146433041301627,
    "predict_director_f1": 0.48362720403022674,
    "predict_director_number": 554,
    "predict_director_precision": 0.4521193092621664,
    "predict_director_recall": 0.51985559566787,
    "predict_disaster_f1": 0.32377049180327866,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.28113879003558717,
    "predict_disaster_recall": 0.38164251207729466,
    "predict_disease_f1": 0.5243128964059197,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.4343257443082312,
    "predict_disease_recall": 0.6613333333333333,
    "predict_education_f1": 0.6391520072169597,
    "predict_education_number": 2082,
    "predict_education_precision": 0.6024659863945578,
    "predict_education_recall": 0.6805955811719501,
    "predict_educationaldegree_f1": 0.4505263157894737,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.3670668953687822,
    "predict_educationaldegree_recall": 0.5831062670299727,
    "predict_election_f1": 0.14509803921568626,
    "predict_election_number": 184,
    "predict_election_precision": 0.11349693251533742,
    "predict_election_recall": 0.20108695652173914,
    "predict_film_f1": 0.5369039843239712,
    "predict_film_number": 759,
    "predict_film_precision": 0.5323834196891192,
    "predict_film_recall": 0.541501976284585,
    "predict_food_f1": 0.38075742067553736,
    "predict_food_number": 432,
    "predict_food_precision": 0.3412844036697248,
    "predict_food_recall": 0.4305555555555556,
    "predict_game_f1": 0.5099268547544409,
    "predict_game_number": 496,
    "predict_game_precision": 0.5292841648590022,
    "predict_game_recall": 0.49193548387096775,
    "predict_god_f1": 0.5740045078888054,
    "predict_god_number": 635,
    "predict_god_precision": 0.5488505747126436,
    "predict_god_recall": 0.6015748031496063,
    "predict_government/governmentagency_f1": 0.30614657210401897,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.280151433207139,
    "predict_government/governmentagency_recall": 0.33745928338762216,
    "predict_hospital_f1": 0.6229116945107399,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.5506329113924051,
    "predict_hospital_recall": 0.717032967032967,
    "predict_hotel_f1": 0.5512605042016807,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.49696969696969695,
    "predict_hotel_recall": 0.6188679245283019,
    "predict_island_f1": 0.5136129506990433,
    "predict_island_number": 646,
    "predict_island_precision": 0.4894810659186536,
    "predict_island_recall": 0.5402476780185759,
    "predict_language_f1": 0.6364734299516909,
    "predict_language_number": 753,
    "predict_language_precision": 0.583610188261351,
    "predict_language_recall": 0.699867197875166,
    "predict_law_f1": 0.34768211920529796,
    "predict_law_number": 488,
    "predict_law_precision": 0.2916666666666667,
    "predict_law_recall": 0.430327868852459,
    "predict_library_f1": 0.5285895806861499,
    "predict_library_number": 357,
    "predict_library_precision": 0.48372093023255813,
    "predict_library_recall": 0.5826330532212886,
    "predict_livingthing_f1": 0.48638132295719844,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.41981528127623846,
    "predict_livingthing_recall": 0.5780346820809249,
    "predict_loss": 0.5089574456214905,
    "predict_media/newspaper_f1": 0.5113981762917933,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.4814020028612303,
    "predict_media/newspaper_recall": 0.5453808752025932,
    "predict_medical_f1": 0.44568868980963045,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.4012096774193548,
    "predict_medical_recall": 0.5012594458438288,
    "predict_mountain_f1": 0.5670241286863271,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.5215782983970407,
    "predict_mountain_recall": 0.6211453744493393,
    "predict_music_f1": 0.6153846153846154,
    "predict_music_number": 1041,
    "predict_music_precision": 0.5879265091863517,
    "predict_music_recall": 0.6455331412103746,
    "predict_other_f1": 0.4459960724416321,
    "predict_other_number": 21035,
    "predict_other_precision": 0.4121798749747933,
    "predict_other_recall": 0.4858569051580699,
    "predict_overall_accuracy": 0.9000948912875901,
    "predict_overall_f1": 0.5589033762857034,
    "predict_overall_precision": 0.520492824840651,
    "predict_overall_recall": 0.6034347520951162,
    "predict_painting_f1": 0.0,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.0,
    "predict_painting_recall": 0.0,
    "predict_park_f1": 0.3879781420765028,
    "predict_park_number": 458,
    "predict_park_precision": 0.3328125,
    "predict_park_recall": 0.4650655021834061,
    "predict_politicalparty_f1": 0.5645816409423233,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.49466192170818507,
    "predict_politicalparty_recall": 0.6575212866603595,
    "predict_politician_f1": 0.5579865109392993,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5267080745341615,
    "predict_politician_recall": 0.5932144106330884,
    "predict_protest_f1": 0.17445482866043613,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.18064516129032257,
    "predict_protest_recall": 0.1686746987951807,
    "predict_religion_f1": 0.4278846153846154,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.3603238866396761,
    "predict_religion_recall": 0.5266272189349113,
    "predict_restaurant_f1": 0.23660714285714285,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.24537037037037038,
    "predict_restaurant_recall": 0.22844827586206898,
    "predict_road/railway/highway/transit_f1": 0.5485949987110079,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.4887459807073955,
    "predict_road/railway/highway/transit_recall": 0.6251468860164512,
    "predict_runtime": 166.6027,
    "predict_samples_per_second": 225.969,
    "predict_scholar_f1": 0.30817610062893075,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.2892561983471074,
    "predict_scholar_recall": 0.3297442799461642,
    "predict_ship_f1": 0.4760820045558087,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.41967871485943775,
    "predict_ship_recall": 0.55,
    "predict_showorganization_f1": 0.4163783160322953,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.3744813278008299,
    "predict_showorganization_recall": 0.4688311688311688,
    "predict_software_f1": 0.4847494553376906,
    "predict_software_number": 889,
    "predict_software_precision": 0.4699049630411827,
    "predict_software_recall": 0.500562429696288,
    "predict_soldier_f1": 0.3935926773455378,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.3885542168674699,
    "predict_soldier_recall": 0.3987635239567233,
    "predict_sportsevent_f1": 0.460431654676259,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.42038885969521805,
    "predict_sportsevent_recall": 0.5089058524173028,
    "predict_sportsfacility_f1": 0.5320715036803365,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.4764595103578154,
    "predict_sportsfacility_recall": 0.6023809523809524,
    "predict_sportsleague_f1": 0.4598168870803662,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.4181313598519889,
    "predict_sportsleague_recall": 0.5107344632768361,
    "predict_sportsteam_f1": 0.6488084241640495,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.5980926430517711,
    "predict_sportsteam_recall": 0.7089220831651191,
    "predict_steps_per_second": 7.065,
    "predict_theater_f1": 0.6247379454926625,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.5983935742971888,
    "predict_theater_recall": 0.6535087719298246,
    "predict_train_f1": 0.3429355281207134,
    "predict_train_number": 314,
    "predict_train_precision": 0.30120481927710846,
    "predict_train_recall": 0.3980891719745223,
    "predict_weapon_f1": 0.40417598806860544,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.3784916201117318,
    "predict_weapon_recall": 0.4336,
    "predict_writtenart_f1": 0.4139433551198257,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.3760886777513856,
    "predict_writtenart_recall": 0.46027131782945735
}