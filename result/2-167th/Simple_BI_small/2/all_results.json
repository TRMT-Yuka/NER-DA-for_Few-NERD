{
    "predict_GPE_f1": 0.7532313530179058,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7299135870564442,
    "predict_GPE_recall": 0.7780880983879661,
    "predict_actor_f1": 0.6971916971916972,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6971916971916972,
    "predict_actor_recall": 0.6971916971916972,
    "predict_airplane_f1": 0.5189504373177842,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.4831704668838219,
    "predict_airplane_recall": 0.5604534005037783,
    "predict_airport_f1": 0.6059907834101382,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.5218253968253969,
    "predict_airport_recall": 0.7225274725274725,
    "predict_artist/author_f1": 0.5837922895357985,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5348390197020663,
    "predict_artist/author_recall": 0.6426096997690531,
    "predict_astronomything_f1": 0.6116433308769345,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.6111929307805597,
    "predict_astronomything_recall": 0.612094395280236,
    "predict_athlete_f1": 0.7925385239253853,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7498465316144874,
    "predict_athlete_recall": 0.8403852769177846,
    "predict_attack/battle/war/militaryconflict_f1": 0.5767761650114591,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.4970375246872943,
    "predict_attack/battle/war/militaryconflict_recall": 0.6869881710646042,
    "predict_award_f1": 0.41076487252124644,
    "predict_award_number": 941,
    "predict_award_precision": 0.3695836873406967,
    "predict_award_recall": 0.4622741764080765,
    "predict_biologything_f1": 0.553071189925469,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.5337301587301587,
    "predict_biologything_recall": 0.5738666666666666,
    "predict_bodiesofwater_f1": 0.6175152749490835,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.5894245723172629,
    "predict_bodiesofwater_recall": 0.6484174508126604,
    "predict_broadcastprogram_f1": 0.41904761904761906,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.4030534351145038,
    "predict_broadcastprogram_recall": 0.43636363636363634,
    "predict_car_f1": 0.6008064516129032,
    "predict_car_number": 688,
    "predict_car_precision": 0.55875,
    "predict_car_recall": 0.6497093023255814,
    "predict_chemicalthing_f1": 0.4967741935483871,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.4662629757785467,
    "predict_chemicalthing_recall": 0.5315581854043393,
    "predict_company_f1": 0.5549326016939042,
    "predict_company_number": 3903,
    "predict_company_precision": 0.5191964285714286,
    "predict_company_recall": 0.5959518319241609,
    "predict_currency_f1": 0.66746126340882,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.6370875995449374,
    "predict_currency_recall": 0.7008760951188986,
    "predict_director_f1": 0.5483870967741935,
    "predict_director_number": 554,
    "predict_director_precision": 0.4772727272727273,
    "predict_director_recall": 0.644404332129964,
    "predict_disaster_f1": 0.36717062634989195,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.33203125,
    "predict_disaster_recall": 0.4106280193236715,
    "predict_disease_f1": 0.5282805429864252,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.4587426326129666,
    "predict_disease_recall": 0.6226666666666667,
    "predict_education_f1": 0.6503178928247049,
    "predict_education_number": 2082,
    "predict_education_precision": 0.6167097329888027,
    "predict_education_recall": 0.6878001921229587,
    "predict_educationaldegree_f1": 0.447191011235955,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.38049713193116635,
    "predict_educationaldegree_recall": 0.5422343324250681,
    "predict_election_f1": 0.20202020202020202,
    "predict_election_number": 184,
    "predict_election_precision": 0.18867924528301888,
    "predict_election_recall": 0.21739130434782608,
    "predict_film_f1": 0.5699937225360954,
    "predict_film_number": 759,
    "predict_film_precision": 0.5443645083932853,
    "predict_film_recall": 0.5981554677206851,
    "predict_food_f1": 0.3761863675582398,
    "predict_food_number": 432,
    "predict_food_precision": 0.2998624484181568,
    "predict_food_recall": 0.5046296296296297,
    "predict_game_f1": 0.5471502590673575,
    "predict_game_number": 496,
    "predict_game_precision": 0.5628997867803838,
    "predict_game_recall": 0.532258064516129,
    "predict_god_f1": 0.5912806539509536,
    "predict_god_number": 635,
    "predict_god_precision": 0.5210084033613446,
    "predict_god_recall": 0.6834645669291338,
    "predict_government/governmentagency_f1": 0.30568921596377013,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.2702702702702703,
    "predict_government/governmentagency_recall": 0.3517915309446254,
    "predict_hospital_f1": 0.5770171149144255,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.5198237885462555,
    "predict_hospital_recall": 0.6483516483516484,
    "predict_hotel_f1": 0.5423728813559323,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.49230769230769234,
    "predict_hotel_recall": 0.6037735849056604,
    "predict_island_f1": 0.5585874799357944,
    "predict_island_number": 646,
    "predict_island_precision": 0.58,
    "predict_island_recall": 0.5386996904024768,
    "predict_language_f1": 0.610730593607306,
    "predict_language_number": 753,
    "predict_language_precision": 0.5355355355355356,
    "predict_language_recall": 0.7104913678618858,
    "predict_law_f1": 0.436235708003518,
    "predict_law_number": 488,
    "predict_law_precision": 0.38212634822804314,
    "predict_law_recall": 0.5081967213114754,
    "predict_library_f1": 0.5486725663716814,
    "predict_library_number": 357,
    "predict_library_precision": 0.5,
    "predict_library_recall": 0.6078431372549019,
    "predict_livingthing_f1": 0.5330444203683641,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.5015290519877675,
    "predict_livingthing_recall": 0.5687861271676301,
    "predict_loss": 0.5035048127174377,
    "predict_media/newspaper_f1": 0.5423340961098398,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.5122478386167147,
    "predict_media/newspaper_recall": 0.5761750405186385,
    "predict_medical_f1": 0.3558011049723757,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.3169291338582677,
    "predict_medical_recall": 0.40554156171284633,
    "predict_mountain_f1": 0.5606813342796308,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.5425824175824175,
    "predict_mountain_recall": 0.580029368575624,
    "predict_music_f1": 0.6043165467625898,
    "predict_music_number": 1041,
    "predict_music_precision": 0.603448275862069,
    "predict_music_recall": 0.6051873198847262,
    "predict_other_f1": 0.4477128592632573,
    "predict_other_number": 21035,
    "predict_other_precision": 0.4248218172506508,
    "predict_other_recall": 0.47321131447587356,
    "predict_overall_accuracy": 0.9025106019842485,
    "predict_overall_f1": 0.567760053270027,
    "predict_overall_precision": 0.5331297460898563,
    "predict_overall_recall": 0.6072018329686661,
    "predict_painting_f1": 0.1509433962264151,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.1188118811881188,
    "predict_painting_recall": 0.20689655172413793,
    "predict_park_f1": 0.40347490347490345,
    "predict_park_number": 458,
    "predict_park_precision": 0.3615916955017301,
    "predict_park_recall": 0.45633187772925765,
    "predict_politicalparty_f1": 0.5683423348566681,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.5066666666666667,
    "predict_politicalparty_recall": 0.6471144749290445,
    "predict_politician_f1": 0.5452800000000001,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5025066352108523,
    "predict_politician_recall": 0.5960125918153201,
    "predict_protest_f1": 0.12244897959183673,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.189873417721519,
    "predict_protest_recall": 0.09036144578313253,
    "predict_religion_f1": 0.45700245700245695,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.3907563025210084,
    "predict_religion_recall": 0.5502958579881657,
    "predict_restaurant_f1": 0.3063063063063063,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.32075471698113206,
    "predict_restaurant_recall": 0.29310344827586204,
    "predict_road/railway/highway/transit_f1": 0.5892557358701735,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.5625,
    "predict_road/railway/highway/transit_recall": 0.618683901292597,
    "predict_runtime": 281.7346,
    "predict_samples_per_second": 133.626,
    "predict_scholar_f1": 0.3337696335078534,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.3248407643312102,
    "predict_scholar_recall": 0.34320323014804843,
    "predict_ship_f1": 0.501775147928994,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.4559139784946237,
    "predict_ship_recall": 0.5578947368421052,
    "predict_showorganization_f1": 0.44494130799329235,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.39057899901864573,
    "predict_showorganization_recall": 0.5168831168831168,
    "predict_software_f1": 0.5390749601275917,
    "predict_software_number": 889,
    "predict_software_precision": 0.5110887096774194,
    "predict_software_recall": 0.5703037120359955,
    "predict_soldier_f1": 0.4199192462987887,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.37187127532777114,
    "predict_soldier_recall": 0.482225656877898,
    "predict_sportsevent_f1": 0.4532561505065123,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.4158258098778545,
    "predict_sportsevent_recall": 0.49809160305343514,
    "predict_sportsfacility_f1": 0.5617977528089887,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.4919499105545617,
    "predict_sportsfacility_recall": 0.6547619047619048,
    "predict_sportsleague_f1": 0.4720314033366045,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.417172593235039,
    "predict_sportsleague_recall": 0.5435028248587571,
    "predict_sportsteam_f1": 0.658703071672355,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.6210225241329996,
    "predict_sportsteam_recall": 0.7012515139281389,
    "predict_steps_per_second": 4.178,
    "predict_theater_f1": 0.5706666666666667,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.4798206278026906,
    "predict_theater_recall": 0.7039473684210527,
    "predict_train_f1": 0.37866666666666665,
    "predict_train_number": 314,
    "predict_train_precision": 0.3256880733944954,
    "predict_train_recall": 0.45222929936305734,
    "predict_weapon_f1": 0.42088091353996737,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.4292845257903494,
    "predict_weapon_recall": 0.4128,
    "predict_writtenart_f1": 0.42344706911636043,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.38596491228070173,
    "predict_writtenart_recall": 0.4689922480620155
}