{
    "predict_GPE_f1": 0.7564833900580029,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7404401069769624,
    "predict_GPE_recall": 0.7732372972708119,
    "predict_actor_f1": 0.6473099914602903,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6064,
    "predict_actor_recall": 0.6941391941391941,
    "predict_airplane_f1": 0.5359951603145796,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.5157159487776485,
    "predict_airplane_recall": 0.5579345088161209,
    "predict_airport_f1": 0.6859296482412061,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.6319444444444444,
    "predict_airport_recall": 0.75,
    "predict_artist/author_f1": 0.561027232961761,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5487165332597295,
    "predict_artist/author_recall": 0.5739030023094688,
    "predict_astronomything_f1": 0.5829725829725829,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.5706214689265536,
    "predict_astronomything_recall": 0.5958702064896755,
    "predict_athlete_f1": 0.7701633271594545,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7542875989445911,
    "predict_athlete_recall": 0.7867217062263502,
    "predict_attack/battle/war/militaryconflict_f1": 0.6273666092943201,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5951020408163266,
    "predict_attack/battle/war/militaryconflict_recall": 0.6633303002729755,
    "predict_award_f1": 0.45375722543352603,
    "predict_award_number": 941,
    "predict_award_precision": 0.4149779735682819,
    "predict_award_recall": 0.5005313496280552,
    "predict_biologything_f1": 0.5044525929806181,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.49562532166752443,
    "predict_biologything_recall": 0.5136,
    "predict_bodiesofwater_f1": 0.6249488752556237,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.5987460815047022,
    "predict_bodiesofwater_recall": 0.6535500427715997,
    "predict_broadcastprogram_f1": 0.37358818418766293,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.39377289377289376,
    "predict_broadcastprogram_recall": 0.35537190082644626,
    "predict_car_f1": 0.5569620253164558,
    "predict_car_number": 688,
    "predict_car_precision": 0.5395095367847411,
    "predict_car_recall": 0.5755813953488372,
    "predict_chemicalthing_f1": 0.4720327421555252,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.4379746835443038,
    "predict_chemicalthing_recall": 0.5118343195266272,
    "predict_company_f1": 0.5502685150493318,
    "predict_company_number": 3903,
    "predict_company_precision": 0.5367933723196882,
    "predict_company_recall": 0.5644376120932616,
    "predict_currency_f1": 0.6526315789473683,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.5854870775347912,
    "predict_currency_recall": 0.737171464330413,
    "predict_director_f1": 0.5350649350649351,
    "predict_director_number": 554,
    "predict_director_precision": 0.5141430948419301,
    "predict_director_recall": 0.5577617328519856,
    "predict_disaster_f1": 0.38923395445134584,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.34057971014492755,
    "predict_disaster_recall": 0.45410628019323673,
    "predict_disease_f1": 0.49058894960534305,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.4503901895206243,
    "predict_disease_recall": 0.5386666666666666,
    "predict_education_f1": 0.6598546775658493,
    "predict_education_number": 2082,
    "predict_education_precision": 0.6257536606373816,
    "predict_education_recall": 0.6978866474543708,
    "predict_educationaldegree_f1": 0.4444444444444445,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.37523452157598497,
    "predict_educationaldegree_recall": 0.5449591280653951,
    "predict_election_f1": 0.21256038647342995,
    "predict_election_number": 184,
    "predict_election_precision": 0.19130434782608696,
    "predict_election_recall": 0.2391304347826087,
    "predict_film_f1": 0.5879332477535302,
    "predict_film_number": 759,
    "predict_film_precision": 0.5732165206508135,
    "predict_film_recall": 0.6034255599472991,
    "predict_food_f1": 0.3561368209255533,
    "predict_food_number": 432,
    "predict_food_precision": 0.31494661921708184,
    "predict_food_recall": 0.4097222222222222,
    "predict_game_f1": 0.5720040281973817,
    "predict_game_number": 496,
    "predict_game_precision": 0.5714285714285714,
    "predict_game_recall": 0.5725806451612904,
    "predict_god_f1": 0.5,
    "predict_god_number": 635,
    "predict_god_precision": 0.5251299826689775,
    "predict_god_recall": 0.47716535433070867,
    "predict_government/governmentagency_f1": 0.308165548098434,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.2699657030867222,
    "predict_government/governmentagency_recall": 0.358957654723127,
    "predict_hospital_f1": 0.5456852791878173,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.5070754716981132,
    "predict_hospital_recall": 0.5906593406593407,
    "predict_hotel_f1": 0.551984877126654,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.553030303030303,
    "predict_hotel_recall": 0.5509433962264151,
    "predict_island_f1": 0.5390505359877489,
    "predict_island_number": 646,
    "predict_island_precision": 0.5333333333333333,
    "predict_island_recall": 0.544891640866873,
    "predict_language_f1": 0.6029498525073747,
    "predict_language_number": 753,
    "predict_language_precision": 0.5424628450106157,
    "predict_language_recall": 0.6786188579017264,
    "predict_law_f1": 0.4415584415584416,
    "predict_law_number": 488,
    "predict_law_precision": 0.3823088455772114,
    "predict_law_recall": 0.5225409836065574,
    "predict_library_f1": 0.5575447570332481,
    "predict_library_number": 357,
    "predict_library_precision": 0.5129411764705882,
    "predict_library_recall": 0.6106442577030813,
    "predict_livingthing_f1": 0.4742589703588143,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.43100189035916825,
    "predict_livingthing_recall": 0.5271676300578034,
    "predict_loss": 0.5203870534896851,
    "predict_media/newspaper_f1": 0.5295489891135303,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.5089686098654709,
    "predict_media/newspaper_recall": 0.5518638573743923,
    "predict_medical_f1": 0.38980509745127434,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.48148148148148145,
    "predict_medical_recall": 0.327455919395466,
    "predict_mountain_f1": 0.5539143279172822,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.5572065378900446,
    "predict_mountain_recall": 0.5506607929515418,
    "predict_music_f1": 0.6132701421800948,
    "predict_music_number": 1041,
    "predict_music_precision": 0.6052385406922357,
    "predict_music_recall": 0.6215177713736791,
    "predict_other_f1": 0.44804062258527433,
    "predict_other_number": 21035,
    "predict_other_precision": 0.4182605111294312,
    "predict_other_recall": 0.4823864986926551,
    "predict_overall_accuracy": 0.900722433212385,
    "predict_overall_f1": 0.562160995752945,
    "predict_overall_precision": 0.5355747846076214,
    "predict_overall_recall": 0.5915245840729885,
    "predict_painting_f1": 0.05714285714285715,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.16666666666666666,
    "predict_painting_recall": 0.034482758620689655,
    "predict_park_f1": 0.4170905391658189,
    "predict_park_number": 458,
    "predict_park_precision": 0.3904761904761905,
    "predict_park_recall": 0.44759825327510916,
    "predict_politicalparty_f1": 0.5904255319148937,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.5554628857381151,
    "predict_politicalparty_recall": 0.630085146641438,
    "predict_politician_f1": 0.5375647668393781,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5004522158577027,
    "predict_politician_recall": 0.5806225953130465,
    "predict_protest_f1": 0.2849162011173184,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.265625,
    "predict_protest_recall": 0.3072289156626506,
    "predict_religion_f1": 0.4607843137254902,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.39330543933054396,
    "predict_religion_recall": 0.5562130177514792,
    "predict_restaurant_f1": 0.3245436105476674,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.3065134099616858,
    "predict_restaurant_recall": 0.3448275862068966,
    "predict_road/railway/highway/transit_f1": 0.5634201585503964,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.5437158469945356,
    "predict_road/railway/highway/transit_recall": 0.5846063454759107,
    "predict_runtime": 268.9025,
    "predict_samples_per_second": 140.002,
    "predict_scholar_f1": 0.3151432469304229,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.31950207468879666,
    "predict_scholar_recall": 0.31090174966352624,
    "predict_ship_f1": 0.43391521197007477,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.41232227488151657,
    "predict_ship_recall": 0.45789473684210524,
    "predict_showorganization_f1": 0.38602941176470584,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.3654292343387471,
    "predict_showorganization_recall": 0.4090909090909091,
    "predict_software_f1": 0.4783118405627198,
    "predict_software_number": 889,
    "predict_software_precision": 0.49938800489596086,
    "predict_software_recall": 0.45894263217097864,
    "predict_soldier_f1": 0.39065817409766457,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.360313315926893,
    "predict_soldier_recall": 0.4265842349304482,
    "predict_sportsevent_f1": 0.43723208818126147,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.4214876033057851,
    "predict_sportsevent_recall": 0.4541984732824427,
    "predict_sportsfacility_f1": 0.5669988925802879,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.5300207039337475,
    "predict_sportsfacility_recall": 0.6095238095238096,
    "predict_sportsleague_f1": 0.5046094129063562,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.4421768707482993,
    "predict_sportsleague_recall": 0.5875706214689266,
    "predict_sportsteam_f1": 0.6342769701606733,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.6026899309342058,
    "predict_sportsteam_recall": 0.6693580944691159,
    "predict_steps_per_second": 4.377,
    "predict_theater_f1": 0.5823591923485654,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.5649484536082474,
    "predict_theater_recall": 0.6008771929824561,
    "predict_train_f1": 0.3823109843081312,
    "predict_train_number": 314,
    "predict_train_precision": 0.3462532299741602,
    "predict_train_recall": 0.4267515923566879,
    "predict_weapon_f1": 0.33072236727589205,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.36259541984732824,
    "predict_weapon_recall": 0.304,
    "predict_writtenart_f1": 0.4879544459045116,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.44524380495603516,
    "predict_writtenart_recall": 0.5397286821705426
}