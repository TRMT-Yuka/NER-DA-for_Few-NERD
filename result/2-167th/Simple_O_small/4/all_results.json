{
    "predict_GPE_f1": 0.7658785573265277,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7528994082840237,
    "predict_GPE_recall": 0.7793130481650252,
    "predict_actor_f1": 0.6712604076945162,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6336043360433604,
    "predict_actor_recall": 0.7136752136752137,
    "predict_airplane_f1": 0.5035714285714286,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.47742663656884876,
    "predict_airplane_recall": 0.5327455919395466,
    "predict_airport_f1": 0.6068965517241379,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.5217391304347826,
    "predict_airport_recall": 0.7252747252747253,
    "predict_artist/author_f1": 0.5604685212298681,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5686274509803921,
    "predict_artist/author_recall": 0.5525404157043879,
    "predict_astronomything_f1": 0.6476578411405296,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.6,
    "predict_astronomything_recall": 0.7035398230088495,
    "predict_athlete_f1": 0.7468511619655845,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7710622710622711,
    "predict_athlete_recall": 0.7241142070863433,
    "predict_attack/battle/war/militaryconflict_f1": 0.6233333333333334,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5749423520368947,
    "predict_attack/battle/war/militaryconflict_recall": 0.6806187443130118,
    "predict_award_f1": 0.44047058823529417,
    "predict_award_number": 941,
    "predict_award_precision": 0.3952702702702703,
    "predict_award_recall": 0.4973432518597237,
    "predict_biologything_f1": 0.5165007857517026,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.5074626865671642,
    "predict_biologything_recall": 0.5258666666666667,
    "predict_bodiesofwater_f1": 0.6327543424317619,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.6124899919935949,
    "predict_bodiesofwater_recall": 0.6544054747647562,
    "predict_broadcastprogram_f1": 0.44801223241590216,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.4167852062588905,
    "predict_broadcastprogram_recall": 0.484297520661157,
    "predict_car_f1": 0.5458392101551481,
    "predict_car_number": 688,
    "predict_car_precision": 0.5301369863013699,
    "predict_car_recall": 0.5625,
    "predict_chemicalthing_f1": 0.4882506527415144,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.4369158878504673,
    "predict_chemicalthing_recall": 0.5532544378698225,
    "predict_company_f1": 0.5660997067448681,
    "predict_company_number": 3903,
    "predict_company_precision": 0.5220683686715708,
    "predict_company_recall": 0.6182423776582117,
    "predict_currency_f1": 0.6371477860839564,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.5893617021276596,
    "predict_currency_recall": 0.6933667083854819,
    "predict_director_f1": 0.5549645390070922,
    "predict_director_number": 554,
    "predict_director_precision": 0.5452961672473867,
    "predict_director_recall": 0.5649819494584838,
    "predict_disaster_f1": 0.3557951482479784,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.4024390243902439,
    "predict_disaster_recall": 0.3188405797101449,
    "predict_disease_f1": 0.5038932146829811,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.43225190839694655,
    "predict_disease_recall": 0.604,
    "predict_education_f1": 0.6722197208464656,
    "predict_education_number": 2082,
    "predict_education_precision": 0.6326271186440678,
    "predict_education_recall": 0.7170989433237271,
    "predict_educationaldegree_f1": 0.4077669902912622,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.3375,
    "predict_educationaldegree_recall": 0.5149863760217984,
    "predict_election_f1": 0.18340611353711792,
    "predict_election_number": 184,
    "predict_election_precision": 0.15328467153284672,
    "predict_election_recall": 0.22826086956521738,
    "predict_film_f1": 0.5631313131313131,
    "predict_film_number": 759,
    "predict_film_precision": 0.5406060606060606,
    "predict_film_recall": 0.5876152832674572,
    "predict_food_f1": 0.42388059701492536,
    "predict_food_number": 432,
    "predict_food_precision": 0.3717277486910995,
    "predict_food_recall": 0.4930555555555556,
    "predict_game_f1": 0.4943820224719101,
    "predict_game_number": 496,
    "predict_game_precision": 0.43267776096822996,
    "predict_game_recall": 0.5766129032258065,
    "predict_god_f1": 0.5385159010600707,
    "predict_god_number": 635,
    "predict_god_precision": 0.48846153846153845,
    "predict_god_recall": 0.6,
    "predict_government/governmentagency_f1": 0.3130912419896247,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.2944890929965557,
    "predict_government/governmentagency_recall": 0.33420195439739414,
    "predict_hospital_f1": 0.6052963430012611,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.5594405594405595,
    "predict_hospital_recall": 0.6593406593406593,
    "predict_hotel_f1": 0.5571955719557197,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.5451263537906137,
    "predict_hotel_recall": 0.569811320754717,
    "predict_island_f1": 0.5388453314326443,
    "predict_island_number": 646,
    "predict_island_precision": 0.49933949801849403,
    "predict_island_recall": 0.5851393188854489,
    "predict_language_f1": 0.5929468021518232,
    "predict_language_number": 753,
    "predict_language_precision": 0.5391304347826087,
    "predict_language_recall": 0.6586985391766268,
    "predict_law_f1": 0.4354697102721686,
    "predict_law_number": 488,
    "predict_law_precision": 0.38095238095238093,
    "predict_law_recall": 0.5081967213114754,
    "predict_library_f1": 0.5829145728643216,
    "predict_library_number": 357,
    "predict_library_precision": 0.5284738041002278,
    "predict_library_recall": 0.6498599439775911,
    "predict_livingthing_f1": 0.531839021905247,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.47540983606557374,
    "predict_livingthing_recall": 0.6034682080924856,
    "predict_loss": 0.5193536877632141,
    "predict_media/newspaper_f1": 0.48906882591093115,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.4886731391585761,
    "predict_media/newspaper_recall": 0.48946515397082657,
    "predict_medical_f1": 0.2656826568265683,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.25961538461538464,
    "predict_medical_recall": 0.27204030226700254,
    "predict_mountain_f1": 0.6016628873771731,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.6199376947040498,
    "predict_mountain_recall": 0.5844346549192364,
    "predict_music_f1": 0.5996343692870201,
    "predict_music_number": 1041,
    "predict_music_precision": 0.5719267654751525,
    "predict_music_recall": 0.6301633045148896,
    "predict_other_f1": 0.45877607667953335,
    "predict_other_number": 21035,
    "predict_other_precision": 0.421787152597791,
    "predict_other_recall": 0.5028761587829808,
    "predict_overall_accuracy": 0.9008776901245746,
    "predict_overall_f1": 0.5666215281498729,
    "predict_overall_precision": 0.5365399162377078,
    "predict_overall_recall": 0.6002765966230442,
    "predict_painting_f1": 0.21138211382113822,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.2,
    "predict_painting_recall": 0.22413793103448276,
    "predict_park_f1": 0.40414507772020725,
    "predict_park_number": 458,
    "predict_park_precision": 0.38461538461538464,
    "predict_park_recall": 0.425764192139738,
    "predict_politicalparty_f1": 0.5466607695709863,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.5132890365448505,
    "predict_politicalparty_recall": 0.5846736045411542,
    "predict_politician_f1": 0.5432724814063556,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.525678770035983,
    "predict_politician_recall": 0.5620846449807625,
    "predict_protest_f1": 0.14414414414414414,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.1437125748502994,
    "predict_protest_recall": 0.14457831325301204,
    "predict_religion_f1": 0.4234828496042216,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.3821428571428571,
    "predict_religion_recall": 0.47485207100591714,
    "predict_restaurant_f1": 0.3163265306122449,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.3875,
    "predict_restaurant_recall": 0.2672413793103448,
    "predict_road/railway/highway/transit_f1": 0.5899705014749262,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.5426739023186976,
    "predict_road/railway/highway/transit_recall": 0.6462984723854289,
    "predict_runtime": 269.3751,
    "predict_samples_per_second": 139.757,
    "predict_scholar_f1": 0.30748299319727895,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.3108665749656121,
    "predict_scholar_recall": 0.3041722745625841,
    "predict_ship_f1": 0.5154130702836006,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.48491879350348027,
    "predict_ship_recall": 0.55,
    "predict_showorganization_f1": 0.3924050632911393,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.38271604938271603,
    "predict_showorganization_recall": 0.4025974025974026,
    "predict_software_f1": 0.42563482466747277,
    "predict_software_number": 889,
    "predict_software_precision": 0.46013071895424834,
    "predict_software_recall": 0.39595050618672667,
    "predict_soldier_f1": 0.3708029197080292,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.35131396957123096,
    "predict_soldier_recall": 0.39258114374034003,
    "predict_sportsevent_f1": 0.4348837209302326,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.4004282655246253,
    "predict_sportsevent_recall": 0.4758269720101781,
    "predict_sportsfacility_f1": 0.5203073545554336,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.48268839103869654,
    "predict_sportsfacility_recall": 0.5642857142857143,
    "predict_sportsleague_f1": 0.5257936507936507,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.46861184792219274,
    "predict_sportsleague_recall": 0.5988700564971752,
    "predict_sportsteam_f1": 0.6598600869729627,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.6205547652916074,
    "predict_sportsteam_recall": 0.7044812272910779,
    "predict_steps_per_second": 4.369,
    "predict_theater_f1": 0.583170254403131,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.5265017667844523,
    "predict_theater_recall": 0.6535087719298246,
    "predict_train_f1": 0.3154761904761905,
    "predict_train_number": 314,
    "predict_train_precision": 0.29608938547486036,
    "predict_train_recall": 0.3375796178343949,
    "predict_weapon_f1": 0.39592430858806404,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.36315086782376504,
    "predict_weapon_recall": 0.4352,
    "predict_writtenart_f1": 0.4699763593380615,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.45891043397968606,
    "predict_writtenart_recall": 0.48158914728682173
}