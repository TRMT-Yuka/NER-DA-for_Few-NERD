{
    "predict_GPE_f1": 0.7666005478416926,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7398696385432335,
    "predict_GPE_recall": 0.7953353912489588,
    "predict_actor_f1": 0.670440251572327,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6913099870298314,
    "predict_actor_recall": 0.6507936507936508,
    "predict_airplane_f1": 0.47489150650960943,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.46764346764346765,
    "predict_airplane_recall": 0.482367758186398,
    "predict_airport_f1": 0.689922480620155,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.651219512195122,
    "predict_airport_recall": 0.7335164835164835,
    "predict_artist/author_f1": 0.5543130990415335,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5143280632411067,
    "predict_artist/author_recall": 0.601039260969977,
    "predict_astronomything_f1": 0.5798588838999358,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.5130533484676504,
    "predict_astronomything_recall": 0.6666666666666666,
    "predict_athlete_f1": 0.7618073316283035,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7552400270453009,
    "predict_athlete_recall": 0.7684898520811834,
    "predict_attack/battle/war/militaryconflict_f1": 0.6151202749140894,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5825874694873882,
    "predict_attack/battle/war/militaryconflict_recall": 0.651501364877161,
    "predict_award_f1": 0.4652981427174976,
    "predict_award_number": 941,
    "predict_award_precision": 0.4307692307692308,
    "predict_award_recall": 0.5058448459086079,
    "predict_biologything_f1": 0.529669260700389,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.48681269557443,
    "predict_biologything_recall": 0.5808,
    "predict_bodiesofwater_f1": 0.6237580993520518,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.6300174520069808,
    "predict_bodiesofwater_recall": 0.6176218990590248,
    "predict_broadcastprogram_f1": 0.4355345911949685,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.41529235382308843,
    "predict_broadcastprogram_recall": 0.4578512396694215,
    "predict_car_f1": 0.5436893203883495,
    "predict_car_number": 688,
    "predict_car_precision": 0.519893899204244,
    "predict_car_recall": 0.5697674418604651,
    "predict_chemicalthing_f1": 0.4575471698113207,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.4385171790235081,
    "predict_chemicalthing_recall": 0.47830374753451677,
    "predict_company_f1": 0.5545673076923078,
    "predict_company_number": 3903,
    "predict_company_precision": 0.522300203758207,
    "predict_company_recall": 0.5910837817063798,
    "predict_currency_f1": 0.6161504424778762,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.5520317145688801,
    "predict_currency_recall": 0.6971214017521903,
    "predict_director_f1": 0.49268668206312544,
    "predict_director_number": 554,
    "predict_director_precision": 0.42953020134228187,
    "predict_director_recall": 0.5776173285198556,
    "predict_disaster_f1": 0.33469387755102037,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.28975265017667845,
    "predict_disaster_recall": 0.3961352657004831,
    "predict_disease_f1": 0.5072314049586776,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.4139966273187184,
    "predict_disease_recall": 0.6546666666666666,
    "predict_education_f1": 0.6855965193496679,
    "predict_education_number": 2082,
    "predict_education_precision": 0.6551422319474836,
    "predict_education_recall": 0.7190201729106628,
    "predict_educationaldegree_f1": 0.4527027027027027,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.3857965451055662,
    "predict_educationaldegree_recall": 0.547683923705722,
    "predict_election_f1": 0.11009174311926605,
    "predict_election_number": 184,
    "predict_election_precision": 0.09523809523809523,
    "predict_election_recall": 0.13043478260869565,
    "predict_film_f1": 0.5685752330226365,
    "predict_film_number": 759,
    "predict_film_precision": 0.5746971736204576,
    "predict_film_recall": 0.5625823451910409,
    "predict_food_f1": 0.3546694648478489,
    "predict_food_number": 432,
    "predict_food_precision": 0.32437619961612285,
    "predict_food_recall": 0.3912037037037037,
    "predict_game_f1": 0.46516613076098606,
    "predict_game_number": 496,
    "predict_game_precision": 0.4965675057208238,
    "predict_game_recall": 0.4375,
    "predict_god_f1": 0.5559416261292565,
    "predict_god_number": 635,
    "predict_god_precision": 0.4975124378109453,
    "predict_god_recall": 0.6299212598425197,
    "predict_government/governmentagency_f1": 0.3055640946818322,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.2892898719441211,
    "predict_government/governmentagency_recall": 0.3237785016286645,
    "predict_hospital_f1": 0.6132075471698114,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.5371900826446281,
    "predict_hospital_recall": 0.7142857142857143,
    "predict_hotel_f1": 0.5703971119133574,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.5467128027681661,
    "predict_hotel_recall": 0.5962264150943396,
    "predict_island_f1": 0.5134730538922155,
    "predict_island_number": 646,
    "predict_island_precision": 0.4971014492753623,
    "predict_island_recall": 0.5309597523219814,
    "predict_language_f1": 0.6055261610817165,
    "predict_language_number": 753,
    "predict_language_precision": 0.5432489451476793,
    "predict_language_recall": 0.6839309428950863,
    "predict_law_f1": 0.37104825291181365,
    "predict_law_number": 488,
    "predict_law_precision": 0.3123249299719888,
    "predict_law_recall": 0.4569672131147541,
    "predict_library_f1": 0.5393548387096774,
    "predict_library_number": 357,
    "predict_library_precision": 0.5,
    "predict_library_recall": 0.5854341736694678,
    "predict_livingthing_f1": 0.4859908303616913,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.4344262295081967,
    "predict_livingthing_recall": 0.5514450867052023,
    "predict_loss": 0.6126720905303955,
    "predict_media/newspaper_f1": 0.4997968305566843,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.5012224938875306,
    "predict_media/newspaper_recall": 0.4983792544570502,
    "predict_medical_f1": 0.44902912621359226,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.4332552693208431,
    "predict_medical_recall": 0.4659949622166247,
    "predict_mountain_f1": 0.5517241379310345,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.5513196480938416,
    "predict_mountain_recall": 0.5521292217327459,
    "predict_music_f1": 0.604355716878403,
    "predict_music_number": 1041,
    "predict_music_precision": 0.5726569217540842,
    "predict_music_recall": 0.6397694524495677,
    "predict_other_f1": 0.44661024579094266,
    "predict_other_number": 21035,
    "predict_other_precision": 0.4241012268627367,
    "predict_other_recall": 0.47164250059424767,
    "predict_overall_accuracy": 0.9001209483917338,
    "predict_overall_f1": 0.5640631161787545,
    "predict_overall_precision": 0.5338733906568239,
    "predict_overall_recall": 0.5978718573256822,
    "predict_painting_f1": 0.0,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.0,
    "predict_painting_recall": 0.0,
    "predict_park_f1": 0.4489402697495183,
    "predict_park_number": 458,
    "predict_park_precision": 0.4017241379310345,
    "predict_park_recall": 0.5087336244541485,
    "predict_politicalparty_f1": 0.5767790262172284,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.5148588410104011,
    "predict_politicalparty_recall": 0.6556291390728477,
    "predict_politician_f1": 0.5500081846456049,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5169230769230769,
    "predict_politician_recall": 0.5876180482686254,
    "predict_protest_f1": 0.2018348623853211,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.20496894409937888,
    "predict_protest_recall": 0.19879518072289157,
    "predict_religion_f1": 0.3925233644859813,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.33907427341227125,
    "predict_religion_recall": 0.46597633136094674,
    "predict_restaurant_f1": 0.2505694760820045,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.26570048309178745,
    "predict_restaurant_recall": 0.23706896551724138,
    "predict_road/railway/highway/transit_f1": 0.5697159238988793,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.511943793911007,
    "predict_road/railway/highway/transit_recall": 0.6421856639247944,
    "predict_runtime": 153.2543,
    "predict_samples_per_second": 245.651,
    "predict_scholar_f1": 0.33270082226438963,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.3138424821002387,
    "predict_scholar_recall": 0.35397039030955585,
    "predict_ship_f1": 0.4882860665844636,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.4593967517401392,
    "predict_ship_recall": 0.5210526315789473,
    "predict_showorganization_f1": 0.42909535452322733,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.4053117782909931,
    "predict_showorganization_recall": 0.45584415584415583,
    "predict_software_f1": 0.4735658042744657,
    "predict_software_number": 889,
    "predict_software_precision": 0.4735658042744657,
    "predict_software_recall": 0.4735658042744657,
    "predict_soldier_f1": 0.39032006245121,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.3943217665615142,
    "predict_soldier_recall": 0.38639876352395675,
    "predict_sportsevent_f1": 0.4547896150402865,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.42833052276559863,
    "predict_sportsevent_recall": 0.4847328244274809,
    "predict_sportsfacility_f1": 0.5340659340659341,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.4959183673469388,
    "predict_sportsfacility_recall": 0.5785714285714286,
    "predict_sportsleague_f1": 0.4847270906359539,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.4352517985611511,
    "predict_sportsleague_recall": 0.5468926553672316,
    "predict_sportsteam_f1": 0.648565965583174,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.6160552124954595,
    "predict_sportsteam_recall": 0.6846992329430763,
    "predict_steps_per_second": 7.68,
    "predict_theater_f1": 0.6087888531618436,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.5953878406708596,
    "predict_theater_recall": 0.6228070175438597,
    "predict_train_f1": 0.33282904689863846,
    "predict_train_number": 314,
    "predict_train_precision": 0.3170028818443804,
    "predict_train_recall": 0.3503184713375796,
    "predict_weapon_f1": 0.40971168437025796,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.38961038961038963,
    "predict_weapon_recall": 0.432,
    "predict_writtenart_f1": 0.4202772963604853,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.38009404388714735,
    "predict_writtenart_recall": 0.4699612403100775
}