{
    "predict_GPE_f1": 0.7497501308838228,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7288668856706612,
    "predict_GPE_recall": 0.7718653535205057,
    "predict_actor_f1": 0.6774734488541084,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6247422680412371,
    "predict_actor_recall": 0.73992673992674,
    "predict_airplane_f1": 0.5234899328859061,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.5076923076923077,
    "predict_airplane_recall": 0.5403022670025189,
    "predict_airport_f1": 0.5892018779342724,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.514344262295082,
    "predict_airport_recall": 0.6895604395604396,
    "predict_artist/author_f1": 0.5491379310344828,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5466247139588101,
    "predict_artist/author_recall": 0.5516743648960739,
    "predict_astronomything_f1": 0.6218836565096953,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.5861618798955613,
    "predict_astronomything_recall": 0.6622418879056047,
    "predict_athlete_f1": 0.7801709401709402,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7753992524634726,
    "predict_athlete_recall": 0.7850017199862401,
    "predict_attack/battle/war/militaryconflict_f1": 0.621656050955414,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5828025477707006,
    "predict_attack/battle/war/militaryconflict_recall": 0.6660600545950864,
    "predict_award_f1": 0.4649033570701933,
    "predict_award_number": 941,
    "predict_award_precision": 0.4458536585365854,
    "predict_award_recall": 0.485653560042508,
    "predict_biologything_f1": 0.5205823293172691,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.4917022285443338,
    "predict_biologything_recall": 0.5530666666666667,
    "predict_bodiesofwater_f1": 0.6322471434617011,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.6256281407035176,
    "predict_bodiesofwater_recall": 0.6390076988879384,
    "predict_broadcastprogram_f1": 0.39076669414674364,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.38980263157894735,
    "predict_broadcastprogram_recall": 0.39173553719008264,
    "predict_car_f1": 0.6082548877624908,
    "predict_car_number": 688,
    "predict_car_precision": 0.6060606060606061,
    "predict_car_recall": 0.6104651162790697,
    "predict_chemicalthing_f1": 0.5038693035253654,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.44664634146341464,
    "predict_chemicalthing_recall": 0.5779092702169625,
    "predict_company_f1": 0.5537451361867703,
    "predict_company_number": 3903,
    "predict_company_precision": 0.5269613515389956,
    "predict_company_recall": 0.5833973866256725,
    "predict_currency_f1": 0.5920695274307441,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.5230326295585412,
    "predict_currency_recall": 0.6821026282853567,
    "predict_director_f1": 0.552434456928839,
    "predict_director_number": 554,
    "predict_director_precision": 0.5739299610894941,
    "predict_director_recall": 0.5324909747292419,
    "predict_disaster_f1": 0.3747747747747748,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.2988505747126437,
    "predict_disaster_recall": 0.5024154589371981,
    "predict_disease_f1": 0.5334128878281623,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.48272138228941686,
    "predict_disease_recall": 0.596,
    "predict_education_f1": 0.6430601092896175,
    "predict_education_number": 2082,
    "predict_education_precision": 0.5900521460088247,
    "predict_education_recall": 0.7065321805955812,
    "predict_educationaldegree_f1": 0.4364508393285371,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.3897216274089936,
    "predict_educationaldegree_recall": 0.49591280653950953,
    "predict_election_f1": 0.1553398058252427,
    "predict_election_number": 184,
    "predict_election_precision": 0.14035087719298245,
    "predict_election_recall": 0.17391304347826086,
    "predict_film_f1": 0.5208070617906685,
    "predict_film_number": 759,
    "predict_film_precision": 0.49939540507859737,
    "predict_film_recall": 0.544137022397892,
    "predict_food_f1": 0.42567567567567566,
    "predict_food_number": 432,
    "predict_food_precision": 0.4144736842105263,
    "predict_food_recall": 0.4375,
    "predict_game_f1": 0.5270758122743683,
    "predict_game_number": 496,
    "predict_game_precision": 0.477124183006536,
    "predict_game_recall": 0.5887096774193549,
    "predict_god_f1": 0.5580715850986122,
    "predict_god_number": 635,
    "predict_god_precision": 0.5204359673024523,
    "predict_god_recall": 0.6015748031496063,
    "predict_government/governmentagency_f1": 0.3111111111111111,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.2885793871866295,
    "predict_government/governmentagency_recall": 0.33745928338762216,
    "predict_hospital_f1": 0.4887005649717514,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.502906976744186,
    "predict_hospital_recall": 0.47527472527472525,
    "predict_hotel_f1": 0.4848484848484849,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.4376899696048632,
    "predict_hotel_recall": 0.5433962264150943,
    "predict_island_f1": 0.5172678434382195,
    "predict_island_number": 646,
    "predict_island_precision": 0.512937595129376,
    "predict_island_recall": 0.521671826625387,
    "predict_language_f1": 0.632059326868226,
    "predict_language_number": 753,
    "predict_language_precision": 0.554,
    "predict_language_recall": 0.7357237715803453,
    "predict_law_f1": 0.45233968804159447,
    "predict_law_number": 488,
    "predict_law_precision": 0.3918918918918919,
    "predict_law_recall": 0.5348360655737705,
    "predict_library_f1": 0.5059665871121719,
    "predict_library_number": 357,
    "predict_library_precision": 0.4407484407484408,
    "predict_library_recall": 0.5938375350140056,
    "predict_livingthing_f1": 0.5368731563421828,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.46706586826347307,
    "predict_livingthing_recall": 0.63121387283237,
    "predict_loss": 0.5089136958122253,
    "predict_media/newspaper_f1": 0.525260029717682,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.4849108367626886,
    "predict_media/newspaper_recall": 0.5729335494327391,
    "predict_medical_f1": 0.3388429752066116,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.3738601823708207,
    "predict_medical_recall": 0.30982367758186397,
    "predict_mountain_f1": 0.5712300208478109,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.5422163588390502,
    "predict_mountain_recall": 0.6035242290748899,
    "predict_music_f1": 0.5926597190756684,
    "predict_music_number": 1041,
    "predict_music_precision": 0.5608919382504288,
    "predict_music_recall": 0.6282420749279539,
    "predict_other_f1": 0.4529107760645795,
    "predict_other_number": 21035,
    "predict_other_precision": 0.4111511767670893,
    "predict_other_recall": 0.5041121939624436,
    "predict_overall_accuracy": 0.9007463188911834,
    "predict_overall_f1": 0.5618826854302874,
    "predict_overall_precision": 0.528970651213223,
    "predict_overall_recall": 0.5991619535152541,
    "predict_painting_f1": 0.0,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.0,
    "predict_painting_recall": 0.0,
    "predict_park_f1": 0.4506283662477559,
    "predict_park_number": 458,
    "predict_park_precision": 0.3826219512195122,
    "predict_park_recall": 0.5480349344978166,
    "predict_politicalparty_f1": 0.5888936719758933,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.5402843601895735,
    "predict_politicalparty_recall": 0.6471144749290445,
    "predict_politician_f1": 0.541629523979319,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5523636363636364,
    "predict_politician_recall": 0.5313046519762155,
    "predict_protest_f1": 0.1353846153846154,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.13836477987421383,
    "predict_protest_recall": 0.13253012048192772,
    "predict_religion_f1": 0.4272363150867824,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.38929440389294406,
    "predict_religion_recall": 0.47337278106508873,
    "predict_restaurant_f1": 0.2889305816135085,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.2558139534883721,
    "predict_restaurant_recall": 0.33189655172413796,
    "predict_road/railway/highway/transit_f1": 0.5767293930559236,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.5253500724287784,
    "predict_road/railway/highway/transit_recall": 0.6392479435957696,
    "predict_runtime": 276.5503,
    "predict_samples_per_second": 136.131,
    "predict_scholar_f1": 0.24940047961630696,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.30708661417322836,
    "predict_scholar_recall": 0.20995962314939434,
    "predict_ship_f1": 0.4903078677309008,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.43259557344064387,
    "predict_ship_recall": 0.5657894736842105,
    "predict_showorganization_f1": 0.4312459651387992,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.4287548138639281,
    "predict_showorganization_recall": 0.43376623376623374,
    "predict_software_f1": 0.5054602184087363,
    "predict_software_number": 889,
    "predict_software_precision": 0.4700193423597679,
    "predict_software_recall": 0.5466816647919011,
    "predict_soldier_f1": 0.38568298027757486,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.3656509695290859,
    "predict_soldier_recall": 0.4080370942812983,
    "predict_sportsevent_f1": 0.4602026049204052,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.4221986192246415,
    "predict_sportsevent_recall": 0.5057251908396947,
    "predict_sportsfacility_f1": 0.5253863134657838,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.4897119341563786,
    "predict_sportsfacility_recall": 0.5666666666666667,
    "predict_sportsleague_f1": 0.43854899837574446,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.420997920997921,
    "predict_sportsleague_recall": 0.4576271186440678,
    "predict_sportsteam_f1": 0.6330016895062887,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.5915789473684211,
    "predict_sportsteam_recall": 0.6806620912394025,
    "predict_steps_per_second": 4.256,
    "predict_theater_f1": 0.5020242914979757,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.46616541353383456,
    "predict_theater_recall": 0.543859649122807,
    "predict_train_f1": 0.35665294924554186,
    "predict_train_number": 314,
    "predict_train_precision": 0.3132530120481928,
    "predict_train_recall": 0.4140127388535032,
    "predict_weapon_f1": 0.4205128205128205,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.45137614678899085,
    "predict_weapon_recall": 0.3936,
    "predict_writtenart_f1": 0.4402569593147752,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.39447429009976975,
    "predict_writtenart_recall": 0.49806201550387597
}