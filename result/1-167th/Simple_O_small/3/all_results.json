{
    "predict_GPE_f1": 0.7562922614575507,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7260514808637245,
    "predict_GPE_recall": 0.7891616443725807,
    "predict_actor_f1": 0.6155703077851539,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6085918854415274,
    "predict_actor_recall": 0.6227106227106227,
    "predict_airplane_f1": 0.4959159859976663,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.46195652173913043,
    "predict_airplane_recall": 0.535264483627204,
    "predict_airport_f1": 0.6310432569974554,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.5876777251184834,
    "predict_airport_recall": 0.6813186813186813,
    "predict_artist/author_f1": 0.5402425578831311,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5168776371308017,
    "predict_artist/author_recall": 0.5658198614318707,
    "predict_astronomything_f1": 0.5140614780902552,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.4618096357226792,
    "predict_astronomything_recall": 0.5796460176991151,
    "predict_athlete_f1": 0.7625228823431519,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7385557704706641,
    "predict_athlete_recall": 0.7880976952184382,
    "predict_attack/battle/war/militaryconflict_f1": 0.5983208130799823,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5816151202749141,
    "predict_attack/battle/war/militaryconflict_recall": 0.6160145586897179,
    "predict_award_f1": 0.42286245353159846,
    "predict_award_number": 941,
    "predict_award_precision": 0.37572254335260113,
    "predict_award_recall": 0.48352816153028694,
    "predict_biologything_f1": 0.513022113022113,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.475626423690205,
    "predict_biologything_recall": 0.5568,
    "predict_bodiesofwater_f1": 0.5611775528978841,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.6069651741293532,
    "predict_bodiesofwater_recall": 0.5218135158254918,
    "predict_broadcastprogram_f1": 0.3438985736925515,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.3302891933028919,
    "predict_broadcastprogram_recall": 0.3586776859504132,
    "predict_car_f1": 0.5675471698113207,
    "predict_car_number": 688,
    "predict_car_precision": 0.5902668759811617,
    "predict_car_recall": 0.5465116279069767,
    "predict_chemicalthing_f1": 0.44411326378539495,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.44744744744744747,
    "predict_chemicalthing_recall": 0.4408284023668639,
    "predict_company_f1": 0.5539559493047866,
    "predict_company_number": 3903,
    "predict_company_precision": 0.532907196969697,
    "predict_company_recall": 0.576735844222393,
    "predict_currency_f1": 0.5947368421052632,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.6269070735090153,
    "predict_currency_recall": 0.5657071339173968,
    "predict_director_f1": 0.45064054257724195,
    "predict_director_number": 554,
    "predict_director_precision": 0.3868046571798189,
    "predict_director_recall": 0.5397111913357401,
    "predict_disaster_f1": 0.3828715365239295,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.4,
    "predict_disaster_recall": 0.3671497584541063,
    "predict_disease_f1": 0.46756152125279643,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.4026974951830443,
    "predict_disease_recall": 0.5573333333333333,
    "predict_education_f1": 0.6274169020204214,
    "predict_education_number": 2082,
    "predict_education_precision": 0.5727885759619199,
    "predict_education_recall": 0.6935638808837656,
    "predict_educationaldegree_f1": 0.38315789473684214,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.31217838765008576,
    "predict_educationaldegree_recall": 0.49591280653950953,
    "predict_election_f1": 0.17013232514177692,
    "predict_election_number": 184,
    "predict_election_precision": 0.13043478260869565,
    "predict_election_recall": 0.24456521739130435,
    "predict_film_f1": 0.45848191543555783,
    "predict_film_number": 759,
    "predict_film_precision": 0.37375415282392027,
    "predict_film_recall": 0.5928853754940712,
    "predict_food_f1": 0.3833333333333333,
    "predict_food_number": 432,
    "predict_food_precision": 0.3194444444444444,
    "predict_food_recall": 0.4791666666666667,
    "predict_game_f1": 0.28804347826086957,
    "predict_game_number": 496,
    "predict_game_precision": 0.44166666666666665,
    "predict_game_recall": 0.21370967741935484,
    "predict_god_f1": 0.49586776859504134,
    "predict_god_number": 635,
    "predict_god_precision": 0.5217391304347826,
    "predict_god_recall": 0.47244094488188976,
    "predict_government/governmentagency_f1": 0.28655142103721065,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.26038338658146964,
    "predict_government/governmentagency_recall": 0.31856677524429966,
    "predict_hospital_f1": 0.548936170212766,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.4479166666666667,
    "predict_hospital_recall": 0.7087912087912088,
    "predict_hotel_f1": 0.5457570715474209,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.4880952380952381,
    "predict_hotel_recall": 0.6188679245283019,
    "predict_island_f1": 0.4757033248081841,
    "predict_island_number": 646,
    "predict_island_precision": 0.5294117647058824,
    "predict_island_recall": 0.43188854489164086,
    "predict_language_f1": 0.5184729064039408,
    "predict_language_number": 753,
    "predict_language_precision": 0.4833524684270953,
    "predict_language_recall": 0.5590969455511288,
    "predict_law_f1": 0.43852106620808257,
    "predict_law_number": 488,
    "predict_law_precision": 0.37777777777777777,
    "predict_law_recall": 0.5225409836065574,
    "predict_library_f1": 0.48,
    "predict_library_number": 357,
    "predict_library_precision": 0.43340857787810383,
    "predict_library_recall": 0.5378151260504201,
    "predict_livingthing_f1": 0.5025960539979232,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.45617342130065974,
    "predict_livingthing_recall": 0.5595375722543353,
    "predict_loss": 0.5234364867210388,
    "predict_media/newspaper_f1": 0.527046783625731,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.4800266311584554,
    "predict_media/newspaper_recall": 0.5842787682333873,
    "predict_medical_f1": 0.36363636363636365,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.3812154696132597,
    "predict_medical_recall": 0.34760705289672544,
    "predict_mountain_f1": 0.5113924050632911,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.44938820912124583,
    "predict_mountain_recall": 0.593245227606461,
    "predict_music_f1": 0.5573770491803278,
    "predict_music_number": 1041,
    "predict_music_precision": 0.49551569506726456,
    "predict_music_recall": 0.6368876080691642,
    "predict_other_f1": 0.42066731741946933,
    "predict_other_number": 21035,
    "predict_other_precision": 0.394367954743979,
    "predict_other_recall": 0.4507249821725695,
    "predict_overall_accuracy": 0.8962362684489726,
    "predict_overall_f1": 0.5406039712914,
    "predict_overall_precision": 0.511725447539684,
    "predict_overall_recall": 0.5729368781736366,
    "predict_painting_f1": 0.0,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.0,
    "predict_painting_recall": 0.0,
    "predict_park_f1": 0.33825198637911463,
    "predict_park_number": 458,
    "predict_park_precision": 0.35224586288416077,
    "predict_park_recall": 0.32532751091703055,
    "predict_politicalparty_f1": 0.576241134751773,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.5421184320266889,
    "predict_politicalparty_recall": 0.6149479659413434,
    "predict_politician_f1": 0.5019197207678884,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5008707767328457,
    "predict_politician_recall": 0.502973067506121,
    "predict_protest_f1": 0.1440922190201729,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.13812154696132597,
    "predict_protest_recall": 0.15060240963855423,
    "predict_religion_f1": 0.42307692307692313,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.3733031674208145,
    "predict_religion_recall": 0.4881656804733728,
    "predict_restaurant_f1": 0.24836601307189543,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.2511013215859031,
    "predict_restaurant_recall": 0.24568965517241378,
    "predict_road/railway/highway/transit_f1": 0.5424540857066809,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.4958637469586375,
    "predict_road/railway/highway/transit_recall": 0.5987074030552292,
    "predict_runtime": 276.9157,
    "predict_samples_per_second": 135.951,
    "predict_scholar_f1": 0.2502994011976048,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.22545846817691478,
    "predict_scholar_recall": 0.2812920592193809,
    "predict_ship_f1": 0.3448275862068966,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.5,
    "predict_ship_recall": 0.2631578947368421,
    "predict_showorganization_f1": 0.4206060606060606,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.39431818181818185,
    "predict_showorganization_recall": 0.45064935064935063,
    "predict_software_f1": 0.3885578069129917,
    "predict_software_number": 889,
    "predict_software_precision": 0.4131812420785805,
    "predict_software_recall": 0.36670416197975253,
    "predict_soldier_f1": 0.3490427098674521,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.3333333333333333,
    "predict_soldier_recall": 0.366306027820711,
    "predict_sportsevent_f1": 0.4354120267260579,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.38712871287128714,
    "predict_sportsevent_recall": 0.49745547073791346,
    "predict_sportsfacility_f1": 0.5894736842105263,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.4928,
    "predict_sportsfacility_recall": 0.7333333333333333,
    "predict_sportsleague_f1": 0.4860813704496788,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.46185147507629704,
    "predict_sportsleague_recall": 0.5129943502824859,
    "predict_sportsteam_f1": 0.6505836575875487,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.6278633120540743,
    "predict_sportsteam_recall": 0.6750100928542592,
    "predict_steps_per_second": 4.25,
    "predict_theater_f1": 0.5614385614385614,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.5155963302752293,
    "predict_theater_recall": 0.6162280701754386,
    "predict_train_f1": 0.329700272479564,
    "predict_train_number": 314,
    "predict_train_precision": 0.28809523809523807,
    "predict_train_recall": 0.3853503184713376,
    "predict_weapon_f1": 0.3735881841876629,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.40874524714828897,
    "predict_weapon_recall": 0.344,
    "predict_writtenart_f1": 0.34517258629314657,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.35677352637021714,
    "predict_writtenart_recall": 0.33430232558139533
}