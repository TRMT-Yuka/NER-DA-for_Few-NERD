{
    "predict_GPE_f1": 0.7423336002637901,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7147262914417888,
    "predict_GPE_recall": 0.7721593414669998,
    "predict_actor_f1": 0.6536873156342183,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.632420091324201,
    "predict_actor_recall": 0.6764346764346765,
    "predict_airplane_f1": 0.5125958378970427,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.45348837209302323,
    "predict_airplane_recall": 0.5894206549118388,
    "predict_airport_f1": 0.6451612903225806,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.5555555555555556,
    "predict_airport_recall": 0.7692307692307693,
    "predict_artist/author_f1": 0.5151426051161423,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5248651887357699,
    "predict_artist/author_recall": 0.5057736720554272,
    "predict_astronomything_f1": 0.5922330097087379,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.5589005235602095,
    "predict_astronomything_recall": 0.6297935103244838,
    "predict_athlete_f1": 0.7733110925771477,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7506476683937824,
    "predict_athlete_recall": 0.7973856209150327,
    "predict_attack/battle/war/militaryconflict_f1": 0.542387178405736,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5055031446540881,
    "predict_attack/battle/war/militaryconflict_recall": 0.5850773430391265,
    "predict_award_f1": 0.38971583220568334,
    "predict_award_number": 941,
    "predict_award_precision": 0.3385579937304075,
    "predict_award_recall": 0.45908607863974493,
    "predict_biologything_f1": 0.508108108108108,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.5150684931506849,
    "predict_biologything_recall": 0.5013333333333333,
    "predict_bodiesofwater_f1": 0.5987730061349694,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.5736677115987461,
    "predict_bodiesofwater_recall": 0.6261762189905903,
    "predict_broadcastprogram_f1": 0.36682615629984056,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.3543913713405239,
    "predict_broadcastprogram_recall": 0.38016528925619836,
    "predict_car_f1": 0.581989247311828,
    "predict_car_number": 688,
    "predict_car_precision": 0.54125,
    "predict_car_recall": 0.6293604651162791,
    "predict_chemicalthing_f1": 0.25916561314791403,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.3609154929577465,
    "predict_chemicalthing_recall": 0.20216962524654833,
    "predict_company_f1": 0.5582319925163705,
    "predict_company_number": 3903,
    "predict_company_precision": 0.5134437513443751,
    "predict_company_recall": 0.6115808352549321,
    "predict_currency_f1": 0.6670378619153675,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.600802407221665,
    "predict_currency_recall": 0.7496871088861077,
    "predict_director_f1": 0.43226788432267876,
    "predict_director_number": 554,
    "predict_director_precision": 0.3736842105263158,
    "predict_director_recall": 0.5126353790613718,
    "predict_disaster_f1": 0.3271889400921659,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.31277533039647576,
    "predict_disaster_recall": 0.34299516908212563,
    "predict_disease_f1": 0.4639898024219248,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.4444444444444444,
    "predict_disease_recall": 0.48533333333333334,
    "predict_education_f1": 0.6260325965617325,
    "predict_education_number": 2082,
    "predict_education_precision": 0.5848977889027952,
    "predict_education_recall": 0.6733909702209414,
    "predict_educationaldegree_f1": 0.406282722513089,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.3299319727891156,
    "predict_educationaldegree_recall": 0.5286103542234333,
    "predict_election_f1": 0.15938303341902313,
    "predict_election_number": 184,
    "predict_election_precision": 0.15121951219512195,
    "predict_election_recall": 0.16847826086956522,
    "predict_film_f1": 0.43184559710494574,
    "predict_film_number": 759,
    "predict_film_precision": 0.3982202447163515,
    "predict_film_recall": 0.47167325428194995,
    "predict_food_f1": 0.40140227870289225,
    "predict_food_number": 432,
    "predict_food_precision": 0.3229901269393512,
    "predict_food_recall": 0.5300925925925926,
    "predict_game_f1": 0.26287262872628725,
    "predict_game_number": 496,
    "predict_game_precision": 0.40082644628099173,
    "predict_game_recall": 0.19556451612903225,
    "predict_god_f1": 0.5056338028169014,
    "predict_god_number": 635,
    "predict_god_precision": 0.4573248407643312,
    "predict_god_recall": 0.5653543307086614,
    "predict_government/governmentagency_f1": 0.3061342592592593,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.27537740760020823,
    "predict_government/governmentagency_recall": 0.3446254071661238,
    "predict_hospital_f1": 0.5369458128078818,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.48660714285714285,
    "predict_hospital_recall": 0.5989010989010989,
    "predict_hotel_f1": 0.5363128491620113,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.5294117647058824,
    "predict_hotel_recall": 0.5433962264150943,
    "predict_island_f1": 0.4185779816513761,
    "predict_island_number": 646,
    "predict_island_precision": 0.3324225865209472,
    "predict_island_recall": 0.565015479876161,
    "predict_language_f1": 0.6143552311435523,
    "predict_language_number": 753,
    "predict_language_precision": 0.5667789001122334,
    "predict_language_recall": 0.6706507304116865,
    "predict_law_f1": 0.4055727554179567,
    "predict_law_number": 488,
    "predict_law_precision": 0.32587064676616917,
    "predict_law_recall": 0.5368852459016393,
    "predict_library_f1": 0.5588972431077694,
    "predict_library_number": 357,
    "predict_library_precision": 0.5056689342403629,
    "predict_library_recall": 0.6246498599439776,
    "predict_livingthing_f1": 0.5117168818747011,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.4363784665579119,
    "predict_livingthing_recall": 0.6184971098265896,
    "predict_loss": 0.51481693983078,
    "predict_media/newspaper_f1": 0.5173682059664896,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.5218466611706513,
    "predict_media/newspaper_recall": 0.5129659643435981,
    "predict_medical_f1": 0.2545454545454546,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.1659021406727829,
    "predict_medical_recall": 0.5465994962216625,
    "predict_mountain_f1": 0.4856361149110807,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.45454545454545453,
    "predict_mountain_recall": 0.5212922173274597,
    "predict_music_f1": 0.5844027640671273,
    "predict_music_number": 1041,
    "predict_music_precision": 0.601015228426396,
    "predict_music_recall": 0.5686839577329491,
    "predict_other_f1": 0.4380849220103986,
    "predict_other_number": 21035,
    "predict_other_precision": 0.4024278606965174,
    "predict_other_recall": 0.4806750653672451,
    "predict_overall_accuracy": 0.895459983888024,
    "predict_overall_f1": 0.5420566094406278,
    "predict_overall_precision": 0.5037081011155315,
    "predict_overall_recall": 0.586725426247781,
    "predict_painting_f1": 0.0,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.0,
    "predict_painting_recall": 0.0,
    "predict_park_f1": 0.26,
    "predict_park_number": 458,
    "predict_park_precision": 0.22274143302180685,
    "predict_park_recall": 0.31222707423580787,
    "predict_politicalparty_f1": 0.575545491972005,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.5094752186588921,
    "predict_politicalparty_recall": 0.6613055818353831,
    "predict_politician_f1": 0.5378343118069145,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5038191261839291,
    "predict_politician_recall": 0.5767750961874781,
    "predict_protest_f1": 0.11320754716981134,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.15151515151515152,
    "predict_protest_recall": 0.09036144578313253,
    "predict_religion_f1": 0.3967459324155194,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.3438177874186551,
    "predict_religion_recall": 0.46893491124260356,
    "predict_restaurant_f1": 0.2804123711340206,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.26877470355731226,
    "predict_restaurant_recall": 0.29310344827586204,
    "predict_road/railway/highway/transit_f1": 0.5768828451882845,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.5197926484448633,
    "predict_road/railway/highway/transit_recall": 0.6480611045828437,
    "predict_runtime": 155.0209,
    "predict_samples_per_second": 242.851,
    "predict_scholar_f1": 0.27549668874172184,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.2711864406779661,
    "predict_scholar_recall": 0.27994616419919244,
    "predict_ship_f1": 0.3844444444444444,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.3326923076923077,
    "predict_ship_recall": 0.45526315789473687,
    "predict_showorganization_f1": 0.39459776864357016,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.36012861736334406,
    "predict_showorganization_recall": 0.43636363636363634,
    "predict_software_f1": 0.5090180360721442,
    "predict_software_number": 889,
    "predict_software_precision": 0.45889792231255644,
    "predict_software_recall": 0.5714285714285714,
    "predict_soldier_f1": 0.3942161339421613,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.38830584707646176,
    "predict_soldier_recall": 0.40030911901081917,
    "predict_sportsevent_f1": 0.4781997187060478,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.4286434694906707,
    "predict_sportsevent_recall": 0.5407124681933843,
    "predict_sportsfacility_f1": 0.5377969762419007,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.49209486166007904,
    "predict_sportsfacility_recall": 0.5928571428571429,
    "predict_sportsleague_f1": 0.5018939393939393,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.4319478402607987,
    "predict_sportsleague_recall": 0.5988700564971752,
    "predict_sportsteam_f1": 0.6352811870305918,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.5814889336016097,
    "predict_sportsteam_recall": 0.7000403714170368,
    "predict_steps_per_second": 7.593,
    "predict_theater_f1": 0.5682507583417593,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.5272045028142589,
    "predict_theater_recall": 0.6162280701754386,
    "predict_train_f1": 0.33429394812680113,
    "predict_train_number": 314,
    "predict_train_precision": 0.30526315789473685,
    "predict_train_recall": 0.36942675159235666,
    "predict_weapon_f1": 0.4337349397590361,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.4096728307254623,
    "predict_weapon_recall": 0.4608,
    "predict_writtenart_f1": 0.36689655172413793,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.284796573875803,
    "predict_writtenart_recall": 0.5155038759689923
}