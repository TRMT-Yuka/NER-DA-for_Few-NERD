{
    "predict_GPE_f1": 0.7404685561822736,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7088000716910118,
    "predict_GPE_recall": 0.7750992209319418,
    "predict_actor_f1": 0.6412478336221836,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6085526315789473,
    "predict_actor_recall": 0.6776556776556777,
    "predict_airplane_f1": 0.5199089874857793,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.47406639004149376,
    "predict_airplane_recall": 0.575566750629723,
    "predict_airport_f1": 0.6150442477876106,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.5148148148148148,
    "predict_airport_recall": 0.7637362637362637,
    "predict_artist/author_f1": 0.5094201840221996,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5155187703221993,
    "predict_artist/author_recall": 0.5034642032332564,
    "predict_astronomything_f1": 0.5877437325905293,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.5567282321899736,
    "predict_astronomything_recall": 0.6224188790560472,
    "predict_athlete_f1": 0.7697709413141615,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.74886141834743,
    "predict_athlete_recall": 0.7918816649466804,
    "predict_attack/battle/war/militaryconflict_f1": 0.5866666666666668,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5411222136817833,
    "predict_attack/battle/war/militaryconflict_recall": 0.640582347588717,
    "predict_award_f1": 0.3809942806863176,
    "predict_award_number": 941,
    "predict_award_precision": 0.32507507507507505,
    "predict_award_recall": 0.46014877789585545,
    "predict_biologything_f1": 0.504244918960638,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.4870775347912525,
    "predict_biologything_recall": 0.5226666666666666,
    "predict_bodiesofwater_f1": 0.5914684167350288,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.5681639085894405,
    "predict_bodiesofwater_recall": 0.6167664670658682,
    "predict_broadcastprogram_f1": 0.350597609561753,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.3384615384615385,
    "predict_broadcastprogram_recall": 0.36363636363636365,
    "predict_car_f1": 0.563270603504218,
    "predict_car_number": 688,
    "predict_car_precision": 0.5087924970691676,
    "predict_car_recall": 0.6308139534883721,
    "predict_chemicalthing_f1": 0.36025504782146645,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.39055299539170507,
    "predict_chemicalthing_recall": 0.3343195266272189,
    "predict_company_f1": 0.5524952919020715,
    "predict_company_number": 3903,
    "predict_company_precision": 0.5109949923797082,
    "predict_company_recall": 0.6013323084806559,
    "predict_currency_f1": 0.6813186813186812,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.6072477962781586,
    "predict_currency_recall": 0.7759699624530664,
    "predict_director_f1": 0.4376811594202898,
    "predict_director_number": 554,
    "predict_director_precision": 0.36561743341404357,
    "predict_director_recall": 0.5451263537906137,
    "predict_disaster_f1": 0.2805429864253394,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.26382978723404255,
    "predict_disaster_recall": 0.2995169082125604,
    "predict_disease_f1": 0.49910017996400713,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.4536532170119956,
    "predict_disease_recall": 0.5546666666666666,
    "predict_education_f1": 0.6272540515863958,
    "predict_education_number": 2082,
    "predict_education_precision": 0.5976511526750761,
    "predict_education_recall": 0.659942363112392,
    "predict_educationaldegree_f1": 0.40043763676148797,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.33455210237659966,
    "predict_educationaldegree_recall": 0.4986376021798365,
    "predict_election_f1": 0.18779342723004697,
    "predict_election_number": 184,
    "predict_election_precision": 0.1652892561983471,
    "predict_election_recall": 0.21739130434782608,
    "predict_film_f1": 0.4335031126202603,
    "predict_film_number": 759,
    "predict_film_precision": 0.37996031746031744,
    "predict_film_recall": 0.5046113306982872,
    "predict_food_f1": 0.40103716508210896,
    "predict_food_number": 432,
    "predict_food_precision": 0.32,
    "predict_food_recall": 0.5370370370370371,
    "predict_game_f1": 0.26032540675844806,
    "predict_game_number": 496,
    "predict_game_precision": 0.3432343234323432,
    "predict_game_recall": 0.20967741935483872,
    "predict_god_f1": 0.5193298969072165,
    "predict_god_number": 635,
    "predict_god_precision": 0.4394765539803708,
    "predict_god_recall": 0.6346456692913386,
    "predict_government/governmentagency_f1": 0.30344418052256533,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.27877795962902346,
    "predict_government/governmentagency_recall": 0.33289902280130296,
    "predict_hospital_f1": 0.511002444987775,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.460352422907489,
    "predict_hospital_recall": 0.5741758241758241,
    "predict_hotel_f1": 0.5143884892086331,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.49140893470790376,
    "predict_hotel_recall": 0.539622641509434,
    "predict_island_f1": 0.47696139476961397,
    "predict_island_number": 646,
    "predict_island_precision": 0.39895833333333336,
    "predict_island_recall": 0.5928792569659442,
    "predict_language_f1": 0.6212814645308924,
    "predict_language_number": 753,
    "predict_language_precision": 0.5457286432160804,
    "predict_language_recall": 0.7211155378486056,
    "predict_law_f1": 0.3813169984686064,
    "predict_law_number": 488,
    "predict_law_precision": 0.30440097799511,
    "predict_law_recall": 0.5102459016393442,
    "predict_library_f1": 0.5298329355608592,
    "predict_library_number": 357,
    "predict_library_precision": 0.46153846153846156,
    "predict_library_recall": 0.6218487394957983,
    "predict_livingthing_f1": 0.5004830917874397,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.4298755186721992,
    "predict_livingthing_recall": 0.5988439306358382,
    "predict_loss": 0.651968777179718,
    "predict_media/newspaper_f1": 0.500412881915772,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.51010101010101,
    "predict_media/newspaper_recall": 0.49108589951377635,
    "predict_medical_f1": 0.31339031339031337,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.21847070506454816,
    "predict_medical_recall": 0.5541561712846348,
    "predict_mountain_f1": 0.5195530726256984,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.49533954727030627,
    "predict_mountain_recall": 0.5462555066079295,
    "predict_music_f1": 0.5925925925925927,
    "predict_music_number": 1041,
    "predict_music_precision": 0.6185997910135841,
    "predict_music_recall": 0.5686839577329491,
    "predict_other_f1": 0.4396188693691777,
    "predict_other_number": 21035,
    "predict_other_precision": 0.39776007389446943,
    "predict_other_recall": 0.49132398383646303,
    "predict_overall_accuracy": 0.8950756416019039,
    "predict_overall_f1": 0.5412664481497317,
    "predict_overall_precision": 0.501425830414195,
    "predict_overall_recall": 0.5879845601288032,
    "predict_painting_f1": 0.0,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.0,
    "predict_painting_recall": 0.0,
    "predict_park_f1": 0.2421052631578947,
    "predict_park_number": 458,
    "predict_park_precision": 0.20234604105571846,
    "predict_park_recall": 0.30131004366812225,
    "predict_politicalparty_f1": 0.5707006369426753,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.5177195685670262,
    "predict_politicalparty_recall": 0.6357615894039735,
    "predict_politician_f1": 0.514729229140942,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5192170818505338,
    "predict_politician_recall": 0.5103182931094788,
    "predict_protest_f1": 0.12857142857142856,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.15789473684210525,
    "predict_protest_recall": 0.10843373493975904,
    "predict_religion_f1": 0.41387283236994216,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.3396584440227704,
    "predict_religion_recall": 0.5295857988165681,
    "predict_restaurant_f1": 0.2850574712643678,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.3054187192118227,
    "predict_restaurant_recall": 0.2672413793103448,
    "predict_road/railway/highway/transit_f1": 0.5509819747107882,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.5081885856079404,
    "predict_road/railway/highway/transit_recall": 0.6016451233842538,
    "predict_runtime": 156.555,
    "predict_samples_per_second": 240.471,
    "predict_scholar_f1": 0.24681421864520453,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.24598930481283424,
    "predict_scholar_recall": 0.24764468371467024,
    "predict_ship_f1": 0.3902439024390244,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.3371647509578544,
    "predict_ship_recall": 0.4631578947368421,
    "predict_showorganization_f1": 0.40239520958083835,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.37333333333333335,
    "predict_showorganization_recall": 0.43636363636363634,
    "predict_software_f1": 0.512743628185907,
    "predict_software_number": 889,
    "predict_software_precision": 0.4613309352517986,
    "predict_software_recall": 0.5770528683914511,
    "predict_soldier_f1": 0.3599677158999193,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.3766891891891892,
    "predict_soldier_recall": 0.3446676970633694,
    "predict_sportsevent_f1": 0.4658836689038031,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.4156686626746507,
    "predict_sportsevent_recall": 0.5298982188295165,
    "predict_sportsfacility_f1": 0.5441020191285867,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.491362763915547,
    "predict_sportsfacility_recall": 0.6095238095238096,
    "predict_sportsleague_f1": 0.4862598975314392,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.41362916006339145,
    "predict_sportsleague_recall": 0.5898305084745763,
    "predict_sportsteam_f1": 0.634676663542643,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.592372288313506,
    "predict_sportsteam_recall": 0.6834880904319741,
    "predict_steps_per_second": 7.518,
    "predict_theater_f1": 0.5349794238683128,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.5038759689922481,
    "predict_theater_recall": 0.5701754385964912,
    "predict_train_f1": 0.32776934749620634,
    "predict_train_number": 314,
    "predict_train_precision": 0.3130434782608696,
    "predict_train_recall": 0.34394904458598724,
    "predict_weapon_f1": 0.4265682656826569,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.3958904109589041,
    "predict_weapon_recall": 0.4624,
    "predict_writtenart_f1": 0.38926681783824646,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.3190830235439901,
    "predict_writtenart_recall": 0.499031007751938
}