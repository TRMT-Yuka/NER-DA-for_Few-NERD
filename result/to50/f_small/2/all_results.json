{
    "predict_GPE_f1": 0.7853845623866064,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.739128555373044,
    "predict_GPE_recall": 0.8378166495173698,
    "predict_actor_f1": 0.6620992052617156,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6006961710591745,
    "predict_actor_recall": 0.7374847374847375,
    "predict_airplane_f1": 0.5354497354497354,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.46167883211678834,
    "predict_airplane_recall": 0.6372795969773299,
    "predict_airport_f1": 0.7346326836581709,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.8085808580858086,
    "predict_airport_recall": 0.6730769230769231,
    "predict_artist/author_f1": 0.597151303413061,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5585721468074409,
    "predict_artist/author_recall": 0.6414549653579676,
    "predict_astronomything_f1": 0.5018796992481204,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.6917098445595855,
    "predict_astronomything_recall": 0.3938053097345133,
    "predict_athlete_f1": 0.7905294311081881,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7571653543307086,
    "predict_athlete_recall": 0.826969384244926,
    "predict_attack/battle/war/militaryconflict_f1": 0.6079460269865068,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5168897386870618,
    "predict_attack/battle/war/militaryconflict_recall": 0.737943585077343,
    "predict_award_f1": 0.49830999517141483,
    "predict_award_number": 941,
    "predict_award_precision": 0.45663716814159294,
    "predict_award_recall": 0.5483528161530287,
    "predict_biologything_f1": 0.5387420237010028,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.4703541583764425,
    "predict_biologything_recall": 0.6304,
    "predict_bodiesofwater_f1": 0.6409822184589331,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.6345347862531433,
    "predict_bodiesofwater_recall": 0.6475620188195038,
    "predict_broadcastprogram_f1": 0.41463414634146345,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.4793926247288503,
    "predict_broadcastprogram_recall": 0.3652892561983471,
    "predict_car_f1": 0.6005471956224351,
    "predict_car_number": 688,
    "predict_car_precision": 0.5671834625322998,
    "predict_car_recall": 0.6380813953488372,
    "predict_chemicalthing_f1": 0.4519607843137255,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.449317738791423,
    "predict_chemicalthing_recall": 0.4546351084812623,
    "predict_company_f1": 0.630882175953785,
    "predict_company_number": 3903,
    "predict_company_precision": 0.5948706309577848,
    "predict_company_recall": 0.6715347168844479,
    "predict_currency_f1": 0.6370455856895557,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.5910064239828694,
    "predict_currency_recall": 0.690863579474343,
    "predict_director_f1": 0.0036036036036036037,
    "predict_director_number": 554,
    "predict_director_precision": 1.0,
    "predict_director_recall": 0.0018050541516245488,
    "predict_disaster_f1": 0.17120622568093385,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.44,
    "predict_disaster_recall": 0.10628019323671498,
    "predict_disease_f1": 0.5211122554067971,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.42449664429530204,
    "predict_disease_recall": 0.6746666666666666,
    "predict_education_f1": 0.7277318640955004,
    "predict_education_number": 2082,
    "predict_education_precision": 0.697009674582234,
    "predict_education_recall": 0.7612872238232469,
    "predict_educationaldegree_f1": 0.3755334281650071,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.39285714285714285,
    "predict_educationaldegree_recall": 0.35967302452316074,
    "predict_election_f1": 0.2961165048543689,
    "predict_election_number": 184,
    "predict_election_precision": 0.2675438596491228,
    "predict_election_recall": 0.33152173913043476,
    "predict_film_f1": 0.5412748171368861,
    "predict_film_number": 759,
    "predict_film_precision": 0.4484848484848485,
    "predict_film_recall": 0.6824769433465085,
    "predict_food_f1": 0.39195979899497485,
    "predict_food_number": 432,
    "predict_food_precision": 0.42857142857142855,
    "predict_food_recall": 0.3611111111111111,
    "predict_game_f1": 0.5868131868131868,
    "predict_game_number": 496,
    "predict_game_precision": 0.644927536231884,
    "predict_game_recall": 0.5383064516129032,
    "predict_god_f1": 0.04301075268817204,
    "predict_god_number": 635,
    "predict_god_precision": 0.875,
    "predict_god_recall": 0.02204724409448819,
    "predict_government/governmentagency_f1": 0.33523537803138376,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.37037037037037035,
    "predict_government/governmentagency_recall": 0.30618892508143325,
    "predict_hospital_f1": 0.7110519307589881,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.689922480620155,
    "predict_hospital_recall": 0.7335164835164835,
    "predict_hotel_f1": 0.4594594594594595,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.5698324022346368,
    "predict_hotel_recall": 0.3849056603773585,
    "predict_island_f1": 0.23379629629629628,
    "predict_island_number": 646,
    "predict_island_precision": 0.463302752293578,
    "predict_island_recall": 0.1563467492260062,
    "predict_language_f1": 0.5654303708887334,
    "predict_language_number": 753,
    "predict_language_precision": 0.5976331360946746,
    "predict_language_recall": 0.5365205843293492,
    "predict_law_f1": 0.5038167938931297,
    "predict_law_number": 488,
    "predict_law_precision": 0.42981186685962375,
    "predict_law_recall": 0.6086065573770492,
    "predict_library_f1": 0.6639004149377593,
    "predict_library_number": 357,
    "predict_library_precision": 0.6557377049180327,
    "predict_library_recall": 0.6722689075630253,
    "predict_livingthing_f1": 0.5155243116578793,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.5225653206650831,
    "predict_livingthing_recall": 0.5086705202312138,
    "predict_loss": 0.36978068947792053,
    "predict_media/newspaper_f1": 0.5986062717770035,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.5250611246943765,
    "predict_media/newspaper_recall": 0.6961102106969206,
    "predict_medical_f1": 0.0,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.0,
    "predict_medical_recall": 0.0,
    "predict_mountain_f1": 0.5588484335309061,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.66,
    "predict_mountain_recall": 0.4845814977973568,
    "predict_music_f1": 0.6753246753246753,
    "predict_music_number": 1041,
    "predict_music_precision": 0.6325503355704698,
    "predict_music_recall": 0.7243035542747358,
    "predict_other_f1": 0.500288773379537,
    "predict_other_number": 21035,
    "predict_other_precision": 0.46954092482174875,
    "predict_other_recall": 0.5353458521511766,
    "predict_overall_accuracy": 0.9082464220338873,
    "predict_overall_f1": 0.596020305778802,
    "predict_overall_precision": 0.5745092406396629,
    "predict_overall_recall": 0.619204887916443,
    "predict_painting_f1": 0.0,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.0,
    "predict_painting_recall": 0.0,
    "predict_park_f1": 0.39469808541973495,
    "predict_park_number": 458,
    "predict_park_precision": 0.6063348416289592,
    "predict_park_recall": 0.2925764192139738,
    "predict_politicalparty_f1": 0.6034782608695652,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.5583266291230893,
    "predict_politicalparty_recall": 0.6565752128666036,
    "predict_politician_f1": 0.5923229649238915,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5620094191522763,
    "predict_politician_recall": 0.6260930395243092,
    "predict_protest_f1": 0.0,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.0,
    "predict_protest_recall": 0.0,
    "predict_religion_f1": 0.4183460736622655,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.3944954128440367,
    "predict_religion_recall": 0.4452662721893491,
    "predict_restaurant_f1": 0.0,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.0,
    "predict_restaurant_recall": 0.0,
    "predict_road/railway/highway/transit_f1": 0.6039856923863056,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.5343580470162749,
    "predict_road/railway/highway/transit_recall": 0.6944770857814336,
    "predict_runtime": 270.3361,
    "predict_samples_per_second": 139.26,
    "predict_scholar_f1": 0.0,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.0,
    "predict_scholar_recall": 0.0,
    "predict_ship_f1": 0.45741324921135645,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.5708661417322834,
    "predict_ship_recall": 0.3815789473684211,
    "predict_showorganization_f1": 0.4757709251101322,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.46153846153846156,
    "predict_showorganization_recall": 0.4909090909090909,
    "predict_software_f1": 0.502301117685733,
    "predict_software_number": 889,
    "predict_software_precision": 0.6044303797468354,
    "predict_software_recall": 0.4296962879640045,
    "predict_soldier_f1": 0.02118003025718608,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.5,
    "predict_soldier_recall": 0.010819165378670788,
    "predict_sportsevent_f1": 0.4765784114052953,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.439142091152815,
    "predict_sportsevent_recall": 0.5209923664122137,
    "predict_sportsfacility_f1": 0.5991649269311065,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.533457249070632,
    "predict_sportsfacility_recall": 0.6833333333333333,
    "predict_sportsleague_f1": 0.5344555497106785,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.5,
    "predict_sportsleague_recall": 0.5740112994350283,
    "predict_sportsteam_f1": 0.6809827115559599,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.6199469847581179,
    "predict_sportsteam_recall": 0.7553492127573678,
    "predict_steps_per_second": 4.354,
    "predict_theater_f1": 0.6494066882416397,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.6390658174097664,
    "predict_theater_recall": 0.6600877192982456,
    "predict_train_f1": 0.3744,
    "predict_train_number": 314,
    "predict_train_precision": 0.3762057877813505,
    "predict_train_recall": 0.37261146496815284,
    "predict_weapon_f1": 0.4201680672268908,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.4424778761061947,
    "predict_weapon_recall": 0.4,
    "predict_writtenart_f1": 0.4672815107597717,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.42730923694779116,
    "predict_writtenart_recall": 0.5155038759689923
}