{
    "predict_GPE_f1": 0.7370810460241355,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.6989544895448955,
    "predict_GPE_recall": 0.7796070361115194,
    "predict_actor_f1": 0.6811905492482356,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6847624922887107,
    "predict_actor_recall": 0.6776556776556777,
    "predict_airplane_f1": 0.48933649289099523,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.46196868008948544,
    "predict_airplane_recall": 0.5201511335012594,
    "predict_airport_f1": 0.5885350318471338,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.5486935866983373,
    "predict_airport_recall": 0.6346153846153846,
    "predict_artist/author_f1": 0.5703520852280108,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5185447673045122,
    "predict_artist/author_recall": 0.6336605080831409,
    "predict_astronomything_f1": 0.6353631694790902,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.6321167883211679,
    "predict_astronomything_recall": 0.6386430678466076,
    "predict_athlete_f1": 0.7682206172028891,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7346938775510204,
    "predict_athlete_recall": 0.804953560371517,
    "predict_attack/battle/war/militaryconflict_f1": 0.5889311364596536,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5496845425867508,
    "predict_attack/battle/war/militaryconflict_recall": 0.6342129208371247,
    "predict_award_f1": 0.4301675977653631,
    "predict_award_number": 941,
    "predict_award_precision": 0.3827671913835957,
    "predict_award_recall": 0.4909670563230606,
    "predict_biologything_f1": 0.5314142106465616,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.464828137490008,
    "predict_biologything_recall": 0.6202666666666666,
    "predict_bodiesofwater_f1": 0.5936777178103315,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.5403508771929825,
    "predict_bodiesofwater_recall": 0.6586826347305389,
    "predict_broadcastprogram_f1": 0.3794788273615635,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.3739967897271268,
    "predict_broadcastprogram_recall": 0.3851239669421488,
    "predict_car_f1": 0.5636743215031316,
    "predict_car_number": 688,
    "predict_car_precision": 0.540720961281709,
    "predict_car_recall": 0.5886627906976745,
    "predict_chemicalthing_f1": 0.4578535237217872,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.42955920484010374,
    "predict_chemicalthing_recall": 0.490138067061144,
    "predict_company_f1": 0.5151477983564332,
    "predict_company_number": 3903,
    "predict_company_precision": 0.49411764705882355,
    "predict_company_recall": 0.5380476556495004,
    "predict_currency_f1": 0.6549502050380784,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.6156387665198237,
    "predict_currency_recall": 0.6996245306633292,
    "predict_director_f1": 0.4246959775491113,
    "predict_director_number": 554,
    "predict_director_precision": 0.4407766990291262,
    "predict_director_recall": 0.40974729241877256,
    "predict_disaster_f1": 0.3747609942638623,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.310126582278481,
    "predict_disaster_recall": 0.47342995169082125,
    "predict_disease_f1": 0.5247148288973383,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.4427131072410632,
    "predict_disease_recall": 0.644,
    "predict_education_f1": 0.5895404120443741,
    "predict_education_number": 2082,
    "predict_education_precision": 0.5576017130620985,
    "predict_education_recall": 0.6253602305475504,
    "predict_educationaldegree_f1": 0.40046296296296297,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.34808853118712274,
    "predict_educationaldegree_recall": 0.4713896457765668,
    "predict_election_f1": 0.13930348258706468,
    "predict_election_number": 184,
    "predict_election_precision": 0.12844036697247707,
    "predict_election_recall": 0.15217391304347827,
    "predict_film_f1": 0.5523059617547806,
    "predict_film_number": 759,
    "predict_film_precision": 0.4818449460255152,
    "predict_film_recall": 0.6469038208168643,
    "predict_food_f1": 0.3853564547206165,
    "predict_food_number": 432,
    "predict_food_precision": 0.33003300330033003,
    "predict_food_recall": 0.46296296296296297,
    "predict_game_f1": 0.5039525691699605,
    "predict_game_number": 496,
    "predict_game_precision": 0.4941860465116279,
    "predict_game_recall": 0.5141129032258065,
    "predict_god_f1": 0.5229508196721311,
    "predict_god_number": 635,
    "predict_god_precision": 0.5452991452991452,
    "predict_god_recall": 0.5023622047244094,
    "predict_government/governmentagency_f1": 0.2932862190812721,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.2675980655561526,
    "predict_government/governmentagency_recall": 0.3244299674267101,
    "predict_hospital_f1": 0.5341040462427746,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.46107784431137727,
    "predict_hospital_recall": 0.6346153846153846,
    "predict_hotel_f1": 0.34418604651162793,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.29210526315789476,
    "predict_hotel_recall": 0.4188679245283019,
    "predict_island_f1": 0.4985549132947976,
    "predict_island_number": 646,
    "predict_island_precision": 0.46747967479674796,
    "predict_island_recall": 0.5340557275541795,
    "predict_language_f1": 0.5907928388746804,
    "predict_language_number": 753,
    "predict_language_precision": 0.5696670776818742,
    "predict_language_recall": 0.6135458167330677,
    "predict_law_f1": 0.3371900826446281,
    "predict_law_number": 488,
    "predict_law_precision": 0.28254847645429365,
    "predict_law_recall": 0.4180327868852459,
    "predict_library_f1": 0.45476190476190476,
    "predict_library_number": 357,
    "predict_library_precision": 0.39544513457556935,
    "predict_library_recall": 0.5350140056022409,
    "predict_livingthing_f1": 0.38406658739595717,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.3953488372093023,
    "predict_livingthing_recall": 0.37341040462427744,
    "predict_loss": 0.6211668848991394,
    "predict_media/newspaper_f1": 0.5134350036310821,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.4651315789473684,
    "predict_media/newspaper_recall": 0.5729335494327391,
    "predict_medical_f1": 0.35413642960812775,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.4178082191780822,
    "predict_medical_recall": 0.30730478589420657,
    "predict_mountain_f1": 0.5381870092790864,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.5236111111111111,
    "predict_mountain_recall": 0.55359765051395,
    "predict_music_f1": 0.5970409051348999,
    "predict_music_number": 1041,
    "predict_music_precision": 0.5457438345266508,
    "predict_music_recall": 0.6589817483189241,
    "predict_other_f1": 0.43005237181835815,
    "predict_other_number": 21035,
    "predict_other_precision": 0.3933527834726384,
    "predict_other_recall": 0.4743047302115522,
    "predict_overall_accuracy": 0.8971232957025321,
    "predict_overall_f1": 0.541314990276008,
    "predict_overall_precision": 0.5050773218914811,
    "predict_overall_recall": 0.583154439995046,
    "predict_painting_f1": 0.2413793103448276,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.2413793103448276,
    "predict_painting_recall": 0.2413793103448276,
    "predict_park_f1": 0.3741152679474216,
    "predict_park_number": 458,
    "predict_park_precision": 0.3483992467043315,
    "predict_park_recall": 0.4039301310043668,
    "predict_politicalparty_f1": 0.546304163126593,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.49575944487278334,
    "predict_politicalparty_recall": 0.6083254493850521,
    "predict_politician_f1": 0.4822746086017635,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.4966641957005189,
    "predict_politician_recall": 0.46869534802378454,
    "predict_protest_f1": 0.18181818181818182,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.20610687022900764,
    "predict_protest_recall": 0.16265060240963855,
    "predict_religion_f1": 0.4092140921409214,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.3775,
    "predict_religion_recall": 0.4467455621301775,
    "predict_restaurant_f1": 0.25098039215686274,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.2302158273381295,
    "predict_restaurant_recall": 0.27586206896551724,
    "predict_road/railway/highway/transit_f1": 0.5488803932277445,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.5127551020408163,
    "predict_road/railway/highway/transit_recall": 0.5904817861339601,
    "predict_runtime": 238.7377,
    "predict_samples_per_second": 157.692,
    "predict_scholar_f1": 0.3088512241054614,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.28941176470588237,
    "predict_scholar_recall": 0.3310901749663526,
    "predict_ship_f1": 0.454320987654321,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.42790697674418604,
    "predict_ship_recall": 0.4842105263157895,
    "predict_showorganization_f1": 0.4016636957813428,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.3702081051478642,
    "predict_showorganization_recall": 0.43896103896103894,
    "predict_software_f1": 0.485981308411215,
    "predict_software_number": 889,
    "predict_software_precision": 0.4513018322082932,
    "predict_software_recall": 0.5264341957255343,
    "predict_soldier_f1": 0.3543307086614173,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.3611556982343499,
    "predict_soldier_recall": 0.34775888717156106,
    "predict_sportsevent_f1": 0.4288913773796193,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.383,
    "predict_sportsevent_recall": 0.4872773536895674,
    "predict_sportsfacility_f1": 0.4911894273127753,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.4569672131147541,
    "predict_sportsfacility_recall": 0.530952380952381,
    "predict_sportsleague_f1": 0.3903192584963954,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.35856196783349104,
    "predict_sportsleague_recall": 0.42824858757062145,
    "predict_sportsteam_f1": 0.6325654041390081,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.6124763705103969,
    "predict_sportsteam_recall": 0.6540169559951554,
    "predict_steps_per_second": 4.93,
    "predict_theater_f1": 0.4995044598612488,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.45569620253164556,
    "predict_theater_recall": 0.5526315789473685,
    "predict_train_f1": 0.3910171730515192,
    "predict_train_number": 314,
    "predict_train_precision": 0.3340857787810384,
    "predict_train_recall": 0.4713375796178344,
    "predict_weapon_f1": 0.4022801302931596,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.4096185737976783,
    "predict_weapon_recall": 0.3952,
    "predict_writtenart_f1": 0.40636474908200737,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.35095137420718814,
    "predict_writtenart_recall": 0.48255813953488375
}