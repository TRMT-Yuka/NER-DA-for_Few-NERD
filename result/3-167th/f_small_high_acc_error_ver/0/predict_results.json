{
    "predict_GPE_f1": 0.7969196607847306,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7693851486954936,
    "predict_GPE_recall": 0.8264981135773434,
    "predict_actor_f1": 0.753206130747576,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.77228992944195,
    "predict_actor_recall": 0.7350427350427351,
    "predict_airplane_f1": 0.5900514579759862,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.5403141361256545,
    "predict_airplane_recall": 0.6498740554156172,
    "predict_airport_f1": 0.7870619946091645,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.7724867724867724,
    "predict_airport_recall": 0.8021978021978022,
    "predict_artist/author_f1": 0.6496047166019028,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.6061515378844711,
    "predict_artist/author_recall": 0.6997690531177829,
    "predict_astronomything_f1": 0.6761833208114201,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.6891271056661562,
    "predict_astronomything_recall": 0.6637168141592921,
    "predict_athlete_f1": 0.7893961708394697,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7528089887640449,
    "predict_athlete_recall": 0.8297213622291022,
    "predict_attack/battle/war/militaryconflict_f1": 0.6443817962142571,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5780346820809249,
    "predict_attack/battle/war/militaryconflict_recall": 0.7279344858962693,
    "predict_award_f1": 0.5287356321839081,
    "predict_award_number": 941,
    "predict_award_precision": 0.4990566037735849,
    "predict_award_recall": 0.5621679064824655,
    "predict_biologything_f1": 0.5477061638052352,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.5798569725864124,
    "predict_biologything_recall": 0.5189333333333334,
    "predict_bodiesofwater_f1": 0.6598019801980197,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.6143067846607669,
    "predict_bodiesofwater_recall": 0.7125748502994012,
    "predict_broadcastprogram_f1": 0.5060240963855422,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.46473029045643155,
    "predict_broadcastprogram_recall": 0.5553719008264463,
    "predict_car_f1": 0.6410803127221039,
    "predict_car_number": 688,
    "predict_car_precision": 0.627260083449235,
    "predict_car_recall": 0.6555232558139535,
    "predict_chemicalthing_f1": 0.49096622152395913,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.40796344647519583,
    "predict_chemicalthing_recall": 0.616370808678501,
    "predict_company_f1": 0.6342962507682852,
    "predict_company_number": 3903,
    "predict_company_precision": 0.6096408317580341,
    "predict_company_recall": 0.6610299769408148,
    "predict_currency_f1": 0.6841477949940405,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.6530147895335608,
    "predict_currency_recall": 0.718397997496871,
    "predict_director_f1": 0.609865470852018,
    "predict_director_number": 554,
    "predict_director_precision": 0.5204081632653061,
    "predict_director_recall": 0.7364620938628159,
    "predict_disaster_f1": 0.44298245614035087,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.40562248995983935,
    "predict_disaster_recall": 0.48792270531400966,
    "predict_disease_f1": 0.5712656784492589,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.499003984063745,
    "predict_disease_recall": 0.668,
    "predict_education_f1": 0.7440462427745664,
    "predict_education_number": 2082,
    "predict_education_precision": 0.717342844404815,
    "predict_education_recall": 0.7728146013448607,
    "predict_educationaldegree_f1": 0.4407530454042082,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.3712686567164179,
    "predict_educationaldegree_recall": 0.5422343324250681,
    "predict_election_f1": 0.21298701298701297,
    "predict_election_number": 184,
    "predict_election_precision": 0.20398009950248755,
    "predict_election_recall": 0.22282608695652173,
    "predict_film_f1": 0.6529595015576325,
    "predict_film_number": 759,
    "predict_film_precision": 0.6193853427895981,
    "predict_film_recall": 0.6903820816864296,
    "predict_food_f1": 0.4763005780346821,
    "predict_food_number": 432,
    "predict_food_precision": 0.47575057736720555,
    "predict_food_recall": 0.47685185185185186,
    "predict_game_f1": 0.6227795193312435,
    "predict_game_number": 496,
    "predict_game_precision": 0.6464208242950108,
    "predict_game_recall": 0.6008064516129032,
    "predict_god_f1": 0.5906148867313916,
    "predict_god_number": 635,
    "predict_god_precision": 0.6073211314475874,
    "predict_god_recall": 0.5748031496062992,
    "predict_government/governmentagency_f1": 0.3496644295302013,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.36055363321799305,
    "predict_government/governmentagency_recall": 0.33941368078175893,
    "predict_hospital_f1": 0.7258883248730965,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.6745283018867925,
    "predict_hospital_recall": 0.7857142857142857,
    "predict_hotel_f1": 0.6000000000000001,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.611764705882353,
    "predict_hotel_recall": 0.5886792452830188,
    "predict_island_f1": 0.567449956483899,
    "predict_island_number": 646,
    "predict_island_precision": 0.6481113320079522,
    "predict_island_recall": 0.5046439628482973,
    "predict_language_f1": 0.6778846153846153,
    "predict_language_number": 753,
    "predict_language_precision": 0.6190998902305159,
    "predict_language_recall": 0.749003984063745,
    "predict_law_f1": 0.5480943738656987,
    "predict_law_number": 488,
    "predict_law_precision": 0.49185667752442996,
    "predict_law_recall": 0.6188524590163934,
    "predict_library_f1": 0.665742024965326,
    "predict_library_number": 357,
    "predict_library_precision": 0.6593406593406593,
    "predict_library_recall": 0.6722689075630253,
    "predict_livingthing_f1": 0.5215393452039059,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.5182648401826484,
    "predict_livingthing_recall": 0.5248554913294797,
    "predict_loss": 0.3424018621444702,
    "predict_media/newspaper_f1": 0.5969101123595506,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.5266418835192069,
    "predict_media/newspaper_recall": 0.6888168557536467,
    "predict_medical_f1": 0.3323262839879154,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.41509433962264153,
    "predict_medical_recall": 0.2770780856423174,
    "predict_mountain_f1": 0.6291441788743254,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.6623376623376623,
    "predict_mountain_recall": 0.5991189427312775,
    "predict_music_f1": 0.7161572052401747,
    "predict_music_number": 1041,
    "predict_music_precision": 0.7235294117647059,
    "predict_music_recall": 0.7089337175792507,
    "predict_other_f1": 0.5253271028037384,
    "predict_other_number": 21035,
    "predict_other_precision": 0.5165173443602114,
    "predict_other_recall": 0.5344425956738769,
    "predict_overall_accuracy": 0.9152232116683713,
    "predict_overall_f1": 0.6284470895659562,
    "predict_overall_precision": 0.6058466872922673,
    "predict_overall_recall": 0.6527989926928952,
    "predict_painting_f1": 0.0,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.0,
    "predict_painting_recall": 0.0,
    "predict_park_f1": 0.5607476635514018,
    "predict_park_number": 458,
    "predict_park_precision": 0.6030150753768844,
    "predict_park_recall": 0.5240174672489083,
    "predict_politicalparty_f1": 0.6155758077879039,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.5475313190862195,
    "predict_politicalparty_recall": 0.7029328287606433,
    "predict_politician_f1": 0.623251165889407,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5949125596184419,
    "predict_politician_recall": 0.6544246239944036,
    "predict_protest_f1": 0.010752688172043012,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.05,
    "predict_protest_recall": 0.006024096385542169,
    "predict_religion_f1": 0.49689440993788825,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.4282655246252677,
    "predict_religion_recall": 0.591715976331361,
    "predict_restaurant_f1": 0.3063583815028902,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.4649122807017544,
    "predict_restaurant_recall": 0.22844827586206898,
    "predict_road/railway/highway/transit_f1": 0.646542261251372,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.6065911431513903,
    "predict_road/railway/highway/transit_recall": 0.6921269095182139,
    "predict_runtime": 305.3424,
    "predict_samples_per_second": 123.294,
    "predict_scholar_f1": 0.2899305555555556,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.4083129584352078,
    "predict_scholar_recall": 0.22476446837146702,
    "predict_ship_f1": 0.5572916666666666,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.5515463917525774,
    "predict_ship_recall": 0.5631578947368421,
    "predict_showorganization_f1": 0.4809688581314879,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.43257261410788383,
    "predict_showorganization_recall": 0.5415584415584416,
    "predict_software_f1": 0.546430488459474,
    "predict_software_number": 889,
    "predict_software_precision": 0.5225872689938398,
    "predict_software_recall": 0.5725534308211474,
    "predict_soldier_f1": 0.4,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.4598393574297189,
    "predict_soldier_recall": 0.35394126738794435,
    "predict_sportsevent_f1": 0.508108108108108,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.4812286689419795,
    "predict_sportsevent_recall": 0.5381679389312977,
    "predict_sportsfacility_f1": 0.6358974358974359,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.5585585585585585,
    "predict_sportsfacility_recall": 0.7380952380952381,
    "predict_sportsleague_f1": 0.5506653019447288,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.5032740879326474,
    "predict_sportsleague_recall": 0.607909604519774,
    "predict_sportsteam_f1": 0.6845194424064565,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.6272268907563026,
    "predict_sportsteam_recall": 0.7533306419055309,
    "predict_steps_per_second": 7.706,
    "predict_theater_f1": 0.6565656565656566,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.6086142322097379,
    "predict_theater_recall": 0.7127192982456141,
    "predict_train_f1": 0.4738292011019284,
    "predict_train_number": 314,
    "predict_train_precision": 0.4174757281553398,
    "predict_train_recall": 0.5477707006369427,
    "predict_weapon_f1": 0.4870188003581021,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.5528455284552846,
    "predict_weapon_recall": 0.4352,
    "predict_writtenart_f1": 0.5237668161434977,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.48747913188647746,
    "predict_writtenart_recall": 0.5658914728682171
}