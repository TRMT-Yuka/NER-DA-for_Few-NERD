{
    "predict_GPE_f1": 0.7930454556221428,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7676082171680118,
    "predict_GPE_recall": 0.8202263707188006,
    "predict_actor_f1": 0.7559157212317666,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.8058051140290255,
    "predict_actor_recall": 0.7118437118437119,
    "predict_airplane_f1": 0.5867287543655414,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.5454545454545454,
    "predict_airplane_recall": 0.6347607052896725,
    "predict_airport_f1": 0.7988505747126436,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.8373493975903614,
    "predict_airport_recall": 0.7637362637362637,
    "predict_artist/author_f1": 0.6471461341249494,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.607550038003547,
    "predict_artist/author_recall": 0.6922632794457275,
    "predict_astronomything_f1": 0.6382978723404256,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.658307210031348,
    "predict_astronomything_recall": 0.6194690265486725,
    "predict_athlete_f1": 0.7988027934818757,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.77309301577084,
    "predict_athlete_recall": 0.826281389748882,
    "predict_attack/battle/war/militaryconflict_f1": 0.6411960132890366,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5897631779984721,
    "predict_attack/battle/war/militaryconflict_recall": 0.7024567788898999,
    "predict_award_f1": 0.5306543019062339,
    "predict_award_number": 941,
    "predict_award_precision": 0.515,
    "predict_award_recall": 0.5472901168969182,
    "predict_biologything_f1": 0.5653194263363754,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.5530612244897959,
    "predict_biologything_recall": 0.5781333333333334,
    "predict_bodiesofwater_f1": 0.678921568627451,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.6497263487099296,
    "predict_bodiesofwater_recall": 0.7108639863130881,
    "predict_broadcastprogram_f1": 0.4905349794238683,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.4885245901639344,
    "predict_broadcastprogram_recall": 0.4925619834710744,
    "predict_car_f1": 0.6563421828908556,
    "predict_car_number": 688,
    "predict_car_precision": 0.6661676646706587,
    "predict_car_recall": 0.6468023255813954,
    "predict_chemicalthing_f1": 0.4784995425434583,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.4462457337883959,
    "predict_chemicalthing_recall": 0.5157790927021696,
    "predict_company_f1": 0.6334195296145795,
    "predict_company_number": 3903,
    "predict_company_precision": 0.6097676623992413,
    "predict_company_recall": 0.6589802715859595,
    "predict_currency_f1": 0.6403940886699507,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.6303030303030303,
    "predict_currency_recall": 0.6508135168961201,
    "predict_director_f1": 0.6377597109304427,
    "predict_director_number": 554,
    "predict_director_precision": 0.6383363471971067,
    "predict_director_recall": 0.6371841155234657,
    "predict_disaster_f1": 0.3951612903225806,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.3391003460207612,
    "predict_disaster_recall": 0.47342995169082125,
    "predict_disease_f1": 0.5417185554171856,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.508177570093458,
    "predict_disease_recall": 0.58,
    "predict_education_f1": 0.7350588235294118,
    "predict_education_number": 2082,
    "predict_education_precision": 0.7204797047970479,
    "predict_education_recall": 0.7502401536983669,
    "predict_educationaldegree_f1": 0.4640371229698376,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.40404040404040403,
    "predict_educationaldegree_recall": 0.5449591280653951,
    "predict_election_f1": 0.22871046228710465,
    "predict_election_number": 184,
    "predict_election_precision": 0.20704845814977973,
    "predict_election_recall": 0.2554347826086957,
    "predict_film_f1": 0.6481481481481481,
    "predict_film_number": 759,
    "predict_film_precision": 0.650730411686587,
    "predict_film_recall": 0.6455862977602108,
    "predict_food_f1": 0.43742405832320774,
    "predict_food_number": 432,
    "predict_food_precision": 0.46035805626598464,
    "predict_food_recall": 0.4166666666666667,
    "predict_game_f1": 0.6058823529411764,
    "predict_game_number": 496,
    "predict_game_precision": 0.5896946564885496,
    "predict_game_recall": 0.6229838709677419,
    "predict_god_f1": 0.33786848072562364,
    "predict_god_number": 635,
    "predict_god_precision": 0.6032388663967612,
    "predict_god_recall": 0.2346456692913386,
    "predict_government/governmentagency_f1": 0.34234234234234234,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.36565507031828276,
    "predict_government/governmentagency_recall": 0.3218241042345277,
    "predict_hospital_f1": 0.7176165803108809,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.678921568627451,
    "predict_hospital_recall": 0.760989010989011,
    "predict_hotel_f1": 0.6033519553072626,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.5955882352941176,
    "predict_hotel_recall": 0.6113207547169811,
    "predict_island_f1": 0.5842323651452282,
    "predict_island_number": 646,
    "predict_island_precision": 0.629695885509839,
    "predict_island_recall": 0.544891640866873,
    "predict_language_f1": 0.6593001841620626,
    "predict_language_number": 753,
    "predict_language_precision": 0.613013698630137,
    "predict_language_recall": 0.7131474103585658,
    "predict_law_f1": 0.5300988319856245,
    "predict_law_number": 488,
    "predict_law_precision": 0.472,
    "predict_law_recall": 0.6045081967213115,
    "predict_library_f1": 0.6781002638522428,
    "predict_library_number": 357,
    "predict_library_precision": 0.6408977556109726,
    "predict_library_recall": 0.7198879551820728,
    "predict_livingthing_f1": 0.5170149253731343,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.5345679012345679,
    "predict_livingthing_recall": 0.500578034682081,
    "predict_loss": 0.34218722581863403,
    "predict_media/newspaper_f1": 0.5979680696661829,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.5413929040735874,
    "predict_media/newspaper_recall": 0.6677471636952999,
    "predict_medical_f1": 0.06619385342789598,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.5384615384615384,
    "predict_medical_recall": 0.03526448362720403,
    "predict_mountain_f1": 0.6207928197456993,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.6326219512195121,
    "predict_mountain_recall": 0.6093979441997063,
    "predict_music_f1": 0.71513353115727,
    "predict_music_number": 1041,
    "predict_music_precision": 0.7370030581039755,
    "predict_music_recall": 0.6945244956772334,
    "predict_other_f1": 0.5262344626991161,
    "predict_other_number": 21035,
    "predict_other_precision": 0.5040484067560509,
    "predict_other_recall": 0.5504635131922986,
    "predict_overall_accuracy": 0.9143730986456821,
    "predict_overall_f1": 0.6247821470782667,
    "predict_overall_precision": 0.6068746108343711,
    "predict_overall_recall": 0.6437786401354085,
    "predict_painting_f1": 0.0,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.0,
    "predict_painting_recall": 0.0,
    "predict_park_f1": 0.5618199802176063,
    "predict_park_number": 458,
    "predict_park_precision": 0.5135623869801085,
    "predict_park_recall": 0.6200873362445415,
    "predict_politicalparty_f1": 0.62004662004662,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.6112132352941176,
    "predict_politicalparty_recall": 0.6291390728476821,
    "predict_politician_f1": 0.5987175160310496,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5784153896315618,
    "predict_politician_recall": 0.6204966771598461,
    "predict_protest_f1": 0.13545816733067728,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.2,
    "predict_protest_recall": 0.10240963855421686,
    "predict_religion_f1": 0.4636871508379888,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.43915343915343913,
    "predict_religion_recall": 0.4911242603550296,
    "predict_restaurant_f1": 0.44247787610619466,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.45454545454545453,
    "predict_restaurant_recall": 0.43103448275862066,
    "predict_road/railway/highway/transit_f1": 0.6411865373645179,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.623059866962306,
    "predict_road/railway/highway/transit_recall": 0.6603995299647474,
    "predict_runtime": 243.681,
    "predict_samples_per_second": 154.493,
    "predict_scholar_f1": 0.36233040702314445,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.44509803921568625,
    "predict_scholar_recall": 0.30551816958277256,
    "predict_ship_f1": 0.5445292620865141,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.5270935960591133,
    "predict_ship_recall": 0.5631578947368421,
    "predict_showorganization_f1": 0.4762449914138523,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.4257932446264074,
    "predict_showorganization_recall": 0.5402597402597402,
    "predict_software_f1": 0.545138888888889,
    "predict_software_number": 889,
    "predict_software_precision": 0.5613825983313468,
    "predict_software_recall": 0.5298087739032621,
    "predict_soldier_f1": 0.441017733230532,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.44,
    "predict_soldier_recall": 0.4420401854714065,
    "predict_sportsevent_f1": 0.5052501544163064,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.4909963985594238,
    "predict_sportsevent_recall": 0.5203562340966921,
    "predict_sportsfacility_f1": 0.6303664921465968,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.5626168224299065,
    "predict_sportsfacility_recall": 0.7166666666666667,
    "predict_sportsleague_f1": 0.553860819828408,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.47897774113767516,
    "predict_sportsleague_recall": 0.656497175141243,
    "predict_sportsteam_f1": 0.6898263027295285,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.6542360608254888,
    "predict_sportsteam_recall": 0.7295115058538555,
    "predict_steps_per_second": 4.83,
    "predict_theater_f1": 0.6768558951965065,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.6739130434782609,
    "predict_theater_recall": 0.6798245614035088,
    "predict_train_f1": 0.4349112426035503,
    "predict_train_number": 314,
    "predict_train_precision": 0.40607734806629836,
    "predict_train_recall": 0.4681528662420382,
    "predict_weapon_f1": 0.4757929883138564,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.4973821989528796,
    "predict_weapon_recall": 0.456,
    "predict_writtenart_f1": 0.5422264875239924,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.5370722433460076,
    "predict_writtenart_recall": 0.5474806201550387
}