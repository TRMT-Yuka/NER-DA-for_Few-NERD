{
    "predict_GPE_f1": 0.7513503269212547,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7273311012246021,
    "predict_GPE_recall": 0.777010142584154,
    "predict_actor_f1": 0.6811505507955936,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6828220858895706,
    "predict_actor_recall": 0.6794871794871795,
    "predict_airplane_f1": 0.5147232037691402,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.4834070796460177,
    "predict_airplane_recall": 0.5503778337531486,
    "predict_airport_f1": 0.5941320293398532,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.5352422907488987,
    "predict_airport_recall": 0.6675824175824175,
    "predict_artist/author_f1": 0.5907082608113536,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5508114856429464,
    "predict_artist/author_recall": 0.6368360277136259,
    "predict_astronomything_f1": 0.6497601096641535,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.6069142125480154,
    "predict_astronomything_recall": 0.6991150442477876,
    "predict_athlete_f1": 0.7599022004889975,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7221189591078067,
    "predict_athlete_recall": 0.8018575851393189,
    "predict_attack/battle/war/militaryconflict_f1": 0.5822680412371133,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5324283559577677,
    "predict_attack/battle/war/militaryconflict_recall": 0.6424021838034577,
    "predict_award_f1": 0.43628117913832193,
    "predict_award_number": 941,
    "predict_award_precision": 0.3805379746835443,
    "predict_award_recall": 0.5111583421891605,
    "predict_biologything_f1": 0.5273159144893111,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.5219435736677116,
    "predict_biologything_recall": 0.5328,
    "predict_bodiesofwater_f1": 0.5938864628820961,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.554074074074074,
    "predict_bodiesofwater_recall": 0.6398631308810949,
    "predict_broadcastprogram_f1": 0.43970588235294117,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.39602649006622515,
    "predict_broadcastprogram_recall": 0.49421487603305786,
    "predict_car_f1": 0.5772893772893772,
    "predict_car_number": 688,
    "predict_car_precision": 0.5819793205317577,
    "predict_car_recall": 0.5726744186046512,
    "predict_chemicalthing_f1": 0.4844771241830065,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.41352859135285913,
    "predict_chemicalthing_recall": 0.5848126232741617,
    "predict_company_f1": 0.556288271314178,
    "predict_company_number": 3903,
    "predict_company_precision": 0.5147090869470473,
    "predict_company_recall": 0.6051755060210094,
    "predict_currency_f1": 0.6469565217391304,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.6025917926565875,
    "predict_currency_recall": 0.6983729662077597,
    "predict_director_f1": 0.5465376023827253,
    "predict_director_number": 554,
    "predict_director_precision": 0.46514575411913817,
    "predict_director_recall": 0.6624548736462094,
    "predict_disaster_f1": 0.3358490566037736,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.2755417956656347,
    "predict_disaster_recall": 0.42995169082125606,
    "predict_disease_f1": 0.5480984340044743,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.4720616570327553,
    "predict_disease_recall": 0.6533333333333333,
    "predict_education_f1": 0.6325765924619793,
    "predict_education_number": 2082,
    "predict_education_precision": 0.5845213849287169,
    "predict_education_recall": 0.6892411143131604,
    "predict_educationaldegree_f1": 0.4180064308681672,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.34452296819787986,
    "predict_educationaldegree_recall": 0.5313351498637602,
    "predict_election_f1": 0.19565217391304346,
    "predict_election_number": 184,
    "predict_election_precision": 0.16304347826086957,
    "predict_election_recall": 0.24456521739130435,
    "predict_film_f1": 0.5781637717121588,
    "predict_film_number": 759,
    "predict_film_precision": 0.5463071512309496,
    "predict_film_recall": 0.613965744400527,
    "predict_food_f1": 0.4012605042016807,
    "predict_food_number": 432,
    "predict_food_precision": 0.36730769230769234,
    "predict_food_recall": 0.44212962962962965,
    "predict_game_f1": 0.5495750708215297,
    "predict_game_number": 496,
    "predict_game_precision": 0.5168738898756661,
    "predict_game_recall": 0.5866935483870968,
    "predict_god_f1": 0.5555555555555556,
    "predict_god_number": 635,
    "predict_god_precision": 0.5184174624829468,
    "predict_god_recall": 0.5984251968503937,
    "predict_government/governmentagency_f1": 0.2924080664294187,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.2683723462166576,
    "predict_government/governmentagency_recall": 0.3211726384364821,
    "predict_hospital_f1": 0.5053128689492326,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.44306418219461696,
    "predict_hospital_recall": 0.5879120879120879,
    "predict_hotel_f1": 0.4895104895104895,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.4560260586319218,
    "predict_hotel_recall": 0.5283018867924528,
    "predict_island_f1": 0.48839071257005606,
    "predict_island_number": 646,
    "predict_island_precision": 0.5058043117744611,
    "predict_island_recall": 0.47213622291021673,
    "predict_language_f1": 0.5989904655075715,
    "predict_language_number": 753,
    "predict_language_precision": 0.5184466019417475,
    "predict_language_recall": 0.7091633466135459,
    "predict_law_f1": 0.44347826086956527,
    "predict_law_number": 488,
    "predict_law_precision": 0.3851963746223565,
    "predict_law_recall": 0.5225409836065574,
    "predict_library_f1": 0.5142083897158323,
    "predict_library_number": 357,
    "predict_library_precision": 0.4973821989528796,
    "predict_library_recall": 0.5322128851540616,
    "predict_livingthing_f1": 0.5005302226935313,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.4622918707149853,
    "predict_livingthing_recall": 0.545664739884393,
    "predict_loss": 0.6185356974601746,
    "predict_media/newspaper_f1": 0.5003641660597232,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.45436507936507936,
    "predict_media/newspaper_recall": 0.5567260940032415,
    "predict_medical_f1": 0.3853658536585366,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.3735224586288416,
    "predict_medical_recall": 0.3979848866498741,
    "predict_mountain_f1": 0.5632772494513533,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.5612244897959183,
    "predict_mountain_recall": 0.5653450807635829,
    "predict_music_f1": 0.6441297396071265,
    "predict_music_number": 1041,
    "predict_music_precision": 0.6141114982578397,
    "predict_music_recall": 0.6772334293948127,
    "predict_other_f1": 0.4537554585152838,
    "predict_other_number": 21035,
    "predict_other_precision": 0.4195840904502322,
    "predict_other_recall": 0.49398621345376753,
    "predict_overall_accuracy": 0.9021045454446753,
    "predict_overall_f1": 0.5606901747028709,
    "predict_overall_precision": 0.5239196908150181,
    "predict_overall_recall": 0.6030116005449366,
    "predict_painting_f1": 0.24793388429752067,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.23809523809523808,
    "predict_painting_recall": 0.25862068965517243,
    "predict_park_f1": 0.35025906735751294,
    "predict_park_number": 458,
    "predict_park_precision": 0.3333333333333333,
    "predict_park_recall": 0.36899563318777295,
    "predict_politicalparty_f1": 0.564040404040404,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.4922425952045134,
    "predict_politicalparty_recall": 0.6603595080416272,
    "predict_politician_f1": 0.5423728813559322,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5364351693465618,
    "predict_politician_recall": 0.5484435117173837,
    "predict_protest_f1": 0.18433179723502305,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.14925373134328357,
    "predict_protest_recall": 0.24096385542168675,
    "predict_religion_f1": 0.4328180737217598,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.36182902584493043,
    "predict_religion_recall": 0.5384615384615384,
    "predict_restaurant_f1": 0.24034334763948498,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.23931623931623933,
    "predict_restaurant_recall": 0.2413793103448276,
    "predict_road/railway/highway/transit_f1": 0.5584520290244558,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.5146111936602278,
    "predict_road/railway/highway/transit_recall": 0.6104582843713279,
    "predict_runtime": 304.5643,
    "predict_samples_per_second": 123.609,
    "predict_scholar_f1": 0.30446549391069017,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.30612244897959184,
    "predict_scholar_recall": 0.3028263795423957,
    "predict_ship_f1": 0.4683714670255719,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.4793388429752066,
    "predict_ship_recall": 0.45789473684210524,
    "predict_showorganization_f1": 0.4236796285548462,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.3830010493179433,
    "predict_showorganization_recall": 0.474025974025974,
    "predict_software_f1": 0.4804413239719157,
    "predict_software_number": 889,
    "predict_software_precision": 0.4334841628959276,
    "predict_software_recall": 0.5388076490438695,
    "predict_soldier_f1": 0.3394648829431438,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.3697632058287796,
    "predict_soldier_recall": 0.31375579598145287,
    "predict_sportsevent_f1": 0.4124129930394431,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.37899786780383793,
    "predict_sportsevent_recall": 0.45229007633587787,
    "predict_sportsfacility_f1": 0.547945205479452,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.4914933837429111,
    "predict_sportsfacility_recall": 0.6190476190476191,
    "predict_sportsleague_f1": 0.4613109906357812,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.4090909090909091,
    "predict_sportsleague_recall": 0.5288135593220339,
    "predict_sportsteam_f1": 0.6283987915407856,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.5902802412202909,
    "predict_sportsteam_recall": 0.6717803794913202,
    "predict_steps_per_second": 7.726,
    "predict_theater_f1": 0.5917753259779338,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.5452865064695009,
    "predict_theater_recall": 0.6469298245614035,
    "predict_train_f1": 0.3894472361809046,
    "predict_train_number": 314,
    "predict_train_precision": 0.3215767634854772,
    "predict_train_recall": 0.49363057324840764,
    "predict_weapon_f1": 0.4096586178184846,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.4270833333333333,
    "predict_weapon_recall": 0.3936,
    "predict_writtenart_f1": 0.45589447650453424,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.396700143472023,
    "predict_writtenart_recall": 0.5358527131782945
}