{
    "predict_GPE_f1": 0.7641968887417845,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7383617342043949,
    "predict_GPE_recall": 0.7919055318731932,
    "predict_actor_f1": 0.7015643802647412,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6915776986951364,
    "predict_actor_recall": 0.7118437118437119,
    "predict_airplane_f1": 0.5256869772998806,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.5,
    "predict_airplane_recall": 0.5541561712846348,
    "predict_airport_f1": 0.6254295532646049,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.5363457760314342,
    "predict_airport_recall": 0.75,
    "predict_artist/author_f1": 0.6093562574970012,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.565981678633325,
    "predict_artist/author_recall": 0.6599307159353349,
    "predict_astronomything_f1": 0.5972323379461035,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.5899280575539568,
    "predict_astronomything_recall": 0.6047197640117994,
    "predict_athlete_f1": 0.7701450795315503,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7828713574982231,
    "predict_athlete_recall": 0.7578259373925008,
    "predict_attack/battle/war/militaryconflict_f1": 0.5854665565648224,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5359032501889645,
    "predict_attack/battle/war/militaryconflict_recall": 0.6451319381255687,
    "predict_award_f1": 0.4517133956386293,
    "predict_award_number": 941,
    "predict_award_precision": 0.4416243654822335,
    "predict_award_recall": 0.4622741764080765,
    "predict_biologything_f1": 0.5062416998671978,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.5042328042328043,
    "predict_biologything_recall": 0.5082666666666666,
    "predict_bodiesofwater_f1": 0.6033057851239668,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.6511397423191279,
    "predict_bodiesofwater_recall": 0.5620188195038495,
    "predict_broadcastprogram_f1": 0.45327102803738323,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.42857142857142855,
    "predict_broadcastprogram_recall": 0.4809917355371901,
    "predict_car_f1": 0.5448129851799576,
    "predict_car_number": 688,
    "predict_car_precision": 0.5294924554183813,
    "predict_car_recall": 0.561046511627907,
    "predict_chemicalthing_f1": 0.4535909281814364,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.3950256035113387,
    "predict_chemicalthing_recall": 0.5325443786982249,
    "predict_company_f1": 0.5499371069182389,
    "predict_company_number": 3903,
    "predict_company_precision": 0.5401531999011614,
    "predict_company_recall": 0.5600819882141942,
    "predict_currency_f1": 0.6327356853672643,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.5881720430107527,
    "predict_currency_recall": 0.6846057571964956,
    "predict_director_f1": 0.6130397967823877,
    "predict_director_number": 554,
    "predict_director_precision": 0.5773524720893142,
    "predict_director_recall": 0.6534296028880866,
    "predict_disaster_f1": 0.3811764705882353,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.37155963302752293,
    "predict_disaster_recall": 0.391304347826087,
    "predict_disease_f1": 0.5240023134759977,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.4627170582226762,
    "predict_disease_recall": 0.604,
    "predict_education_f1": 0.663494221617947,
    "predict_education_number": 2082,
    "predict_education_precision": 0.6280566280566281,
    "predict_education_recall": 0.7031700288184438,
    "predict_educationaldegree_f1": 0.46135265700483097,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.41431670281995664,
    "predict_educationaldegree_recall": 0.5204359673024523,
    "predict_election_f1": 0.17941952506596304,
    "predict_election_number": 184,
    "predict_election_precision": 0.17435897435897435,
    "predict_election_recall": 0.18478260869565216,
    "predict_film_f1": 0.5819721718088325,
    "predict_film_number": 759,
    "predict_film_precision": 0.5380313199105146,
    "predict_film_recall": 0.6337285902503293,
    "predict_food_f1": 0.3831867057673509,
    "predict_food_number": 432,
    "predict_food_precision": 0.3316412859560068,
    "predict_food_recall": 0.4537037037037037,
    "predict_game_f1": 0.5112195121951221,
    "predict_game_number": 496,
    "predict_game_precision": 0.4952741020793951,
    "predict_game_recall": 0.5282258064516129,
    "predict_god_f1": 0.5434599156118143,
    "predict_god_number": 635,
    "predict_god_precision": 0.5854545454545454,
    "predict_god_recall": 0.5070866141732283,
    "predict_government/governmentagency_f1": 0.3261983720229123,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.30359147025813693,
    "predict_government/governmentagency_recall": 0.352442996742671,
    "predict_hospital_f1": 0.5731414868105515,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.5085106382978724,
    "predict_hospital_recall": 0.6565934065934066,
    "predict_hotel_f1": 0.5196581196581196,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.475,
    "predict_hotel_recall": 0.5735849056603773,
    "predict_island_f1": 0.5495160089352197,
    "predict_island_number": 646,
    "predict_island_precision": 0.5294117647058824,
    "predict_island_recall": 0.5712074303405573,
    "predict_language_f1": 0.595797280593325,
    "predict_language_number": 753,
    "predict_language_precision": 0.5572254335260116,
    "predict_language_recall": 0.6401062416998672,
    "predict_law_f1": 0.5105990783410138,
    "predict_law_number": 488,
    "predict_law_precision": 0.4639865996649916,
    "predict_law_recall": 0.5676229508196722,
    "predict_library_f1": 0.5930521091811414,
    "predict_library_number": 357,
    "predict_library_precision": 0.532293986636971,
    "predict_library_recall": 0.6694677871148459,
    "predict_livingthing_f1": 0.5382639958911145,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.48428835489833644,
    "predict_livingthing_recall": 0.6057803468208093,
    "predict_loss": 0.6396262049674988,
    "predict_media/newspaper_f1": 0.5061830173124484,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.5151006711409396,
    "predict_media/newspaper_recall": 0.49756888168557534,
    "predict_medical_f1": 0.3453815261044177,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.36857142857142855,
    "predict_medical_recall": 0.3249370277078086,
    "predict_mountain_f1": 0.5814463111760408,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.5784883720930233,
    "predict_mountain_recall": 0.5844346549192364,
    "predict_music_f1": 0.6302057200200702,
    "predict_music_number": 1041,
    "predict_music_precision": 0.6596638655462185,
    "predict_music_recall": 0.6032660902977905,
    "predict_other_f1": 0.4651595623950247,
    "predict_other_number": 21035,
    "predict_other_precision": 0.4450766624679668,
    "predict_other_recall": 0.4871404801521274,
    "predict_overall_accuracy": 0.9030567154585942,
    "predict_overall_f1": 0.5741864340567778,
    "predict_overall_precision": 0.5511748231831775,
    "predict_overall_recall": 0.5992032365933204,
    "predict_painting_f1": 0.3063063063063063,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.32075471698113206,
    "predict_painting_recall": 0.29310344827586204,
    "predict_park_f1": 0.4796828543111992,
    "predict_park_number": 458,
    "predict_park_precision": 0.43920145190562615,
    "predict_park_recall": 0.5283842794759825,
    "predict_politicalparty_f1": 0.5709040844424048,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.5543672014260249,
    "predict_politicalparty_recall": 0.5884578997161779,
    "predict_politician_f1": 0.5474198047419805,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5457073340285019,
    "predict_politician_recall": 0.5491430570129416,
    "predict_protest_f1": 0.19108280254777069,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.20270270270270271,
    "predict_protest_recall": 0.18072289156626506,
    "predict_religion_f1": 0.4173580089342693,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.367003367003367,
    "predict_religion_recall": 0.48372781065088755,
    "predict_restaurant_f1": 0.2675736961451247,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.2822966507177033,
    "predict_restaurant_recall": 0.2543103448275862,
    "predict_road/railway/highway/transit_f1": 0.5720316622691294,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.5191570881226054,
    "predict_road/railway/highway/transit_recall": 0.63689776733255,
    "predict_runtime": 257.2071,
    "predict_samples_per_second": 146.368,
    "predict_scholar_f1": 0.35171966255678133,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.33959899749373434,
    "predict_scholar_recall": 0.36473755047106327,
    "predict_ship_f1": 0.48030495552731894,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.4643734643734644,
    "predict_ship_recall": 0.49736842105263157,
    "predict_showorganization_f1": 0.40562248995983935,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.4185082872928177,
    "predict_showorganization_recall": 0.3935064935064935,
    "predict_software_f1": 0.47323600973236013,
    "predict_software_number": 889,
    "predict_software_precision": 0.5152317880794702,
    "predict_software_recall": 0.437570303712036,
    "predict_soldier_f1": 0.3819672131147541,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.40663176265270506,
    "predict_soldier_recall": 0.3601236476043277,
    "predict_sportsevent_f1": 0.450497949619215,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.4174809989142237,
    "predict_sportsevent_recall": 0.4891857506361323,
    "predict_sportsfacility_f1": 0.5365853658536586,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.46808510638297873,
    "predict_sportsfacility_recall": 0.6285714285714286,
    "predict_sportsleague_f1": 0.47689075630252103,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.44553483807654565,
    "predict_sportsleague_recall": 0.5129943502824859,
    "predict_sportsteam_f1": 0.6400153022188217,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.6081424936386769,
    "predict_sportsteam_recall": 0.6754138070246266,
    "predict_steps_per_second": 4.576,
    "predict_theater_f1": 0.5945945945945945,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.5652173913043478,
    "predict_theater_recall": 0.6271929824561403,
    "predict_train_f1": 0.4040697674418605,
    "predict_train_number": 314,
    "predict_train_precision": 0.3716577540106952,
    "predict_train_recall": 0.4426751592356688,
    "predict_weapon_f1": 0.3959899749373433,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.4143356643356643,
    "predict_weapon_recall": 0.3792,
    "predict_writtenart_f1": 0.5121076233183856,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.4766277128547579,
    "predict_writtenart_recall": 0.5532945736434108
}