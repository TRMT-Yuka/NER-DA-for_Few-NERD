{
    "predict_GPE_f1": 0.7599257187184127,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7303452015181637,
    "predict_GPE_recall": 0.7920035278553579,
    "predict_actor_f1": 0.6979228486646883,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6789838337182448,
    "predict_actor_recall": 0.717948717948718,
    "predict_airplane_f1": 0.5305105853051059,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.5246305418719212,
    "predict_airplane_recall": 0.5365239294710328,
    "predict_airport_f1": 0.6067172264355363,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.5008944543828264,
    "predict_airport_recall": 0.7692307692307693,
    "predict_artist/author_f1": 0.5870210660257317,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5752285951787198,
    "predict_artist/author_recall": 0.5993071593533488,
    "predict_astronomything_f1": 0.578125,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.5575342465753425,
    "predict_astronomything_recall": 0.6002949852507374,
    "predict_athlete_f1": 0.7631668365613319,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7539442766028869,
    "predict_athlete_recall": 0.7726178190574475,
    "predict_attack/battle/war/militaryconflict_f1": 0.6465177398160316,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.6233108108108109,
    "predict_attack/battle/war/militaryconflict_recall": 0.6715195632393085,
    "predict_award_f1": 0.4312267657992565,
    "predict_award_number": 941,
    "predict_award_precision": 0.3831544178364988,
    "predict_award_recall": 0.49309245483528164,
    "predict_biologything_f1": 0.5132788559754852,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.492405683488486,
    "predict_biologything_recall": 0.536,
    "predict_bodiesofwater_f1": 0.6179205409974641,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.6106934001670844,
    "predict_bodiesofwater_recall": 0.6253207869974337,
    "predict_broadcastprogram_f1": 0.4372163388804841,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.403068340306834,
    "predict_broadcastprogram_recall": 0.47768595041322315,
    "predict_car_f1": 0.5647058823529413,
    "predict_car_number": 688,
    "predict_car_precision": 0.5389696169088507,
    "predict_car_recall": 0.5930232558139535,
    "predict_chemicalthing_f1": 0.47074122236671,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.419953596287703,
    "predict_chemicalthing_recall": 0.5355029585798816,
    "predict_company_f1": 0.5325820676139148,
    "predict_company_number": 3903,
    "predict_company_precision": 0.5102088711570054,
    "predict_company_recall": 0.5570074301819113,
    "predict_currency_f1": 0.6311377245508981,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.6050516647531573,
    "predict_currency_recall": 0.6595744680851063,
    "predict_director_f1": 0.5332211942809083,
    "predict_director_number": 554,
    "predict_director_precision": 0.49921259842519683,
    "predict_director_recall": 0.572202166064982,
    "predict_disaster_f1": 0.32671081677704195,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.3008130081300813,
    "predict_disaster_recall": 0.357487922705314,
    "predict_disease_f1": 0.4994272623138603,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.43775100401606426,
    "predict_disease_recall": 0.5813333333333334,
    "predict_education_f1": 0.6513636363636363,
    "predict_education_number": 2082,
    "predict_education_precision": 0.6182053494391717,
    "predict_education_recall": 0.6882804995196926,
    "predict_educationaldegree_f1": 0.38992332968236587,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.326007326007326,
    "predict_educationaldegree_recall": 0.48501362397820164,
    "predict_election_f1": 0.22767857142857145,
    "predict_election_number": 184,
    "predict_election_precision": 0.19318181818181818,
    "predict_election_recall": 0.27717391304347827,
    "predict_film_f1": 0.59254327563249,
    "predict_film_number": 759,
    "predict_film_precision": 0.5989232839838493,
    "predict_film_recall": 0.5862977602108037,
    "predict_food_f1": 0.40793825799338473,
    "predict_food_number": 432,
    "predict_food_precision": 0.3894736842105263,
    "predict_food_recall": 0.42824074074074076,
    "predict_game_f1": 0.5326424870466322,
    "predict_game_number": 496,
    "predict_game_precision": 0.5479744136460555,
    "predict_game_recall": 0.5181451612903226,
    "predict_god_f1": 0.5348646431501232,
    "predict_god_number": 635,
    "predict_god_precision": 0.5582191780821918,
    "predict_god_recall": 0.5133858267716536,
    "predict_government/governmentagency_f1": 0.3069367710251688,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.2901915264074289,
    "predict_government/governmentagency_recall": 0.3257328990228013,
    "predict_hospital_f1": 0.5689655172413792,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.515625,
    "predict_hospital_recall": 0.6346153846153846,
    "predict_hotel_f1": 0.5147540983606558,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.45507246376811594,
    "predict_hotel_recall": 0.5924528301886792,
    "predict_island_f1": 0.49605055292259087,
    "predict_island_number": 646,
    "predict_island_precision": 0.5064516129032258,
    "predict_island_recall": 0.48606811145510836,
    "predict_language_f1": 0.6023809523809524,
    "predict_language_number": 753,
    "predict_language_precision": 0.5458468176914779,
    "predict_language_recall": 0.6719787516600265,
    "predict_law_f1": 0.4527027027027027,
    "predict_law_number": 488,
    "predict_law_precision": 0.3850574712643678,
    "predict_law_recall": 0.5491803278688525,
    "predict_library_f1": 0.547945205479452,
    "predict_library_number": 357,
    "predict_library_precision": 0.4624277456647399,
    "predict_library_recall": 0.6722689075630253,
    "predict_livingthing_f1": 0.4626334519572954,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.4128856624319419,
    "predict_livingthing_recall": 0.5260115606936416,
    "predict_loss": 0.6523258090019226,
    "predict_media/newspaper_f1": 0.4672974084738791,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.47451963241436923,
    "predict_media/newspaper_recall": 0.46029173419773095,
    "predict_medical_f1": 0.3174061433447099,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.49206349206349204,
    "predict_medical_recall": 0.23425692695214106,
    "predict_mountain_f1": 0.5896122896854427,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.5874635568513119,
    "predict_mountain_recall": 0.591776798825257,
    "predict_music_f1": 0.6137566137566137,
    "predict_music_number": 1041,
    "predict_music_precision": 0.6146435452793835,
    "predict_music_recall": 0.6128722382324687,
    "predict_other_f1": 0.45088510170423307,
    "predict_other_number": 21035,
    "predict_other_precision": 0.4194762684124386,
    "predict_other_recall": 0.487378179225101,
    "predict_overall_accuracy": 0.9021566596529628,
    "predict_overall_f1": 0.5630326643632532,
    "predict_overall_precision": 0.5360745849392924,
    "predict_overall_recall": 0.59284564257111,
    "predict_painting_f1": 0.16279069767441862,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.25,
    "predict_painting_recall": 0.1206896551724138,
    "predict_park_f1": 0.4142259414225941,
    "predict_park_number": 458,
    "predict_park_precision": 0.39759036144578314,
    "predict_park_recall": 0.43231441048034935,
    "predict_politicalparty_f1": 0.5298996071584461,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.49189627228525123,
    "predict_politicalparty_recall": 0.5742667928098392,
    "predict_politician_f1": 0.5527086383601756,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5796545105566219,
    "predict_politician_recall": 0.5281566981462049,
    "predict_protest_f1": 0.19759036144578312,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.1646586345381526,
    "predict_protest_recall": 0.2469879518072289,
    "predict_religion_f1": 0.4072910119421747,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.3540983606557377,
    "predict_religion_recall": 0.47928994082840237,
    "predict_restaurant_f1": 0.3221476510067114,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.33488372093023255,
    "predict_restaurant_recall": 0.3103448275862069,
    "predict_road/railway/highway/transit_f1": 0.5817987723512144,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.5330073349633252,
    "predict_road/railway/highway/transit_recall": 0.6404230317273796,
    "predict_runtime": 271.6614,
    "predict_samples_per_second": 138.581,
    "predict_scholar_f1": 0.3088235294117647,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.34035656401944897,
    "predict_scholar_recall": 0.28263795423956933,
    "predict_ship_f1": 0.5023584905660378,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.4551282051282051,
    "predict_ship_recall": 0.5605263157894737,
    "predict_showorganization_f1": 0.4180327868852459,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.4409221902017291,
    "predict_showorganization_recall": 0.3974025974025974,
    "predict_software_f1": 0.43122676579925645,
    "predict_software_number": 889,
    "predict_software_precision": 0.48,
    "predict_software_recall": 0.3914510686164229,
    "predict_soldier_f1": 0.3639097744360903,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.35431918008784774,
    "predict_soldier_recall": 0.3740340030911901,
    "predict_sportsevent_f1": 0.42751260005929437,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.40033314825097166,
    "predict_sportsevent_recall": 0.4586513994910941,
    "predict_sportsfacility_f1": 0.5458207452165156,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.47294938917975565,
    "predict_sportsfacility_recall": 0.6452380952380953,
    "predict_sportsleague_f1": 0.4764764764764765,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.4276729559748428,
    "predict_sportsleague_recall": 0.5378531073446328,
    "predict_sportsteam_f1": 0.6396521051591223,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.6266460108443067,
    "predict_sportsteam_recall": 0.6532095276544206,
    "predict_steps_per_second": 4.333,
    "predict_theater_f1": 0.6115183246073298,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.5851703406813628,
    "predict_theater_recall": 0.6403508771929824,
    "predict_train_f1": 0.4090305444887118,
    "predict_train_number": 314,
    "predict_train_precision": 0.35079726651480636,
    "predict_train_recall": 0.49044585987261147,
    "predict_weapon_f1": 0.3964444444444445,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.446,
    "predict_weapon_recall": 0.3568,
    "predict_writtenart_f1": 0.44628784736623806,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.39013778100072516,
    "predict_writtenart_recall": 0.5213178294573644
}