{
    "predict_GPE_f1": 0.7884150873281308,
    "predict_GPE_number": 20409,
    "predict_GPE_precision": 0.7494590895041285,
    "predict_GPE_recall": 0.8316429026409917,
    "predict_actor_f1": 0.6941541937305845,
    "predict_actor_number": 1638,
    "predict_actor_precision": 0.6458223857067787,
    "predict_actor_recall": 0.7503052503052503,
    "predict_airplane_f1": 0.52964824120603,
    "predict_airplane_number": 794,
    "predict_airplane_precision": 0.4406354515050167,
    "predict_airplane_recall": 0.663727959697733,
    "predict_airport_f1": 0.6960486322188448,
    "predict_airport_number": 364,
    "predict_airport_precision": 0.7789115646258503,
    "predict_airport_recall": 0.6291208791208791,
    "predict_artist/author_f1": 0.6016091357383857,
    "predict_artist/author_number": 3464,
    "predict_artist/author_precision": 0.5464403583215465,
    "predict_artist/author_recall": 0.6691685912240185,
    "predict_astronomything_f1": 0.49811320754716976,
    "predict_astronomything_number": 678,
    "predict_astronomything_precision": 0.6910994764397905,
    "predict_astronomything_recall": 0.3893805309734513,
    "predict_athlete_f1": 0.7918300653594771,
    "predict_athlete_number": 2907,
    "predict_athlete_precision": 0.7541238717709305,
    "predict_athlete_recall": 0.8335053319573443,
    "predict_attack/battle/war/militaryconflict_f1": 0.60734149054505,
    "predict_attack/battle/war/militaryconflict_number": 1099,
    "predict_attack/battle/war/militaryconflict_precision": 0.5125156445556946,
    "predict_attack/battle/war/militaryconflict_recall": 0.7452229299363057,
    "predict_award_f1": 0.46418338108882523,
    "predict_award_number": 941,
    "predict_award_precision": 0.4215091066782307,
    "predict_award_recall": 0.5164718384697131,
    "predict_biologything_f1": 0.5098732684939582,
    "predict_biologything_number": 1875,
    "predict_biologything_precision": 0.569828722002635,
    "predict_biologything_recall": 0.4613333333333333,
    "predict_bodiesofwater_f1": 0.6302748741773133,
    "predict_bodiesofwater_number": 1169,
    "predict_bodiesofwater_precision": 0.5756718528995757,
    "predict_bodiesofwater_recall": 0.6963216424294268,
    "predict_broadcastprogram_f1": 0.440536013400335,
    "predict_broadcastprogram_number": 605,
    "predict_broadcastprogram_precision": 0.4465195246179966,
    "predict_broadcastprogram_recall": 0.43471074380165287,
    "predict_car_f1": 0.6425992779783393,
    "predict_car_number": 688,
    "predict_car_precision": 0.6384505021520803,
    "predict_car_recall": 0.6468023255813954,
    "predict_chemicalthing_f1": 0.46351931330472107,
    "predict_chemicalthing_number": 1014,
    "predict_chemicalthing_precision": 0.36363636363636365,
    "predict_chemicalthing_recall": 0.6390532544378699,
    "predict_company_f1": 0.6210411357844923,
    "predict_company_number": 3903,
    "predict_company_precision": 0.5899031811894883,
    "predict_company_recall": 0.6556495003843198,
    "predict_currency_f1": 0.6370918052988294,
    "predict_currency_number": 799,
    "predict_currency_precision": 0.6274271844660194,
    "predict_currency_recall": 0.6470588235294118,
    "predict_director_f1": 0.09032258064516129,
    "predict_director_number": 554,
    "predict_director_precision": 0.42424242424242425,
    "predict_director_recall": 0.05054151624548736,
    "predict_disaster_f1": 0.05785123966942148,
    "predict_disaster_number": 207,
    "predict_disaster_precision": 0.2,
    "predict_disaster_recall": 0.033816425120772944,
    "predict_disease_f1": 0.5144855144855145,
    "predict_disease_number": 750,
    "predict_disease_precision": 0.41134185303514376,
    "predict_disease_recall": 0.6866666666666666,
    "predict_education_f1": 0.7269040108156828,
    "predict_education_number": 2082,
    "predict_education_precision": 0.684634974533107,
    "predict_education_recall": 0.7747358309317963,
    "predict_educationaldegree_f1": 0.4302600472813239,
    "predict_educationaldegree_number": 367,
    "predict_educationaldegree_precision": 0.37995824634655534,
    "predict_educationaldegree_recall": 0.49591280653950953,
    "predict_election_f1": 0.15789473684210525,
    "predict_election_number": 184,
    "predict_election_precision": 0.15306122448979592,
    "predict_election_recall": 0.16304347826086957,
    "predict_film_f1": 0.5537493445201888,
    "predict_film_number": 759,
    "predict_film_precision": 0.45993031358885017,
    "predict_film_recall": 0.6956521739130435,
    "predict_food_f1": 0.25356576862123614,
    "predict_food_number": 432,
    "predict_food_precision": 0.4020100502512563,
    "predict_food_recall": 0.18518518518518517,
    "predict_game_f1": 0.6071428571428571,
    "predict_game_number": 496,
    "predict_game_precision": 0.68,
    "predict_game_recall": 0.5483870967741935,
    "predict_god_f1": 0.054878048780487805,
    "predict_god_number": 635,
    "predict_god_precision": 0.8571428571428571,
    "predict_god_recall": 0.028346456692913385,
    "predict_government/governmentagency_f1": 0.31145717463848727,
    "predict_government/governmentagency_number": 1535,
    "predict_government/governmentagency_precision": 0.3614457831325301,
    "predict_government/governmentagency_recall": 0.2736156351791531,
    "predict_hospital_f1": 0.6962025316455696,
    "predict_hospital_number": 364,
    "predict_hospital_precision": 0.6455399061032864,
    "predict_hospital_recall": 0.7554945054945055,
    "predict_hotel_f1": 0.5037037037037038,
    "predict_hotel_number": 265,
    "predict_hotel_precision": 0.7285714285714285,
    "predict_hotel_recall": 0.3849056603773585,
    "predict_island_f1": 0.48085485307212816,
    "predict_island_number": 646,
    "predict_island_precision": 0.5660377358490566,
    "predict_island_recall": 0.4179566563467492,
    "predict_language_f1": 0.5382963493199714,
    "predict_language_number": 753,
    "predict_language_precision": 0.5838509316770186,
    "predict_language_recall": 0.49933598937583,
    "predict_law_f1": 0.5079928952042629,
    "predict_law_number": 488,
    "predict_law_precision": 0.4482758620689655,
    "predict_law_recall": 0.5860655737704918,
    "predict_library_f1": 0.035443037974683546,
    "predict_library_number": 357,
    "predict_library_precision": 0.18421052631578946,
    "predict_library_recall": 0.0196078431372549,
    "predict_livingthing_f1": 0.4635241301907968,
    "predict_livingthing_number": 865,
    "predict_livingthing_precision": 0.45038167938931295,
    "predict_livingthing_recall": 0.4774566473988439,
    "predict_loss": 0.37406134605407715,
    "predict_media/newspaper_f1": 0.5903859174001355,
    "predict_media/newspaper_number": 1234,
    "predict_media/newspaper_precision": 0.5069767441860465,
    "predict_media/newspaper_recall": 0.706645056726094,
    "predict_medical_f1": 0.0,
    "predict_medical_number": 397,
    "predict_medical_precision": 0.0,
    "predict_medical_recall": 0.0,
    "predict_mountain_f1": 0.5714285714285715,
    "predict_mountain_number": 681,
    "predict_mountain_precision": 0.6138279932546374,
    "predict_mountain_recall": 0.5345080763582967,
    "predict_music_f1": 0.6701974000962927,
    "predict_music_number": 1041,
    "predict_music_precision": 0.6718146718146718,
    "predict_music_recall": 0.6685878962536023,
    "predict_other_f1": 0.5068532840045465,
    "predict_other_number": 21035,
    "predict_other_precision": 0.4770915498867165,
    "predict_other_recall": 0.5405752317565962,
    "predict_overall_accuracy": 0.9074473375068128,
    "predict_overall_f1": 0.5960915945377941,
    "predict_overall_precision": 0.5759725136180779,
    "predict_overall_recall": 0.6176670932584734,
    "predict_painting_f1": 0.0,
    "predict_painting_number": 58,
    "predict_painting_precision": 0.0,
    "predict_painting_recall": 0.0,
    "predict_park_f1": 0.0,
    "predict_park_number": 458,
    "predict_park_precision": 0.0,
    "predict_park_recall": 0.0,
    "predict_politicalparty_f1": 0.5877829987184964,
    "predict_politicalparty_number": 1057,
    "predict_politicalparty_precision": 0.5358255451713395,
    "predict_politicalparty_recall": 0.6508987701040682,
    "predict_politician_f1": 0.5969738651994498,
    "predict_politician_number": 2859,
    "predict_politician_precision": 0.5870815015218126,
    "predict_politician_recall": 0.6072053165442463,
    "predict_protest_f1": 0.0,
    "predict_protest_number": 166,
    "predict_protest_precision": 0.0,
    "predict_protest_recall": 0.0,
    "predict_religion_f1": 0.4584763212079616,
    "predict_religion_number": 676,
    "predict_religion_precision": 0.42765685019206146,
    "predict_religion_recall": 0.4940828402366864,
    "predict_restaurant_f1": 0.0,
    "predict_restaurant_number": 232,
    "predict_restaurant_precision": 0.0,
    "predict_restaurant_recall": 0.0,
    "predict_road/railway/highway/transit_f1": 0.6224268689057422,
    "predict_road/railway/highway/transit_number": 1702,
    "predict_road/railway/highway/transit_precision": 0.5773869346733669,
    "predict_road/railway/highway/transit_recall": 0.6750881316098707,
    "predict_runtime": 267.6307,
    "predict_samples_per_second": 140.668,
    "predict_scholar_f1": 0.0,
    "predict_scholar_number": 743,
    "predict_scholar_precision": 0.0,
    "predict_scholar_recall": 0.0,
    "predict_ship_f1": 0.4292845257903495,
    "predict_ship_number": 380,
    "predict_ship_precision": 0.583710407239819,
    "predict_ship_recall": 0.3394736842105263,
    "predict_showorganization_f1": 0.4533333333333333,
    "predict_showorganization_number": 770,
    "predict_showorganization_precision": 0.4094240837696335,
    "predict_showorganization_recall": 0.5077922077922078,
    "predict_software_f1": 0.5507900677200903,
    "predict_software_number": 889,
    "predict_software_precision": 0.5526613816534541,
    "predict_software_recall": 0.5489313835770528,
    "predict_soldier_f1": 0.02962962962962963,
    "predict_soldier_number": 647,
    "predict_soldier_precision": 0.35714285714285715,
    "predict_soldier_recall": 0.015455950540958269,
    "predict_sportsevent_f1": 0.5102739726027398,
    "predict_sportsevent_number": 1572,
    "predict_sportsevent_precision": 0.46273291925465837,
    "predict_sportsevent_recall": 0.5687022900763359,
    "predict_sportsfacility_f1": 0.6186612576064909,
    "predict_sportsfacility_number": 420,
    "predict_sportsfacility_precision": 0.5388692579505301,
    "predict_sportsfacility_recall": 0.7261904761904762,
    "predict_sportsleague_f1": 0.550113895216401,
    "predict_sportsleague_number": 885,
    "predict_sportsleague_precision": 0.5545350172215844,
    "predict_sportsleague_recall": 0.5457627118644067,
    "predict_sportsteam_f1": 0.6807142857142857,
    "predict_sportsteam_number": 2477,
    "predict_sportsteam_precision": 0.6103105987832212,
    "predict_sportsteam_recall": 0.7694792087202261,
    "predict_steps_per_second": 4.398,
    "predict_theater_f1": 0.6626139817629179,
    "predict_theater_number": 456,
    "predict_theater_precision": 0.615819209039548,
    "predict_theater_recall": 0.7171052631578947,
    "predict_train_f1": 0.4158415841584158,
    "predict_train_number": 314,
    "predict_train_precision": 0.37404580152671757,
    "predict_train_recall": 0.4681528662420382,
    "predict_weapon_f1": 0.41467889908256883,
    "predict_weapon_number": 625,
    "predict_weapon_precision": 0.4860215053763441,
    "predict_weapon_recall": 0.3616,
    "predict_writtenart_f1": 0.4433291509828523,
    "predict_writtenart_number": 1032,
    "predict_writtenart_precision": 0.3899926416482708,
    "predict_writtenart_recall": 0.5135658914728682
}